{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#display everything \n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('train.csv', encoding='utf-8')\n",
    "test = pd.read_csv('test.csv', encoding='utf-8')\n",
    "submission = pd.read_csv('sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((54273, 13), (36183, 12), (36183, 2))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape, test.shape, submission.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id              0\n",
       "brand           0\n",
       "model           0\n",
       "model_year      0\n",
       "milage          0\n",
       "fuel_type       0\n",
       "engine          0\n",
       "transmission    0\n",
       "ext_col         0\n",
       "int_col         0\n",
       "accident        0\n",
       "clean_title     0\n",
       "price           0\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "id              0\n",
       "brand           0\n",
       "model           0\n",
       "model_year      0\n",
       "milage          0\n",
       "fuel_type       0\n",
       "engine          0\n",
       "transmission    0\n",
       "ext_col         0\n",
       "int_col         0\n",
       "accident        0\n",
       "clean_title     0\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(train.isna().sum())\n",
    "display(test.isna().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above, we can see that there are no missing values in both the training and testing datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>brand</th>\n",
       "      <th>model</th>\n",
       "      <th>model_year</th>\n",
       "      <th>milage</th>\n",
       "      <th>fuel_type</th>\n",
       "      <th>engine</th>\n",
       "      <th>transmission</th>\n",
       "      <th>ext_col</th>\n",
       "      <th>int_col</th>\n",
       "      <th>accident</th>\n",
       "      <th>clean_title</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Ford</td>\n",
       "      <td>F-150 Lariat</td>\n",
       "      <td>2018</td>\n",
       "      <td>74349</td>\n",
       "      <td>Gasoline</td>\n",
       "      <td>375.0HP 3.5L V6 Cylinder Engine Gasoline Fuel</td>\n",
       "      <td>10-Speed A/T</td>\n",
       "      <td>Blue</td>\n",
       "      <td>Gray</td>\n",
       "      <td>None reported</td>\n",
       "      <td>Yes</td>\n",
       "      <td>11000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>BMW</td>\n",
       "      <td>335 i</td>\n",
       "      <td>2007</td>\n",
       "      <td>80000</td>\n",
       "      <td>Gasoline</td>\n",
       "      <td>300.0HP 3.0L Straight 6 Cylinder Engine Gasoli...</td>\n",
       "      <td>6-Speed M/T</td>\n",
       "      <td>Black</td>\n",
       "      <td>Black</td>\n",
       "      <td>None reported</td>\n",
       "      <td>Yes</td>\n",
       "      <td>8250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Jaguar</td>\n",
       "      <td>XF Luxury</td>\n",
       "      <td>2009</td>\n",
       "      <td>91491</td>\n",
       "      <td>Gasoline</td>\n",
       "      <td>300.0HP 4.2L 8 Cylinder Engine Gasoline Fuel</td>\n",
       "      <td>6-Speed A/T</td>\n",
       "      <td>Purple</td>\n",
       "      <td>Beige</td>\n",
       "      <td>None reported</td>\n",
       "      <td>Yes</td>\n",
       "      <td>15000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>BMW</td>\n",
       "      <td>X7 xDrive40i</td>\n",
       "      <td>2022</td>\n",
       "      <td>2437</td>\n",
       "      <td>Hybrid</td>\n",
       "      <td>335.0HP 3.0L Straight 6 Cylinder Engine Gasoli...</td>\n",
       "      <td>Transmission w/Dual Shift Mode</td>\n",
       "      <td>Gray</td>\n",
       "      <td>Brown</td>\n",
       "      <td>None reported</td>\n",
       "      <td>Yes</td>\n",
       "      <td>63500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Pontiac</td>\n",
       "      <td>Firebird Base</td>\n",
       "      <td>2001</td>\n",
       "      <td>111000</td>\n",
       "      <td>Gasoline</td>\n",
       "      <td>200.0HP 3.8L V6 Cylinder Engine Gasoline Fuel</td>\n",
       "      <td>A/T</td>\n",
       "      <td>White</td>\n",
       "      <td>Black</td>\n",
       "      <td>None reported</td>\n",
       "      <td>Yes</td>\n",
       "      <td>7850</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id    brand          model  model_year  milage fuel_type  \\\n",
       "0   0     Ford   F-150 Lariat        2018   74349  Gasoline   \n",
       "1   1      BMW          335 i        2007   80000  Gasoline   \n",
       "2   2   Jaguar      XF Luxury        2009   91491  Gasoline   \n",
       "3   3      BMW   X7 xDrive40i        2022    2437    Hybrid   \n",
       "4   4  Pontiac  Firebird Base        2001  111000  Gasoline   \n",
       "\n",
       "                                              engine  \\\n",
       "0      375.0HP 3.5L V6 Cylinder Engine Gasoline Fuel   \n",
       "1  300.0HP 3.0L Straight 6 Cylinder Engine Gasoli...   \n",
       "2       300.0HP 4.2L 8 Cylinder Engine Gasoline Fuel   \n",
       "3  335.0HP 3.0L Straight 6 Cylinder Engine Gasoli...   \n",
       "4      200.0HP 3.8L V6 Cylinder Engine Gasoline Fuel   \n",
       "\n",
       "                     transmission ext_col int_col       accident clean_title  \\\n",
       "0                    10-Speed A/T    Blue    Gray  None reported         Yes   \n",
       "1                     6-Speed M/T   Black   Black  None reported         Yes   \n",
       "2                     6-Speed A/T  Purple   Beige  None reported         Yes   \n",
       "3  Transmission w/Dual Shift Mode    Gray   Brown  None reported         Yes   \n",
       "4                             A/T   White   Black  None reported         Yes   \n",
       "\n",
       "   price  \n",
       "0  11000  \n",
       "1   8250  \n",
       "2  15000  \n",
       "3  63500  \n",
       "4   7850  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>brand</th>\n",
       "      <th>model</th>\n",
       "      <th>model_year</th>\n",
       "      <th>milage</th>\n",
       "      <th>fuel_type</th>\n",
       "      <th>engine</th>\n",
       "      <th>transmission</th>\n",
       "      <th>ext_col</th>\n",
       "      <th>int_col</th>\n",
       "      <th>accident</th>\n",
       "      <th>clean_title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>54273</td>\n",
       "      <td>Mercedes-Benz</td>\n",
       "      <td>E-Class E 350</td>\n",
       "      <td>2014</td>\n",
       "      <td>73000</td>\n",
       "      <td>Gasoline</td>\n",
       "      <td>302.0HP 3.5L V6 Cylinder Engine Gasoline Fuel</td>\n",
       "      <td>A/T</td>\n",
       "      <td>White</td>\n",
       "      <td>Beige</td>\n",
       "      <td>None reported</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>54274</td>\n",
       "      <td>Lexus</td>\n",
       "      <td>RX 350 Base</td>\n",
       "      <td>2015</td>\n",
       "      <td>128032</td>\n",
       "      <td>Gasoline</td>\n",
       "      <td>275.0HP 3.5L V6 Cylinder Engine Gasoline Fuel</td>\n",
       "      <td>8-Speed A/T</td>\n",
       "      <td>Silver</td>\n",
       "      <td>Black</td>\n",
       "      <td>None reported</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>54275</td>\n",
       "      <td>Mercedes-Benz</td>\n",
       "      <td>C-Class C 300</td>\n",
       "      <td>2015</td>\n",
       "      <td>51983</td>\n",
       "      <td>Gasoline</td>\n",
       "      <td>241.0HP 2.0L 4 Cylinder Engine Gasoline Fuel</td>\n",
       "      <td>7-Speed A/T</td>\n",
       "      <td>Blue</td>\n",
       "      <td>White</td>\n",
       "      <td>None reported</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>54276</td>\n",
       "      <td>Land</td>\n",
       "      <td>Rover Range Rover 5.0L Supercharged Autobiogra...</td>\n",
       "      <td>2018</td>\n",
       "      <td>29500</td>\n",
       "      <td>Gasoline</td>\n",
       "      <td>518.0HP 5.0L 8 Cylinder Engine Gasoline Fuel</td>\n",
       "      <td>Transmission w/Dual Shift Mode</td>\n",
       "      <td>White</td>\n",
       "      <td>White</td>\n",
       "      <td>At least 1 accident or damage reported</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>54277</td>\n",
       "      <td>BMW</td>\n",
       "      <td>X6 xDrive40i</td>\n",
       "      <td>2020</td>\n",
       "      <td>90000</td>\n",
       "      <td>Gasoline</td>\n",
       "      <td>335.0HP 3.0L Straight 6 Cylinder Engine Gasoli...</td>\n",
       "      <td>8-Speed A/T</td>\n",
       "      <td>White</td>\n",
       "      <td>Black</td>\n",
       "      <td>At least 1 accident or damage reported</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id          brand                                              model  \\\n",
       "0  54273  Mercedes-Benz                                      E-Class E 350   \n",
       "1  54274          Lexus                                        RX 350 Base   \n",
       "2  54275  Mercedes-Benz                                      C-Class C 300   \n",
       "3  54276           Land  Rover Range Rover 5.0L Supercharged Autobiogra...   \n",
       "4  54277            BMW                                       X6 xDrive40i   \n",
       "\n",
       "   model_year  milage fuel_type  \\\n",
       "0        2014   73000  Gasoline   \n",
       "1        2015  128032  Gasoline   \n",
       "2        2015   51983  Gasoline   \n",
       "3        2018   29500  Gasoline   \n",
       "4        2020   90000  Gasoline   \n",
       "\n",
       "                                              engine  \\\n",
       "0      302.0HP 3.5L V6 Cylinder Engine Gasoline Fuel   \n",
       "1      275.0HP 3.5L V6 Cylinder Engine Gasoline Fuel   \n",
       "2       241.0HP 2.0L 4 Cylinder Engine Gasoline Fuel   \n",
       "3       518.0HP 5.0L 8 Cylinder Engine Gasoline Fuel   \n",
       "4  335.0HP 3.0L Straight 6 Cylinder Engine Gasoli...   \n",
       "\n",
       "                     transmission ext_col int_col  \\\n",
       "0                             A/T   White   Beige   \n",
       "1                     8-Speed A/T  Silver   Black   \n",
       "2                     7-Speed A/T    Blue   White   \n",
       "3  Transmission w/Dual Shift Mode   White   White   \n",
       "4                     8-Speed A/T   White   Black   \n",
       "\n",
       "                                 accident clean_title  \n",
       "0                           None reported         Yes  \n",
       "1                           None reported         Yes  \n",
       "2                           None reported         Yes  \n",
       "3  At least 1 accident or damage reported         Yes  \n",
       "4  At least 1 accident or damage reported         Yes  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(train.head())\n",
    "display(test.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handling color variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to combine small categories\n",
    "def combine_small_categories(df, column, threshold=0.01):\n",
    "    counts = df[column].value_counts(normalize=True)\n",
    "    small_categories = counts[counts < threshold].index\n",
    "    df[column] = df[column].apply(lambda x: 'Other' if x in small_categories else x)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the function to each categorical column\n",
    "categorical_columns = ['ext_col', 'int_col']\n",
    "for col in categorical_columns:\n",
    "    train = combine_small_categories(train, col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the function to each categorical column\n",
    "categorical_columns = ['ext_col', 'int_col']\n",
    "for col in categorical_columns:\n",
    "    test = combine_small_categories(test, col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ext_col\n",
       "Black     15078\n",
       "White     13422\n",
       "Gray       7909\n",
       "Silver     5161\n",
       "Blue       4668\n",
       "Other      4259\n",
       "Red        3013\n",
       "Green       763\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['ext_col'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to combine values\n",
    "def combine_values(df, col, replace_value='Other'):\n",
    "    df[col] = df[col].replace(['–', '-', '_'], replace_value)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply function to DataFrame\n",
    "train = combine_values(train, 'int_col')\n",
    "test = combine_values(test, 'int_col')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "int_col\n",
       "Black    21122\n",
       "Beige     5468\n",
       "Gray      4303\n",
       "Other     2128\n",
       "Brown     1333\n",
       "Red       1059\n",
       "White      770\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test['int_col'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Working on the engine variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def extract_horsepower(engine_description):\n",
    "  match = re.search(r\"(\\d+)\\.0HP\", engine_description)\n",
    "  if match:\n",
    "    return float(match.group(1))  \n",
    "  else:\n",
    "    return None  # Handle missing values\n",
    "\n",
    "train[\"horsepower\"] = train[\"engine\"].apply(extract_horsepower)\n",
    "test[\"horsepower\"] = test[\"engine\"].apply(extract_horsepower)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def extract_displacement(engine_description):\n",
    "    match = re.search(r\"(\\d+\\.\\d+L)\", engine_description)\n",
    "    if match:\n",
    "        # Extract the numeric part and convert it to a float\n",
    "        return float(match.group(1).replace('L', ''))\n",
    "    else:\n",
    "        return None  # Handle missing values\n",
    "\n",
    "# Assuming 'train' is your DataFrame and 'engine' is the column containing engine descriptions\n",
    "train[\"displacement_value\"] = train[\"engine\"].apply(extract_displacement)\n",
    "test[\"displacement_value\"] = test[\"engine\"].apply(extract_displacement)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def extract_engine_type(engine_description):\n",
    "    # Regex to match engine type after displacement and before fuel type\n",
    "    match = re.search(r\"\\b\\d\\.\\dL\\s(.*?Engine)\\b\", engine_description)\n",
    "    if match:\n",
    "        return match.group(1)\n",
    "    else:\n",
    "        return None  # Handle missing values\n",
    "train[\"engine_type\"] = train[\"engine\"].apply(extract_engine_type)\n",
    "test[\"engine_type\"] = test[\"engine\"].apply(extract_engine_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def extract_fuel_type(engine_description):\n",
    "    # Regex to match the fuel type at the end of the description\n",
    "    match = re.search(r\"(Gasoline Fuel|Diesel Fuel|Electric Fuel System|Hybrid|Gasoline/Mild Electric Hybrid|Flex Fuel Capability)\", engine_description)\n",
    "    if match:\n",
    "        return match.group(1)\n",
    "    else:\n",
    "        return None  # Handle missing values\n",
    "train[\"fuel_type\"] = train[\"engine\"].apply(extract_fuel_type)\n",
    "test[\"fuel_type\"] = test[\"engine\"].apply(extract_fuel_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>brand</th>\n",
       "      <th>model</th>\n",
       "      <th>model_year</th>\n",
       "      <th>milage</th>\n",
       "      <th>fuel_type</th>\n",
       "      <th>engine</th>\n",
       "      <th>transmission</th>\n",
       "      <th>ext_col</th>\n",
       "      <th>int_col</th>\n",
       "      <th>accident</th>\n",
       "      <th>clean_title</th>\n",
       "      <th>price</th>\n",
       "      <th>horsepower</th>\n",
       "      <th>displacement_value</th>\n",
       "      <th>engine_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Ford</td>\n",
       "      <td>F-150 Lariat</td>\n",
       "      <td>2018</td>\n",
       "      <td>74349</td>\n",
       "      <td>Gasoline Fuel</td>\n",
       "      <td>375.0HP 3.5L V6 Cylinder Engine Gasoline Fuel</td>\n",
       "      <td>10-Speed A/T</td>\n",
       "      <td>Blue</td>\n",
       "      <td>Gray</td>\n",
       "      <td>None reported</td>\n",
       "      <td>Yes</td>\n",
       "      <td>11000</td>\n",
       "      <td>375.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>V6 Cylinder Engine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>BMW</td>\n",
       "      <td>335 i</td>\n",
       "      <td>2007</td>\n",
       "      <td>80000</td>\n",
       "      <td>Gasoline Fuel</td>\n",
       "      <td>300.0HP 3.0L Straight 6 Cylinder Engine Gasoli...</td>\n",
       "      <td>6-Speed M/T</td>\n",
       "      <td>Black</td>\n",
       "      <td>Black</td>\n",
       "      <td>None reported</td>\n",
       "      <td>Yes</td>\n",
       "      <td>8250</td>\n",
       "      <td>300.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Straight 6 Cylinder Engine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Jaguar</td>\n",
       "      <td>XF Luxury</td>\n",
       "      <td>2009</td>\n",
       "      <td>91491</td>\n",
       "      <td>Gasoline Fuel</td>\n",
       "      <td>300.0HP 4.2L 8 Cylinder Engine Gasoline Fuel</td>\n",
       "      <td>6-Speed A/T</td>\n",
       "      <td>Other</td>\n",
       "      <td>Beige</td>\n",
       "      <td>None reported</td>\n",
       "      <td>Yes</td>\n",
       "      <td>15000</td>\n",
       "      <td>300.0</td>\n",
       "      <td>4.2</td>\n",
       "      <td>8 Cylinder Engine</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id   brand         model  model_year  milage      fuel_type  \\\n",
       "0   0    Ford  F-150 Lariat        2018   74349  Gasoline Fuel   \n",
       "1   1     BMW         335 i        2007   80000  Gasoline Fuel   \n",
       "2   2  Jaguar     XF Luxury        2009   91491  Gasoline Fuel   \n",
       "\n",
       "                                              engine  transmission ext_col  \\\n",
       "0      375.0HP 3.5L V6 Cylinder Engine Gasoline Fuel  10-Speed A/T    Blue   \n",
       "1  300.0HP 3.0L Straight 6 Cylinder Engine Gasoli...   6-Speed M/T   Black   \n",
       "2       300.0HP 4.2L 8 Cylinder Engine Gasoline Fuel   6-Speed A/T   Other   \n",
       "\n",
       "  int_col       accident clean_title  price  horsepower  displacement_value  \\\n",
       "0    Gray  None reported         Yes  11000       375.0                 3.5   \n",
       "1   Black  None reported         Yes   8250       300.0                 3.0   \n",
       "2   Beige  None reported         Yes  15000       300.0                 4.2   \n",
       "\n",
       "                  engine_type  \n",
       "0          V6 Cylinder Engine  \n",
       "1  Straight 6 Cylinder Engine  \n",
       "2           8 Cylinder Engine  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dealing with brand variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Grouping the car brands\n",
    "brand_categories = {\n",
    "    'performance_sports': [\n",
    "        'Chevrolet', 'BMW', 'Porsche', 'Lamborghini',\n",
    "        'Pontiac', 'Lotus'\n",
    "    ],\n",
    "    \n",
    "    'luxury_luxury_EV': [\n",
    "        'Mercedes-Benz', 'Audi', 'Maserati', 'Cadillac',\n",
    "        'Volvo', 'Tesla', 'Jaguar', 'Rolls-Royce', 'Aston',\n",
    "        'Ferrari', 'Bentley', 'Acura', 'Lexus', 'Lincoln',\n",
    "        'Hummer', 'Genesis', 'Land', 'Buick', 'INFINITI',\n",
    "        'McLaren', 'Alfa', 'Lucid', 'Maybach', 'Bugatti'\n",
    "    ],\n",
    "\n",
    "    'mid_range': [\n",
    "        'Mitsubishi', 'Ford', 'Nissan', 'Toyota', 'Dodge',\n",
    "        'Volkswagen', 'Mazda', 'Chrysler', 'Rivian', 'GMC'\n",
    "    ],\n",
    "\n",
    "    'affordable': [\n",
    "        'Honda', 'Hyundai', 'Subaru', 'Kia',\n",
    "        'Scion', 'Saturn', 'Mercury',\n",
    "        'FIAT', 'Plymouth', 'Suzuki'\n",
    "    ],\n",
    "\n",
    "    'offroad': [\n",
    "        'Jeep', 'RAM', 'MINI'\n",
    "    ]\n",
    "}\n",
    "\n",
    "def assign_brand_group(brand):\n",
    "    for group_name, brands in brand_categories.items():\n",
    "        if brand in brands:\n",
    "            return group_name\n",
    "    return \"Others\"  # Assign to \"Others\" if not found in any defined groups\n",
    "\n",
    "train[\"brand_group\"] = train[\"brand\"].apply(assign_brand_group)\n",
    "test[\"brand_group\"] = test[\"brand\"].apply(assign_brand_group)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handling transmission variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "54268                          8-Speed A/T\n",
       "54269                          6-Speed A/T\n",
       "54270       Transmission w/Dual Shift Mode\n",
       "54271    8-Speed Automatic with Auto-Shift\n",
       "54272                          8-Speed A/T\n",
       "Name: transmission, dtype: object"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['transmission'].tail(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the mapping for each category\n",
    "transmission_mapping = {\n",
    "    'automatic': ['A/T', 'Automatic', 'Automatic CVT', 'Transmission w/Dual Shift Mode', 'Transmission Overdrive Switch',\n",
    "                  'Electronically Controlled Automatic', 'with Overdrive', 'with Auto-Shift', 'DCT Automatic'],\n",
    "    'manual': ['M/T', 'Manual'],\n",
    "    'cvt': ['CVT Transmission', 'CVT-F', 'Variable'],\n",
    "    'dct': ['DCT Automatic'],\n",
    "    'other': ['SCHEDULED FOR OR IN PRODUCTION', '–', 'F']\n",
    "}\n",
    "\n",
    "# Function to categorize the transmission\n",
    "def categorize_transmission(transmission):\n",
    "    transmission = transmission.lower()\n",
    "    if any(keyword.lower() in transmission for keyword in transmission_mapping['automatic']):\n",
    "        return 'automatic'\n",
    "    elif any(keyword.lower() in transmission for keyword in transmission_mapping['manual']):\n",
    "        return 'manual'\n",
    "    elif any(keyword.lower() in transmission for keyword in transmission_mapping['cvt']):\n",
    "        return 'cvt'\n",
    "    elif any(keyword.lower() in transmission for keyword in transmission_mapping['dct']):\n",
    "        return 'dct'\n",
    "    else:\n",
    "        return 'other'\n",
    "\n",
    "# Apply the categorization\n",
    "train['transmission_category'] = train['transmission'].apply(categorize_transmission)\n",
    "test['transmission_category'] = test['transmission'].apply(categorize_transmission)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create boolean features for special characteristics on the training set  \n",
    "train['dual_shift_mode'] = train['transmission'].str.contains('Dual Shift Mode', case=False, na=False).astype(int)\n",
    "train['overdrive'] = train['transmission'].str.contains('Overdrive', case=False, na=False).astype(int)\n",
    "train['auto_shift'] = train['transmission'].str.contains('Auto-Shift', case=False, na=False).astype(int)\n",
    "\n",
    "# Create boolean features for special characteristics on the testing set\n",
    "test['dual_shift_mode'] = test['transmission'].str.contains('Dual Shift Mode', case=False, na=False).astype(int)\n",
    "test['overdrive'] = test['transmission'].str.contains('Overdrive', case=False, na=False).astype(int)\n",
    "test['auto_shift'] = test['transmission'].str.contains('Auto-Shift', case=False, na=False).astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "car_categoricals = ['int_col','ext_col','fuel_type','engine_type',\n",
    "                    'transmission_category','accident','brand_group',]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the function to each categorical column\n",
    "for col in car_categoricals:\n",
    "    train = combine_small_categories(train, col)\n",
    "    test = combine_small_categories(test, col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_drop = ['brand', 'model', 'engine','clean_title', 'id', 'transmission']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.drop(columns=cols_drop, axis=1, inplace=True)\n",
    "test.drop(columns=cols_drop, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 54273 entries, 0 to 54272\n",
      "Data columns (total 15 columns):\n",
      " #   Column                 Non-Null Count  Dtype  \n",
      "---  ------                 --------------  -----  \n",
      " 0   model_year             54273 non-null  int64  \n",
      " 1   milage                 54273 non-null  int64  \n",
      " 2   fuel_type              50120 non-null  object \n",
      " 3   ext_col                54273 non-null  object \n",
      " 4   int_col                54273 non-null  object \n",
      " 5   accident               54273 non-null  object \n",
      " 6   price                  54273 non-null  int64  \n",
      " 7   horsepower             50216 non-null  float64\n",
      " 8   displacement_value     53667 non-null  float64\n",
      " 9   engine_type            50065 non-null  object \n",
      " 10  brand_group            54273 non-null  object \n",
      " 11  transmission_category  54273 non-null  object \n",
      " 12  dual_shift_mode        54273 non-null  int32  \n",
      " 13  overdrive              54273 non-null  int32  \n",
      " 14  auto_shift             54273 non-null  int32  \n",
      "dtypes: float64(2), int32(3), int64(3), object(7)\n",
      "memory usage: 5.6+ MB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 36183 entries, 0 to 36182\n",
      "Data columns (total 14 columns):\n",
      " #   Column                 Non-Null Count  Dtype  \n",
      "---  ------                 --------------  -----  \n",
      " 0   model_year             36183 non-null  int64  \n",
      " 1   milage                 36183 non-null  int64  \n",
      " 2   fuel_type              33485 non-null  object \n",
      " 3   ext_col                36183 non-null  object \n",
      " 4   int_col                36183 non-null  object \n",
      " 5   accident               36183 non-null  object \n",
      " 6   horsepower             33577 non-null  float64\n",
      " 7   displacement_value     35778 non-null  float64\n",
      " 8   engine_type            33451 non-null  object \n",
      " 9   brand_group            36183 non-null  object \n",
      " 10  transmission_category  36183 non-null  object \n",
      " 11  dual_shift_mode        36183 non-null  int32  \n",
      " 12  overdrive              36183 non-null  int32  \n",
      " 13  auto_shift             36183 non-null  int32  \n",
      "dtypes: float64(2), int32(3), int64(2), object(7)\n",
      "memory usage: 3.5+ MB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(train.info())\n",
    "display(test.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count_of_missing_values</th>\n",
       "      <th>%_missing_values</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>engine_type</th>\n",
       "      <td>4208</td>\n",
       "      <td>7.753395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fuel_type</th>\n",
       "      <td>4153</td>\n",
       "      <td>7.652055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>horsepower</th>\n",
       "      <td>4057</td>\n",
       "      <td>7.475172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>displacement_value</th>\n",
       "      <td>606</td>\n",
       "      <td>1.116577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_year</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>milage</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ext_col</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>int_col</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accident</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>price</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>brand_group</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>transmission_category</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dual_shift_mode</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>overdrive</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>auto_shift</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       count_of_missing_values  %_missing_values\n",
       "engine_type                               4208          7.753395\n",
       "fuel_type                                 4153          7.652055\n",
       "horsepower                                4057          7.475172\n",
       "displacement_value                         606          1.116577\n",
       "model_year                                   0          0.000000\n",
       "milage                                       0          0.000000\n",
       "ext_col                                      0          0.000000\n",
       "int_col                                      0          0.000000\n",
       "accident                                     0          0.000000\n",
       "price                                        0          0.000000\n",
       "brand_group                                  0          0.000000\n",
       "transmission_category                        0          0.000000\n",
       "dual_shift_mode                              0          0.000000\n",
       "overdrive                                    0          0.000000\n",
       "auto_shift                                   0          0.000000"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "missing_values = train.isna().sum()\n",
    "pct_missing_values = train.isna().sum()/len(train)*100\n",
    "missing_df = pd.concat([missing_values, pct_missing_values], axis=1)\n",
    "missing_df = missing_df.rename(columns={0:'count_of_missing_values', 1:'%_missing_values'})\n",
    "missing_df.sort_values(by='%_missing_values', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count_of_missing_values</th>\n",
       "      <th>%_missing_values</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>engine_type</th>\n",
       "      <td>2732</td>\n",
       "      <td>7.550507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fuel_type</th>\n",
       "      <td>2698</td>\n",
       "      <td>7.456540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>horsepower</th>\n",
       "      <td>2606</td>\n",
       "      <td>7.202277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>displacement_value</th>\n",
       "      <td>405</td>\n",
       "      <td>1.119310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_year</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>milage</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ext_col</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>int_col</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accident</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>brand_group</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>transmission_category</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dual_shift_mode</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>overdrive</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>auto_shift</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       count_of_missing_values  %_missing_values\n",
       "engine_type                               2732          7.550507\n",
       "fuel_type                                 2698          7.456540\n",
       "horsepower                                2606          7.202277\n",
       "displacement_value                         405          1.119310\n",
       "model_year                                   0          0.000000\n",
       "milage                                       0          0.000000\n",
       "ext_col                                      0          0.000000\n",
       "int_col                                      0          0.000000\n",
       "accident                                     0          0.000000\n",
       "brand_group                                  0          0.000000\n",
       "transmission_category                        0          0.000000\n",
       "dual_shift_mode                              0          0.000000\n",
       "overdrive                                    0          0.000000\n",
       "auto_shift                                   0          0.000000"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "missing_values = test.isna().sum()\n",
    "pct_missing_values = test.isna().sum()/len(test)*100\n",
    "missing_df = pd.concat([missing_values, pct_missing_values], axis=1)\n",
    "missing_df = missing_df.rename(columns={0:'count_of_missing_values', 1:'%_missing_values'})\n",
    "missing_df.sort_values(by='%_missing_values', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imputing the missing values in both the test and train sets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def impute_missing_values_with_mode(df, col):\n",
    "    mode_value = df[col].mode()[0]  # Get the mode of the column\n",
    "    df[col] = df[col].fillna(mode_value)  # Fill missing values with the mode\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill missing values in train DataFrame\n",
    "train = impute_missing_values_with_mode(train, 'fuel_type')\n",
    "train = impute_missing_values_with_mode(train, 'engine_type')\n",
    "\n",
    "# Fill missing values in test DataFrame\n",
    "test = impute_missing_values_with_mode(test, 'fuel_type')\n",
    "test = impute_missing_values_with_mode(test, 'engine_type')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def impute_missing_values_with_median(df, col):\n",
    "    median_value = df[col].median()  # Get the median of the column\n",
    "    df[col] = df[col].fillna(median_value)  # Fill missing values with the mode\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training dataset\n",
    "train = impute_missing_values_with_median(train, 'horsepower')\n",
    "train = impute_missing_values_with_median(train, 'displacement_value')\n",
    "\n",
    "#testing dataset\n",
    "test = impute_missing_values_with_median(test, 'horsepower')\n",
    "test = impute_missing_values_with_median(test, 'displacement_value')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['fuel_type', 'ext_col', 'int_col', 'accident', 'engine_type',\n",
       "       'brand_group', 'transmission_category'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "car_cols2 = train.select_dtypes(include='object').columns\n",
    "car_cols2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoding the categorical variables "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combinin the train and test data for the encoding purposes \n",
    "combined_data = pd.concat([train, test], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "def label_encode_categorical(df):\n",
    "    # Identify categorical columns\n",
    "    categorical_columns = combined_data.select_dtypes(include=['object', 'category']).columns\n",
    "    \n",
    "    # Fit and transform the training data, and transform the test data\n",
    "    for col in categorical_columns:\n",
    "        le = LabelEncoder()\n",
    "        combined_data[col] = le.fit_transform(combined_data[col])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df = label_encode_categorical(combined_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scaling the numerical variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "numeric_cols = test.select_dtypes(include='number').columns  # Select numeric columns\n",
    "def scale_data(df, scaler=MinMaxScaler()):\n",
    "    \"\"\"\n",
    "    Scales numeric columns in a DataFrame using the specified scaler.\n",
    "\n",
    "    Parameters:\n",
    "    df (pd.DataFrame): The input DataFrame to scale.\n",
    "    scaler (object): The scaler instance to use (default is MinMaxScaler).\n",
    "\n",
    "    Returns:\n",
    "    pd.DataFrame: The DataFrame with scaled numeric columns.\n",
    "    \"\"\"\n",
    "    df[numeric_cols] = scaler.fit_transform(df[numeric_cols])  # Apply the scaler to numeric columns\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_combined_df = scale_data(combined_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_year</th>\n",
       "      <th>milage</th>\n",
       "      <th>fuel_type</th>\n",
       "      <th>ext_col</th>\n",
       "      <th>int_col</th>\n",
       "      <th>accident</th>\n",
       "      <th>price</th>\n",
       "      <th>horsepower</th>\n",
       "      <th>displacement_value</th>\n",
       "      <th>engine_type</th>\n",
       "      <th>brand_group</th>\n",
       "      <th>transmission_category</th>\n",
       "      <th>dual_shift_mode</th>\n",
       "      <th>overdrive</th>\n",
       "      <th>auto_shift</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.88</td>\n",
       "      <td>0.183376</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>11000.0</td>\n",
       "      <td>0.321053</td>\n",
       "      <td>0.367742</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.66</td>\n",
       "      <td>0.197333</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>8250.0</td>\n",
       "      <td>0.242105</td>\n",
       "      <td>0.303226</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.70</td>\n",
       "      <td>0.225713</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>15000.0</td>\n",
       "      <td>0.242105</td>\n",
       "      <td>0.458065</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.96</td>\n",
       "      <td>0.005772</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>63500.0</td>\n",
       "      <td>0.278947</td>\n",
       "      <td>0.303226</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.54</td>\n",
       "      <td>0.273895</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7850.0</td>\n",
       "      <td>0.136842</td>\n",
       "      <td>0.406452</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   model_year    milage  fuel_type  ext_col  int_col  accident    price  \\\n",
       "0        0.88  0.183376          2        1        3         1  11000.0   \n",
       "1        0.66  0.197333          2        0        1         1   8250.0   \n",
       "2        0.70  0.225713          2        4        0         1  15000.0   \n",
       "3        0.96  0.005772          3        2        2         1  63500.0   \n",
       "4        0.54  0.273895          2        7        1         1   7850.0   \n",
       "\n",
       "   horsepower  displacement_value  engine_type  brand_group  \\\n",
       "0    0.321053            0.367742            5            3   \n",
       "1    0.242105            0.303226            4            5   \n",
       "2    0.242105            0.458065            1            2   \n",
       "3    0.278947            0.303226            4            5   \n",
       "4    0.136842            0.406452            5            5   \n",
       "\n",
       "   transmission_category  dual_shift_mode  overdrive  auto_shift  \n",
       "0                      1              0.0        0.0         0.0  \n",
       "1                      3              0.0        0.0         0.0  \n",
       "2                      1              0.0        0.0         0.0  \n",
       "3                      1              1.0        0.0         0.0  \n",
       "4                      1              0.0        0.0         0.0  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaled_combined_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Split back into train and test sets\n",
    "scaled_train = scaled_combined_df.iloc[:len(train), :]\n",
    "scaled_test = scaled_combined_df.iloc[len(train):, :]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((54273, 15), (36183, 15))"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaled_train.shape, scaled_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_5712\\2955031298.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  scaled_test.drop(columns='price', axis=1, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "scaled_test.drop(columns='price', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from catboost import CatBoostRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from lightgbm import LGBMRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = scaled_train.drop(columns='price', axis=1, inplace=False) \n",
    "y = scaled_train['price']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y,test_size = 0.2, random_state=42 )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Necessary imports\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "from sklearn.metrics import make_scorer, mean_squared_error\n",
    "\n",
    "# Function to train models and visualize RMSE\n",
    "def train_and_evaluate_models(X_train, X_test, y_train, y_test):\n",
    "    # Initialize models\n",
    "    models = [\n",
    "        ('CatBoost', CatBoostRegressor(verbose=0)),\n",
    "        ('XGB', XGBRegressor(verbosity=0)),\n",
    "        ('LGBM', LGBMRegressor())\n",
    "    ]\n",
    "    \n",
    "    # Lists to store results\n",
    "    names = []\n",
    "    rmse_scores = []\n",
    "    \n",
    "    # Train and evaluate each model\n",
    "    for name, model in models:\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "        rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "        names.append(name)\n",
    "        rmse_scores.append(rmse)\n",
    "        print(f\"{name} RMSE: {rmse:.3f}\")\n",
    "        \n",
    "        # Visualize RMSE scores in a bar chart\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.bar(names, rmse_scores, color=['blue', 'green', 'red'])\n",
    "    plt.xlabel('Model')\n",
    "    plt.ylabel('RMSE')\n",
    "    plt.title('RMSE of Different Regression Models')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CatBoost RMSE: 54846.201\n",
      "XGB RMSE: 57215.066\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.082312 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 617\n",
      "[LightGBM] [Info] Number of data points in the train set: 43418, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 39329.732369\n",
      "LGBM RMSE: 48931.310\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_and_evaluate_models(X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011355 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 617\n",
      "[LightGBM] [Info] Number of data points in the train set: 43418, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 39329.732369\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LGBMRegressor()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;LGBMRegressor<span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>LGBMRegressor()</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "LGBMRegressor()"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lgbm = LGBMRegressor()\n",
    "lgbm.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\PC\\anaconda3-2\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lgbm train R2 is: 0.3087169473898542\n",
      "Lgbm test R2 is: 0.18520585495258113\n",
      "LGBM Model RMSE: 48931.30960646055\n"
     ]
    }
   ],
   "source": [
    "lgbm_pred = lgbm.predict(X_test)\n",
    "rmse = mean_squared_error(y_test, lgbm_pred, squared=False)  # Calculate RMSE\n",
    "r2_train = lgbm.score(X_train, y_train)\n",
    "r2_test = lgbm.score(X_test, y_test)\n",
    "print(f\"Lgbm train R2 is: {r2_train}\")\n",
    "print(f\"Lgbm test R2 is: {r2_test}\")\n",
    "print(f\"LGBM Model RMSE: {rmse}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgbm_predictions =lgbm.predict(scaled_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>54273</td>\n",
       "      <td>23916.407736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>54274</td>\n",
       "      <td>18399.130487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>54275</td>\n",
       "      <td>26412.117190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>54276</td>\n",
       "      <td>66045.605306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>54277</td>\n",
       "      <td>37510.554271</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id         price\n",
       "0  54273  23916.407736\n",
       "1  54274  18399.130487\n",
       "2  54275  26412.117190\n",
       "3  54276  66045.605306\n",
       "4  54277  37510.554271"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create submission file\n",
    "sub = pd.DataFrame({'id': submission['id'], 'price': lgbm_predictions})\n",
    "\n",
    "# Preview sub file\n",
    "sub.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a csv file\n",
    "#sub.to_csv('submission8.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "\n",
    "# Define objective function for Optuna to optimize\n",
    "def objective(trial):\n",
    "    params = {\n",
    "        'num_leaves': trial.suggest_int('num_leaves', 20, 100),\n",
    "        'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
    "        'max_depth': trial.suggest_int('max_depth', 5, 15),\n",
    "        'subsample': trial.suggest_uniform('subsample', 0.6, 1.0),\n",
    "        'colsample_bytree': trial.suggest_uniform('colsample_bytree', 0.6, 1.0),\n",
    "        'reg_alpha': trial.suggest_loguniform('reg_alpha', 1e-5, 10.0),\n",
    "        'reg_lambda': trial.suggest_loguniform('reg_lambda', 1e-5, 10.0),\n",
    "        'min_child_samples': trial.suggest_int('min_child_samples', 5, 100)\n",
    "    }\n",
    "\n",
    "    # Initialize LGBMRegressor with current parameters\n",
    "    model = LGBMRegressor(**params, random_state=42)\n",
    "\n",
    "    # Fit the model on training data\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Predict on the validation set\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    # Calculate RMSE\n",
    "    rmse = mean_squared_error(y_test, y_pred, squared=False)\n",
    "\n",
    "    return rmse\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-23 12:11:52,406] A new study created in memory with name: no-name-0edad6be-9870-45e1-a190-e55cdac69de0\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_5712\\3184931164.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_5712\\3184931164.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'subsample': trial.suggest_uniform('subsample', 0.6, 1.0),\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_5712\\3184931164.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'colsample_bytree': trial.suggest_uniform('colsample_bytree', 0.6, 1.0),\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_5712\\3184931164.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'reg_alpha': trial.suggest_loguniform('reg_alpha', 1e-5, 10.0),\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_5712\\3184931164.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'reg_lambda': trial.suggest_loguniform('reg_lambda', 1e-5, 10.0),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.012645 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 615\n",
      "[LightGBM] [Info] Number of data points in the train set: 43418, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 39329.732369\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\PC\\anaconda3-2\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "[I 2024-06-23 12:11:54,731] Trial 0 finished with value: 49083.435594444534 and parameters: {'num_leaves': 50, 'learning_rate': 0.2536999076681772, 'max_depth': 13, 'subsample': 0.8394633936788146, 'colsample_bytree': 0.6624074561769746, 'reg_alpha': 8.629132190071849e-05, 'reg_lambda': 2.231010801867923e-05, 'min_child_samples': 88}. Best is trial 0 with value: 49083.435594444534.\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_5712\\3184931164.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_5712\\3184931164.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'subsample': trial.suggest_uniform('subsample', 0.6, 1.0),\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_5712\\3184931164.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'colsample_bytree': trial.suggest_uniform('colsample_bytree', 0.6, 1.0),\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_5712\\3184931164.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'reg_alpha': trial.suggest_loguniform('reg_alpha', 1e-5, 10.0),\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_5712\\3184931164.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'reg_lambda': trial.suggest_loguniform('reg_lambda', 1e-5, 10.0),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.044152 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 617\n",
      "[LightGBM] [Info] Number of data points in the train set: 43418, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 39329.732369\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\PC\\anaconda3-2\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "[I 2024-06-23 12:11:55,589] Trial 1 finished with value: 47786.79752175341 and parameters: {'num_leaves': 68, 'learning_rate': 0.11114989443094977, 'max_depth': 5, 'subsample': 0.9879639408647978, 'colsample_bytree': 0.9329770563201687, 'reg_alpha': 0.00018794668241638458, 'reg_lambda': 0.00012329623163659834, 'min_child_samples': 22}. Best is trial 1 with value: 47786.79752175341.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_5712\\3184931164.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_5712\\3184931164.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'subsample': trial.suggest_uniform('subsample', 0.6, 1.0),\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_5712\\3184931164.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'colsample_bytree': trial.suggest_uniform('colsample_bytree', 0.6, 1.0),\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_5712\\3184931164.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'reg_alpha': trial.suggest_loguniform('reg_alpha', 1e-5, 10.0),\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_5712\\3184931164.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'reg_lambda': trial.suggest_loguniform('reg_lambda', 1e-5, 10.0),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.042509 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 617\n",
      "[LightGBM] [Info] Number of data points in the train set: 43418, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 39329.732369\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\PC\\anaconda3-2\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "[I 2024-06-23 12:11:57,485] Trial 2 finished with value: 47634.46684949353 and parameters: {'num_leaves': 44, 'learning_rate': 0.05958389350068958, 'max_depth': 9, 'subsample': 0.7164916560792167, 'colsample_bytree': 0.8447411578889518, 'reg_alpha': 6.870101665590028e-05, 'reg_lambda': 0.0005660670699258885, 'min_child_samples': 40}. Best is trial 2 with value: 47634.46684949353.\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_5712\\3184931164.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_5712\\3184931164.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'subsample': trial.suggest_uniform('subsample', 0.6, 1.0),\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_5712\\3184931164.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'colsample_bytree': trial.suggest_uniform('colsample_bytree', 0.6, 1.0),\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_5712\\3184931164.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'reg_alpha': trial.suggest_loguniform('reg_alpha', 1e-5, 10.0),\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_5712\\3184931164.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'reg_lambda': trial.suggest_loguniform('reg_lambda', 1e-5, 10.0),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007524 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 617\n",
      "[LightGBM] [Info] Number of data points in the train set: 43418, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 39329.732369\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\PC\\anaconda3-2\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "[I 2024-06-23 12:11:58,758] Trial 3 finished with value: 48715.702420599446 and parameters: {'num_leaves': 56, 'learning_rate': 0.14447746112718687, 'max_depth': 7, 'subsample': 0.8056937753654446, 'colsample_bytree': 0.836965827544817, 'reg_alpha': 1.8997763474111268e-05, 'reg_lambda': 0.0441844152119972, 'min_child_samples': 21}. Best is trial 2 with value: 47634.46684949353.\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_5712\\3184931164.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_5712\\3184931164.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'subsample': trial.suggest_uniform('subsample', 0.6, 1.0),\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_5712\\3184931164.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'colsample_bytree': trial.suggest_uniform('colsample_bytree', 0.6, 1.0),\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_5712\\3184931164.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'reg_alpha': trial.suggest_loguniform('reg_alpha', 1e-5, 10.0),\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_5712\\3184931164.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'reg_lambda': trial.suggest_loguniform('reg_lambda', 1e-5, 10.0),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.050522 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 617\n",
      "[LightGBM] [Info] Number of data points in the train set: 43418, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 39329.732369\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\PC\\anaconda3-2\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "[I 2024-06-23 12:11:59,746] Trial 4 finished with value: 48866.25081347685 and parameters: {'num_leaves': 25, 'learning_rate': 0.2521267904777921, 'max_depth': 15, 'subsample': 0.9233589392465844, 'colsample_bytree': 0.7218455076693483, 'reg_alpha': 3.855073690026178e-05, 'reg_lambda': 0.12746711578215045, 'min_child_samples': 47}. Best is trial 2 with value: 47634.46684949353.\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_5712\\3184931164.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_5712\\3184931164.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'subsample': trial.suggest_uniform('subsample', 0.6, 1.0),\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_5712\\3184931164.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'colsample_bytree': trial.suggest_uniform('colsample_bytree', 0.6, 1.0),\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_5712\\3184931164.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'reg_alpha': trial.suggest_loguniform('reg_alpha', 1e-5, 10.0),\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_5712\\3184931164.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'reg_lambda': trial.suggest_loguniform('reg_lambda', 1e-5, 10.0),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.024790 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 615\n",
      "[LightGBM] [Info] Number of data points in the train set: 43418, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 39329.732369\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\PC\\anaconda3-2\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "[I 2024-06-23 12:12:00,906] Trial 5 finished with value: 47263.500345720655 and parameters: {'num_leaves': 29, 'learning_rate': 0.05388108577817234, 'max_depth': 5, 'subsample': 0.9637281608315128, 'colsample_bytree': 0.7035119926400067, 'reg_alpha': 0.0944351568796267, 'reg_lambda': 0.0007417652034871827, 'min_child_samples': 54}. Best is trial 5 with value: 47263.500345720655.\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_5712\\3184931164.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_5712\\3184931164.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'subsample': trial.suggest_uniform('subsample', 0.6, 1.0),\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_5712\\3184931164.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'colsample_bytree': trial.suggest_uniform('colsample_bytree', 0.6, 1.0),\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_5712\\3184931164.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'reg_alpha': trial.suggest_loguniform('reg_alpha', 1e-5, 10.0),\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_5712\\3184931164.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'reg_lambda': trial.suggest_loguniform('reg_lambda', 1e-5, 10.0),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005912 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 615\n",
      "[LightGBM] [Info] Number of data points in the train set: 43418, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 39329.732369\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\PC\\anaconda3-2\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "[I 2024-06-23 12:12:02,245] Trial 6 finished with value: 47617.39092365927 and parameters: {'num_leaves': 64, 'learning_rate': 0.01875220945578641, 'max_depth': 15, 'subsample': 0.9100531293444458, 'colsample_bytree': 0.9757995766256756, 'reg_alpha': 2.3386439256208704, 'reg_lambda': 0.038672288491177424, 'min_child_samples': 93}. Best is trial 5 with value: 47263.500345720655.\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_5712\\3184931164.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_5712\\3184931164.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'subsample': trial.suggest_uniform('subsample', 0.6, 1.0),\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_5712\\3184931164.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'colsample_bytree': trial.suggest_uniform('colsample_bytree', 0.6, 1.0),\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_5712\\3184931164.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'reg_alpha': trial.suggest_loguniform('reg_alpha', 1e-5, 10.0),\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_5712\\3184931164.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'reg_lambda': trial.suggest_loguniform('reg_lambda', 1e-5, 10.0),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011635 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 617\n",
      "[LightGBM] [Info] Number of data points in the train set: 43418, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 39329.732369\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\PC\\anaconda3-2\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "[I 2024-06-23 12:12:03,852] Trial 7 finished with value: 47675.20025400037 and parameters: {'num_leaves': 27, 'learning_rate': 0.01947558230629543, 'max_depth': 5, 'subsample': 0.7301321323053057, 'colsample_bytree': 0.7554709158757928, 'reg_alpha': 0.0004247116662617141, 'reg_lambda': 0.9384800715909529, 'min_child_samples': 39}. Best is trial 5 with value: 47263.500345720655.\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_5712\\3184931164.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_5712\\3184931164.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'subsample': trial.suggest_uniform('subsample', 0.6, 1.0),\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_5712\\3184931164.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'colsample_bytree': trial.suggest_uniform('colsample_bytree', 0.6, 1.0),\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_5712\\3184931164.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'reg_alpha': trial.suggest_loguniform('reg_alpha', 1e-5, 10.0),\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_5712\\3184931164.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'reg_lambda': trial.suggest_loguniform('reg_lambda', 1e-5, 10.0),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003174 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 617\n",
      "[LightGBM] [Info] Number of data points in the train set: 43418, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 39329.732369\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\PC\\anaconda3-2\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "[I 2024-06-23 12:12:05,309] Trial 8 finished with value: 47484.43734078048 and parameters: {'num_leaves': 42, 'learning_rate': 0.06333268775321843, 'max_depth': 6, 'subsample': 0.9208787923016158, 'colsample_bytree': 0.6298202574719083, 'reg_alpha': 8.342988013047341, 'reg_lambda': 0.43000015861626045, 'min_child_samples': 24}. Best is trial 5 with value: 47263.500345720655.\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_5712\\3184931164.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_5712\\3184931164.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'subsample': trial.suggest_uniform('subsample', 0.6, 1.0),\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_5712\\3184931164.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'colsample_bytree': trial.suggest_uniform('colsample_bytree', 0.6, 1.0),\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_5712\\3184931164.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'reg_alpha': trial.suggest_loguniform('reg_alpha', 1e-5, 10.0),\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_5712\\3184931164.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'reg_lambda': trial.suggest_loguniform('reg_lambda', 1e-5, 10.0),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002450 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 617\n",
      "[LightGBM] [Info] Number of data points in the train set: 43418, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 39329.732369\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\PC\\anaconda3-2\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "[I 2024-06-23 12:12:06,111] Trial 9 finished with value: 49533.149802695814 and parameters: {'num_leaves': 20, 'learning_rate': 0.1601531217136121, 'max_depth': 12, 'subsample': 0.8916028672163949, 'colsample_bytree': 0.9085081386743783, 'reg_alpha': 2.781428564375753e-05, 'reg_lambda': 0.0014151235919053699, 'min_child_samples': 16}. Best is trial 5 with value: 47263.500345720655.\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_5712\\3184931164.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_5712\\3184931164.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'subsample': trial.suggest_uniform('subsample', 0.6, 1.0),\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_5712\\3184931164.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'colsample_bytree': trial.suggest_uniform('colsample_bytree', 0.6, 1.0),\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_5712\\3184931164.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'reg_alpha': trial.suggest_loguniform('reg_alpha', 1e-5, 10.0),\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_5712\\3184931164.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'reg_lambda': trial.suggest_loguniform('reg_lambda', 1e-5, 10.0),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.070831 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 615\n",
      "[LightGBM] [Info] Number of data points in the train set: 43418, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 39329.732369\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\PC\\anaconda3-2\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "[I 2024-06-23 12:12:08,746] Trial 10 finished with value: 48607.1980871724 and parameters: {'num_leaves': 96, 'learning_rate': 0.010206070557576998, 'max_depth': 9, 'subsample': 0.6071847502459278, 'colsample_bytree': 0.7090747508804338, 'reg_alpha': 0.1385104184841322, 'reg_lambda': 5.73620251630527, 'min_child_samples': 69}. Best is trial 5 with value: 47263.500345720655.\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_5712\\3184931164.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_5712\\3184931164.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'subsample': trial.suggest_uniform('subsample', 0.6, 1.0),\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_5712\\3184931164.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'colsample_bytree': trial.suggest_uniform('colsample_bytree', 0.6, 1.0),\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_5712\\3184931164.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'reg_alpha': trial.suggest_loguniform('reg_alpha', 1e-5, 10.0),\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_5712\\3184931164.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'reg_lambda': trial.suggest_loguniform('reg_lambda', 1e-5, 10.0),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003075 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 615\n",
      "[LightGBM] [Info] Number of data points in the train set: 43418, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 39329.732369\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\PC\\anaconda3-2\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "[I 2024-06-23 12:12:10,247] Trial 11 finished with value: 47378.6933844893 and parameters: {'num_leaves': 36, 'learning_rate': 0.05066279925177419, 'max_depth': 7, 'subsample': 0.9783238879894853, 'colsample_bytree': 0.6133578302780329, 'reg_alpha': 8.098247674170269, 'reg_lambda': 0.0024847588207063767, 'min_child_samples': 65}. Best is trial 5 with value: 47263.500345720655.\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_5712\\3184931164.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_5712\\3184931164.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'subsample': trial.suggest_uniform('subsample', 0.6, 1.0),\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_5712\\3184931164.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'colsample_bytree': trial.suggest_uniform('colsample_bytree', 0.6, 1.0),\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_5712\\3184931164.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'reg_alpha': trial.suggest_loguniform('reg_alpha', 1e-5, 10.0),\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_5712\\3184931164.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'reg_lambda': trial.suggest_loguniform('reg_lambda', 1e-5, 10.0),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005836 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 615\n",
      "[LightGBM] [Info] Number of data points in the train set: 43418, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 39329.732369\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\PC\\anaconda3-2\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "[I 2024-06-23 12:12:11,661] Trial 12 finished with value: 47400.35090271675 and parameters: {'num_leaves': 36, 'learning_rate': 0.027912153491801303, 'max_depth': 7, 'subsample': 0.9872607155373294, 'colsample_bytree': 0.6257372131795154, 'reg_alpha': 0.06686699170398881, 'reg_lambda': 0.003914090495844409, 'min_child_samples': 66}. Best is trial 5 with value: 47263.500345720655.\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_5712\\3184931164.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_5712\\3184931164.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'subsample': trial.suggest_uniform('subsample', 0.6, 1.0),\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_5712\\3184931164.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'colsample_bytree': trial.suggest_uniform('colsample_bytree', 0.6, 1.0),\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_5712\\3184931164.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'reg_alpha': trial.suggest_loguniform('reg_alpha', 1e-5, 10.0),\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_5712\\3184931164.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'reg_lambda': trial.suggest_loguniform('reg_lambda', 1e-5, 10.0),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013035 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 615\n",
      "[LightGBM] [Info] Number of data points in the train set: 43418, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 39329.732369\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\PC\\anaconda3-2\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "[I 2024-06-23 12:12:13,451] Trial 13 finished with value: 47315.8467459842 and parameters: {'num_leaves': 76, 'learning_rate': 0.03903858603536136, 'max_depth': 8, 'subsample': 0.9984066126989742, 'colsample_bytree': 0.684887414915549, 'reg_alpha': 0.005486054780596624, 'reg_lambda': 0.0005204631774806725, 'min_child_samples': 65}. Best is trial 5 with value: 47263.500345720655.\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_5712\\3184931164.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_5712\\3184931164.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'subsample': trial.suggest_uniform('subsample', 0.6, 1.0),\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_5712\\3184931164.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'colsample_bytree': trial.suggest_uniform('colsample_bytree', 0.6, 1.0),\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_5712\\3184931164.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'reg_alpha': trial.suggest_loguniform('reg_alpha', 1e-5, 10.0),\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_5712\\3184931164.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'reg_lambda': trial.suggest_loguniform('reg_lambda', 1e-5, 10.0),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008922 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 615\n",
      "[LightGBM] [Info] Number of data points in the train set: 43418, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 39329.732369\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\PC\\anaconda3-2\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "[I 2024-06-23 12:12:18,158] Trial 14 finished with value: 47354.05052154826 and parameters: {'num_leaves': 81, 'learning_rate': 0.037144135906544085, 'max_depth': 10, 'subsample': 0.8578694741072342, 'colsample_bytree': 0.7796937548766031, 'reg_alpha': 0.0014730328623335294, 'reg_lambda': 0.00013262449021038777, 'min_child_samples': 79}. Best is trial 5 with value: 47263.500345720655.\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_5712\\3184931164.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_5712\\3184931164.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'subsample': trial.suggest_uniform('subsample', 0.6, 1.0),\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_5712\\3184931164.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'colsample_bytree': trial.suggest_uniform('colsample_bytree', 0.6, 1.0),\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_5712\\3184931164.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'reg_alpha': trial.suggest_loguniform('reg_alpha', 1e-5, 10.0),\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_5712\\3184931164.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'reg_lambda': trial.suggest_loguniform('reg_lambda', 1e-5, 10.0),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.018964 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 615\n",
      "[LightGBM] [Info] Number of data points in the train set: 43418, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 39329.732369\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\PC\\anaconda3-2\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "[I 2024-06-23 12:12:21,439] Trial 15 finished with value: 47742.791901595454 and parameters: {'num_leaves': 77, 'learning_rate': 0.09160994419974852, 'max_depth': 8, 'subsample': 0.9509476077214297, 'colsample_bytree': 0.6810381919322529, 'reg_alpha': 0.010035048090158021, 'reg_lambda': 1.6989804820852618e-05, 'min_child_samples': 55}. Best is trial 5 with value: 47263.500345720655.\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_5712\\3184931164.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_5712\\3184931164.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'subsample': trial.suggest_uniform('subsample', 0.6, 1.0),\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_5712\\3184931164.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'colsample_bytree': trial.suggest_uniform('colsample_bytree', 0.6, 1.0),\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_5712\\3184931164.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'reg_alpha': trial.suggest_loguniform('reg_alpha', 1e-5, 10.0),\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_5712\\3184931164.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'reg_lambda': trial.suggest_loguniform('reg_lambda', 1e-5, 10.0),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003718 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 615\n",
      "[LightGBM] [Info] Number of data points in the train set: 43418, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 39329.732369\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\PC\\anaconda3-2\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "[I 2024-06-23 12:12:23,730] Trial 16 finished with value: 47351.803064227286 and parameters: {'num_leaves': 95, 'learning_rate': 0.0330552246243208, 'max_depth': 11, 'subsample': 0.77923661166059, 'colsample_bytree': 0.7532329274044126, 'reg_alpha': 0.1986352901063075, 'reg_lambda': 0.0003096235530082275, 'min_child_samples': 55}. Best is trial 5 with value: 47263.500345720655.\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_5712\\3184931164.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_5712\\3184931164.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'subsample': trial.suggest_uniform('subsample', 0.6, 1.0),\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_5712\\3184931164.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'colsample_bytree': trial.suggest_uniform('colsample_bytree', 0.6, 1.0),\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_5712\\3184931164.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'reg_alpha': trial.suggest_loguniform('reg_alpha', 1e-5, 10.0),\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_5712\\3184931164.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'reg_lambda': trial.suggest_loguniform('reg_lambda', 1e-5, 10.0),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003774 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 615\n",
      "[LightGBM] [Info] Number of data points in the train set: 43418, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 39329.732369\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\PC\\anaconda3-2\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "[I 2024-06-23 12:12:24,801] Trial 17 finished with value: 47478.33027399229 and parameters: {'num_leaves': 82, 'learning_rate': 0.08407654179943178, 'max_depth': 5, 'subsample': 0.8715960262589024, 'colsample_bytree': 0.6803255311489224, 'reg_alpha': 0.004345880761785714, 'reg_lambda': 0.016603543253036524, 'min_child_samples': 75}. Best is trial 5 with value: 47263.500345720655.\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_5712\\3184931164.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_5712\\3184931164.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'subsample': trial.suggest_uniform('subsample', 0.6, 1.0),\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_5712\\3184931164.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'colsample_bytree': trial.suggest_uniform('colsample_bytree', 0.6, 1.0),\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_5712\\3184931164.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'reg_alpha': trial.suggest_loguniform('reg_alpha', 1e-5, 10.0),\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_5712\\3184931164.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'reg_lambda': trial.suggest_loguniform('reg_lambda', 1e-5, 10.0),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003826 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 615\n",
      "[LightGBM] [Info] Number of data points in the train set: 43418, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 39329.732369\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\PC\\anaconda3-2\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "[I 2024-06-23 12:12:26,507] Trial 18 finished with value: 47327.44892174948 and parameters: {'num_leaves': 69, 'learning_rate': 0.04323444823345438, 'max_depth': 8, 'subsample': 0.9613676974312834, 'colsample_bytree': 0.8160380080454376, 'reg_alpha': 0.025281436440769696, 'reg_lambda': 0.007352704786614045, 'min_child_samples': 99}. Best is trial 5 with value: 47263.500345720655.\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_5712\\3184931164.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_5712\\3184931164.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'subsample': trial.suggest_uniform('subsample', 0.6, 1.0),\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_5712\\3184931164.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'colsample_bytree': trial.suggest_uniform('colsample_bytree', 0.6, 1.0),\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_5712\\3184931164.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'reg_alpha': trial.suggest_loguniform('reg_alpha', 1e-5, 10.0),\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_5712\\3184931164.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'reg_lambda': trial.suggest_loguniform('reg_lambda', 1e-5, 10.0),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.017507 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 617\n",
      "[LightGBM] [Info] Number of data points in the train set: 43418, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 39329.732369\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\PC\\anaconda3-2\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "[I 2024-06-23 12:12:28,730] Trial 19 finished with value: 47415.44732961321 and parameters: {'num_leaves': 87, 'learning_rate': 0.023333530158706012, 'max_depth': 6, 'subsample': 0.6017949844194721, 'colsample_bytree': 0.7237669253842854, 'reg_alpha': 0.9145424437209991, 'reg_lambda': 7.432962123822877e-05, 'min_child_samples': 35}. Best is trial 5 with value: 47263.500345720655.\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_5712\\3184931164.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_5712\\3184931164.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'subsample': trial.suggest_uniform('subsample', 0.6, 1.0),\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_5712\\3184931164.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'colsample_bytree': trial.suggest_uniform('colsample_bytree', 0.6, 1.0),\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_5712\\3184931164.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'reg_alpha': trial.suggest_loguniform('reg_alpha', 1e-5, 10.0),\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_5712\\3184931164.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'reg_lambda': trial.suggest_loguniform('reg_lambda', 1e-5, 10.0),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005871 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 615\n",
      "[LightGBM] [Info] Number of data points in the train set: 43418, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 39329.732369\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\PC\\anaconda3-2\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "[I 2024-06-23 12:12:30,519] Trial 20 finished with value: 48221.306919206974 and parameters: {'num_leaves': 56, 'learning_rate': 0.01173599692785137, 'max_depth': 9, 'subsample': 0.6628974418511197, 'colsample_bytree': 0.6597346726890919, 'reg_alpha': 0.0015650066712313941, 'reg_lambda': 0.0008480606911833949, 'min_child_samples': 57}. Best is trial 5 with value: 47263.500345720655.\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_5712\\3184931164.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_5712\\3184931164.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'subsample': trial.suggest_uniform('subsample', 0.6, 1.0),\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_5712\\3184931164.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'colsample_bytree': trial.suggest_uniform('colsample_bytree', 0.6, 1.0),\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_5712\\3184931164.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'reg_alpha': trial.suggest_loguniform('reg_alpha', 1e-5, 10.0),\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_5712\\3184931164.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'reg_lambda': trial.suggest_loguniform('reg_lambda', 1e-5, 10.0),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014069 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 615\n",
      "[LightGBM] [Info] Number of data points in the train set: 43418, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 39329.732369\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\PC\\anaconda3-2\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "[I 2024-06-23 12:12:32,209] Trial 21 finished with value: 47360.024641426025 and parameters: {'num_leaves': 71, 'learning_rate': 0.045989693733405376, 'max_depth': 8, 'subsample': 0.9502583389350209, 'colsample_bytree': 0.8075301549946484, 'reg_alpha': 0.02445583047148844, 'reg_lambda': 0.006125245673012747, 'min_child_samples': 97}. Best is trial 5 with value: 47263.500345720655.\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_5712\\3184931164.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_5712\\3184931164.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'subsample': trial.suggest_uniform('subsample', 0.6, 1.0),\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_5712\\3184931164.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'colsample_bytree': trial.suggest_uniform('colsample_bytree', 0.6, 1.0),\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_5712\\3184931164.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'reg_alpha': trial.suggest_loguniform('reg_alpha', 1e-5, 10.0),\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_5712\\3184931164.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'reg_lambda': trial.suggest_loguniform('reg_lambda', 1e-5, 10.0),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.024007 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 617\n",
      "[LightGBM] [Info] Number of data points in the train set: 43418, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 39329.732369\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\PC\\anaconda3-2\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "[I 2024-06-23 12:12:33,918] Trial 22 finished with value: 49631.267614626566 and parameters: {'num_leaves': 76, 'learning_rate': 0.04308515119132366, 'max_depth': 10, 'subsample': 0.9522985279777161, 'colsample_bytree': 0.8738445964974808, 'reg_alpha': 0.027483512170123278, 'reg_lambda': 0.008648234410108672, 'min_child_samples': 5}. Best is trial 5 with value: 47263.500345720655.\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_5712\\3184931164.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_5712\\3184931164.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'subsample': trial.suggest_uniform('subsample', 0.6, 1.0),\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_5712\\3184931164.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'colsample_bytree': trial.suggest_uniform('colsample_bytree', 0.6, 1.0),\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_5712\\3184931164.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'reg_alpha': trial.suggest_loguniform('reg_alpha', 1e-5, 10.0),\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_5712\\3184931164.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'reg_lambda': trial.suggest_loguniform('reg_lambda', 1e-5, 10.0),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.014976 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 615\n",
      "[LightGBM] [Info] Number of data points in the train set: 43418, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 39329.732369\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\PC\\anaconda3-2\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "[I 2024-06-23 12:12:35,287] Trial 23 finished with value: 47424.46068733031 and parameters: {'num_leaves': 61, 'learning_rate': 0.07157608708663106, 'max_depth': 8, 'subsample': 0.9977130327249748, 'colsample_bytree': 0.7787094917665794, 'reg_alpha': 0.4185104181355613, 'reg_lambda': 0.00036856879408206714, 'min_child_samples': 86}. Best is trial 5 with value: 47263.500345720655.\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_5712\\3184931164.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_5712\\3184931164.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'subsample': trial.suggest_uniform('subsample', 0.6, 1.0),\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_5712\\3184931164.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'colsample_bytree': trial.suggest_uniform('colsample_bytree', 0.6, 1.0),\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_5712\\3184931164.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'reg_alpha': trial.suggest_loguniform('reg_alpha', 1e-5, 10.0),\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_5712\\3184931164.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'reg_lambda': trial.suggest_loguniform('reg_lambda', 1e-5, 10.0),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.030232 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 615\n",
      "[LightGBM] [Info] Number of data points in the train set: 43418, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 39329.732369\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\PC\\anaconda3-2\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "[I 2024-06-23 12:12:36,762] Trial 24 finished with value: 47463.83205277739 and parameters: {'num_leaves': 87, 'learning_rate': 0.030034023428346837, 'max_depth': 6, 'subsample': 0.9498859797103634, 'colsample_bytree': 0.7442578096512015, 'reg_alpha': 0.0071224831788172386, 'reg_lambda': 0.0017189553904035405, 'min_child_samples': 79}. Best is trial 5 with value: 47263.500345720655.\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_5712\\3184931164.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_5712\\3184931164.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'subsample': trial.suggest_uniform('subsample', 0.6, 1.0),\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_5712\\3184931164.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'colsample_bytree': trial.suggest_uniform('colsample_bytree', 0.6, 1.0),\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_5712\\3184931164.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'reg_alpha': trial.suggest_loguniform('reg_alpha', 1e-5, 10.0),\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_5712\\3184931164.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'reg_lambda': trial.suggest_loguniform('reg_lambda', 1e-5, 10.0),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003782 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 615\n",
      "[LightGBM] [Info] Number of data points in the train set: 43418, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 39329.732369\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\PC\\anaconda3-2\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "[I 2024-06-23 12:12:38,707] Trial 25 finished with value: 48188.04052249703 and parameters: {'num_leaves': 69, 'learning_rate': 0.014023347876983932, 'max_depth': 10, 'subsample': 0.8934469652223761, 'colsample_bytree': 0.8012364486139857, 'reg_alpha': 0.03022777916577448, 'reg_lambda': 0.019858171361660487, 'min_child_samples': 100}. Best is trial 5 with value: 47263.500345720655.\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_5712\\3184931164.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_5712\\3184931164.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'subsample': trial.suggest_uniform('subsample', 0.6, 1.0),\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_5712\\3184931164.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'colsample_bytree': trial.suggest_uniform('colsample_bytree', 0.6, 1.0),\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_5712\\3184931164.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'reg_alpha': trial.suggest_loguniform('reg_alpha', 1e-5, 10.0),\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_5712\\3184931164.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'reg_lambda': trial.suggest_loguniform('reg_lambda', 1e-5, 10.0),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.016512 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 615\n",
      "[LightGBM] [Info] Number of data points in the train set: 43418, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 39329.732369\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\PC\\anaconda3-2\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "[I 2024-06-23 12:12:40,097] Trial 26 finished with value: 47424.054326777106 and parameters: {'num_leaves': 56, 'learning_rate': 0.038251646240773825, 'max_depth': 7, 'subsample': 0.8325593181256693, 'colsample_bytree': 0.8353690020265996, 'reg_alpha': 0.002185515193054722, 'reg_lambda': 4.34531091979032e-05, 'min_child_samples': 72}. Best is trial 5 with value: 47263.500345720655.\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_5712\\3184931164.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_5712\\3184931164.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'subsample': trial.suggest_uniform('subsample', 0.6, 1.0),\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_5712\\3184931164.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'colsample_bytree': trial.suggest_uniform('colsample_bytree', 0.6, 1.0),\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_5712\\3184931164.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'reg_alpha': trial.suggest_loguniform('reg_alpha', 1e-5, 10.0),\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_5712\\3184931164.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'reg_lambda': trial.suggest_loguniform('reg_lambda', 1e-5, 10.0),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002676 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 615\n",
      "[LightGBM] [Info] Number of data points in the train set: 43418, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 39329.732369\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\PC\\anaconda3-2\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "[I 2024-06-23 12:12:44,677] Trial 27 finished with value: 47462.404119987455 and parameters: {'num_leaves': 49, 'learning_rate': 0.05216702167766569, 'max_depth': 11, 'subsample': 0.9700505870963769, 'colsample_bytree': 0.6960571958355272, 'reg_alpha': 0.0005705339659456088, 'reg_lambda': 0.00029004240338865783, 'min_child_samples': 61}. Best is trial 5 with value: 47263.500345720655.\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_5712\\3184931164.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_5712\\3184931164.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'subsample': trial.suggest_uniform('subsample', 0.6, 1.0),\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_5712\\3184931164.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'colsample_bytree': trial.suggest_uniform('colsample_bytree', 0.6, 1.0),\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_5712\\3184931164.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'reg_alpha': trial.suggest_loguniform('reg_alpha', 1e-5, 10.0),\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_5712\\3184931164.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'reg_lambda': trial.suggest_loguniform('reg_lambda', 1e-5, 10.0),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.041364 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 617\n",
      "[LightGBM] [Info] Number of data points in the train set: 43418, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 39329.732369\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\PC\\anaconda3-2\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "[I 2024-06-23 12:12:47,776] Trial 28 finished with value: 47342.912488949354 and parameters: {'num_leaves': 75, 'learning_rate': 0.02507353181286162, 'max_depth': 8, 'subsample': 0.9255413060137144, 'colsample_bytree': 0.6532912859582701, 'reg_alpha': 0.06343383527693555, 'reg_lambda': 0.13958972970053352, 'min_child_samples': 46}. Best is trial 5 with value: 47263.500345720655.\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_5712\\3184931164.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_5712\\3184931164.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'subsample': trial.suggest_uniform('subsample', 0.6, 1.0),\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_5712\\3184931164.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'colsample_bytree': trial.suggest_uniform('colsample_bytree', 0.6, 1.0),\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_5712\\3184931164.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'reg_alpha': trial.suggest_loguniform('reg_alpha', 1e-5, 10.0),\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_5712\\3184931164.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'reg_lambda': trial.suggest_loguniform('reg_lambda', 1e-5, 10.0),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013902 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 615\n",
      "[LightGBM] [Info] Number of data points in the train set: 43418, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 39329.732369\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\PC\\anaconda3-2\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "[I 2024-06-23 12:12:49,720] Trial 29 finished with value: 47458.97167836649 and parameters: {'num_leaves': 90, 'learning_rate': 0.07700289234482116, 'max_depth': 6, 'subsample': 0.8295783063339567, 'colsample_bytree': 0.8777718346547335, 'reg_alpha': 0.011661559460649548, 'reg_lambda': 0.004394594347332282, 'min_child_samples': 89}. Best is trial 5 with value: 47263.500345720655.\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_5712\\3184931164.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_5712\\3184931164.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'subsample': trial.suggest_uniform('subsample', 0.6, 1.0),\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_5712\\3184931164.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'colsample_bytree': trial.suggest_uniform('colsample_bytree', 0.6, 1.0),\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_5712\\3184931164.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'reg_alpha': trial.suggest_loguniform('reg_alpha', 1e-5, 10.0),\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_5712\\3184931164.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'reg_lambda': trial.suggest_loguniform('reg_lambda', 1e-5, 10.0),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.021100 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 615\n",
      "[LightGBM] [Info] Number of data points in the train set: 43418, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 39329.732369\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\PC\\anaconda3-2\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "[I 2024-06-23 12:12:52,176] Trial 30 finished with value: 48048.19483558039 and parameters: {'num_leaves': 64, 'learning_rate': 0.1229364729027871, 'max_depth': 12, 'subsample': 0.8738945895178951, 'colsample_bytree': 0.6008612192692453, 'reg_alpha': 0.5380312529617896, 'reg_lambda': 4.633541982358969e-05, 'min_child_samples': 82}. Best is trial 5 with value: 47263.500345720655.\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_5712\\3184931164.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_5712\\3184931164.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'subsample': trial.suggest_uniform('subsample', 0.6, 1.0),\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_5712\\3184931164.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'colsample_bytree': trial.suggest_uniform('colsample_bytree', 0.6, 1.0),\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_5712\\3184931164.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'reg_alpha': trial.suggest_loguniform('reg_alpha', 1e-5, 10.0),\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_5712\\3184931164.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'reg_lambda': trial.suggest_loguniform('reg_lambda', 1e-5, 10.0),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008126 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 617\n",
      "[LightGBM] [Info] Number of data points in the train set: 43418, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 39329.732369\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\PC\\anaconda3-2\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "[I 2024-06-23 12:12:56,813] Trial 31 finished with value: 47332.1569883933 and parameters: {'num_leaves': 74, 'learning_rate': 0.022807278152722175, 'max_depth': 8, 'subsample': 0.9447274511338819, 'colsample_bytree': 0.6485372782829163, 'reg_alpha': 0.07400728301175266, 'reg_lambda': 0.08659549055335411, 'min_child_samples': 47}. Best is trial 5 with value: 47263.500345720655.\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_5712\\3184931164.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_5712\\3184931164.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'subsample': trial.suggest_uniform('subsample', 0.6, 1.0),\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_5712\\3184931164.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'colsample_bytree': trial.suggest_uniform('colsample_bytree', 0.6, 1.0),\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_5712\\3184931164.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'reg_alpha': trial.suggest_loguniform('reg_alpha', 1e-5, 10.0),\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_5712\\3184931164.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'reg_lambda': trial.suggest_loguniform('reg_lambda', 1e-5, 10.0),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.033624 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 617\n",
      "[LightGBM] [Info] Number of data points in the train set: 43418, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 39329.732369\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\PC\\anaconda3-2\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "[I 2024-06-23 12:13:01,276] Trial 32 finished with value: 47433.26278296707 and parameters: {'num_leaves': 72, 'learning_rate': 0.018986760780313767, 'max_depth': 9, 'subsample': 0.9994348356846481, 'colsample_bytree': 0.648752450102718, 'reg_alpha': 0.1111518987150512, 'reg_lambda': 0.1371186809142164, 'min_child_samples': 48}. Best is trial 5 with value: 47263.500345720655.\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_5712\\3184931164.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_5712\\3184931164.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'subsample': trial.suggest_uniform('subsample', 0.6, 1.0),\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_5712\\3184931164.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'colsample_bytree': trial.suggest_uniform('colsample_bytree', 0.6, 1.0),\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_5712\\3184931164.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'reg_alpha': trial.suggest_loguniform('reg_alpha', 1e-5, 10.0),\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_5712\\3184931164.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'reg_lambda': trial.suggest_loguniform('reg_lambda', 1e-5, 10.0),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.018221 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 617\n",
      "[LightGBM] [Info] Number of data points in the train set: 43418, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 39329.732369\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\PC\\anaconda3-2\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "[I 2024-06-23 12:13:04,476] Trial 33 finished with value: 47442.39284963134 and parameters: {'num_leaves': 81, 'learning_rate': 0.03625393675807768, 'max_depth': 8, 'subsample': 0.9569684600541349, 'colsample_bytree': 0.6880096091732868, 'reg_alpha': 0.020518729978521853, 'reg_lambda': 0.0008453782380365557, 'min_child_samples': 40}. Best is trial 5 with value: 47263.500345720655.\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_5712\\3184931164.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_5712\\3184931164.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'subsample': trial.suggest_uniform('subsample', 0.6, 1.0),\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_5712\\3184931164.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'colsample_bytree': trial.suggest_uniform('colsample_bytree', 0.6, 1.0),\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_5712\\3184931164.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'reg_alpha': trial.suggest_loguniform('reg_alpha', 1e-5, 10.0),\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_5712\\3184931164.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'reg_lambda': trial.suggest_loguniform('reg_lambda', 1e-5, 10.0),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.017843 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 617\n",
      "[LightGBM] [Info] Number of data points in the train set: 43418, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 39329.732369\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\PC\\anaconda3-2\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "[I 2024-06-23 12:13:06,379] Trial 34 finished with value: 47369.25823249654 and parameters: {'num_leaves': 66, 'learning_rate': 0.05718438958949782, 'max_depth': 5, 'subsample': 0.9302558363672154, 'colsample_bytree': 0.6419260187644336, 'reg_alpha': 0.0036382304106575003, 'reg_lambda': 0.03333154723218095, 'min_child_samples': 30}. Best is trial 5 with value: 47263.500345720655.\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_5712\\3184931164.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_5712\\3184931164.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'subsample': trial.suggest_uniform('subsample', 0.6, 1.0),\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_5712\\3184931164.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'colsample_bytree': trial.suggest_uniform('colsample_bytree', 0.6, 1.0),\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_5712\\3184931164.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'reg_alpha': trial.suggest_loguniform('reg_alpha', 1e-5, 10.0),\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_5712\\3184931164.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'reg_lambda': trial.suggest_loguniform('reg_lambda', 1e-5, 10.0),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.027952 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 615\n",
      "[LightGBM] [Info] Number of data points in the train set: 43418, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 39329.732369\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\PC\\anaconda3-2\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "[I 2024-06-23 12:13:09,309] Trial 35 finished with value: 47361.42171282222 and parameters: {'num_leaves': 51, 'learning_rate': 0.022562387992226807, 'max_depth': 7, 'subsample': 0.9709462303645454, 'colsample_bytree': 0.7191089399700726, 'reg_alpha': 0.057204499730080745, 'reg_lambda': 0.00015830110999314812, 'min_child_samples': 50}. Best is trial 5 with value: 47263.500345720655.\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_5712\\3184931164.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_5712\\3184931164.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'subsample': trial.suggest_uniform('subsample', 0.6, 1.0),\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_5712\\3184931164.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'colsample_bytree': trial.suggest_uniform('colsample_bytree', 0.6, 1.0),\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_5712\\3184931164.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'reg_alpha': trial.suggest_loguniform('reg_alpha', 1e-5, 10.0),\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_5712\\3184931164.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'reg_lambda': trial.suggest_loguniform('reg_lambda', 1e-5, 10.0),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008282 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 615\n",
      "[LightGBM] [Info] Number of data points in the train set: 43418, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 39329.732369\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\PC\\anaconda3-2\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "[I 2024-06-23 12:13:11,945] Trial 36 finished with value: 47773.088029073966 and parameters: {'num_leaves': 62, 'learning_rate': 0.014982701775944794, 'max_depth': 9, 'subsample': 0.8968622976599171, 'colsample_bytree': 0.6711824869379552, 'reg_alpha': 0.22801765230603424, 'reg_lambda': 0.07630941473698076, 'min_child_samples': 59}. Best is trial 5 with value: 47263.500345720655.\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_5712\\3184931164.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_5712\\3184931164.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'subsample': trial.suggest_uniform('subsample', 0.6, 1.0),\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_5712\\3184931164.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'colsample_bytree': trial.suggest_uniform('colsample_bytree', 0.6, 1.0),\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_5712\\3184931164.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'reg_alpha': trial.suggest_loguniform('reg_alpha', 1e-5, 10.0),\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_5712\\3184931164.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'reg_lambda': trial.suggest_loguniform('reg_lambda', 1e-5, 10.0),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004252 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 617\n",
      "[LightGBM] [Info] Number of data points in the train set: 43418, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 39329.732369\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\PC\\anaconda3-2\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "[I 2024-06-23 12:13:15,027] Trial 37 finished with value: 47719.987962342064 and parameters: {'num_leaves': 69, 'learning_rate': 0.044953004150970144, 'max_depth': 11, 'subsample': 0.7676549272020203, 'colsample_bytree': 0.7727495463049215, 'reg_alpha': 1.8545810320364609, 'reg_lambda': 0.3527177002369455, 'min_child_samples': 42}. Best is trial 5 with value: 47263.500345720655.\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_5712\\3184931164.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_5712\\3184931164.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'subsample': trial.suggest_uniform('subsample', 0.6, 1.0),\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_5712\\3184931164.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'colsample_bytree': trial.suggest_uniform('colsample_bytree', 0.6, 1.0),\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_5712\\3184931164.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'reg_alpha': trial.suggest_loguniform('reg_alpha', 1e-5, 10.0),\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_5712\\3184931164.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'reg_lambda': trial.suggest_loguniform('reg_lambda', 1e-5, 10.0),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.020231 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 617\n",
      "[LightGBM] [Info] Number of data points in the train set: 43418, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 39329.732369\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\PC\\anaconda3-2\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "[I 2024-06-23 12:13:17,493] Trial 38 finished with value: 47521.70557433044 and parameters: {'num_leaves': 74, 'learning_rate': 0.06561809801704312, 'max_depth': 6, 'subsample': 0.9329417321253382, 'colsample_bytree': 0.8266402508612634, 'reg_alpha': 1.0375469729128144e-05, 'reg_lambda': 0.01233471830216251, 'min_child_samples': 33}. Best is trial 5 with value: 47263.500345720655.\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_5712\\3184931164.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_5712\\3184931164.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'subsample': trial.suggest_uniform('subsample', 0.6, 1.0),\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_5712\\3184931164.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'colsample_bytree': trial.suggest_uniform('colsample_bytree', 0.6, 1.0),\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_5712\\3184931164.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'reg_alpha': trial.suggest_loguniform('reg_alpha', 1e-5, 10.0),\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_5712\\3184931164.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'reg_lambda': trial.suggest_loguniform('reg_lambda', 1e-5, 10.0),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.015553 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 615\n",
      "[LightGBM] [Info] Number of data points in the train set: 43418, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 39329.732369\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\PC\\anaconda3-2\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "[I 2024-06-23 12:13:20,379] Trial 39 finished with value: 49205.0488295399 and parameters: {'num_leaves': 51, 'learning_rate': 0.22065541126061422, 'max_depth': 14, 'subsample': 0.9803352379816823, 'colsample_bytree': 0.9919381085597447, 'reg_alpha': 0.01385479582440115, 'reg_lambda': 2.4834627419091992, 'min_child_samples': 64}. Best is trial 5 with value: 47263.500345720655.\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_5712\\3184931164.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_5712\\3184931164.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'subsample': trial.suggest_uniform('subsample', 0.6, 1.0),\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_5712\\3184931164.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'colsample_bytree': trial.suggest_uniform('colsample_bytree', 0.6, 1.0),\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_5712\\3184931164.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'reg_alpha': trial.suggest_loguniform('reg_alpha', 1e-5, 10.0),\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_5712\\3184931164.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'reg_lambda': trial.suggest_loguniform('reg_lambda', 1e-5, 10.0),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.015636 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 617\n",
      "[LightGBM] [Info] Number of data points in the train set: 43418, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 39329.732369\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\PC\\anaconda3-2\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "[I 2024-06-23 12:13:22,267] Trial 40 finished with value: 47771.63231415848 and parameters: {'num_leaves': 32, 'learning_rate': 0.015958340754130905, 'max_depth': 7, 'subsample': 0.9054954175103853, 'colsample_bytree': 0.735838188643962, 'reg_alpha': 0.0002732745756185212, 'reg_lambda': 0.0025001717108872556, 'min_child_samples': 45}. Best is trial 5 with value: 47263.500345720655.\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_5712\\3184931164.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_5712\\3184931164.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'subsample': trial.suggest_uniform('subsample', 0.6, 1.0),\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_5712\\3184931164.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'colsample_bytree': trial.suggest_uniform('colsample_bytree', 0.6, 1.0),\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_5712\\3184931164.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'reg_alpha': trial.suggest_loguniform('reg_alpha', 1e-5, 10.0),\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_5712\\3184931164.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'reg_lambda': trial.suggest_loguniform('reg_lambda', 1e-5, 10.0),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.015144 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 615\n",
      "[LightGBM] [Info] Number of data points in the train set: 43418, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 39329.732369\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\PC\\anaconda3-2\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "[I 2024-06-23 12:13:26,259] Trial 41 finished with value: 47285.03658267411 and parameters: {'num_leaves': 77, 'learning_rate': 0.02612699355076985, 'max_depth': 8, 'subsample': 0.9365587405211511, 'colsample_bytree': 0.6585621203367547, 'reg_alpha': 0.058105764108655936, 'reg_lambda': 0.3364191822420051, 'min_child_samples': 50}. Best is trial 5 with value: 47263.500345720655.\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_5712\\3184931164.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_5712\\3184931164.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'subsample': trial.suggest_uniform('subsample', 0.6, 1.0),\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_5712\\3184931164.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'colsample_bytree': trial.suggest_uniform('colsample_bytree', 0.6, 1.0),\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_5712\\3184931164.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'reg_alpha': trial.suggest_loguniform('reg_alpha', 1e-5, 10.0),\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_5712\\3184931164.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'reg_lambda': trial.suggest_loguniform('reg_lambda', 1e-5, 10.0),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009176 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 615\n",
      "[LightGBM] [Info] Number of data points in the train set: 43418, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 39329.732369\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\PC\\anaconda3-2\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "[I 2024-06-23 12:13:28,842] Trial 42 finished with value: 47250.39683656214 and parameters: {'num_leaves': 78, 'learning_rate': 0.028978185149279547, 'max_depth': 8, 'subsample': 0.936434365663524, 'colsample_bytree': 0.7050309902430671, 'reg_alpha': 0.042238075412521434, 'reg_lambda': 0.49553771490952214, 'min_child_samples': 51}. Best is trial 42 with value: 47250.39683656214.\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_5712\\3184931164.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_5712\\3184931164.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'subsample': trial.suggest_uniform('subsample', 0.6, 1.0),\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_5712\\3184931164.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'colsample_bytree': trial.suggest_uniform('colsample_bytree', 0.6, 1.0),\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_5712\\3184931164.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'reg_alpha': trial.suggest_loguniform('reg_alpha', 1e-5, 10.0),\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_5712\\3184931164.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'reg_lambda': trial.suggest_loguniform('reg_lambda', 1e-5, 10.0),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.014211 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 615\n",
      "[LightGBM] [Info] Number of data points in the train set: 43418, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 39329.732369\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\PC\\anaconda3-2\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "[I 2024-06-23 12:13:31,524] Trial 43 finished with value: 47274.25995255403 and parameters: {'num_leaves': 84, 'learning_rate': 0.030685910702326433, 'max_depth': 9, 'subsample': 0.9643882659980564, 'colsample_bytree': 0.6951730417657652, 'reg_alpha': 0.29075200887473174, 'reg_lambda': 1.0522125726292435, 'min_child_samples': 52}. Best is trial 42 with value: 47250.39683656214.\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_5712\\3184931164.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_5712\\3184931164.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'subsample': trial.suggest_uniform('subsample', 0.6, 1.0),\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_5712\\3184931164.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'colsample_bytree': trial.suggest_uniform('colsample_bytree', 0.6, 1.0),\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_5712\\3184931164.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'reg_alpha': trial.suggest_loguniform('reg_alpha', 1e-5, 10.0),\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_5712\\3184931164.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'reg_lambda': trial.suggest_loguniform('reg_lambda', 1e-5, 10.0),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.042160 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 615\n",
      "[LightGBM] [Info] Number of data points in the train set: 43418, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 39329.732369\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\PC\\anaconda3-2\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "[I 2024-06-23 12:13:35,841] Trial 44 finished with value: 47220.70371791789 and parameters: {'num_leaves': 100, 'learning_rate': 0.028758450770345504, 'max_depth': 9, 'subsample': 0.9796890193788262, 'colsample_bytree': 0.7065219901975103, 'reg_alpha': 0.3581324638929259, 'reg_lambda': 2.0031408204768573, 'min_child_samples': 54}. Best is trial 44 with value: 47220.70371791789.\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_5712\\3184931164.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_5712\\3184931164.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'subsample': trial.suggest_uniform('subsample', 0.6, 1.0),\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_5712\\3184931164.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'colsample_bytree': trial.suggest_uniform('colsample_bytree', 0.6, 1.0),\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_5712\\3184931164.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'reg_alpha': trial.suggest_loguniform('reg_alpha', 1e-5, 10.0),\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_5712\\3184931164.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'reg_lambda': trial.suggest_loguniform('reg_lambda', 1e-5, 10.0),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004613 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 615\n",
      "[LightGBM] [Info] Number of data points in the train set: 43418, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 39329.732369\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\PC\\anaconda3-2\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "[I 2024-06-23 12:13:39,845] Trial 45 finished with value: 47246.910514304334 and parameters: {'num_leaves': 100, 'learning_rate': 0.02842598043462858, 'max_depth': 9, 'subsample': 0.9150787546492432, 'colsample_bytree': 0.7137792462044901, 'reg_alpha': 0.41834784771558925, 'reg_lambda': 1.4155683603801894, 'min_child_samples': 53}. Best is trial 44 with value: 47220.70371791789.\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_5712\\3184931164.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_5712\\3184931164.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'subsample': trial.suggest_uniform('subsample', 0.6, 1.0),\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_5712\\3184931164.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'colsample_bytree': trial.suggest_uniform('colsample_bytree', 0.6, 1.0),\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_5712\\3184931164.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'reg_alpha': trial.suggest_loguniform('reg_alpha', 1e-5, 10.0),\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_5712\\3184931164.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'reg_lambda': trial.suggest_loguniform('reg_lambda', 1e-5, 10.0),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.017886 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 615\n",
      "[LightGBM] [Info] Number of data points in the train set: 43418, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 39329.732369\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\PC\\anaconda3-2\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "[I 2024-06-23 12:13:44,822] Trial 46 finished with value: 47288.49003580794 and parameters: {'num_leaves': 99, 'learning_rate': 0.03187685592414619, 'max_depth': 9, 'subsample': 0.9130343249008058, 'colsample_bytree': 0.7023846863688551, 'reg_alpha': 2.866696814875752, 'reg_lambda': 1.6960072781688817, 'min_child_samples': 52}. Best is trial 44 with value: 47220.70371791789.\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_5712\\3184931164.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_5712\\3184931164.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'subsample': trial.suggest_uniform('subsample', 0.6, 1.0),\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_5712\\3184931164.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'colsample_bytree': trial.suggest_uniform('colsample_bytree', 0.6, 1.0),\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_5712\\3184931164.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'reg_alpha': trial.suggest_loguniform('reg_alpha', 1e-5, 10.0),\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_5712\\3184931164.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'reg_lambda': trial.suggest_loguniform('reg_lambda', 1e-5, 10.0),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005591 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 615\n",
      "[LightGBM] [Info] Number of data points in the train set: 43418, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 39329.732369\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\PC\\anaconda3-2\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "[I 2024-06-23 12:13:46,926] Trial 47 finished with value: 47030.7971133361 and parameters: {'num_leaves': 100, 'learning_rate': 0.02909062925711322, 'max_depth': 9, 'subsample': 0.8534764783613766, 'colsample_bytree': 0.7310259101237966, 'reg_alpha': 0.3815604585392236, 'reg_lambda': 8.69647257000582, 'min_child_samples': 62}. Best is trial 47 with value: 47030.7971133361.\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_5712\\3184931164.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_5712\\3184931164.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'subsample': trial.suggest_uniform('subsample', 0.6, 1.0),\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_5712\\3184931164.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'colsample_bytree': trial.suggest_uniform('colsample_bytree', 0.6, 1.0),\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_5712\\3184931164.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'reg_alpha': trial.suggest_loguniform('reg_alpha', 1e-5, 10.0),\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_5712\\3184931164.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'reg_lambda': trial.suggest_loguniform('reg_lambda', 1e-5, 10.0),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002735 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 615\n",
      "[LightGBM] [Info] Number of data points in the train set: 43418, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 39329.732369\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\PC\\anaconda3-2\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "[I 2024-06-23 12:13:49,961] Trial 48 finished with value: 47431.1899632115 and parameters: {'num_leaves': 94, 'learning_rate': 0.017419241429175943, 'max_depth': 12, 'subsample': 0.8054548741291244, 'colsample_bytree': 0.7635906965838338, 'reg_alpha': 1.0347405262614833, 'reg_lambda': 4.707891061018038, 'min_child_samples': 61}. Best is trial 47 with value: 47030.7971133361.\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_5712\\3184931164.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_5712\\3184931164.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'subsample': trial.suggest_uniform('subsample', 0.6, 1.0),\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_5712\\3184931164.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'colsample_bytree': trial.suggest_uniform('colsample_bytree', 0.6, 1.0),\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_5712\\3184931164.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'reg_alpha': trial.suggest_loguniform('reg_alpha', 1e-5, 10.0),\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_5712\\3184931164.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'reg_lambda': trial.suggest_loguniform('reg_lambda', 1e-5, 10.0),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.476766 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 615\n",
      "[LightGBM] [Info] Number of data points in the train set: 43418, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 39329.732369\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\PC\\anaconda3-2\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "[I 2024-06-23 12:13:55,190] Trial 49 finished with value: 47488.37404550499 and parameters: {'num_leaves': 100, 'learning_rate': 0.02075497716312864, 'max_depth': 10, 'subsample': 0.8517652196296973, 'colsample_bytree': 0.7268783769254491, 'reg_alpha': 4.005669601144665, 'reg_lambda': 9.8283760552456, 'min_child_samples': 70}. Best is trial 47 with value: 47030.7971133361.\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_5712\\3184931164.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_5712\\3184931164.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'subsample': trial.suggest_uniform('subsample', 0.6, 1.0),\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_5712\\3184931164.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'colsample_bytree': trial.suggest_uniform('colsample_bytree', 0.6, 1.0),\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_5712\\3184931164.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'reg_alpha': trial.suggest_loguniform('reg_alpha', 1e-5, 10.0),\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_5712\\3184931164.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'reg_lambda': trial.suggest_loguniform('reg_lambda', 1e-5, 10.0),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.012406 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 617\n",
      "[LightGBM] [Info] Number of data points in the train set: 43418, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 39329.732369\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\PC\\anaconda3-2\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "[I 2024-06-23 12:13:57,435] Trial 50 finished with value: 47389.42803211185 and parameters: {'num_leaves': 91, 'learning_rate': 0.027701238173304124, 'max_depth': 11, 'subsample': 0.8769251632668433, 'colsample_bytree': 0.7445250017244398, 'reg_alpha': 0.8553210030977285, 'reg_lambda': 3.336142846615146, 'min_child_samples': 43}. Best is trial 47 with value: 47030.7971133361.\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_5712\\3184931164.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_5712\\3184931164.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'subsample': trial.suggest_uniform('subsample', 0.6, 1.0),\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_5712\\3184931164.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'colsample_bytree': trial.suggest_uniform('colsample_bytree', 0.6, 1.0),\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_5712\\3184931164.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'reg_alpha': trial.suggest_loguniform('reg_alpha', 1e-5, 10.0),\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_5712\\3184931164.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'reg_lambda': trial.suggest_loguniform('reg_lambda', 1e-5, 10.0),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.016641 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 615\n",
      "[LightGBM] [Info] Number of data points in the train set: 43418, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 39329.732369\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\PC\\anaconda3-2\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "[I 2024-06-23 12:14:05,321] Trial 51 finished with value: 47232.394578242966 and parameters: {'num_leaves': 97, 'learning_rate': 0.030783844148013172, 'max_depth': 10, 'subsample': 0.9781451933077588, 'colsample_bytree': 0.7091157261950283, 'reg_alpha': 0.30799719519881574, 'reg_lambda': 0.6626123538446356, 'min_child_samples': 55}. Best is trial 47 with value: 47030.7971133361.\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_5712\\3184931164.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_5712\\3184931164.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'subsample': trial.suggest_uniform('subsample', 0.6, 1.0),\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_5712\\3184931164.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'colsample_bytree': trial.suggest_uniform('colsample_bytree', 0.6, 1.0),\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_5712\\3184931164.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'reg_alpha': trial.suggest_loguniform('reg_alpha', 1e-5, 10.0),\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_5712\\3184931164.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'reg_lambda': trial.suggest_loguniform('reg_lambda', 1e-5, 10.0),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002960 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 615\n",
      "[LightGBM] [Info] Number of data points in the train set: 43418, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 39329.732369\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\PC\\anaconda3-2\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "[I 2024-06-23 12:14:09,160] Trial 52 finished with value: 47267.653545858026 and parameters: {'num_leaves': 96, 'learning_rate': 0.03200943576212919, 'max_depth': 10, 'subsample': 0.9145839106454199, 'colsample_bytree': 0.7080284359629699, 'reg_alpha': 0.11732373324959594, 'reg_lambda': 0.8052971349306642, 'min_child_samples': 57}. Best is trial 47 with value: 47030.7971133361.\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_5712\\3184931164.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_5712\\3184931164.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'subsample': trial.suggest_uniform('subsample', 0.6, 1.0),\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_5712\\3184931164.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'colsample_bytree': trial.suggest_uniform('colsample_bytree', 0.6, 1.0),\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_5712\\3184931164.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'reg_alpha': trial.suggest_loguniform('reg_alpha', 1e-5, 10.0),\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_5712\\3184931164.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'reg_lambda': trial.suggest_loguniform('reg_lambda', 1e-5, 10.0),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.020972 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 615\n",
      "[LightGBM] [Info] Number of data points in the train set: 43418, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 39329.732369\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\PC\\anaconda3-2\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "[I 2024-06-23 12:14:14,917] Trial 53 finished with value: 47307.21624677571 and parameters: {'num_leaves': 100, 'learning_rate': 0.03513962526161938, 'max_depth': 10, 'subsample': 0.9810526254658327, 'colsample_bytree': 0.7145478603714793, 'reg_alpha': 0.38693779791592947, 'reg_lambda': 0.6784170881015906, 'min_child_samples': 54}. Best is trial 47 with value: 47030.7971133361.\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_5712\\3184931164.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_5712\\3184931164.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'subsample': trial.suggest_uniform('subsample', 0.6, 1.0),\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_5712\\3184931164.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'colsample_bytree': trial.suggest_uniform('colsample_bytree', 0.6, 1.0),\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_5712\\3184931164.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'reg_alpha': trial.suggest_loguniform('reg_alpha', 1e-5, 10.0),\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_5712\\3184931164.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'reg_lambda': trial.suggest_loguniform('reg_lambda', 1e-5, 10.0),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.014305 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 615\n",
      "[LightGBM] [Info] Number of data points in the train set: 43418, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 39329.732369\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\PC\\anaconda3-2\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "[I 2024-06-23 12:14:18,425] Trial 54 finished with value: 47160.689332220776 and parameters: {'num_leaves': 93, 'learning_rate': 0.027906527991630802, 'max_depth': 9, 'subsample': 0.886998158024742, 'colsample_bytree': 0.6725937935213705, 'reg_alpha': 0.1568976170513108, 'reg_lambda': 8.262219997530527, 'min_child_samples': 62}. Best is trial 47 with value: 47030.7971133361.\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_5712\\3184931164.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_5712\\3184931164.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'subsample': trial.suggest_uniform('subsample', 0.6, 1.0),\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_5712\\3184931164.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'colsample_bytree': trial.suggest_uniform('colsample_bytree', 0.6, 1.0),\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_5712\\3184931164.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'reg_alpha': trial.suggest_loguniform('reg_alpha', 1e-5, 10.0),\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_5712\\3184931164.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'reg_lambda': trial.suggest_loguniform('reg_lambda', 1e-5, 10.0),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007416 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 615\n",
      "[LightGBM] [Info] Number of data points in the train set: 43418, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 39329.732369\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\PC\\anaconda3-2\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "[I 2024-06-23 12:14:21,600] Trial 55 finished with value: 47341.49371141629 and parameters: {'num_leaves': 93, 'learning_rate': 0.0210346271626771, 'max_depth': 9, 'subsample': 0.8485495792812808, 'colsample_bytree': 0.6722167794688765, 'reg_alpha': 0.19145790955951936, 'reg_lambda': 6.885440109198536, 'min_child_samples': 63}. Best is trial 47 with value: 47030.7971133361.\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_5712\\3184931164.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_5712\\3184931164.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'subsample': trial.suggest_uniform('subsample', 0.6, 1.0),\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_5712\\3184931164.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'colsample_bytree': trial.suggest_uniform('colsample_bytree', 0.6, 1.0),\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_5712\\3184931164.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'reg_alpha': trial.suggest_loguniform('reg_alpha', 1e-5, 10.0),\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_5712\\3184931164.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'reg_lambda': trial.suggest_loguniform('reg_lambda', 1e-5, 10.0),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.018742 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 615\n",
      "[LightGBM] [Info] Number of data points in the train set: 43418, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 39329.732369\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\PC\\anaconda3-2\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "[I 2024-06-23 12:14:24,661] Trial 56 finished with value: 47241.27648025637 and parameters: {'num_leaves': 97, 'learning_rate': 0.02594686763270808, 'max_depth': 9, 'subsample': 0.901630774443682, 'colsample_bytree': 0.6336979184033574, 'reg_alpha': 0.577486812582813, 'reg_lambda': 1.607707918916694, 'min_child_samples': 68}. Best is trial 47 with value: 47030.7971133361.\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_5712\\3184931164.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_5712\\3184931164.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'subsample': trial.suggest_uniform('subsample', 0.6, 1.0),\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_5712\\3184931164.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'colsample_bytree': trial.suggest_uniform('colsample_bytree', 0.6, 1.0),\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_5712\\3184931164.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'reg_alpha': trial.suggest_loguniform('reg_alpha', 1e-5, 10.0),\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_5712\\3184931164.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'reg_lambda': trial.suggest_loguniform('reg_lambda', 1e-5, 10.0),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.016093 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 615\n",
      "[LightGBM] [Info] Number of data points in the train set: 43418, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 39329.732369\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\PC\\anaconda3-2\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "[I 2024-06-23 12:14:29,407] Trial 57 finished with value: 47348.21895117658 and parameters: {'num_leaves': 98, 'learning_rate': 0.0249613035057314, 'max_depth': 10, 'subsample': 0.8223785884548132, 'colsample_bytree': 0.629844337436923, 'reg_alpha': 1.3705350057047045, 'reg_lambda': 1.6518686967369238, 'min_child_samples': 72}. Best is trial 47 with value: 47030.7971133361.\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_5712\\3184931164.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_5712\\3184931164.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'subsample': trial.suggest_uniform('subsample', 0.6, 1.0),\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_5712\\3184931164.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'colsample_bytree': trial.suggest_uniform('colsample_bytree', 0.6, 1.0),\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_5712\\3184931164.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'reg_alpha': trial.suggest_loguniform('reg_alpha', 1e-5, 10.0),\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_5712\\3184931164.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'reg_lambda': trial.suggest_loguniform('reg_lambda', 1e-5, 10.0),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004678 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 615\n",
      "[LightGBM] [Info] Number of data points in the train set: 43418, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 39329.732369\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\PC\\anaconda3-2\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "[I 2024-06-23 12:14:32,982] Trial 58 finished with value: 48163.73780962434 and parameters: {'num_leaves': 89, 'learning_rate': 0.01294114243997913, 'max_depth': 9, 'subsample': 0.8847533199070741, 'colsample_bytree': 0.6133749633625979, 'reg_alpha': 4.955658982994745, 'reg_lambda': 3.2768454704766654, 'min_child_samples': 66}. Best is trial 47 with value: 47030.7971133361.\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_5712\\3184931164.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_5712\\3184931164.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'subsample': trial.suggest_uniform('subsample', 0.6, 1.0),\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_5712\\3184931164.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'colsample_bytree': trial.suggest_uniform('colsample_bytree', 0.6, 1.0),\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_5712\\3184931164.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'reg_alpha': trial.suggest_loguniform('reg_alpha', 1e-5, 10.0),\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_5712\\3184931164.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'reg_lambda': trial.suggest_loguniform('reg_lambda', 1e-5, 10.0),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012338 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 615\n",
      "[LightGBM] [Info] Number of data points in the train set: 43418, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 39329.732369\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\PC\\anaconda3-2\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "[I 2024-06-23 12:14:35,728] Trial 59 finished with value: 47356.64182874078 and parameters: {'num_leaves': 97, 'learning_rate': 0.040475719078674546, 'max_depth': 11, 'subsample': 0.7760803595105176, 'colsample_bytree': 0.6331907038486027, 'reg_alpha': 0.538386838798283, 'reg_lambda': 1.5359556949272963, 'min_child_samples': 74}. Best is trial 47 with value: 47030.7971133361.\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_5712\\3184931164.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_5712\\3184931164.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'subsample': trial.suggest_uniform('subsample', 0.6, 1.0),\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_5712\\3184931164.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'colsample_bytree': trial.suggest_uniform('colsample_bytree', 0.6, 1.0),\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_5712\\3184931164.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'reg_alpha': trial.suggest_loguniform('reg_alpha', 1e-5, 10.0),\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_5712\\3184931164.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'reg_lambda': trial.suggest_loguniform('reg_lambda', 1e-5, 10.0),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007259 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 615\n",
      "[LightGBM] [Info] Number of data points in the train set: 43418, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 39329.732369\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\PC\\anaconda3-2\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "[I 2024-06-23 12:14:38,842] Trial 60 finished with value: 47711.35773590357 and parameters: {'num_leaves': 93, 'learning_rate': 0.017151726329672462, 'max_depth': 9, 'subsample': 0.8641709439965435, 'colsample_bytree': 0.6705940736781482, 'reg_alpha': 0.7231999170885755, 'reg_lambda': 9.933324539848966, 'min_child_samples': 69}. Best is trial 47 with value: 47030.7971133361.\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_5712\\3184931164.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_5712\\3184931164.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'subsample': trial.suggest_uniform('subsample', 0.6, 1.0),\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_5712\\3184931164.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'colsample_bytree': trial.suggest_uniform('colsample_bytree', 0.6, 1.0),\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_5712\\3184931164.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'reg_alpha': trial.suggest_loguniform('reg_alpha', 1e-5, 10.0),\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_5712\\3184931164.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'reg_lambda': trial.suggest_loguniform('reg_lambda', 1e-5, 10.0),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.062566 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 615\n",
      "[LightGBM] [Info] Number of data points in the train set: 43418, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 39329.732369\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\PC\\anaconda3-2\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "[I 2024-06-23 12:14:41,326] Trial 61 finished with value: 47295.36517650338 and parameters: {'num_leaves': 86, 'learning_rate': 0.027204360050958606, 'max_depth': 10, 'subsample': 0.9016620070886315, 'colsample_bytree': 0.7283927685686495, 'reg_alpha': 0.17480312074160573, 'reg_lambda': 0.5062648998683746, 'min_child_samples': 58}. Best is trial 47 with value: 47030.7971133361.\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_5712\\3184931164.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_5712\\3184931164.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'subsample': trial.suggest_uniform('subsample', 0.6, 1.0),\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_5712\\3184931164.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'colsample_bytree': trial.suggest_uniform('colsample_bytree', 0.6, 1.0),\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_5712\\3184931164.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'reg_alpha': trial.suggest_loguniform('reg_alpha', 1e-5, 10.0),\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_5712\\3184931164.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'reg_lambda': trial.suggest_loguniform('reg_lambda', 1e-5, 10.0),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.017736 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 615\n",
      "[LightGBM] [Info] Number of data points in the train set: 43418, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 39329.732369\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\PC\\anaconda3-2\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "[I 2024-06-23 12:14:43,855] Trial 62 finished with value: 47180.6307841709 and parameters: {'num_leaves': 92, 'learning_rate': 0.02872978649194083, 'max_depth': 9, 'subsample': 0.8854637766428898, 'colsample_bytree': 0.789791677764828, 'reg_alpha': 0.3321366287165132, 'reg_lambda': 0.20053726531419921, 'min_child_samples': 60}. Best is trial 47 with value: 47030.7971133361.\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_5712\\3184931164.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_5712\\3184931164.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'subsample': trial.suggest_uniform('subsample', 0.6, 1.0),\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_5712\\3184931164.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'colsample_bytree': trial.suggest_uniform('colsample_bytree', 0.6, 1.0),\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_5712\\3184931164.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'reg_alpha': trial.suggest_loguniform('reg_alpha', 1e-5, 10.0),\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_5712\\3184931164.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'reg_lambda': trial.suggest_loguniform('reg_lambda', 1e-5, 10.0),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013467 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 615\n",
      "[LightGBM] [Info] Number of data points in the train set: 43418, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 39329.732369\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\PC\\anaconda3-2\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "[I 2024-06-23 12:14:46,305] Trial 63 finished with value: 47143.80072601046 and parameters: {'num_leaves': 92, 'learning_rate': 0.034398477908126314, 'max_depth': 9, 'subsample': 0.8819485937827428, 'colsample_bytree': 0.79520065314099, 'reg_alpha': 0.30664684477241333, 'reg_lambda': 0.21934328706090336, 'min_child_samples': 61}. Best is trial 47 with value: 47030.7971133361.\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_5712\\3184931164.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_5712\\3184931164.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'subsample': trial.suggest_uniform('subsample', 0.6, 1.0),\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_5712\\3184931164.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'colsample_bytree': trial.suggest_uniform('colsample_bytree', 0.6, 1.0),\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_5712\\3184931164.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'reg_alpha': trial.suggest_loguniform('reg_alpha', 1e-5, 10.0),\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_5712\\3184931164.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'reg_lambda': trial.suggest_loguniform('reg_lambda', 1e-5, 10.0),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003437 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 615\n",
      "[LightGBM] [Info] Number of data points in the train set: 43418, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 39329.732369\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\PC\\anaconda3-2\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "[I 2024-06-23 12:14:49,392] Trial 64 finished with value: 47196.232737515675 and parameters: {'num_leaves': 91, 'learning_rate': 0.023743745181246292, 'max_depth': 10, 'subsample': 0.8150343100233038, 'colsample_bytree': 0.7909247255871322, 'reg_alpha': 1.3120399969384131, 'reg_lambda': 0.26336953268209, 'min_child_samples': 61}. Best is trial 47 with value: 47030.7971133361.\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_5712\\3184931164.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_5712\\3184931164.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'subsample': trial.suggest_uniform('subsample', 0.6, 1.0),\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_5712\\3184931164.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'colsample_bytree': trial.suggest_uniform('colsample_bytree', 0.6, 1.0),\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_5712\\3184931164.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'reg_alpha': trial.suggest_loguniform('reg_alpha', 1e-5, 10.0),\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_5712\\3184931164.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'reg_lambda': trial.suggest_loguniform('reg_lambda', 1e-5, 10.0),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.020491 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 615\n",
      "[LightGBM] [Info] Number of data points in the train set: 43418, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 39329.732369\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\PC\\anaconda3-2\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "[I 2024-06-23 12:14:51,958] Trial 65 finished with value: 47232.26997482827 and parameters: {'num_leaves': 91, 'learning_rate': 0.0342483663276969, 'max_depth': 10, 'subsample': 0.7343992545311087, 'colsample_bytree': 0.7945696698703696, 'reg_alpha': 1.4973360538882339, 'reg_lambda': 0.24361775722508394, 'min_child_samples': 61}. Best is trial 47 with value: 47030.7971133361.\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_5712\\3184931164.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_5712\\3184931164.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'subsample': trial.suggest_uniform('subsample', 0.6, 1.0),\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_5712\\3184931164.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'colsample_bytree': trial.suggest_uniform('colsample_bytree', 0.6, 1.0),\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_5712\\3184931164.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'reg_alpha': trial.suggest_loguniform('reg_alpha', 1e-5, 10.0),\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_5712\\3184931164.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'reg_lambda': trial.suggest_loguniform('reg_lambda', 1e-5, 10.0),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.015329 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 615\n",
      "[LightGBM] [Info] Number of data points in the train set: 43418, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 39329.732369\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\PC\\anaconda3-2\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "[I 2024-06-23 12:14:54,536] Trial 66 finished with value: 47357.96430274346 and parameters: {'num_leaves': 91, 'learning_rate': 0.0487474867564004, 'max_depth': 11, 'subsample': 0.702093135408144, 'colsample_bytree': 0.7857715458458573, 'reg_alpha': 8.92859544205361, 'reg_lambda': 0.20739458204581068, 'min_child_samples': 61}. Best is trial 47 with value: 47030.7971133361.\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_5712\\3184931164.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_5712\\3184931164.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'subsample': trial.suggest_uniform('subsample', 0.6, 1.0),\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_5712\\3184931164.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'colsample_bytree': trial.suggest_uniform('colsample_bytree', 0.6, 1.0),\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_5712\\3184931164.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'reg_alpha': trial.suggest_loguniform('reg_alpha', 1e-5, 10.0),\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_5712\\3184931164.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'reg_lambda': trial.suggest_loguniform('reg_lambda', 1e-5, 10.0),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011383 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 615\n",
      "[LightGBM] [Info] Number of data points in the train set: 43418, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 39329.732369\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\PC\\anaconda3-2\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "[I 2024-06-23 12:14:57,955] Trial 67 finished with value: 47387.377841752874 and parameters: {'num_leaves': 84, 'learning_rate': 0.03446947432450113, 'max_depth': 10, 'subsample': 0.7896678377281273, 'colsample_bytree': 0.8645137961073939, 'reg_alpha': 1.7994806388216502, 'reg_lambda': 0.07522150817738822, 'min_child_samples': 78}. Best is trial 47 with value: 47030.7971133361.\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_5712\\3184931164.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_5712\\3184931164.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'subsample': trial.suggest_uniform('subsample', 0.6, 1.0),\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_5712\\3184931164.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'colsample_bytree': trial.suggest_uniform('colsample_bytree', 0.6, 1.0),\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_5712\\3184931164.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'reg_alpha': trial.suggest_loguniform('reg_alpha', 1e-5, 10.0),\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_5712\\3184931164.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'reg_lambda': trial.suggest_loguniform('reg_lambda', 1e-5, 10.0),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.018984 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 615\n",
      "[LightGBM] [Info] Number of data points in the train set: 43418, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 39329.732369\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\PC\\anaconda3-2\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "[I 2024-06-23 12:15:00,103] Trial 68 finished with value: 47225.538364343476 and parameters: {'num_leaves': 88, 'learning_rate': 0.038944049137729364, 'max_depth': 9, 'subsample': 0.7372880169198435, 'colsample_bytree': 0.7867318651992825, 'reg_alpha': 1.2216219551479004, 'reg_lambda': 0.29631571364542253, 'min_child_samples': 63}. Best is trial 47 with value: 47030.7971133361.\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_5712\\3184931164.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_5712\\3184931164.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'subsample': trial.suggest_uniform('subsample', 0.6, 1.0),\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_5712\\3184931164.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'colsample_bytree': trial.suggest_uniform('colsample_bytree', 0.6, 1.0),\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_5712\\3184931164.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'reg_alpha': trial.suggest_loguniform('reg_alpha', 1e-5, 10.0),\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_5712\\3184931164.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'reg_lambda': trial.suggest_loguniform('reg_lambda', 1e-5, 10.0),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.065590 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 615\n",
      "[LightGBM] [Info] Number of data points in the train set: 43418, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 39329.732369\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\PC\\anaconda3-2\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "[I 2024-06-23 12:15:02,657] Trial 69 finished with value: 47287.57706664562 and parameters: {'num_leaves': 88, 'learning_rate': 0.021566805804518023, 'max_depth': 9, 'subsample': 0.7576490631295887, 'colsample_bytree': 0.8133873504940131, 'reg_alpha': 3.261806838218856, 'reg_lambda': 5.379142819404277, 'min_child_samples': 65}. Best is trial 47 with value: 47030.7971133361.\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_5712\\3184931164.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_5712\\3184931164.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'subsample': trial.suggest_uniform('subsample', 0.6, 1.0),\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_5712\\3184931164.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'colsample_bytree': trial.suggest_uniform('colsample_bytree', 0.6, 1.0),\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_5712\\3184931164.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'reg_alpha': trial.suggest_loguniform('reg_alpha', 1e-5, 10.0),\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_5712\\3184931164.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'reg_lambda': trial.suggest_loguniform('reg_lambda', 1e-5, 10.0),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.080845 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 615\n",
      "[LightGBM] [Info] Number of data points in the train set: 43418, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 39329.732369\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\PC\\anaconda3-2\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "[I 2024-06-23 12:15:04,784] Trial 70 finished with value: 47271.961884825614 and parameters: {'num_leaves': 93, 'learning_rate': 0.038183348595683064, 'max_depth': 8, 'subsample': 0.8149992567554543, 'colsample_bytree': 0.7637873401285463, 'reg_alpha': 1.1371916982366823, 'reg_lambda': 0.028974358466929896, 'min_child_samples': 58}. Best is trial 47 with value: 47030.7971133361.\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_5712\\3184931164.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_5712\\3184931164.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'subsample': trial.suggest_uniform('subsample', 0.6, 1.0),\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_5712\\3184931164.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'colsample_bytree': trial.suggest_uniform('colsample_bytree', 0.6, 1.0),\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_5712\\3184931164.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'reg_alpha': trial.suggest_loguniform('reg_alpha', 1e-5, 10.0),\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_5712\\3184931164.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'reg_lambda': trial.suggest_loguniform('reg_lambda', 1e-5, 10.0),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011489 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 615\n",
      "[LightGBM] [Info] Number of data points in the train set: 43418, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 39329.732369\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\PC\\anaconda3-2\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "[I 2024-06-23 12:15:08,146] Trial 71 finished with value: 47245.35053729808 and parameters: {'num_leaves': 85, 'learning_rate': 0.042472041279179716, 'max_depth': 9, 'subsample': 0.7414527898701964, 'colsample_bytree': 0.7926086337361579, 'reg_alpha': 5.833625543535698, 'reg_lambda': 0.269277232569886, 'min_child_samples': 62}. Best is trial 47 with value: 47030.7971133361.\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_5712\\3184931164.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_5712\\3184931164.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'subsample': trial.suggest_uniform('subsample', 0.6, 1.0),\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_5712\\3184931164.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'colsample_bytree': trial.suggest_uniform('colsample_bytree', 0.6, 1.0),\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_5712\\3184931164.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'reg_alpha': trial.suggest_loguniform('reg_alpha', 1e-5, 10.0),\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_5712\\3184931164.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'reg_lambda': trial.suggest_loguniform('reg_lambda', 1e-5, 10.0),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.016053 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 615\n",
      "[LightGBM] [Info] Number of data points in the train set: 43418, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 39329.732369\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\PC\\anaconda3-2\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "[I 2024-06-23 12:15:10,171] Trial 72 finished with value: 47293.27018795469 and parameters: {'num_leaves': 91, 'learning_rate': 0.02355604232158013, 'max_depth': 10, 'subsample': 0.7001328148892817, 'colsample_bytree': 0.7986528643660015, 'reg_alpha': 2.61326268959475, 'reg_lambda': 0.1833574155009776, 'min_child_samples': 68}. Best is trial 47 with value: 47030.7971133361.\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_5712\\3184931164.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_5712\\3184931164.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'subsample': trial.suggest_uniform('subsample', 0.6, 1.0),\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_5712\\3184931164.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'colsample_bytree': trial.suggest_uniform('colsample_bytree', 0.6, 1.0),\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_5712\\3184931164.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'reg_alpha': trial.suggest_loguniform('reg_alpha', 1e-5, 10.0),\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_5712\\3184931164.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'reg_lambda': trial.suggest_loguniform('reg_lambda', 1e-5, 10.0),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002990 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 615\n",
      "[LightGBM] [Info] Number of data points in the train set: 43418, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 39329.732369\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\PC\\anaconda3-2\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "[I 2024-06-23 12:15:13,155] Trial 73 finished with value: 47343.271745203376 and parameters: {'num_leaves': 95, 'learning_rate': 0.03317620294171829, 'max_depth': 9, 'subsample': 0.6666729349928702, 'colsample_bytree': 0.8485237868364259, 'reg_alpha': 1.760956122801871, 'reg_lambda': 2.688452547912529, 'min_child_samples': 59}. Best is trial 47 with value: 47030.7971133361.\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_5712\\3184931164.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_5712\\3184931164.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'subsample': trial.suggest_uniform('subsample', 0.6, 1.0),\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_5712\\3184931164.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'colsample_bytree': trial.suggest_uniform('colsample_bytree', 0.6, 1.0),\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_5712\\3184931164.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'reg_alpha': trial.suggest_loguniform('reg_alpha', 1e-5, 10.0),\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_5712\\3184931164.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'reg_lambda': trial.suggest_loguniform('reg_lambda', 1e-5, 10.0),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.029197 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 615\n",
      "[LightGBM] [Info] Number of data points in the train set: 43418, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 39329.732369\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\PC\\anaconda3-2\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "[I 2024-06-23 12:15:16,735] Trial 74 finished with value: 47515.16920425763 and parameters: {'num_leaves': 88, 'learning_rate': 0.019080197405554847, 'max_depth': 10, 'subsample': 0.7432299286800335, 'colsample_bytree': 0.8217054192847625, 'reg_alpha': 0.25669348229586375, 'reg_lambda': 0.05170663024839306, 'min_child_samples': 66}. Best is trial 47 with value: 47030.7971133361.\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_5712\\3184931164.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_5712\\3184931164.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'subsample': trial.suggest_uniform('subsample', 0.6, 1.0),\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_5712\\3184931164.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'colsample_bytree': trial.suggest_uniform('colsample_bytree', 0.6, 1.0),\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_5712\\3184931164.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'reg_alpha': trial.suggest_loguniform('reg_alpha', 1e-5, 10.0),\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_5712\\3184931164.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'reg_lambda': trial.suggest_loguniform('reg_lambda', 1e-5, 10.0),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.016357 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 615\n",
      "[LightGBM] [Info] Number of data points in the train set: 43418, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 39329.732369\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\PC\\anaconda3-2\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "[I 2024-06-23 12:15:19,073] Trial 75 finished with value: 47572.43538180356 and parameters: {'num_leaves': 92, 'learning_rate': 0.049040377627818814, 'max_depth': 8, 'subsample': 0.8408483274965919, 'colsample_bytree': 0.7740394799643461, 'reg_alpha': 0.1361194088325308, 'reg_lambda': 0.10853605249327404, 'min_child_samples': 76}. Best is trial 47 with value: 47030.7971133361.\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_5712\\3184931164.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_5712\\3184931164.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'subsample': trial.suggest_uniform('subsample', 0.6, 1.0),\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_5712\\3184931164.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'colsample_bytree': trial.suggest_uniform('colsample_bytree', 0.6, 1.0),\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_5712\\3184931164.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'reg_alpha': trial.suggest_loguniform('reg_alpha', 1e-5, 10.0),\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_5712\\3184931164.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'reg_lambda': trial.suggest_loguniform('reg_lambda', 1e-5, 10.0),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014993 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 615\n",
      "[LightGBM] [Info] Number of data points in the train set: 43418, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 39329.732369\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\PC\\anaconda3-2\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "[I 2024-06-23 12:15:22,124] Trial 76 finished with value: 47471.11660620587 and parameters: {'num_leaves': 95, 'learning_rate': 0.03689978843844921, 'max_depth': 10, 'subsample': 0.7239642422013502, 'colsample_bytree': 0.9476560237832987, 'reg_alpha': 0.705281418450796, 'reg_lambda': 0.2406974085770005, 'min_child_samples': 56}. Best is trial 47 with value: 47030.7971133361.\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_5712\\3184931164.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_5712\\3184931164.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'subsample': trial.suggest_uniform('subsample', 0.6, 1.0),\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_5712\\3184931164.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'colsample_bytree': trial.suggest_uniform('colsample_bytree', 0.6, 1.0),\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_5712\\3184931164.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'reg_alpha': trial.suggest_loguniform('reg_alpha', 1e-5, 10.0),\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_5712\\3184931164.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'reg_lambda': trial.suggest_loguniform('reg_lambda', 1e-5, 10.0),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.048761 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 615\n",
      "[LightGBM] [Info] Number of data points in the train set: 43418, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 39329.732369\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\PC\\anaconda3-2\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "[I 2024-06-23 12:15:24,426] Trial 77 finished with value: 47158.36527953038 and parameters: {'num_leaves': 89, 'learning_rate': 0.02434406463799372, 'max_depth': 11, 'subsample': 0.7867282720973406, 'colsample_bytree': 0.7578429217732078, 'reg_alpha': 8.207972412515652e-05, 'reg_lambda': 3.9155108322188896, 'min_child_samples': 61}. Best is trial 47 with value: 47030.7971133361.\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_5712\\3184931164.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_5712\\3184931164.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'subsample': trial.suggest_uniform('subsample', 0.6, 1.0),\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_5712\\3184931164.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'colsample_bytree': trial.suggest_uniform('colsample_bytree', 0.6, 1.0),\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_5712\\3184931164.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'reg_alpha': trial.suggest_loguniform('reg_alpha', 1e-5, 10.0),\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_5712\\3184931164.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'reg_lambda': trial.suggest_loguniform('reg_lambda', 1e-5, 10.0),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002796 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 615\n",
      "[LightGBM] [Info] Number of data points in the train set: 43418, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 39329.732369\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\PC\\anaconda3-2\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "[I 2024-06-23 12:15:27,368] Trial 78 finished with value: 47323.85367185038 and parameters: {'num_leaves': 80, 'learning_rate': 0.023404828169782586, 'max_depth': 12, 'subsample': 0.7977681979927289, 'colsample_bytree': 0.758653437570361, 'reg_alpha': 0.09177782371368223, 'reg_lambda': 4.385755703575005, 'min_child_samples': 72}. Best is trial 47 with value: 47030.7971133361.\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_5712\\3184931164.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_5712\\3184931164.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'subsample': trial.suggest_uniform('subsample', 0.6, 1.0),\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_5712\\3184931164.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'colsample_bytree': trial.suggest_uniform('colsample_bytree', 0.6, 1.0),\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_5712\\3184931164.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'reg_alpha': trial.suggest_loguniform('reg_alpha', 1e-5, 10.0),\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_5712\\3184931164.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'reg_lambda': trial.suggest_loguniform('reg_lambda', 1e-5, 10.0),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.019533 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 615\n",
      "[LightGBM] [Info] Number of data points in the train set: 43418, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 39329.732369\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\PC\\anaconda3-2\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "[I 2024-06-23 12:15:29,589] Trial 79 finished with value: 47179.76554426933 and parameters: {'num_leaves': 82, 'learning_rate': 0.024648259384376817, 'max_depth': 11, 'subsample': 0.8609648548208695, 'colsample_bytree': 0.7862048463873167, 'reg_alpha': 0.0007529354657241135, 'reg_lambda': 6.841686715523531, 'min_child_samples': 64}. Best is trial 47 with value: 47030.7971133361.\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_5712\\3184931164.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_5712\\3184931164.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'subsample': trial.suggest_uniform('subsample', 0.6, 1.0),\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_5712\\3184931164.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'colsample_bytree': trial.suggest_uniform('colsample_bytree', 0.6, 1.0),\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_5712\\3184931164.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'reg_alpha': trial.suggest_loguniform('reg_alpha', 1e-5, 10.0),\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_5712\\3184931164.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'reg_lambda': trial.suggest_loguniform('reg_lambda', 1e-5, 10.0),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002509 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 615\n",
      "[LightGBM] [Info] Number of data points in the train set: 43418, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 39329.732369\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\PC\\anaconda3-2\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "[I 2024-06-23 12:15:32,259] Trial 80 finished with value: 47333.93418993532 and parameters: {'num_leaves': 82, 'learning_rate': 0.020566272588053356, 'max_depth': 13, 'subsample': 0.8384499271998181, 'colsample_bytree': 0.7381424666572366, 'reg_alpha': 8.134058200204402e-05, 'reg_lambda': 6.654623834604011, 'min_child_samples': 49}. Best is trial 47 with value: 47030.7971133361.\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_5712\\3184931164.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_5712\\3184931164.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'subsample': trial.suggest_uniform('subsample', 0.6, 1.0),\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_5712\\3184931164.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'colsample_bytree': trial.suggest_uniform('colsample_bytree', 0.6, 1.0),\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_5712\\3184931164.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'reg_alpha': trial.suggest_loguniform('reg_alpha', 1e-5, 10.0),\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_5712\\3184931164.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'reg_lambda': trial.suggest_loguniform('reg_lambda', 1e-5, 10.0),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002998 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 615\n",
      "[LightGBM] [Info] Number of data points in the train set: 43418, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 39329.732369\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\PC\\anaconda3-2\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "[I 2024-06-23 12:15:34,473] Trial 81 finished with value: 47164.4830117317 and parameters: {'num_leaves': 88, 'learning_rate': 0.025480690279371346, 'max_depth': 11, 'subsample': 0.8633476538577257, 'colsample_bytree': 0.7822722366023966, 'reg_alpha': 0.00025405409442786524, 'reg_lambda': 7.864701365164506, 'min_child_samples': 64}. Best is trial 47 with value: 47030.7971133361.\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_5712\\3184931164.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_5712\\3184931164.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'subsample': trial.suggest_uniform('subsample', 0.6, 1.0),\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_5712\\3184931164.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'colsample_bytree': trial.suggest_uniform('colsample_bytree', 0.6, 1.0),\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_5712\\3184931164.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'reg_alpha': trial.suggest_loguniform('reg_alpha', 1e-5, 10.0),\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_5712\\3184931164.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'reg_lambda': trial.suggest_loguniform('reg_lambda', 1e-5, 10.0),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005315 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 615\n",
      "[LightGBM] [Info] Number of data points in the train set: 43418, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 39329.732369\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\PC\\anaconda3-2\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "[I 2024-06-23 12:15:37,286] Trial 82 finished with value: 47315.48112678176 and parameters: {'num_leaves': 83, 'learning_rate': 0.02531794487992101, 'max_depth': 12, 'subsample': 0.865637476794146, 'colsample_bytree': 0.7705202769607216, 'reg_alpha': 0.00013500955816351417, 'reg_lambda': 2.315499038652968, 'min_child_samples': 66}. Best is trial 47 with value: 47030.7971133361.\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_5712\\3184931164.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_5712\\3184931164.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'subsample': trial.suggest_uniform('subsample', 0.6, 1.0),\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_5712\\3184931164.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'colsample_bytree': trial.suggest_uniform('colsample_bytree', 0.6, 1.0),\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_5712\\3184931164.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'reg_alpha': trial.suggest_loguniform('reg_alpha', 1e-5, 10.0),\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_5712\\3184931164.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'reg_lambda': trial.suggest_loguniform('reg_lambda', 1e-5, 10.0),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.048015 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 615\n",
      "[LightGBM] [Info] Number of data points in the train set: 43418, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 39329.732369\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\PC\\anaconda3-2\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "[I 2024-06-23 12:15:40,054] Trial 83 finished with value: 47188.15641962592 and parameters: {'num_leaves': 79, 'learning_rate': 0.029483200874307, 'max_depth': 11, 'subsample': 0.8829686702790541, 'colsample_bytree': 0.8075946394989485, 'reg_alpha': 4.0763898656106373e-05, 'reg_lambda': 7.3819309685333, 'min_child_samples': 58}. Best is trial 47 with value: 47030.7971133361.\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_5712\\3184931164.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_5712\\3184931164.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'subsample': trial.suggest_uniform('subsample', 0.6, 1.0),\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_5712\\3184931164.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'colsample_bytree': trial.suggest_uniform('colsample_bytree', 0.6, 1.0),\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_5712\\3184931164.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'reg_alpha': trial.suggest_loguniform('reg_alpha', 1e-5, 10.0),\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_5712\\3184931164.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'reg_lambda': trial.suggest_loguniform('reg_lambda', 1e-5, 10.0),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.710006 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 615\n",
      "[LightGBM] [Info] Number of data points in the train set: 43418, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 39329.732369\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\PC\\anaconda3-2\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "[I 2024-06-23 12:15:44,103] Trial 84 finished with value: 47650.56609707731 and parameters: {'num_leaves': 89, 'learning_rate': 0.017360878565067184, 'max_depth': 11, 'subsample': 0.8807686996039432, 'colsample_bytree': 0.8084064447306023, 'reg_alpha': 4.259199976809703e-05, 'reg_lambda': 8.330921400153201, 'min_child_samples': 70}. Best is trial 47 with value: 47030.7971133361.\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_5712\\3184931164.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_5712\\3184931164.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'subsample': trial.suggest_uniform('subsample', 0.6, 1.0),\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_5712\\3184931164.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'colsample_bytree': trial.suggest_uniform('colsample_bytree', 0.6, 1.0),\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_5712\\3184931164.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'reg_alpha': trial.suggest_loguniform('reg_alpha', 1e-5, 10.0),\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_5712\\3184931164.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'reg_lambda': trial.suggest_loguniform('reg_lambda', 1e-5, 10.0),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002663 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 615\n",
      "[LightGBM] [Info] Number of data points in the train set: 43418, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 39329.732369\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\PC\\anaconda3-2\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "[I 2024-06-23 12:15:47,771] Trial 85 finished with value: 47299.08843742813 and parameters: {'num_leaves': 80, 'learning_rate': 0.02278043095590356, 'max_depth': 11, 'subsample': 0.8575893563205225, 'colsample_bytree': 0.8366048947748065, 'reg_alpha': 0.0005631249386121676, 'reg_lambda': 4.933637020548143, 'min_child_samples': 60}. Best is trial 47 with value: 47030.7971133361.\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_5712\\3184931164.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_5712\\3184931164.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'subsample': trial.suggest_uniform('subsample', 0.6, 1.0),\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_5712\\3184931164.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'colsample_bytree': trial.suggest_uniform('colsample_bytree', 0.6, 1.0),\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_5712\\3184931164.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'reg_alpha': trial.suggest_loguniform('reg_alpha', 1e-5, 10.0),\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_5712\\3184931164.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'reg_lambda': trial.suggest_loguniform('reg_lambda', 1e-5, 10.0),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010016 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 615\n",
      "[LightGBM] [Info] Number of data points in the train set: 43418, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 39329.732369\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\PC\\anaconda3-2\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "[I 2024-06-23 12:15:50,125] Trial 86 finished with value: 47221.949367891044 and parameters: {'num_leaves': 85, 'learning_rate': 0.024568808707163922, 'max_depth': 11, 'subsample': 0.8884098703865754, 'colsample_bytree': 0.7836486642412888, 'reg_alpha': 1.4723428962390532e-05, 'reg_lambda': 1.1593792545775878, 'min_child_samples': 63}. Best is trial 47 with value: 47030.7971133361.\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_5712\\3184931164.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_5712\\3184931164.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'subsample': trial.suggest_uniform('subsample', 0.6, 1.0),\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_5712\\3184931164.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'colsample_bytree': trial.suggest_uniform('colsample_bytree', 0.6, 1.0),\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_5712\\3184931164.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'reg_alpha': trial.suggest_loguniform('reg_alpha', 1e-5, 10.0),\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_5712\\3184931164.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'reg_lambda': trial.suggest_loguniform('reg_lambda', 1e-5, 10.0),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.148415 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 615\n",
      "[LightGBM] [Info] Number of data points in the train set: 43418, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 39329.732369\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\PC\\anaconda3-2\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "[I 2024-06-23 12:15:53,262] Trial 87 finished with value: 47388.855421501394 and parameters: {'num_leaves': 86, 'learning_rate': 0.019736461469964627, 'max_depth': 12, 'subsample': 0.8172852151023602, 'colsample_bytree': 0.750752731966253, 'reg_alpha': 0.00013429423078848497, 'reg_lambda': 3.278868135140536, 'min_child_samples': 57}. Best is trial 47 with value: 47030.7971133361.\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_5712\\3184931164.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_5712\\3184931164.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'subsample': trial.suggest_uniform('subsample', 0.6, 1.0),\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_5712\\3184931164.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'colsample_bytree': trial.suggest_uniform('colsample_bytree', 0.6, 1.0),\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_5712\\3184931164.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'reg_alpha': trial.suggest_loguniform('reg_alpha', 1e-5, 10.0),\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_5712\\3184931164.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'reg_lambda': trial.suggest_loguniform('reg_lambda', 1e-5, 10.0),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.028470 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 615\n",
      "[LightGBM] [Info] Number of data points in the train set: 43418, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 39329.732369\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\PC\\anaconda3-2\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "[I 2024-06-23 12:15:56,511] Trial 88 finished with value: 47371.51771377173 and parameters: {'num_leaves': 79, 'learning_rate': 0.028311521088835195, 'max_depth': 11, 'subsample': 0.8687318886420126, 'colsample_bytree': 0.8269927926631584, 'reg_alpha': 4.6789529052439806e-05, 'reg_lambda': 7.254818551620835, 'min_child_samples': 67}. Best is trial 47 with value: 47030.7971133361.\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_5712\\3184931164.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_5712\\3184931164.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'subsample': trial.suggest_uniform('subsample', 0.6, 1.0),\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_5712\\3184931164.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'colsample_bytree': trial.suggest_uniform('colsample_bytree', 0.6, 1.0),\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_5712\\3184931164.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'reg_alpha': trial.suggest_loguniform('reg_alpha', 1e-5, 10.0),\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_5712\\3184931164.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'reg_lambda': trial.suggest_loguniform('reg_lambda', 1e-5, 10.0),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.044159 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 615\n",
      "[LightGBM] [Info] Number of data points in the train set: 43418, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 39329.732369\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\PC\\anaconda3-2\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "[I 2024-06-23 12:16:01,073] Trial 89 finished with value: 47339.06826526787 and parameters: {'num_leaves': 90, 'learning_rate': 0.030502419238017595, 'max_depth': 11, 'subsample': 0.8453425432062803, 'colsample_bytree': 0.7668092763771156, 'reg_alpha': 2.3165947240776108e-05, 'reg_lambda': 3.274776882074962, 'min_child_samples': 82}. Best is trial 47 with value: 47030.7971133361.\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_5712\\3184931164.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_5712\\3184931164.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'subsample': trial.suggest_uniform('subsample', 0.6, 1.0),\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_5712\\3184931164.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'colsample_bytree': trial.suggest_uniform('colsample_bytree', 0.6, 1.0),\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_5712\\3184931164.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'reg_alpha': trial.suggest_loguniform('reg_alpha', 1e-5, 10.0),\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_5712\\3184931164.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'reg_lambda': trial.suggest_loguniform('reg_lambda', 1e-5, 10.0),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013641 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 615\n",
      "[LightGBM] [Info] Number of data points in the train set: 43418, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 39329.732369\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\PC\\anaconda3-2\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "[I 2024-06-23 12:16:04,070] Trial 90 finished with value: 47617.136927756495 and parameters: {'num_leaves': 95, 'learning_rate': 0.015407995375081321, 'max_depth': 13, 'subsample': 0.8321009566111123, 'colsample_bytree': 0.8001649931191611, 'reg_alpha': 0.0009363126137858203, 'reg_lambda': 4.242688442163947, 'min_child_samples': 64}. Best is trial 47 with value: 47030.7971133361.\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_5712\\3184931164.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_5712\\3184931164.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'subsample': trial.suggest_uniform('subsample', 0.6, 1.0),\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_5712\\3184931164.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'colsample_bytree': trial.suggest_uniform('colsample_bytree', 0.6, 1.0),\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_5712\\3184931164.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'reg_alpha': trial.suggest_loguniform('reg_alpha', 1e-5, 10.0),\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_5712\\3184931164.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'reg_lambda': trial.suggest_loguniform('reg_lambda', 1e-5, 10.0),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.021326 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 615\n",
      "[LightGBM] [Info] Number of data points in the train set: 43418, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 39329.732369\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\PC\\anaconda3-2\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "[I 2024-06-23 12:16:07,969] Trial 91 finished with value: 47184.288158213014 and parameters: {'num_leaves': 94, 'learning_rate': 0.026368041582723028, 'max_depth': 11, 'subsample': 0.8557894776439976, 'colsample_bytree': 0.755450686700626, 'reg_alpha': 0.00034357486378724434, 'reg_lambda': 2.1571191109110233, 'min_child_samples': 55}. Best is trial 47 with value: 47030.7971133361.\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_5712\\3184931164.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_5712\\3184931164.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'subsample': trial.suggest_uniform('subsample', 0.6, 1.0),\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_5712\\3184931164.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'colsample_bytree': trial.suggest_uniform('colsample_bytree', 0.6, 1.0),\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_5712\\3184931164.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'reg_alpha': trial.suggest_loguniform('reg_alpha', 1e-5, 10.0),\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_5712\\3184931164.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'reg_lambda': trial.suggest_loguniform('reg_lambda', 1e-5, 10.0),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005247 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 615\n",
      "[LightGBM] [Info] Number of data points in the train set: 43418, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 39329.732369\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\PC\\anaconda3-2\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "[I 2024-06-23 12:16:10,891] Trial 92 finished with value: 47168.75989404505 and parameters: {'num_leaves': 93, 'learning_rate': 0.026757987596683627, 'max_depth': 11, 'subsample': 0.8568989662608046, 'colsample_bytree': 0.777541212982551, 'reg_alpha': 0.00020912638156835554, 'reg_lambda': 6.147888845029897, 'min_child_samples': 56}. Best is trial 47 with value: 47030.7971133361.\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_5712\\3184931164.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_5712\\3184931164.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'subsample': trial.suggest_uniform('subsample', 0.6, 1.0),\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_5712\\3184931164.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'colsample_bytree': trial.suggest_uniform('colsample_bytree', 0.6, 1.0),\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_5712\\3184931164.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'reg_alpha': trial.suggest_loguniform('reg_alpha', 1e-5, 10.0),\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_5712\\3184931164.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'reg_lambda': trial.suggest_loguniform('reg_lambda', 1e-5, 10.0),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003655 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 615\n",
      "[LightGBM] [Info] Number of data points in the train set: 43418, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 39329.732369\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\PC\\anaconda3-2\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "[I 2024-06-23 12:16:14,432] Trial 93 finished with value: 47229.69668968711 and parameters: {'num_leaves': 94, 'learning_rate': 0.02657349818884051, 'max_depth': 12, 'subsample': 0.8569271895038935, 'colsample_bytree': 0.7529800151786046, 'reg_alpha': 0.000215059050045749, 'reg_lambda': 5.97365064505739, 'min_child_samples': 54}. Best is trial 47 with value: 47030.7971133361.\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_5712\\3184931164.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_5712\\3184931164.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'subsample': trial.suggest_uniform('subsample', 0.6, 1.0),\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_5712\\3184931164.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'colsample_bytree': trial.suggest_uniform('colsample_bytree', 0.6, 1.0),\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_5712\\3184931164.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'reg_alpha': trial.suggest_loguniform('reg_alpha', 1e-5, 10.0),\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_5712\\3184931164.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'reg_lambda': trial.suggest_loguniform('reg_lambda', 1e-5, 10.0),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.017627 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 615\n",
      "[LightGBM] [Info] Number of data points in the train set: 43418, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 39329.732369\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\PC\\anaconda3-2\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "[I 2024-06-23 12:16:19,055] Trial 94 finished with value: 47298.16207449371 and parameters: {'num_leaves': 87, 'learning_rate': 0.029364545791675863, 'max_depth': 11, 'subsample': 0.8905939486082018, 'colsample_bytree': 0.8081888481033431, 'reg_alpha': 0.00031464276405416056, 'reg_lambda': 7.658284838687824, 'min_child_samples': 59}. Best is trial 47 with value: 47030.7971133361.\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_5712\\3184931164.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_5712\\3184931164.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'subsample': trial.suggest_uniform('subsample', 0.6, 1.0),\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_5712\\3184931164.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'colsample_bytree': trial.suggest_uniform('colsample_bytree', 0.6, 1.0),\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_5712\\3184931164.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'reg_alpha': trial.suggest_loguniform('reg_alpha', 1e-5, 10.0),\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_5712\\3184931164.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'reg_lambda': trial.suggest_loguniform('reg_lambda', 1e-5, 10.0),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004200 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 615\n",
      "[LightGBM] [Info] Number of data points in the train set: 43418, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 39329.732369\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\PC\\anaconda3-2\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "[I 2024-06-23 12:16:23,473] Trial 95 finished with value: 47289.108629936854 and parameters: {'num_leaves': 98, 'learning_rate': 0.02234474000632017, 'max_depth': 12, 'subsample': 0.8680904208504475, 'colsample_bytree': 0.8480041949612358, 'reg_alpha': 0.0003461182427364292, 'reg_lambda': 9.893313052242755, 'min_child_samples': 52}. Best is trial 47 with value: 47030.7971133361.\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_5712\\3184931164.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_5712\\3184931164.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'subsample': trial.suggest_uniform('subsample', 0.6, 1.0),\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_5712\\3184931164.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'colsample_bytree': trial.suggest_uniform('colsample_bytree', 0.6, 1.0),\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_5712\\3184931164.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'reg_alpha': trial.suggest_loguniform('reg_alpha', 1e-5, 10.0),\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_5712\\3184931164.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'reg_lambda': trial.suggest_loguniform('reg_lambda', 1e-5, 10.0),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012741 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 615\n",
      "[LightGBM] [Info] Number of data points in the train set: 43418, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 39329.732369\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\PC\\anaconda3-2\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "[I 2024-06-23 12:16:26,712] Trial 96 finished with value: 47414.558373341664 and parameters: {'num_leaves': 93, 'learning_rate': 0.01821510369486019, 'max_depth': 11, 'subsample': 0.8532425690259533, 'colsample_bytree': 0.7768313418420595, 'reg_alpha': 0.00012467777953943809, 'reg_lambda': 3.8721442686505627, 'min_child_samples': 57}. Best is trial 47 with value: 47030.7971133361.\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_5712\\3184931164.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_5712\\3184931164.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'subsample': trial.suggest_uniform('subsample', 0.6, 1.0),\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_5712\\3184931164.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'colsample_bytree': trial.suggest_uniform('colsample_bytree', 0.6, 1.0),\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_5712\\3184931164.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'reg_alpha': trial.suggest_loguniform('reg_alpha', 1e-5, 10.0),\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_5712\\3184931164.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'reg_lambda': trial.suggest_loguniform('reg_lambda', 1e-5, 10.0),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.198576 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 615\n",
      "[LightGBM] [Info] Number of data points in the train set: 43418, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 39329.732369\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\PC\\anaconda3-2\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "[I 2024-06-23 12:16:33,200] Trial 97 finished with value: 47246.85151519865 and parameters: {'num_leaves': 96, 'learning_rate': 0.02658127414602078, 'max_depth': 12, 'subsample': 0.8831613515545128, 'colsample_bytree': 0.7468463199255229, 'reg_alpha': 0.0008103942553692994, 'reg_lambda': 2.48785762072424, 'min_child_samples': 55}. Best is trial 47 with value: 47030.7971133361.\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_5712\\3184931164.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_5712\\3184931164.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'subsample': trial.suggest_uniform('subsample', 0.6, 1.0),\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_5712\\3184931164.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'colsample_bytree': trial.suggest_uniform('colsample_bytree', 0.6, 1.0),\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_5712\\3184931164.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'reg_alpha': trial.suggest_loguniform('reg_alpha', 1e-5, 10.0),\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_5712\\3184931164.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'reg_lambda': trial.suggest_loguniform('reg_lambda', 1e-5, 10.0),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.052428 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 617\n",
      "[LightGBM] [Info] Number of data points in the train set: 43418, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 39329.732369\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\PC\\anaconda3-2\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "[I 2024-06-23 12:16:37,290] Trial 98 finished with value: 47782.05757149687 and parameters: {'num_leaves': 83, 'learning_rate': 0.03136643987128017, 'max_depth': 11, 'subsample': 0.8737432016858168, 'colsample_bytree': 0.7383391128465182, 'reg_alpha': 7.119202545204079e-05, 'reg_lambda': 4.926268637562034, 'min_child_samples': 17}. Best is trial 47 with value: 47030.7971133361.\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_5712\\3184931164.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_5712\\3184931164.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'subsample': trial.suggest_uniform('subsample', 0.6, 1.0),\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_5712\\3184931164.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'colsample_bytree': trial.suggest_uniform('colsample_bytree', 0.6, 1.0),\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_5712\\3184931164.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'reg_alpha': trial.suggest_loguniform('reg_alpha', 1e-5, 10.0),\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_5712\\3184931164.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'reg_lambda': trial.suggest_loguniform('reg_lambda', 1e-5, 10.0),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.034581 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 617\n",
      "[LightGBM] [Info] Number of data points in the train set: 43418, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 39329.732369\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\PC\\anaconda3-2\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "[I 2024-06-23 12:16:40,939] Trial 99 finished with value: 47249.917050664924 and parameters: {'num_leaves': 22, 'learning_rate': 0.03361032185982988, 'max_depth': 11, 'subsample': 0.8993541079686757, 'colsample_bytree': 0.7593994489932311, 'reg_alpha': 0.00017194105072598808, 'reg_lambda': 1.093309562945302, 'min_child_samples': 45}. Best is trial 47 with value: 47030.7971133361.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'num_leaves': 100, 'learning_rate': 0.02909062925711322, 'max_depth': 9, 'subsample': 0.8534764783613766, 'colsample_bytree': 0.7310259101237966, 'reg_alpha': 0.3815604585392236, 'reg_lambda': 8.69647257000582, 'min_child_samples': 62}\n",
      "Best RMSE: 47030.7971133361\n"
     ]
    }
   ],
   "source": [
    "# Setup Optuna study\n",
    "study = optuna.create_study(direction='minimize', sampler=optuna.samplers.TPESampler(seed=42))\n",
    "study.optimize(objective, n_trials=100)\n",
    "\n",
    "# Print best parameters and best score\n",
    "print(\"Best Parameters:\", study.best_params)\n",
    "print(\"Best RMSE:\", study.best_value)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.015823 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 615\n",
      "[LightGBM] [Info] Number of data points in the train set: 43418, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 39329.732369\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\PC\\anaconda3-2\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lgbm train R2 is: 0.17198243490652532\n",
      "Lgbm test R2 is: 0.24727056391950208\n",
      "Final Model Test RMSE: 47030.7971133361\n"
     ]
    }
   ],
   "source": [
    "# Use the best parameters to train the final model\n",
    "best_params = study.best_params\n",
    "final_model = LGBMRegressor(**best_params, random_state=42)\n",
    "final_model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate final model on test set\n",
    "y_pred_final = final_model.predict(X_test)\n",
    "test_rmse = mean_squared_error(y_test, y_pred_final, squared=False)\n",
    "r2_train = final_model.score(X_train, y_train)\n",
    "r2_test = final_model.score(X_test, y_test)\n",
    "print(f\"Lgbm train R2 is: {r2_train}\")\n",
    "print(f\"Lgbm test R2 is: {r2_test}\")\n",
    "print(\"Final Model Test RMSE:\", test_rmse)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "boosted_predictions = final_model.predict(scaled_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>54273</td>\n",
       "      <td>24657.366463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>54274</td>\n",
       "      <td>19689.348591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>54275</td>\n",
       "      <td>27272.074674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>54276</td>\n",
       "      <td>54226.307514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>54277</td>\n",
       "      <td>40842.960138</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id         price\n",
       "0  54273  24657.366463\n",
       "1  54274  19689.348591\n",
       "2  54275  27272.074674\n",
       "3  54276  54226.307514\n",
       "4  54277  40842.960138"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create submission file\n",
    "sub1 = pd.DataFrame({'id': submission['id'], 'price': boosted_predictions})\n",
    "\n",
    "# Preview sub file\n",
    "sub1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a csv file\n",
    "sub1.to_csv('submission9.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tuning the catboost regressor model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import catboost as cb\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import optuna\n",
    "\n",
    "def objective(trial):\n",
    "    params = {\n",
    "        \"iterations\": 1000,\n",
    "        \"learning_rate\": trial.suggest_float(\"learning_rate\", 1e-3, 0.1, log=True),\n",
    "        \"depth\": trial.suggest_int(\"depth\", 1, 10),\n",
    "        \"subsample\": trial.suggest_float(\"subsample\", 0.05, 1.0),\n",
    "        \"colsample_bylevel\": trial.suggest_float(\"colsample_bylevel\", 0.05, 1.0),\n",
    "        \"min_data_in_leaf\": trial.suggest_int(\"min_data_in_leaf\", 1, 100),\n",
    "    }\n",
    "\n",
    "    model = cb.CatBoostRegressor(**params, silent=True)\n",
    "    model.fit(X_train, y_train)\n",
    "    predictions = model.predict(X_test)\n",
    "    rmse = mean_squared_error(y_test, predictions, squared=False)\n",
    "    return rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-21 10:10:08,992] A new study created in memory with name: no-name-ecd5b551-3418-4c69-b6eb-62171d987ad4\n",
      "c:\\Users\\PC\\anaconda3-2\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "[I 2024-06-21 10:10:42,935] Trial 0 finished with value: 0.016858731951802257 and parameters: {'learning_rate': 0.05648886342676039, 'depth': 10, 'subsample': 0.9410584695505052, 'colsample_bylevel': 0.2352414404604335, 'min_data_in_leaf': 9}. Best is trial 0 with value: 0.016858731951802257.\n",
      "c:\\Users\\PC\\anaconda3-2\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "[I 2024-06-21 10:11:09,121] Trial 1 finished with value: 0.016160124387081372 and parameters: {'learning_rate': 0.002550260994108929, 'depth': 10, 'subsample': 0.16072203915690203, 'colsample_bylevel': 0.449948980006006, 'min_data_in_leaf': 63}. Best is trial 1 with value: 0.016160124387081372.\n",
      "c:\\Users\\PC\\anaconda3-2\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "[I 2024-06-21 10:11:20,822] Trial 2 finished with value: 0.016138508965196113 and parameters: {'learning_rate': 0.0030375454710057826, 'depth': 6, 'subsample': 0.6026258161038592, 'colsample_bylevel': 0.8583418730895376, 'min_data_in_leaf': 21}. Best is trial 2 with value: 0.016138508965196113.\n",
      "c:\\Users\\PC\\anaconda3-2\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "[I 2024-06-21 10:11:57,634] Trial 3 finished with value: 0.017104729479333645 and parameters: {'learning_rate': 0.04912724421901241, 'depth': 10, 'subsample': 0.7966482499406656, 'colsample_bylevel': 0.48219540490875706, 'min_data_in_leaf': 5}. Best is trial 2 with value: 0.016138508965196113.\n",
      "c:\\Users\\PC\\anaconda3-2\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "[I 2024-06-21 10:12:08,952] Trial 4 finished with value: 0.01694777782317966 and parameters: {'learning_rate': 0.04851042503800746, 'depth': 4, 'subsample': 0.9046243054860784, 'colsample_bylevel': 0.7283246961737917, 'min_data_in_leaf': 75}. Best is trial 2 with value: 0.016138508965196113.\n",
      "c:\\Users\\PC\\anaconda3-2\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "[I 2024-06-21 10:12:17,818] Trial 5 finished with value: 0.016228242912240856 and parameters: {'learning_rate': 0.03824699768175045, 'depth': 4, 'subsample': 0.7030600925914416, 'colsample_bylevel': 0.2553795765202593, 'min_data_in_leaf': 14}. Best is trial 2 with value: 0.016138508965196113.\n",
      "c:\\Users\\PC\\anaconda3-2\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "[I 2024-06-21 10:12:55,875] Trial 6 finished with value: 0.0161203193396299 and parameters: {'learning_rate': 0.010035995859901142, 'depth': 9, 'subsample': 0.6880556403067327, 'colsample_bylevel': 0.8062706768928884, 'min_data_in_leaf': 81}. Best is trial 6 with value: 0.0161203193396299.\n",
      "c:\\Users\\PC\\anaconda3-2\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "[I 2024-06-21 10:13:08,904] Trial 7 finished with value: 0.01611693624559222 and parameters: {'learning_rate': 0.007436411297928352, 'depth': 7, 'subsample': 0.6525635055768815, 'colsample_bylevel': 0.6373195784569853, 'min_data_in_leaf': 78}. Best is trial 7 with value: 0.01611693624559222.\n",
      "c:\\Users\\PC\\anaconda3-2\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "[I 2024-06-21 10:13:14,881] Trial 8 finished with value: 0.016555275158658303 and parameters: {'learning_rate': 0.0026524470132290694, 'depth': 5, 'subsample': 0.3538656776674152, 'colsample_bylevel': 0.12871940529977394, 'min_data_in_leaf': 45}. Best is trial 7 with value: 0.01611693624559222.\n",
      "c:\\Users\\PC\\anaconda3-2\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "[I 2024-06-21 10:13:21,645] Trial 9 finished with value: 0.016773297330911954 and parameters: {'learning_rate': 0.0018295523097919292, 'depth': 2, 'subsample': 0.9045568608324809, 'colsample_bylevel': 0.28434719776327, 'min_data_in_leaf': 44}. Best is trial 7 with value: 0.01611693624559222.\n",
      "c:\\Users\\PC\\anaconda3-2\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "[I 2024-06-21 10:13:34,083] Trial 10 finished with value: 0.016251951948196237 and parameters: {'learning_rate': 0.010719599736756168, 'depth': 7, 'subsample': 0.3819837504321587, 'colsample_bylevel': 0.9785434438322789, 'min_data_in_leaf': 98}. Best is trial 7 with value: 0.01611693624559222.\n",
      "c:\\Users\\PC\\anaconda3-2\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "[I 2024-06-21 10:13:59,512] Trial 11 finished with value: 0.016096756753260662 and parameters: {'learning_rate': 0.009399009738247475, 'depth': 8, 'subsample': 0.5410231370722798, 'colsample_bylevel': 0.6695844909151241, 'min_data_in_leaf': 92}. Best is trial 11 with value: 0.016096756753260662.\n",
      "c:\\Users\\PC\\anaconda3-2\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "[I 2024-06-21 10:14:21,001] Trial 12 finished with value: 0.016010797412101666 and parameters: {'learning_rate': 0.006010746289448281, 'depth': 8, 'subsample': 0.45389486020016206, 'colsample_bylevel': 0.6409166252012644, 'min_data_in_leaf': 98}. Best is trial 12 with value: 0.016010797412101666.\n",
      "c:\\Users\\PC\\anaconda3-2\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "[I 2024-06-21 10:14:40,782] Trial 13 finished with value: 0.01637772258749699 and parameters: {'learning_rate': 0.019412293094649192, 'depth': 8, 'subsample': 0.4259789900680295, 'colsample_bylevel': 0.6031417225146691, 'min_data_in_leaf': 100}. Best is trial 12 with value: 0.016010797412101666.\n",
      "c:\\Users\\PC\\anaconda3-2\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "[I 2024-06-21 10:14:59,633] Trial 14 finished with value: 0.016040420057051055 and parameters: {'learning_rate': 0.004962099444058858, 'depth': 8, 'subsample': 0.1818571002369459, 'colsample_bylevel': 0.6419747695908707, 'min_data_in_leaf': 89}. Best is trial 12 with value: 0.016010797412101666.\n",
      "c:\\Users\\PC\\anaconda3-2\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "[I 2024-06-21 10:15:15,633] Trial 15 finished with value: 0.01668385007550988 and parameters: {'learning_rate': 0.0010168235586535486, 'depth': 8, 'subsample': 0.08368556921853304, 'colsample_bylevel': 0.4073410050272392, 'min_data_in_leaf': 62}. Best is trial 12 with value: 0.016010797412101666.\n",
      "c:\\Users\\PC\\anaconda3-2\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "[I 2024-06-21 10:15:20,223] Trial 16 finished with value: 0.016506379867101597 and parameters: {'learning_rate': 0.005161539072443253, 'depth': 1, 'subsample': 0.26051982791656036, 'colsample_bylevel': 0.5369085862664884, 'min_data_in_leaf': 86}. Best is trial 12 with value: 0.016010797412101666.\n",
      "c:\\Users\\PC\\anaconda3-2\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "[I 2024-06-21 10:15:31,869] Trial 17 finished with value: 0.016659596694905975 and parameters: {'learning_rate': 0.023267829085553464, 'depth': 6, 'subsample': 0.25041243676762154, 'colsample_bylevel': 0.7758479430744246, 'min_data_in_leaf': 32}. Best is trial 12 with value: 0.016010797412101666.\n",
      "c:\\Users\\PC\\anaconda3-2\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "[I 2024-06-21 10:16:10,905] Trial 18 finished with value: 0.01809005106915859 and parameters: {'learning_rate': 0.09423954848907441, 'depth': 9, 'subsample': 0.4830730501489014, 'colsample_bylevel': 0.9268385783121209, 'min_data_in_leaf': 67}. Best is trial 12 with value: 0.016010797412101666.\n",
      "c:\\Users\\PC\\anaconda3-2\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "[I 2024-06-21 10:16:22,710] Trial 19 finished with value: 0.01604223996716786 and parameters: {'learning_rate': 0.004667791326179208, 'depth': 7, 'subsample': 0.05179658435215806, 'colsample_bylevel': 0.5623385823933656, 'min_data_in_leaf': 92}. Best is trial 12 with value: 0.016010797412101666.\n",
      "c:\\Users\\PC\\anaconda3-2\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "[I 2024-06-21 10:16:38,992] Trial 20 finished with value: 0.016222057742076374 and parameters: {'learning_rate': 0.01521282240555368, 'depth': 9, 'subsample': 0.2663836652849599, 'colsample_bylevel': 0.3849097527668097, 'min_data_in_leaf': 55}. Best is trial 12 with value: 0.016010797412101666.\n",
      "c:\\Users\\PC\\anaconda3-2\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "[I 2024-06-21 10:16:48,316] Trial 21 finished with value: 0.01604637761604051 and parameters: {'learning_rate': 0.005222388479458895, 'depth': 7, 'subsample': 0.059654405802085364, 'colsample_bylevel': 0.5551784635266642, 'min_data_in_leaf': 89}. Best is trial 12 with value: 0.016010797412101666.\n",
      "c:\\Users\\PC\\anaconda3-2\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "[I 2024-06-21 10:16:55,023] Trial 22 finished with value: 0.01611791491511671 and parameters: {'learning_rate': 0.005294432818443244, 'depth': 5, 'subsample': 0.16615354701949228, 'colsample_bylevel': 0.7094076082539899, 'min_data_in_leaf': 93}. Best is trial 12 with value: 0.016010797412101666.\n",
      "c:\\Users\\PC\\anaconda3-2\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "[I 2024-06-21 10:17:04,627] Trial 23 finished with value: 0.01607132146147786 and parameters: {'learning_rate': 0.0036482808377680804, 'depth': 7, 'subsample': 0.16426970100658905, 'colsample_bylevel': 0.5951441615193585, 'min_data_in_leaf': 72}. Best is trial 12 with value: 0.016010797412101666.\n",
      "c:\\Users\\PC\\anaconda3-2\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "[I 2024-06-21 10:17:18,339] Trial 24 finished with value: 0.016359955364015428 and parameters: {'learning_rate': 0.0015322923251899455, 'depth': 8, 'subsample': 0.3367374413424522, 'colsample_bylevel': 0.504889937580555, 'min_data_in_leaf': 85}. Best is trial 12 with value: 0.016010797412101666.\n",
      "c:\\Users\\PC\\anaconda3-2\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "[I 2024-06-21 10:17:25,075] Trial 25 finished with value: 0.016025532625076087 and parameters: {'learning_rate': 0.006666663105761098, 'depth': 6, 'subsample': 0.0545723881266037, 'colsample_bylevel': 0.33875474027723784, 'min_data_in_leaf': 100}. Best is trial 12 with value: 0.016010797412101666.\n",
      "c:\\Users\\PC\\anaconda3-2\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "[I 2024-06-21 10:17:30,419] Trial 26 finished with value: 0.016096948420538104 and parameters: {'learning_rate': 0.007891542887255472, 'depth': 4, 'subsample': 0.1594672540543, 'colsample_bylevel': 0.3474411887117634, 'min_data_in_leaf': 98}. Best is trial 12 with value: 0.016010797412101666.\n",
      "c:\\Users\\PC\\anaconda3-2\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "[I 2024-06-21 10:17:36,936] Trial 27 finished with value: 0.016041217766007417 and parameters: {'learning_rate': 0.0139987882891298, 'depth': 6, 'subsample': 0.4887025368950091, 'colsample_bylevel': 0.14600684476010511, 'min_data_in_leaf': 82}. Best is trial 12 with value: 0.016010797412101666.\n",
      "c:\\Users\\PC\\anaconda3-2\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "[I 2024-06-21 10:17:42,054] Trial 28 finished with value: 0.016146567624421737 and parameters: {'learning_rate': 0.006757168269241205, 'depth': 3, 'subsample': 0.28023769308654833, 'colsample_bylevel': 0.3153964453701019, 'min_data_in_leaf': 74}. Best is trial 12 with value: 0.016010797412101666.\n",
      "c:\\Users\\PC\\anaconda3-2\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "[I 2024-06-21 10:17:46,633] Trial 29 finished with value: 0.016729897057062 and parameters: {'learning_rate': 0.003623879022784317, 'depth': 9, 'subsample': 0.10322949927293931, 'colsample_bylevel': 0.07758904967788999, 'min_data_in_leaf': 97}. Best is trial 12 with value: 0.016010797412101666.\n"
     ]
    }
   ],
   "source": [
    "study = optuna.create_study(direction='minimize')\n",
    "study.optimize(objective, n_trials=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters: {'learning_rate': 0.006010746289448281, 'depth': 8, 'subsample': 0.45389486020016206, 'colsample_bylevel': 0.6409166252012644, 'min_data_in_leaf': 98}\n",
      "Best RMSE: 0.016010797412101666\n"
     ]
    }
   ],
   "source": [
    "print('Best hyperparameters:', study.best_params)\n",
    "print('Best RMSE:', study.best_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.0259923\ttotal: 16.4ms\tremaining: 16.4s\n",
      "1:\tlearn: 0.0259758\ttotal: 31.8ms\tremaining: 15.9s\n",
      "2:\tlearn: 0.0259610\ttotal: 48.2ms\tremaining: 16s\n",
      "3:\tlearn: 0.0259435\ttotal: 63.9ms\tremaining: 15.9s\n",
      "4:\tlearn: 0.0259275\ttotal: 78.7ms\tremaining: 15.7s\n",
      "5:\tlearn: 0.0259132\ttotal: 93.4ms\tremaining: 15.5s\n",
      "6:\tlearn: 0.0258981\ttotal: 112ms\tremaining: 15.9s\n",
      "7:\tlearn: 0.0258835\ttotal: 133ms\tremaining: 16.5s\n",
      "8:\tlearn: 0.0258691\ttotal: 159ms\tremaining: 17.5s\n",
      "9:\tlearn: 0.0258526\ttotal: 174ms\tremaining: 17.2s\n",
      "10:\tlearn: 0.0258384\ttotal: 191ms\tremaining: 17.2s\n",
      "11:\tlearn: 0.0258255\ttotal: 204ms\tremaining: 16.8s\n",
      "12:\tlearn: 0.0258078\ttotal: 220ms\tremaining: 16.7s\n",
      "13:\tlearn: 0.0257936\ttotal: 238ms\tremaining: 16.7s\n",
      "14:\tlearn: 0.0257801\ttotal: 253ms\tremaining: 16.6s\n",
      "15:\tlearn: 0.0257640\ttotal: 264ms\tremaining: 16.2s\n",
      "16:\tlearn: 0.0257515\ttotal: 278ms\tremaining: 16.1s\n",
      "17:\tlearn: 0.0257380\ttotal: 293ms\tremaining: 16s\n",
      "18:\tlearn: 0.0257217\ttotal: 308ms\tremaining: 15.9s\n",
      "19:\tlearn: 0.0257080\ttotal: 322ms\tremaining: 15.8s\n",
      "20:\tlearn: 0.0256948\ttotal: 338ms\tremaining: 15.7s\n",
      "21:\tlearn: 0.0256810\ttotal: 351ms\tremaining: 15.6s\n",
      "22:\tlearn: 0.0256689\ttotal: 363ms\tremaining: 15.4s\n",
      "23:\tlearn: 0.0256566\ttotal: 376ms\tremaining: 15.3s\n",
      "24:\tlearn: 0.0256416\ttotal: 392ms\tremaining: 15.3s\n",
      "25:\tlearn: 0.0256325\ttotal: 401ms\tremaining: 15s\n",
      "26:\tlearn: 0.0256216\ttotal: 420ms\tremaining: 15.1s\n",
      "27:\tlearn: 0.0256103\ttotal: 435ms\tremaining: 15.1s\n",
      "28:\tlearn: 0.0255979\ttotal: 453ms\tremaining: 15.2s\n",
      "29:\tlearn: 0.0255861\ttotal: 467ms\tremaining: 15.1s\n",
      "30:\tlearn: 0.0255744\ttotal: 485ms\tremaining: 15.2s\n",
      "31:\tlearn: 0.0255614\ttotal: 501ms\tremaining: 15.1s\n",
      "32:\tlearn: 0.0255487\ttotal: 517ms\tremaining: 15.1s\n",
      "33:\tlearn: 0.0255379\ttotal: 533ms\tremaining: 15.1s\n",
      "34:\tlearn: 0.0255256\ttotal: 549ms\tremaining: 15.1s\n",
      "35:\tlearn: 0.0255139\ttotal: 569ms\tremaining: 15.2s\n",
      "36:\tlearn: 0.0255017\ttotal: 586ms\tremaining: 15.3s\n",
      "37:\tlearn: 0.0254893\ttotal: 603ms\tremaining: 15.3s\n",
      "38:\tlearn: 0.0254767\ttotal: 617ms\tremaining: 15.2s\n",
      "39:\tlearn: 0.0254637\ttotal: 635ms\tremaining: 15.2s\n",
      "40:\tlearn: 0.0254525\ttotal: 652ms\tremaining: 15.2s\n",
      "41:\tlearn: 0.0254416\ttotal: 665ms\tremaining: 15.2s\n",
      "42:\tlearn: 0.0254321\ttotal: 689ms\tremaining: 15.3s\n",
      "43:\tlearn: 0.0254202\ttotal: 770ms\tremaining: 16.7s\n",
      "44:\tlearn: 0.0254090\ttotal: 786ms\tremaining: 16.7s\n",
      "45:\tlearn: 0.0253984\ttotal: 802ms\tremaining: 16.6s\n",
      "46:\tlearn: 0.0253878\ttotal: 821ms\tremaining: 16.6s\n",
      "47:\tlearn: 0.0253774\ttotal: 837ms\tremaining: 16.6s\n",
      "48:\tlearn: 0.0253673\ttotal: 851ms\tremaining: 16.5s\n",
      "49:\tlearn: 0.0253575\ttotal: 864ms\tremaining: 16.4s\n",
      "50:\tlearn: 0.0253473\ttotal: 878ms\tremaining: 16.3s\n",
      "51:\tlearn: 0.0253341\ttotal: 890ms\tremaining: 16.2s\n",
      "52:\tlearn: 0.0253239\ttotal: 914ms\tremaining: 16.3s\n",
      "53:\tlearn: 0.0253138\ttotal: 934ms\tremaining: 16.4s\n",
      "54:\tlearn: 0.0253046\ttotal: 948ms\tremaining: 16.3s\n",
      "55:\tlearn: 0.0252934\ttotal: 965ms\tremaining: 16.3s\n",
      "56:\tlearn: 0.0252849\ttotal: 979ms\tremaining: 16.2s\n",
      "57:\tlearn: 0.0252753\ttotal: 996ms\tremaining: 16.2s\n",
      "58:\tlearn: 0.0252660\ttotal: 1.01s\tremaining: 16.1s\n",
      "59:\tlearn: 0.0252575\ttotal: 1.03s\tremaining: 16.1s\n",
      "60:\tlearn: 0.0252490\ttotal: 1.04s\tremaining: 16s\n",
      "61:\tlearn: 0.0252399\ttotal: 1.05s\tremaining: 16s\n",
      "62:\tlearn: 0.0252305\ttotal: 1.07s\tremaining: 15.9s\n",
      "63:\tlearn: 0.0252215\ttotal: 1.08s\tremaining: 15.9s\n",
      "64:\tlearn: 0.0252117\ttotal: 1.1s\tremaining: 15.8s\n",
      "65:\tlearn: 0.0252014\ttotal: 1.11s\tremaining: 15.8s\n",
      "66:\tlearn: 0.0251935\ttotal: 1.13s\tremaining: 15.8s\n",
      "67:\tlearn: 0.0251835\ttotal: 1.15s\tremaining: 15.8s\n",
      "68:\tlearn: 0.0251747\ttotal: 1.17s\tremaining: 15.8s\n",
      "69:\tlearn: 0.0251659\ttotal: 1.19s\tremaining: 15.8s\n",
      "70:\tlearn: 0.0251576\ttotal: 1.2s\tremaining: 15.7s\n",
      "71:\tlearn: 0.0251491\ttotal: 1.23s\tremaining: 15.8s\n",
      "72:\tlearn: 0.0251410\ttotal: 1.24s\tremaining: 15.8s\n",
      "73:\tlearn: 0.0251320\ttotal: 1.26s\tremaining: 15.7s\n",
      "74:\tlearn: 0.0251232\ttotal: 1.27s\tremaining: 15.6s\n",
      "75:\tlearn: 0.0251149\ttotal: 1.28s\tremaining: 15.6s\n",
      "76:\tlearn: 0.0251055\ttotal: 1.3s\tremaining: 15.6s\n",
      "77:\tlearn: 0.0250947\ttotal: 1.31s\tremaining: 15.5s\n",
      "78:\tlearn: 0.0250868\ttotal: 1.33s\tremaining: 15.5s\n",
      "79:\tlearn: 0.0250795\ttotal: 1.35s\tremaining: 15.5s\n",
      "80:\tlearn: 0.0250715\ttotal: 1.37s\tremaining: 15.5s\n",
      "81:\tlearn: 0.0250636\ttotal: 1.38s\tremaining: 15.5s\n",
      "82:\tlearn: 0.0250569\ttotal: 1.4s\tremaining: 15.4s\n",
      "83:\tlearn: 0.0250489\ttotal: 1.41s\tremaining: 15.4s\n",
      "84:\tlearn: 0.0250418\ttotal: 1.43s\tremaining: 15.4s\n",
      "85:\tlearn: 0.0250346\ttotal: 1.44s\tremaining: 15.3s\n",
      "86:\tlearn: 0.0250245\ttotal: 1.46s\tremaining: 15.3s\n",
      "87:\tlearn: 0.0250175\ttotal: 1.47s\tremaining: 15.3s\n",
      "88:\tlearn: 0.0250093\ttotal: 1.48s\tremaining: 15.2s\n",
      "89:\tlearn: 0.0249991\ttotal: 1.5s\tremaining: 15.2s\n",
      "90:\tlearn: 0.0249917\ttotal: 1.51s\tremaining: 15.1s\n",
      "91:\tlearn: 0.0249856\ttotal: 1.53s\tremaining: 15.1s\n",
      "92:\tlearn: 0.0249789\ttotal: 1.54s\tremaining: 15s\n",
      "93:\tlearn: 0.0249680\ttotal: 1.55s\tremaining: 15s\n",
      "94:\tlearn: 0.0249607\ttotal: 1.59s\tremaining: 15.1s\n",
      "95:\tlearn: 0.0249526\ttotal: 1.6s\tremaining: 15.1s\n",
      "96:\tlearn: 0.0249455\ttotal: 1.62s\tremaining: 15.1s\n",
      "97:\tlearn: 0.0249406\ttotal: 1.63s\tremaining: 15s\n",
      "98:\tlearn: 0.0249325\ttotal: 1.65s\tremaining: 15s\n",
      "99:\tlearn: 0.0249264\ttotal: 1.66s\tremaining: 15s\n",
      "100:\tlearn: 0.0249199\ttotal: 1.68s\tremaining: 14.9s\n",
      "101:\tlearn: 0.0249129\ttotal: 1.7s\tremaining: 15s\n",
      "102:\tlearn: 0.0249067\ttotal: 1.72s\tremaining: 15s\n",
      "103:\tlearn: 0.0248995\ttotal: 1.74s\tremaining: 15s\n",
      "104:\tlearn: 0.0248909\ttotal: 1.75s\tremaining: 14.9s\n",
      "105:\tlearn: 0.0248844\ttotal: 1.77s\tremaining: 14.9s\n",
      "106:\tlearn: 0.0248735\ttotal: 1.78s\tremaining: 14.9s\n",
      "107:\tlearn: 0.0248677\ttotal: 1.8s\tremaining: 14.9s\n",
      "108:\tlearn: 0.0248608\ttotal: 1.82s\tremaining: 14.9s\n",
      "109:\tlearn: 0.0248548\ttotal: 1.83s\tremaining: 14.8s\n",
      "110:\tlearn: 0.0248497\ttotal: 1.85s\tremaining: 14.8s\n",
      "111:\tlearn: 0.0248437\ttotal: 1.86s\tremaining: 14.8s\n",
      "112:\tlearn: 0.0248365\ttotal: 1.89s\tremaining: 14.8s\n",
      "113:\tlearn: 0.0248297\ttotal: 1.9s\tremaining: 14.8s\n",
      "114:\tlearn: 0.0248222\ttotal: 1.91s\tremaining: 14.7s\n",
      "115:\tlearn: 0.0248135\ttotal: 1.93s\tremaining: 14.7s\n",
      "116:\tlearn: 0.0248085\ttotal: 1.94s\tremaining: 14.7s\n",
      "117:\tlearn: 0.0248021\ttotal: 1.96s\tremaining: 14.6s\n",
      "118:\tlearn: 0.0247934\ttotal: 1.97s\tremaining: 14.6s\n",
      "119:\tlearn: 0.0247881\ttotal: 1.99s\tremaining: 14.6s\n",
      "120:\tlearn: 0.0247799\ttotal: 2s\tremaining: 14.5s\n",
      "121:\tlearn: 0.0247744\ttotal: 2.02s\tremaining: 14.5s\n",
      "122:\tlearn: 0.0247688\ttotal: 2.04s\tremaining: 14.6s\n",
      "123:\tlearn: 0.0247635\ttotal: 2.05s\tremaining: 14.5s\n",
      "124:\tlearn: 0.0247560\ttotal: 2.08s\tremaining: 14.5s\n",
      "125:\tlearn: 0.0247507\ttotal: 2.09s\tremaining: 14.5s\n",
      "126:\tlearn: 0.0247462\ttotal: 2.1s\tremaining: 14.5s\n",
      "127:\tlearn: 0.0247412\ttotal: 2.12s\tremaining: 14.4s\n",
      "128:\tlearn: 0.0247340\ttotal: 2.14s\tremaining: 14.5s\n",
      "129:\tlearn: 0.0247270\ttotal: 2.15s\tremaining: 14.4s\n",
      "130:\tlearn: 0.0247219\ttotal: 2.17s\tremaining: 14.4s\n",
      "131:\tlearn: 0.0247158\ttotal: 2.19s\tremaining: 14.4s\n",
      "132:\tlearn: 0.0247101\ttotal: 2.2s\tremaining: 14.4s\n",
      "133:\tlearn: 0.0247057\ttotal: 2.23s\tremaining: 14.4s\n",
      "134:\tlearn: 0.0247003\ttotal: 2.25s\tremaining: 14.4s\n",
      "135:\tlearn: 0.0246946\ttotal: 2.27s\tremaining: 14.4s\n",
      "136:\tlearn: 0.0246896\ttotal: 2.28s\tremaining: 14.4s\n",
      "137:\tlearn: 0.0246852\ttotal: 2.29s\tremaining: 14.3s\n",
      "138:\tlearn: 0.0246805\ttotal: 2.31s\tremaining: 14.3s\n",
      "139:\tlearn: 0.0246740\ttotal: 2.33s\tremaining: 14.3s\n",
      "140:\tlearn: 0.0246675\ttotal: 2.34s\tremaining: 14.2s\n",
      "141:\tlearn: 0.0246620\ttotal: 2.35s\tremaining: 14.2s\n",
      "142:\tlearn: 0.0246570\ttotal: 2.37s\tremaining: 14.2s\n",
      "143:\tlearn: 0.0246531\ttotal: 2.38s\tremaining: 14.2s\n",
      "144:\tlearn: 0.0246477\ttotal: 2.4s\tremaining: 14.1s\n",
      "145:\tlearn: 0.0246429\ttotal: 2.41s\tremaining: 14.1s\n",
      "146:\tlearn: 0.0246389\ttotal: 2.43s\tremaining: 14.1s\n",
      "147:\tlearn: 0.0246320\ttotal: 2.44s\tremaining: 14.1s\n",
      "148:\tlearn: 0.0246296\ttotal: 2.46s\tremaining: 14s\n",
      "149:\tlearn: 0.0246239\ttotal: 2.48s\tremaining: 14.1s\n",
      "150:\tlearn: 0.0246196\ttotal: 2.49s\tremaining: 14s\n",
      "151:\tlearn: 0.0246136\ttotal: 2.51s\tremaining: 14s\n",
      "152:\tlearn: 0.0246091\ttotal: 2.52s\tremaining: 14s\n",
      "153:\tlearn: 0.0246034\ttotal: 2.54s\tremaining: 14s\n",
      "154:\tlearn: 0.0245969\ttotal: 2.56s\tremaining: 14s\n",
      "155:\tlearn: 0.0245928\ttotal: 2.58s\tremaining: 14s\n",
      "156:\tlearn: 0.0245886\ttotal: 2.59s\tremaining: 13.9s\n",
      "157:\tlearn: 0.0245832\ttotal: 2.61s\tremaining: 13.9s\n",
      "158:\tlearn: 0.0245739\ttotal: 2.63s\tremaining: 13.9s\n",
      "159:\tlearn: 0.0245693\ttotal: 2.64s\tremaining: 13.9s\n",
      "160:\tlearn: 0.0245647\ttotal: 2.66s\tremaining: 13.9s\n",
      "161:\tlearn: 0.0245605\ttotal: 2.68s\tremaining: 13.9s\n",
      "162:\tlearn: 0.0245564\ttotal: 2.69s\tremaining: 13.8s\n",
      "163:\tlearn: 0.0245521\ttotal: 2.71s\tremaining: 13.8s\n",
      "164:\tlearn: 0.0245479\ttotal: 2.72s\tremaining: 13.8s\n",
      "165:\tlearn: 0.0245440\ttotal: 2.74s\tremaining: 13.8s\n",
      "166:\tlearn: 0.0245396\ttotal: 2.75s\tremaining: 13.7s\n",
      "167:\tlearn: 0.0245343\ttotal: 2.77s\tremaining: 13.7s\n",
      "168:\tlearn: 0.0245305\ttotal: 2.79s\tremaining: 13.7s\n",
      "169:\tlearn: 0.0245265\ttotal: 2.8s\tremaining: 13.7s\n",
      "170:\tlearn: 0.0245228\ttotal: 2.81s\tremaining: 13.6s\n",
      "171:\tlearn: 0.0245177\ttotal: 2.83s\tremaining: 13.6s\n",
      "172:\tlearn: 0.0245141\ttotal: 2.84s\tremaining: 13.6s\n",
      "173:\tlearn: 0.0245106\ttotal: 2.86s\tremaining: 13.6s\n",
      "174:\tlearn: 0.0245069\ttotal: 2.88s\tremaining: 13.6s\n",
      "175:\tlearn: 0.0245031\ttotal: 2.9s\tremaining: 13.6s\n",
      "176:\tlearn: 0.0244970\ttotal: 2.91s\tremaining: 13.5s\n",
      "177:\tlearn: 0.0244922\ttotal: 2.92s\tremaining: 13.5s\n",
      "178:\tlearn: 0.0244883\ttotal: 2.95s\tremaining: 13.5s\n",
      "179:\tlearn: 0.0244838\ttotal: 2.96s\tremaining: 13.5s\n",
      "180:\tlearn: 0.0244802\ttotal: 2.97s\tremaining: 13.5s\n",
      "181:\tlearn: 0.0244756\ttotal: 2.99s\tremaining: 13.4s\n",
      "182:\tlearn: 0.0244706\ttotal: 3s\tremaining: 13.4s\n",
      "183:\tlearn: 0.0244667\ttotal: 3.02s\tremaining: 13.4s\n",
      "184:\tlearn: 0.0244604\ttotal: 3.04s\tremaining: 13.4s\n",
      "185:\tlearn: 0.0244570\ttotal: 3.05s\tremaining: 13.4s\n",
      "186:\tlearn: 0.0244528\ttotal: 3.07s\tremaining: 13.3s\n",
      "187:\tlearn: 0.0244482\ttotal: 3.08s\tremaining: 13.3s\n",
      "188:\tlearn: 0.0244438\ttotal: 3.1s\tremaining: 13.3s\n",
      "189:\tlearn: 0.0244396\ttotal: 3.12s\tremaining: 13.3s\n",
      "190:\tlearn: 0.0244359\ttotal: 3.13s\tremaining: 13.3s\n",
      "191:\tlearn: 0.0244315\ttotal: 3.15s\tremaining: 13.2s\n",
      "192:\tlearn: 0.0244280\ttotal: 3.16s\tremaining: 13.2s\n",
      "193:\tlearn: 0.0244249\ttotal: 3.17s\tremaining: 13.2s\n",
      "194:\tlearn: 0.0244206\ttotal: 3.19s\tremaining: 13.2s\n",
      "195:\tlearn: 0.0244166\ttotal: 3.2s\tremaining: 13.1s\n",
      "196:\tlearn: 0.0244129\ttotal: 3.22s\tremaining: 13.1s\n",
      "197:\tlearn: 0.0244097\ttotal: 3.23s\tremaining: 13.1s\n",
      "198:\tlearn: 0.0244066\ttotal: 3.25s\tremaining: 13.1s\n",
      "199:\tlearn: 0.0244032\ttotal: 3.27s\tremaining: 13.1s\n",
      "200:\tlearn: 0.0243987\ttotal: 3.28s\tremaining: 13s\n",
      "201:\tlearn: 0.0243956\ttotal: 3.3s\tremaining: 13s\n",
      "202:\tlearn: 0.0243876\ttotal: 3.31s\tremaining: 13s\n",
      "203:\tlearn: 0.0243829\ttotal: 3.34s\tremaining: 13s\n",
      "204:\tlearn: 0.0243800\ttotal: 3.36s\tremaining: 13s\n",
      "205:\tlearn: 0.0243768\ttotal: 3.38s\tremaining: 13s\n",
      "206:\tlearn: 0.0243737\ttotal: 3.39s\tremaining: 13s\n",
      "207:\tlearn: 0.0243708\ttotal: 3.41s\tremaining: 13s\n",
      "208:\tlearn: 0.0243673\ttotal: 3.42s\tremaining: 12.9s\n",
      "209:\tlearn: 0.0243642\ttotal: 3.43s\tremaining: 12.9s\n",
      "210:\tlearn: 0.0243613\ttotal: 3.45s\tremaining: 12.9s\n",
      "211:\tlearn: 0.0243584\ttotal: 3.46s\tremaining: 12.9s\n",
      "212:\tlearn: 0.0243549\ttotal: 3.48s\tremaining: 12.9s\n",
      "213:\tlearn: 0.0243499\ttotal: 3.5s\tremaining: 12.8s\n",
      "214:\tlearn: 0.0243433\ttotal: 3.51s\tremaining: 12.8s\n",
      "215:\tlearn: 0.0243396\ttotal: 3.53s\tremaining: 12.8s\n",
      "216:\tlearn: 0.0243361\ttotal: 3.55s\tremaining: 12.8s\n",
      "217:\tlearn: 0.0243315\ttotal: 3.56s\tremaining: 12.8s\n",
      "218:\tlearn: 0.0243285\ttotal: 3.58s\tremaining: 12.8s\n",
      "219:\tlearn: 0.0243230\ttotal: 3.59s\tremaining: 12.7s\n",
      "220:\tlearn: 0.0243192\ttotal: 3.61s\tremaining: 12.7s\n",
      "221:\tlearn: 0.0243154\ttotal: 3.63s\tremaining: 12.7s\n",
      "222:\tlearn: 0.0243125\ttotal: 3.64s\tremaining: 12.7s\n",
      "223:\tlearn: 0.0243099\ttotal: 3.65s\tremaining: 12.7s\n",
      "224:\tlearn: 0.0243075\ttotal: 3.67s\tremaining: 12.6s\n",
      "225:\tlearn: 0.0243042\ttotal: 3.69s\tremaining: 12.6s\n",
      "226:\tlearn: 0.0243005\ttotal: 3.7s\tremaining: 12.6s\n",
      "227:\tlearn: 0.0242968\ttotal: 3.72s\tremaining: 12.6s\n",
      "228:\tlearn: 0.0242942\ttotal: 3.73s\tremaining: 12.6s\n",
      "229:\tlearn: 0.0242898\ttotal: 3.75s\tremaining: 12.6s\n",
      "230:\tlearn: 0.0242865\ttotal: 3.77s\tremaining: 12.6s\n",
      "231:\tlearn: 0.0242840\ttotal: 3.78s\tremaining: 12.5s\n",
      "232:\tlearn: 0.0242807\ttotal: 3.79s\tremaining: 12.5s\n",
      "233:\tlearn: 0.0242779\ttotal: 3.81s\tremaining: 12.5s\n",
      "234:\tlearn: 0.0242713\ttotal: 3.83s\tremaining: 12.5s\n",
      "235:\tlearn: 0.0242669\ttotal: 3.84s\tremaining: 12.4s\n",
      "236:\tlearn: 0.0242637\ttotal: 3.86s\tremaining: 12.4s\n",
      "237:\tlearn: 0.0242610\ttotal: 3.87s\tremaining: 12.4s\n",
      "238:\tlearn: 0.0242588\ttotal: 3.89s\tremaining: 12.4s\n",
      "239:\tlearn: 0.0242542\ttotal: 3.9s\tremaining: 12.4s\n",
      "240:\tlearn: 0.0242516\ttotal: 3.92s\tremaining: 12.3s\n",
      "241:\tlearn: 0.0242476\ttotal: 3.93s\tremaining: 12.3s\n",
      "242:\tlearn: 0.0242447\ttotal: 3.95s\tremaining: 12.3s\n",
      "243:\tlearn: 0.0242407\ttotal: 3.96s\tremaining: 12.3s\n",
      "244:\tlearn: 0.0242375\ttotal: 3.98s\tremaining: 12.3s\n",
      "245:\tlearn: 0.0242347\ttotal: 4s\tremaining: 12.3s\n",
      "246:\tlearn: 0.0242309\ttotal: 4.02s\tremaining: 12.2s\n",
      "247:\tlearn: 0.0242256\ttotal: 4.03s\tremaining: 12.2s\n",
      "248:\tlearn: 0.0242189\ttotal: 4.04s\tremaining: 12.2s\n",
      "249:\tlearn: 0.0242161\ttotal: 4.06s\tremaining: 12.2s\n",
      "250:\tlearn: 0.0242130\ttotal: 4.07s\tremaining: 12.2s\n",
      "251:\tlearn: 0.0242097\ttotal: 4.09s\tremaining: 12.1s\n",
      "252:\tlearn: 0.0242077\ttotal: 4.11s\tremaining: 12.1s\n",
      "253:\tlearn: 0.0242046\ttotal: 4.12s\tremaining: 12.1s\n",
      "254:\tlearn: 0.0242020\ttotal: 4.13s\tremaining: 12.1s\n",
      "255:\tlearn: 0.0241991\ttotal: 4.15s\tremaining: 12.1s\n",
      "256:\tlearn: 0.0241963\ttotal: 4.16s\tremaining: 12s\n",
      "257:\tlearn: 0.0241926\ttotal: 4.19s\tremaining: 12s\n",
      "258:\tlearn: 0.0241908\ttotal: 4.2s\tremaining: 12s\n",
      "259:\tlearn: 0.0241877\ttotal: 4.22s\tremaining: 12s\n",
      "260:\tlearn: 0.0241845\ttotal: 4.24s\tremaining: 12s\n",
      "261:\tlearn: 0.0241809\ttotal: 4.25s\tremaining: 12s\n",
      "262:\tlearn: 0.0241777\ttotal: 4.27s\tremaining: 12s\n",
      "263:\tlearn: 0.0241747\ttotal: 4.29s\tremaining: 12s\n",
      "264:\tlearn: 0.0241722\ttotal: 4.3s\tremaining: 11.9s\n",
      "265:\tlearn: 0.0241703\ttotal: 4.32s\tremaining: 11.9s\n",
      "266:\tlearn: 0.0241677\ttotal: 4.33s\tremaining: 11.9s\n",
      "267:\tlearn: 0.0241654\ttotal: 4.35s\tremaining: 11.9s\n",
      "268:\tlearn: 0.0241626\ttotal: 4.36s\tremaining: 11.9s\n",
      "269:\tlearn: 0.0241604\ttotal: 4.38s\tremaining: 11.8s\n",
      "270:\tlearn: 0.0241581\ttotal: 4.39s\tremaining: 11.8s\n",
      "271:\tlearn: 0.0241551\ttotal: 4.41s\tremaining: 11.8s\n",
      "272:\tlearn: 0.0241521\ttotal: 4.43s\tremaining: 11.8s\n",
      "273:\tlearn: 0.0241488\ttotal: 4.44s\tremaining: 11.8s\n",
      "274:\tlearn: 0.0241458\ttotal: 4.46s\tremaining: 11.8s\n",
      "275:\tlearn: 0.0241440\ttotal: 4.47s\tremaining: 11.7s\n",
      "276:\tlearn: 0.0241413\ttotal: 4.49s\tremaining: 11.7s\n",
      "277:\tlearn: 0.0241394\ttotal: 4.51s\tremaining: 11.7s\n",
      "278:\tlearn: 0.0241376\ttotal: 4.52s\tremaining: 11.7s\n",
      "279:\tlearn: 0.0241349\ttotal: 4.54s\tremaining: 11.7s\n",
      "280:\tlearn: 0.0241313\ttotal: 4.55s\tremaining: 11.6s\n",
      "281:\tlearn: 0.0241293\ttotal: 4.56s\tremaining: 11.6s\n",
      "282:\tlearn: 0.0241257\ttotal: 4.58s\tremaining: 11.6s\n",
      "283:\tlearn: 0.0241224\ttotal: 4.6s\tremaining: 11.6s\n",
      "284:\tlearn: 0.0241202\ttotal: 4.62s\tremaining: 11.6s\n",
      "285:\tlearn: 0.0241174\ttotal: 4.64s\tremaining: 11.6s\n",
      "286:\tlearn: 0.0241105\ttotal: 4.66s\tremaining: 11.6s\n",
      "287:\tlearn: 0.0241079\ttotal: 4.68s\tremaining: 11.6s\n",
      "288:\tlearn: 0.0241060\ttotal: 4.69s\tremaining: 11.5s\n",
      "289:\tlearn: 0.0241037\ttotal: 4.71s\tremaining: 11.5s\n",
      "290:\tlearn: 0.0240993\ttotal: 4.73s\tremaining: 11.5s\n",
      "291:\tlearn: 0.0240959\ttotal: 4.74s\tremaining: 11.5s\n",
      "292:\tlearn: 0.0240937\ttotal: 4.75s\tremaining: 11.5s\n",
      "293:\tlearn: 0.0240897\ttotal: 4.76s\tremaining: 11.4s\n",
      "294:\tlearn: 0.0240871\ttotal: 4.78s\tremaining: 11.4s\n",
      "295:\tlearn: 0.0240852\ttotal: 4.79s\tremaining: 11.4s\n",
      "296:\tlearn: 0.0240799\ttotal: 4.81s\tremaining: 11.4s\n",
      "297:\tlearn: 0.0240784\ttotal: 4.83s\tremaining: 11.4s\n",
      "298:\tlearn: 0.0240757\ttotal: 4.84s\tremaining: 11.4s\n",
      "299:\tlearn: 0.0240730\ttotal: 4.86s\tremaining: 11.3s\n",
      "300:\tlearn: 0.0240710\ttotal: 4.87s\tremaining: 11.3s\n",
      "301:\tlearn: 0.0240695\ttotal: 4.89s\tremaining: 11.3s\n",
      "302:\tlearn: 0.0240678\ttotal: 4.9s\tremaining: 11.3s\n",
      "303:\tlearn: 0.0240656\ttotal: 4.92s\tremaining: 11.3s\n",
      "304:\tlearn: 0.0240631\ttotal: 4.94s\tremaining: 11.2s\n",
      "305:\tlearn: 0.0240569\ttotal: 4.96s\tremaining: 11.2s\n",
      "306:\tlearn: 0.0240539\ttotal: 4.97s\tremaining: 11.2s\n",
      "307:\tlearn: 0.0240498\ttotal: 4.99s\tremaining: 11.2s\n",
      "308:\tlearn: 0.0240477\ttotal: 5s\tremaining: 11.2s\n",
      "309:\tlearn: 0.0240454\ttotal: 5.02s\tremaining: 11.2s\n",
      "310:\tlearn: 0.0240428\ttotal: 5.03s\tremaining: 11.2s\n",
      "311:\tlearn: 0.0240412\ttotal: 5.05s\tremaining: 11.1s\n",
      "312:\tlearn: 0.0240392\ttotal: 5.07s\tremaining: 11.1s\n",
      "313:\tlearn: 0.0240375\ttotal: 5.08s\tremaining: 11.1s\n",
      "314:\tlearn: 0.0240358\ttotal: 5.1s\tremaining: 11.1s\n",
      "315:\tlearn: 0.0240341\ttotal: 5.11s\tremaining: 11.1s\n",
      "316:\tlearn: 0.0240318\ttotal: 5.13s\tremaining: 11s\n",
      "317:\tlearn: 0.0240301\ttotal: 5.14s\tremaining: 11s\n",
      "318:\tlearn: 0.0240255\ttotal: 5.15s\tremaining: 11s\n",
      "319:\tlearn: 0.0240229\ttotal: 5.17s\tremaining: 11s\n",
      "320:\tlearn: 0.0240211\ttotal: 5.18s\tremaining: 11s\n",
      "321:\tlearn: 0.0240190\ttotal: 5.2s\tremaining: 10.9s\n",
      "322:\tlearn: 0.0240175\ttotal: 5.21s\tremaining: 10.9s\n",
      "323:\tlearn: 0.0240162\ttotal: 5.23s\tremaining: 10.9s\n",
      "324:\tlearn: 0.0240144\ttotal: 5.24s\tremaining: 10.9s\n",
      "325:\tlearn: 0.0240128\ttotal: 5.26s\tremaining: 10.9s\n",
      "326:\tlearn: 0.0240104\ttotal: 5.28s\tremaining: 10.9s\n",
      "327:\tlearn: 0.0240082\ttotal: 5.29s\tremaining: 10.8s\n",
      "328:\tlearn: 0.0240057\ttotal: 5.3s\tremaining: 10.8s\n",
      "329:\tlearn: 0.0240041\ttotal: 5.32s\tremaining: 10.8s\n",
      "330:\tlearn: 0.0240005\ttotal: 5.34s\tremaining: 10.8s\n",
      "331:\tlearn: 0.0239988\ttotal: 5.36s\tremaining: 10.8s\n",
      "332:\tlearn: 0.0239983\ttotal: 5.37s\tremaining: 10.8s\n",
      "333:\tlearn: 0.0239975\ttotal: 5.38s\tremaining: 10.7s\n",
      "334:\tlearn: 0.0239959\ttotal: 5.4s\tremaining: 10.7s\n",
      "335:\tlearn: 0.0239942\ttotal: 5.41s\tremaining: 10.7s\n",
      "336:\tlearn: 0.0239925\ttotal: 5.43s\tremaining: 10.7s\n",
      "337:\tlearn: 0.0239890\ttotal: 5.44s\tremaining: 10.7s\n",
      "338:\tlearn: 0.0239871\ttotal: 5.46s\tremaining: 10.6s\n",
      "339:\tlearn: 0.0239845\ttotal: 5.47s\tremaining: 10.6s\n",
      "340:\tlearn: 0.0239828\ttotal: 5.49s\tremaining: 10.6s\n",
      "341:\tlearn: 0.0239813\ttotal: 5.51s\tremaining: 10.6s\n",
      "342:\tlearn: 0.0239770\ttotal: 5.52s\tremaining: 10.6s\n",
      "343:\tlearn: 0.0239755\ttotal: 5.54s\tremaining: 10.6s\n",
      "344:\tlearn: 0.0239732\ttotal: 5.55s\tremaining: 10.5s\n",
      "345:\tlearn: 0.0239707\ttotal: 5.56s\tremaining: 10.5s\n",
      "346:\tlearn: 0.0239642\ttotal: 5.58s\tremaining: 10.5s\n",
      "347:\tlearn: 0.0239622\ttotal: 5.59s\tremaining: 10.5s\n",
      "348:\tlearn: 0.0239609\ttotal: 5.61s\tremaining: 10.5s\n",
      "349:\tlearn: 0.0239585\ttotal: 5.62s\tremaining: 10.4s\n",
      "350:\tlearn: 0.0239571\ttotal: 5.64s\tremaining: 10.4s\n",
      "351:\tlearn: 0.0239552\ttotal: 5.65s\tremaining: 10.4s\n",
      "352:\tlearn: 0.0239529\ttotal: 5.66s\tremaining: 10.4s\n",
      "353:\tlearn: 0.0239513\ttotal: 5.68s\tremaining: 10.4s\n",
      "354:\tlearn: 0.0239499\ttotal: 5.69s\tremaining: 10.3s\n",
      "355:\tlearn: 0.0239488\ttotal: 5.8s\tremaining: 10.5s\n",
      "356:\tlearn: 0.0239474\ttotal: 5.82s\tremaining: 10.5s\n",
      "357:\tlearn: 0.0239447\ttotal: 5.92s\tremaining: 10.6s\n",
      "358:\tlearn: 0.0239432\ttotal: 5.94s\tremaining: 10.6s\n",
      "359:\tlearn: 0.0239411\ttotal: 5.96s\tremaining: 10.6s\n",
      "360:\tlearn: 0.0239395\ttotal: 5.97s\tremaining: 10.6s\n",
      "361:\tlearn: 0.0239383\ttotal: 5.99s\tremaining: 10.5s\n",
      "362:\tlearn: 0.0239368\ttotal: 6s\tremaining: 10.5s\n",
      "363:\tlearn: 0.0239355\ttotal: 6.02s\tremaining: 10.5s\n",
      "364:\tlearn: 0.0239336\ttotal: 6.03s\tremaining: 10.5s\n",
      "365:\tlearn: 0.0239306\ttotal: 6.05s\tremaining: 10.5s\n",
      "366:\tlearn: 0.0239288\ttotal: 6.06s\tremaining: 10.5s\n",
      "367:\tlearn: 0.0239267\ttotal: 6.08s\tremaining: 10.4s\n",
      "368:\tlearn: 0.0239246\ttotal: 6.09s\tremaining: 10.4s\n",
      "369:\tlearn: 0.0239228\ttotal: 6.11s\tremaining: 10.4s\n",
      "370:\tlearn: 0.0239211\ttotal: 6.12s\tremaining: 10.4s\n",
      "371:\tlearn: 0.0239167\ttotal: 6.14s\tremaining: 10.4s\n",
      "372:\tlearn: 0.0239155\ttotal: 6.15s\tremaining: 10.3s\n",
      "373:\tlearn: 0.0239115\ttotal: 6.17s\tremaining: 10.3s\n",
      "374:\tlearn: 0.0239100\ttotal: 6.18s\tremaining: 10.3s\n",
      "375:\tlearn: 0.0239079\ttotal: 6.2s\tremaining: 10.3s\n",
      "376:\tlearn: 0.0239069\ttotal: 6.21s\tremaining: 10.3s\n",
      "377:\tlearn: 0.0239059\ttotal: 6.23s\tremaining: 10.2s\n",
      "378:\tlearn: 0.0239036\ttotal: 6.24s\tremaining: 10.2s\n",
      "379:\tlearn: 0.0239007\ttotal: 6.26s\tremaining: 10.2s\n",
      "380:\tlearn: 0.0238984\ttotal: 6.27s\tremaining: 10.2s\n",
      "381:\tlearn: 0.0238963\ttotal: 6.29s\tremaining: 10.2s\n",
      "382:\tlearn: 0.0238937\ttotal: 6.3s\tremaining: 10.2s\n",
      "383:\tlearn: 0.0238912\ttotal: 6.32s\tremaining: 10.1s\n",
      "384:\tlearn: 0.0238895\ttotal: 6.33s\tremaining: 10.1s\n",
      "385:\tlearn: 0.0238873\ttotal: 6.35s\tremaining: 10.1s\n",
      "386:\tlearn: 0.0238845\ttotal: 6.37s\tremaining: 10.1s\n",
      "387:\tlearn: 0.0238829\ttotal: 6.38s\tremaining: 10.1s\n",
      "388:\tlearn: 0.0238812\ttotal: 6.4s\tremaining: 10.1s\n",
      "389:\tlearn: 0.0238792\ttotal: 6.42s\tremaining: 10s\n",
      "390:\tlearn: 0.0238780\ttotal: 6.43s\tremaining: 10s\n",
      "391:\tlearn: 0.0238753\ttotal: 6.45s\tremaining: 10s\n",
      "392:\tlearn: 0.0238729\ttotal: 6.46s\tremaining: 9.99s\n",
      "393:\tlearn: 0.0238721\ttotal: 6.48s\tremaining: 9.97s\n",
      "394:\tlearn: 0.0238701\ttotal: 6.5s\tremaining: 9.95s\n",
      "395:\tlearn: 0.0238689\ttotal: 6.51s\tremaining: 9.93s\n",
      "396:\tlearn: 0.0238672\ttotal: 6.52s\tremaining: 9.91s\n",
      "397:\tlearn: 0.0238653\ttotal: 6.54s\tremaining: 9.89s\n",
      "398:\tlearn: 0.0238640\ttotal: 6.55s\tremaining: 9.87s\n",
      "399:\tlearn: 0.0238621\ttotal: 6.57s\tremaining: 9.86s\n",
      "400:\tlearn: 0.0238604\ttotal: 6.59s\tremaining: 9.84s\n",
      "401:\tlearn: 0.0238594\ttotal: 6.6s\tremaining: 9.82s\n",
      "402:\tlearn: 0.0238565\ttotal: 6.62s\tremaining: 9.8s\n",
      "403:\tlearn: 0.0238556\ttotal: 6.63s\tremaining: 9.78s\n",
      "404:\tlearn: 0.0238535\ttotal: 6.65s\tremaining: 9.76s\n",
      "405:\tlearn: 0.0238525\ttotal: 6.67s\tremaining: 9.76s\n",
      "406:\tlearn: 0.0238512\ttotal: 6.68s\tremaining: 9.74s\n",
      "407:\tlearn: 0.0238500\ttotal: 6.7s\tremaining: 9.72s\n",
      "408:\tlearn: 0.0238483\ttotal: 6.72s\tremaining: 9.71s\n",
      "409:\tlearn: 0.0238471\ttotal: 6.74s\tremaining: 9.69s\n",
      "410:\tlearn: 0.0238455\ttotal: 6.76s\tremaining: 9.68s\n",
      "411:\tlearn: 0.0238441\ttotal: 6.78s\tremaining: 9.68s\n",
      "412:\tlearn: 0.0238427\ttotal: 6.8s\tremaining: 9.67s\n",
      "413:\tlearn: 0.0238414\ttotal: 6.82s\tremaining: 9.65s\n",
      "414:\tlearn: 0.0238392\ttotal: 6.83s\tremaining: 9.63s\n",
      "415:\tlearn: 0.0238389\ttotal: 6.85s\tremaining: 9.61s\n",
      "416:\tlearn: 0.0238359\ttotal: 6.86s\tremaining: 9.6s\n",
      "417:\tlearn: 0.0238341\ttotal: 6.88s\tremaining: 9.58s\n",
      "418:\tlearn: 0.0238328\ttotal: 6.89s\tremaining: 9.56s\n",
      "419:\tlearn: 0.0238310\ttotal: 6.91s\tremaining: 9.54s\n",
      "420:\tlearn: 0.0238292\ttotal: 6.92s\tremaining: 9.52s\n",
      "421:\tlearn: 0.0238262\ttotal: 6.94s\tremaining: 9.51s\n",
      "422:\tlearn: 0.0238245\ttotal: 6.96s\tremaining: 9.49s\n",
      "423:\tlearn: 0.0238232\ttotal: 6.98s\tremaining: 9.48s\n",
      "424:\tlearn: 0.0238223\ttotal: 7s\tremaining: 9.47s\n",
      "425:\tlearn: 0.0238213\ttotal: 7.01s\tremaining: 9.45s\n",
      "426:\tlearn: 0.0238198\ttotal: 7.03s\tremaining: 9.43s\n",
      "427:\tlearn: 0.0238176\ttotal: 7.04s\tremaining: 9.41s\n",
      "428:\tlearn: 0.0238160\ttotal: 7.06s\tremaining: 9.4s\n",
      "429:\tlearn: 0.0238153\ttotal: 7.08s\tremaining: 9.38s\n",
      "430:\tlearn: 0.0238139\ttotal: 7.09s\tremaining: 9.36s\n",
      "431:\tlearn: 0.0238129\ttotal: 7.11s\tremaining: 9.35s\n",
      "432:\tlearn: 0.0238117\ttotal: 7.12s\tremaining: 9.33s\n",
      "433:\tlearn: 0.0238105\ttotal: 7.14s\tremaining: 9.31s\n",
      "434:\tlearn: 0.0238093\ttotal: 7.15s\tremaining: 9.29s\n",
      "435:\tlearn: 0.0238081\ttotal: 7.17s\tremaining: 9.27s\n",
      "436:\tlearn: 0.0238073\ttotal: 7.18s\tremaining: 9.25s\n",
      "437:\tlearn: 0.0238063\ttotal: 7.2s\tremaining: 9.23s\n",
      "438:\tlearn: 0.0238053\ttotal: 7.22s\tremaining: 9.23s\n",
      "439:\tlearn: 0.0238045\ttotal: 7.23s\tremaining: 9.2s\n",
      "440:\tlearn: 0.0238037\ttotal: 7.24s\tremaining: 9.18s\n",
      "441:\tlearn: 0.0238022\ttotal: 7.26s\tremaining: 9.16s\n",
      "442:\tlearn: 0.0237972\ttotal: 7.27s\tremaining: 9.14s\n",
      "443:\tlearn: 0.0237961\ttotal: 7.29s\tremaining: 9.12s\n",
      "444:\tlearn: 0.0237916\ttotal: 7.3s\tremaining: 9.11s\n",
      "445:\tlearn: 0.0237907\ttotal: 7.32s\tremaining: 9.09s\n",
      "446:\tlearn: 0.0237892\ttotal: 7.33s\tremaining: 9.07s\n",
      "447:\tlearn: 0.0237857\ttotal: 7.34s\tremaining: 9.05s\n",
      "448:\tlearn: 0.0237850\ttotal: 7.36s\tremaining: 9.03s\n",
      "449:\tlearn: 0.0237847\ttotal: 7.37s\tremaining: 9.01s\n",
      "450:\tlearn: 0.0237832\ttotal: 7.39s\tremaining: 8.99s\n",
      "451:\tlearn: 0.0237823\ttotal: 7.4s\tremaining: 8.97s\n",
      "452:\tlearn: 0.0237816\ttotal: 7.41s\tremaining: 8.95s\n",
      "453:\tlearn: 0.0237807\ttotal: 7.43s\tremaining: 8.94s\n",
      "454:\tlearn: 0.0237791\ttotal: 7.45s\tremaining: 8.92s\n",
      "455:\tlearn: 0.0237777\ttotal: 7.46s\tremaining: 8.9s\n",
      "456:\tlearn: 0.0237758\ttotal: 7.48s\tremaining: 8.89s\n",
      "457:\tlearn: 0.0237743\ttotal: 7.5s\tremaining: 8.87s\n",
      "458:\tlearn: 0.0237702\ttotal: 7.51s\tremaining: 8.85s\n",
      "459:\tlearn: 0.0237686\ttotal: 7.53s\tremaining: 8.84s\n",
      "460:\tlearn: 0.0237665\ttotal: 7.55s\tremaining: 8.83s\n",
      "461:\tlearn: 0.0237652\ttotal: 7.57s\tremaining: 8.81s\n",
      "462:\tlearn: 0.0237627\ttotal: 7.58s\tremaining: 8.79s\n",
      "463:\tlearn: 0.0237619\ttotal: 7.59s\tremaining: 8.77s\n",
      "464:\tlearn: 0.0237603\ttotal: 7.61s\tremaining: 8.76s\n",
      "465:\tlearn: 0.0237588\ttotal: 7.63s\tremaining: 8.74s\n",
      "466:\tlearn: 0.0237565\ttotal: 7.64s\tremaining: 8.73s\n",
      "467:\tlearn: 0.0237556\ttotal: 7.66s\tremaining: 8.71s\n",
      "468:\tlearn: 0.0237546\ttotal: 7.67s\tremaining: 8.69s\n",
      "469:\tlearn: 0.0237536\ttotal: 7.69s\tremaining: 8.67s\n",
      "470:\tlearn: 0.0237505\ttotal: 7.7s\tremaining: 8.65s\n",
      "471:\tlearn: 0.0237483\ttotal: 7.72s\tremaining: 8.63s\n",
      "472:\tlearn: 0.0237474\ttotal: 7.73s\tremaining: 8.62s\n",
      "473:\tlearn: 0.0237460\ttotal: 7.75s\tremaining: 8.6s\n",
      "474:\tlearn: 0.0237453\ttotal: 7.76s\tremaining: 8.58s\n",
      "475:\tlearn: 0.0237443\ttotal: 7.78s\tremaining: 8.56s\n",
      "476:\tlearn: 0.0237419\ttotal: 7.79s\tremaining: 8.54s\n",
      "477:\tlearn: 0.0237413\ttotal: 7.81s\tremaining: 8.53s\n",
      "478:\tlearn: 0.0237406\ttotal: 7.82s\tremaining: 8.5s\n",
      "479:\tlearn: 0.0237397\ttotal: 7.83s\tremaining: 8.49s\n",
      "480:\tlearn: 0.0237390\ttotal: 7.85s\tremaining: 8.47s\n",
      "481:\tlearn: 0.0237387\ttotal: 7.86s\tremaining: 8.45s\n",
      "482:\tlearn: 0.0237367\ttotal: 7.88s\tremaining: 8.43s\n",
      "483:\tlearn: 0.0237359\ttotal: 7.89s\tremaining: 8.42s\n",
      "484:\tlearn: 0.0237343\ttotal: 7.91s\tremaining: 8.4s\n",
      "485:\tlearn: 0.0237339\ttotal: 7.93s\tremaining: 8.38s\n",
      "486:\tlearn: 0.0237332\ttotal: 7.94s\tremaining: 8.37s\n",
      "487:\tlearn: 0.0237325\ttotal: 7.95s\tremaining: 8.35s\n",
      "488:\tlearn: 0.0237322\ttotal: 7.96s\tremaining: 8.32s\n",
      "489:\tlearn: 0.0237314\ttotal: 7.98s\tremaining: 8.3s\n",
      "490:\tlearn: 0.0237293\ttotal: 7.99s\tremaining: 8.29s\n",
      "491:\tlearn: 0.0237284\ttotal: 8.01s\tremaining: 8.27s\n",
      "492:\tlearn: 0.0237261\ttotal: 8.02s\tremaining: 8.25s\n",
      "493:\tlearn: 0.0237251\ttotal: 8.04s\tremaining: 8.23s\n",
      "494:\tlearn: 0.0237238\ttotal: 8.06s\tremaining: 8.22s\n",
      "495:\tlearn: 0.0237228\ttotal: 8.07s\tremaining: 8.2s\n",
      "496:\tlearn: 0.0237222\ttotal: 8.08s\tremaining: 8.18s\n",
      "497:\tlearn: 0.0237218\ttotal: 8.09s\tremaining: 8.16s\n",
      "498:\tlearn: 0.0237210\ttotal: 8.11s\tremaining: 8.14s\n",
      "499:\tlearn: 0.0237202\ttotal: 8.12s\tremaining: 8.12s\n",
      "500:\tlearn: 0.0237193\ttotal: 8.14s\tremaining: 8.1s\n",
      "501:\tlearn: 0.0237177\ttotal: 8.15s\tremaining: 8.08s\n",
      "502:\tlearn: 0.0237150\ttotal: 8.16s\tremaining: 8.07s\n",
      "503:\tlearn: 0.0237142\ttotal: 8.18s\tremaining: 8.05s\n",
      "504:\tlearn: 0.0237130\ttotal: 8.19s\tremaining: 8.03s\n",
      "505:\tlearn: 0.0237115\ttotal: 8.21s\tremaining: 8.01s\n",
      "506:\tlearn: 0.0237107\ttotal: 8.22s\tremaining: 7.99s\n",
      "507:\tlearn: 0.0237097\ttotal: 8.23s\tremaining: 7.97s\n",
      "508:\tlearn: 0.0237079\ttotal: 8.25s\tremaining: 7.96s\n",
      "509:\tlearn: 0.0237070\ttotal: 8.27s\tremaining: 7.94s\n",
      "510:\tlearn: 0.0237059\ttotal: 8.29s\tremaining: 7.93s\n",
      "511:\tlearn: 0.0237051\ttotal: 8.3s\tremaining: 7.91s\n",
      "512:\tlearn: 0.0237032\ttotal: 8.32s\tremaining: 7.9s\n",
      "513:\tlearn: 0.0237019\ttotal: 8.34s\tremaining: 7.88s\n",
      "514:\tlearn: 0.0236994\ttotal: 8.35s\tremaining: 7.86s\n",
      "515:\tlearn: 0.0236983\ttotal: 8.36s\tremaining: 7.84s\n",
      "516:\tlearn: 0.0236978\ttotal: 8.38s\tremaining: 7.83s\n",
      "517:\tlearn: 0.0236962\ttotal: 8.39s\tremaining: 7.81s\n",
      "518:\tlearn: 0.0236915\ttotal: 8.4s\tremaining: 7.79s\n",
      "519:\tlearn: 0.0236908\ttotal: 8.42s\tremaining: 7.77s\n",
      "520:\tlearn: 0.0236891\ttotal: 8.44s\tremaining: 7.75s\n",
      "521:\tlearn: 0.0236855\ttotal: 8.45s\tremaining: 7.74s\n",
      "522:\tlearn: 0.0236846\ttotal: 8.47s\tremaining: 7.72s\n",
      "523:\tlearn: 0.0236831\ttotal: 8.49s\tremaining: 7.71s\n",
      "524:\tlearn: 0.0236828\ttotal: 8.5s\tremaining: 7.69s\n",
      "525:\tlearn: 0.0236806\ttotal: 8.52s\tremaining: 7.68s\n",
      "526:\tlearn: 0.0236803\ttotal: 8.55s\tremaining: 7.67s\n",
      "527:\tlearn: 0.0236794\ttotal: 8.57s\tremaining: 7.66s\n",
      "528:\tlearn: 0.0236778\ttotal: 8.58s\tremaining: 7.64s\n",
      "529:\tlearn: 0.0236763\ttotal: 8.6s\tremaining: 7.63s\n",
      "530:\tlearn: 0.0236753\ttotal: 8.62s\tremaining: 7.61s\n",
      "531:\tlearn: 0.0236740\ttotal: 8.63s\tremaining: 7.59s\n",
      "532:\tlearn: 0.0236725\ttotal: 8.65s\tremaining: 7.58s\n",
      "533:\tlearn: 0.0236713\ttotal: 8.66s\tremaining: 7.56s\n",
      "534:\tlearn: 0.0236706\ttotal: 8.68s\tremaining: 7.54s\n",
      "535:\tlearn: 0.0236697\ttotal: 8.7s\tremaining: 7.53s\n",
      "536:\tlearn: 0.0236685\ttotal: 8.71s\tremaining: 7.51s\n",
      "537:\tlearn: 0.0236663\ttotal: 8.73s\tremaining: 7.5s\n",
      "538:\tlearn: 0.0236606\ttotal: 8.75s\tremaining: 7.49s\n",
      "539:\tlearn: 0.0236599\ttotal: 8.77s\tremaining: 7.47s\n",
      "540:\tlearn: 0.0236590\ttotal: 8.79s\tremaining: 7.46s\n",
      "541:\tlearn: 0.0236584\ttotal: 8.8s\tremaining: 7.44s\n",
      "542:\tlearn: 0.0236545\ttotal: 8.82s\tremaining: 7.42s\n",
      "543:\tlearn: 0.0236536\ttotal: 8.83s\tremaining: 7.4s\n",
      "544:\tlearn: 0.0236520\ttotal: 8.85s\tremaining: 7.38s\n",
      "545:\tlearn: 0.0236506\ttotal: 8.86s\tremaining: 7.37s\n",
      "546:\tlearn: 0.0236487\ttotal: 8.88s\tremaining: 7.35s\n",
      "547:\tlearn: 0.0236482\ttotal: 8.89s\tremaining: 7.33s\n",
      "548:\tlearn: 0.0236472\ttotal: 8.9s\tremaining: 7.31s\n",
      "549:\tlearn: 0.0236446\ttotal: 8.91s\tremaining: 7.29s\n",
      "550:\tlearn: 0.0236443\ttotal: 8.92s\tremaining: 7.27s\n",
      "551:\tlearn: 0.0236434\ttotal: 8.94s\tremaining: 7.25s\n",
      "552:\tlearn: 0.0236427\ttotal: 8.95s\tremaining: 7.23s\n",
      "553:\tlearn: 0.0236411\ttotal: 8.97s\tremaining: 7.22s\n",
      "554:\tlearn: 0.0236404\ttotal: 8.99s\tremaining: 7.21s\n",
      "555:\tlearn: 0.0236390\ttotal: 9.01s\tremaining: 7.2s\n",
      "556:\tlearn: 0.0236383\ttotal: 9.03s\tremaining: 7.18s\n",
      "557:\tlearn: 0.0236369\ttotal: 9.04s\tremaining: 7.16s\n",
      "558:\tlearn: 0.0236362\ttotal: 9.06s\tremaining: 7.14s\n",
      "559:\tlearn: 0.0236339\ttotal: 9.07s\tremaining: 7.13s\n",
      "560:\tlearn: 0.0236333\ttotal: 9.09s\tremaining: 7.11s\n",
      "561:\tlearn: 0.0236325\ttotal: 9.11s\tremaining: 7.1s\n",
      "562:\tlearn: 0.0236317\ttotal: 9.12s\tremaining: 7.08s\n",
      "563:\tlearn: 0.0236310\ttotal: 9.13s\tremaining: 7.06s\n",
      "564:\tlearn: 0.0236308\ttotal: 9.14s\tremaining: 7.04s\n",
      "565:\tlearn: 0.0236284\ttotal: 9.16s\tremaining: 7.02s\n",
      "566:\tlearn: 0.0236278\ttotal: 9.17s\tremaining: 7s\n",
      "567:\tlearn: 0.0236260\ttotal: 9.19s\tremaining: 6.99s\n",
      "568:\tlearn: 0.0236232\ttotal: 9.21s\tremaining: 6.98s\n",
      "569:\tlearn: 0.0236226\ttotal: 9.23s\tremaining: 6.96s\n",
      "570:\tlearn: 0.0236223\ttotal: 9.24s\tremaining: 6.94s\n",
      "571:\tlearn: 0.0236188\ttotal: 9.25s\tremaining: 6.92s\n",
      "572:\tlearn: 0.0236186\ttotal: 9.27s\tremaining: 6.91s\n",
      "573:\tlearn: 0.0236182\ttotal: 9.28s\tremaining: 6.89s\n",
      "574:\tlearn: 0.0236168\ttotal: 9.3s\tremaining: 6.87s\n",
      "575:\tlearn: 0.0236160\ttotal: 9.31s\tremaining: 6.85s\n",
      "576:\tlearn: 0.0236154\ttotal: 9.33s\tremaining: 6.84s\n",
      "577:\tlearn: 0.0236140\ttotal: 9.34s\tremaining: 6.82s\n",
      "578:\tlearn: 0.0236125\ttotal: 9.36s\tremaining: 6.8s\n",
      "579:\tlearn: 0.0236116\ttotal: 9.37s\tremaining: 6.79s\n",
      "580:\tlearn: 0.0236113\ttotal: 9.38s\tremaining: 6.77s\n",
      "581:\tlearn: 0.0236094\ttotal: 9.4s\tremaining: 6.75s\n",
      "582:\tlearn: 0.0236048\ttotal: 9.42s\tremaining: 6.74s\n",
      "583:\tlearn: 0.0236042\ttotal: 9.43s\tremaining: 6.72s\n",
      "584:\tlearn: 0.0236036\ttotal: 9.44s\tremaining: 6.7s\n",
      "585:\tlearn: 0.0236027\ttotal: 9.46s\tremaining: 6.68s\n",
      "586:\tlearn: 0.0236009\ttotal: 9.47s\tremaining: 6.67s\n",
      "587:\tlearn: 0.0236006\ttotal: 9.49s\tremaining: 6.65s\n",
      "588:\tlearn: 0.0235982\ttotal: 9.5s\tremaining: 6.63s\n",
      "589:\tlearn: 0.0235920\ttotal: 9.52s\tremaining: 6.61s\n",
      "590:\tlearn: 0.0235916\ttotal: 9.53s\tremaining: 6.6s\n",
      "591:\tlearn: 0.0235867\ttotal: 9.55s\tremaining: 6.58s\n",
      "592:\tlearn: 0.0235837\ttotal: 9.57s\tremaining: 6.57s\n",
      "593:\tlearn: 0.0235822\ttotal: 9.58s\tremaining: 6.55s\n",
      "594:\tlearn: 0.0235819\ttotal: 9.6s\tremaining: 6.53s\n",
      "595:\tlearn: 0.0235777\ttotal: 9.61s\tremaining: 6.51s\n",
      "596:\tlearn: 0.0235762\ttotal: 9.63s\tremaining: 6.5s\n",
      "597:\tlearn: 0.0235747\ttotal: 9.65s\tremaining: 6.48s\n",
      "598:\tlearn: 0.0235740\ttotal: 9.66s\tremaining: 6.47s\n",
      "599:\tlearn: 0.0235726\ttotal: 9.68s\tremaining: 6.45s\n",
      "600:\tlearn: 0.0235722\ttotal: 9.69s\tremaining: 6.43s\n",
      "601:\tlearn: 0.0235716\ttotal: 9.71s\tremaining: 6.42s\n",
      "602:\tlearn: 0.0235708\ttotal: 9.72s\tremaining: 6.4s\n",
      "603:\tlearn: 0.0235702\ttotal: 9.73s\tremaining: 6.38s\n",
      "604:\tlearn: 0.0235679\ttotal: 9.75s\tremaining: 6.36s\n",
      "605:\tlearn: 0.0235673\ttotal: 9.76s\tremaining: 6.35s\n",
      "606:\tlearn: 0.0235656\ttotal: 9.77s\tremaining: 6.33s\n",
      "607:\tlearn: 0.0235644\ttotal: 9.79s\tremaining: 6.31s\n",
      "608:\tlearn: 0.0235628\ttotal: 9.8s\tremaining: 6.29s\n",
      "609:\tlearn: 0.0235615\ttotal: 9.82s\tremaining: 6.28s\n",
      "610:\tlearn: 0.0235610\ttotal: 9.84s\tremaining: 6.26s\n",
      "611:\tlearn: 0.0235598\ttotal: 9.87s\tremaining: 6.26s\n",
      "612:\tlearn: 0.0235596\ttotal: 9.88s\tremaining: 6.24s\n",
      "613:\tlearn: 0.0235578\ttotal: 9.9s\tremaining: 6.22s\n",
      "614:\tlearn: 0.0235567\ttotal: 9.92s\tremaining: 6.21s\n",
      "615:\tlearn: 0.0235562\ttotal: 9.93s\tremaining: 6.19s\n",
      "616:\tlearn: 0.0235547\ttotal: 9.94s\tremaining: 6.17s\n",
      "617:\tlearn: 0.0235503\ttotal: 9.96s\tremaining: 6.16s\n",
      "618:\tlearn: 0.0235499\ttotal: 9.98s\tremaining: 6.14s\n",
      "619:\tlearn: 0.0235492\ttotal: 10s\tremaining: 6.13s\n",
      "620:\tlearn: 0.0235482\ttotal: 10s\tremaining: 6.11s\n",
      "621:\tlearn: 0.0235474\ttotal: 10s\tremaining: 6.09s\n",
      "622:\tlearn: 0.0235464\ttotal: 10s\tremaining: 6.08s\n",
      "623:\tlearn: 0.0235456\ttotal: 10.1s\tremaining: 6.07s\n",
      "624:\tlearn: 0.0235451\ttotal: 10.1s\tremaining: 6.06s\n",
      "625:\tlearn: 0.0235437\ttotal: 10.1s\tremaining: 6.04s\n",
      "626:\tlearn: 0.0235434\ttotal: 10.1s\tremaining: 6.02s\n",
      "627:\tlearn: 0.0235416\ttotal: 10.1s\tremaining: 6s\n",
      "628:\tlearn: 0.0235404\ttotal: 10.1s\tremaining: 5.99s\n",
      "629:\tlearn: 0.0235393\ttotal: 10.2s\tremaining: 5.97s\n",
      "630:\tlearn: 0.0235387\ttotal: 10.2s\tremaining: 5.95s\n",
      "631:\tlearn: 0.0235380\ttotal: 10.2s\tremaining: 5.93s\n",
      "632:\tlearn: 0.0235365\ttotal: 10.2s\tremaining: 5.92s\n",
      "633:\tlearn: 0.0235361\ttotal: 10.2s\tremaining: 5.9s\n",
      "634:\tlearn: 0.0235355\ttotal: 10.2s\tremaining: 5.88s\n",
      "635:\tlearn: 0.0235343\ttotal: 10.2s\tremaining: 5.87s\n",
      "636:\tlearn: 0.0235339\ttotal: 10.3s\tremaining: 5.85s\n",
      "637:\tlearn: 0.0235329\ttotal: 10.3s\tremaining: 5.83s\n",
      "638:\tlearn: 0.0235322\ttotal: 10.3s\tremaining: 5.81s\n",
      "639:\tlearn: 0.0235303\ttotal: 10.3s\tremaining: 5.8s\n",
      "640:\tlearn: 0.0235288\ttotal: 10.3s\tremaining: 5.79s\n",
      "641:\tlearn: 0.0235275\ttotal: 10.3s\tremaining: 5.77s\n",
      "642:\tlearn: 0.0235270\ttotal: 10.4s\tremaining: 5.75s\n",
      "643:\tlearn: 0.0235264\ttotal: 10.4s\tremaining: 5.74s\n",
      "644:\tlearn: 0.0235262\ttotal: 10.4s\tremaining: 5.72s\n",
      "645:\tlearn: 0.0235244\ttotal: 10.4s\tremaining: 5.71s\n",
      "646:\tlearn: 0.0235242\ttotal: 10.4s\tremaining: 5.69s\n",
      "647:\tlearn: 0.0235239\ttotal: 10.4s\tremaining: 5.67s\n",
      "648:\tlearn: 0.0235234\ttotal: 10.4s\tremaining: 5.65s\n",
      "649:\tlearn: 0.0235231\ttotal: 10.5s\tremaining: 5.63s\n",
      "650:\tlearn: 0.0235209\ttotal: 10.5s\tremaining: 5.61s\n",
      "651:\tlearn: 0.0235199\ttotal: 10.5s\tremaining: 5.6s\n",
      "652:\tlearn: 0.0235187\ttotal: 10.5s\tremaining: 5.58s\n",
      "653:\tlearn: 0.0235178\ttotal: 10.5s\tremaining: 5.56s\n",
      "654:\tlearn: 0.0235171\ttotal: 10.5s\tremaining: 5.55s\n",
      "655:\tlearn: 0.0235162\ttotal: 10.6s\tremaining: 5.53s\n",
      "656:\tlearn: 0.0235090\ttotal: 10.6s\tremaining: 5.52s\n",
      "657:\tlearn: 0.0235045\ttotal: 10.6s\tremaining: 5.5s\n",
      "658:\tlearn: 0.0235032\ttotal: 10.6s\tremaining: 5.48s\n",
      "659:\tlearn: 0.0235025\ttotal: 10.6s\tremaining: 5.46s\n",
      "660:\tlearn: 0.0235012\ttotal: 10.6s\tremaining: 5.45s\n",
      "661:\tlearn: 0.0235008\ttotal: 10.6s\tremaining: 5.43s\n",
      "662:\tlearn: 0.0235003\ttotal: 10.6s\tremaining: 5.41s\n",
      "663:\tlearn: 0.0234998\ttotal: 10.7s\tremaining: 5.4s\n",
      "664:\tlearn: 0.0234991\ttotal: 10.7s\tremaining: 5.38s\n",
      "665:\tlearn: 0.0234983\ttotal: 10.7s\tremaining: 5.36s\n",
      "666:\tlearn: 0.0234925\ttotal: 10.7s\tremaining: 5.35s\n",
      "667:\tlearn: 0.0234919\ttotal: 10.7s\tremaining: 5.33s\n",
      "668:\tlearn: 0.0234914\ttotal: 10.7s\tremaining: 5.32s\n",
      "669:\tlearn: 0.0234912\ttotal: 10.8s\tremaining: 5.3s\n",
      "670:\tlearn: 0.0234907\ttotal: 10.8s\tremaining: 5.28s\n",
      "671:\tlearn: 0.0234879\ttotal: 10.8s\tremaining: 5.27s\n",
      "672:\tlearn: 0.0234875\ttotal: 10.8s\tremaining: 5.25s\n",
      "673:\tlearn: 0.0234827\ttotal: 10.8s\tremaining: 5.23s\n",
      "674:\tlearn: 0.0234821\ttotal: 10.8s\tremaining: 5.22s\n",
      "675:\tlearn: 0.0234819\ttotal: 10.9s\tremaining: 5.2s\n",
      "676:\tlearn: 0.0234813\ttotal: 10.9s\tremaining: 5.19s\n",
      "677:\tlearn: 0.0234805\ttotal: 10.9s\tremaining: 5.17s\n",
      "678:\tlearn: 0.0234800\ttotal: 10.9s\tremaining: 5.15s\n",
      "679:\tlearn: 0.0234787\ttotal: 10.9s\tremaining: 5.14s\n",
      "680:\tlearn: 0.0234734\ttotal: 10.9s\tremaining: 5.12s\n",
      "681:\tlearn: 0.0234720\ttotal: 10.9s\tremaining: 5.1s\n",
      "682:\tlearn: 0.0234712\ttotal: 11s\tremaining: 5.09s\n",
      "683:\tlearn: 0.0234654\ttotal: 11s\tremaining: 5.07s\n",
      "684:\tlearn: 0.0234648\ttotal: 11s\tremaining: 5.05s\n",
      "685:\tlearn: 0.0234629\ttotal: 11s\tremaining: 5.04s\n",
      "686:\tlearn: 0.0234621\ttotal: 11s\tremaining: 5.02s\n",
      "687:\tlearn: 0.0234613\ttotal: 11s\tremaining: 5s\n",
      "688:\tlearn: 0.0234609\ttotal: 11.1s\tremaining: 4.99s\n",
      "689:\tlearn: 0.0234605\ttotal: 11.1s\tremaining: 4.97s\n",
      "690:\tlearn: 0.0234591\ttotal: 11.1s\tremaining: 4.96s\n",
      "691:\tlearn: 0.0234580\ttotal: 11.1s\tremaining: 4.94s\n",
      "692:\tlearn: 0.0234568\ttotal: 11.1s\tremaining: 4.92s\n",
      "693:\tlearn: 0.0234557\ttotal: 11.1s\tremaining: 4.91s\n",
      "694:\tlearn: 0.0234551\ttotal: 11.1s\tremaining: 4.89s\n",
      "695:\tlearn: 0.0234545\ttotal: 11.2s\tremaining: 4.87s\n",
      "696:\tlearn: 0.0234497\ttotal: 11.2s\tremaining: 4.86s\n",
      "697:\tlearn: 0.0234493\ttotal: 11.2s\tremaining: 4.84s\n",
      "698:\tlearn: 0.0234488\ttotal: 11.2s\tremaining: 4.83s\n",
      "699:\tlearn: 0.0234484\ttotal: 11.2s\tremaining: 4.81s\n",
      "700:\tlearn: 0.0234480\ttotal: 11.2s\tremaining: 4.79s\n",
      "701:\tlearn: 0.0234472\ttotal: 11.3s\tremaining: 4.78s\n",
      "702:\tlearn: 0.0234467\ttotal: 11.3s\tremaining: 4.76s\n",
      "703:\tlearn: 0.0234423\ttotal: 11.3s\tremaining: 4.74s\n",
      "704:\tlearn: 0.0234420\ttotal: 11.3s\tremaining: 4.72s\n",
      "705:\tlearn: 0.0234415\ttotal: 11.3s\tremaining: 4.71s\n",
      "706:\tlearn: 0.0234396\ttotal: 11.3s\tremaining: 4.69s\n",
      "707:\tlearn: 0.0234355\ttotal: 11.3s\tremaining: 4.67s\n",
      "708:\tlearn: 0.0234311\ttotal: 11.3s\tremaining: 4.66s\n",
      "709:\tlearn: 0.0234302\ttotal: 11.4s\tremaining: 4.64s\n",
      "710:\tlearn: 0.0234279\ttotal: 11.4s\tremaining: 4.63s\n",
      "711:\tlearn: 0.0234273\ttotal: 11.4s\tremaining: 4.61s\n",
      "712:\tlearn: 0.0234269\ttotal: 11.4s\tremaining: 4.59s\n",
      "713:\tlearn: 0.0234262\ttotal: 11.4s\tremaining: 4.58s\n",
      "714:\tlearn: 0.0234252\ttotal: 11.4s\tremaining: 4.56s\n",
      "715:\tlearn: 0.0234250\ttotal: 11.4s\tremaining: 4.54s\n",
      "716:\tlearn: 0.0234240\ttotal: 11.5s\tremaining: 4.52s\n",
      "717:\tlearn: 0.0234226\ttotal: 11.5s\tremaining: 4.51s\n",
      "718:\tlearn: 0.0234214\ttotal: 11.5s\tremaining: 4.49s\n",
      "719:\tlearn: 0.0234210\ttotal: 11.5s\tremaining: 4.47s\n",
      "720:\tlearn: 0.0234196\ttotal: 11.5s\tremaining: 4.46s\n",
      "721:\tlearn: 0.0234142\ttotal: 11.5s\tremaining: 4.44s\n",
      "722:\tlearn: 0.0234119\ttotal: 11.5s\tremaining: 4.42s\n",
      "723:\tlearn: 0.0234106\ttotal: 11.6s\tremaining: 4.41s\n",
      "724:\tlearn: 0.0234090\ttotal: 11.6s\tremaining: 4.39s\n",
      "725:\tlearn: 0.0234032\ttotal: 11.6s\tremaining: 4.37s\n",
      "726:\tlearn: 0.0234026\ttotal: 11.6s\tremaining: 4.36s\n",
      "727:\tlearn: 0.0234021\ttotal: 11.6s\tremaining: 4.34s\n",
      "728:\tlearn: 0.0233980\ttotal: 11.6s\tremaining: 4.33s\n",
      "729:\tlearn: 0.0233974\ttotal: 11.7s\tremaining: 4.31s\n",
      "730:\tlearn: 0.0233953\ttotal: 11.7s\tremaining: 4.3s\n",
      "731:\tlearn: 0.0233934\ttotal: 11.7s\tremaining: 4.28s\n",
      "732:\tlearn: 0.0233931\ttotal: 11.7s\tremaining: 4.26s\n",
      "733:\tlearn: 0.0233888\ttotal: 11.7s\tremaining: 4.24s\n",
      "734:\tlearn: 0.0233883\ttotal: 11.7s\tremaining: 4.23s\n",
      "735:\tlearn: 0.0233830\ttotal: 11.7s\tremaining: 4.21s\n",
      "736:\tlearn: 0.0233815\ttotal: 11.8s\tremaining: 4.19s\n",
      "737:\tlearn: 0.0233810\ttotal: 11.8s\tremaining: 4.18s\n",
      "738:\tlearn: 0.0233806\ttotal: 11.8s\tremaining: 4.16s\n",
      "739:\tlearn: 0.0233783\ttotal: 11.8s\tremaining: 4.14s\n",
      "740:\tlearn: 0.0233781\ttotal: 11.8s\tremaining: 4.13s\n",
      "741:\tlearn: 0.0233777\ttotal: 11.8s\tremaining: 4.11s\n",
      "742:\tlearn: 0.0233761\ttotal: 11.8s\tremaining: 4.09s\n",
      "743:\tlearn: 0.0233720\ttotal: 11.9s\tremaining: 4.08s\n",
      "744:\tlearn: 0.0233718\ttotal: 11.9s\tremaining: 4.06s\n",
      "745:\tlearn: 0.0233712\ttotal: 11.9s\tremaining: 4.04s\n",
      "746:\tlearn: 0.0233710\ttotal: 11.9s\tremaining: 4.03s\n",
      "747:\tlearn: 0.0233693\ttotal: 11.9s\tremaining: 4.01s\n",
      "748:\tlearn: 0.0233681\ttotal: 11.9s\tremaining: 4s\n",
      "749:\tlearn: 0.0233640\ttotal: 11.9s\tremaining: 3.98s\n",
      "750:\tlearn: 0.0233586\ttotal: 12s\tremaining: 3.96s\n",
      "751:\tlearn: 0.0233564\ttotal: 12s\tremaining: 3.95s\n",
      "752:\tlearn: 0.0233559\ttotal: 12s\tremaining: 3.93s\n",
      "753:\tlearn: 0.0233553\ttotal: 12s\tremaining: 3.92s\n",
      "754:\tlearn: 0.0233537\ttotal: 12s\tremaining: 3.9s\n",
      "755:\tlearn: 0.0233525\ttotal: 12s\tremaining: 3.88s\n",
      "756:\tlearn: 0.0233523\ttotal: 12s\tremaining: 3.87s\n",
      "757:\tlearn: 0.0233509\ttotal: 12.1s\tremaining: 3.85s\n",
      "758:\tlearn: 0.0233499\ttotal: 12.1s\tremaining: 3.84s\n",
      "759:\tlearn: 0.0233497\ttotal: 12.1s\tremaining: 3.82s\n",
      "760:\tlearn: 0.0233493\ttotal: 12.1s\tremaining: 3.8s\n",
      "761:\tlearn: 0.0233479\ttotal: 12.1s\tremaining: 3.78s\n",
      "762:\tlearn: 0.0233436\ttotal: 12.1s\tremaining: 3.77s\n",
      "763:\tlearn: 0.0233431\ttotal: 12.1s\tremaining: 3.75s\n",
      "764:\tlearn: 0.0233425\ttotal: 12.2s\tremaining: 3.73s\n",
      "765:\tlearn: 0.0233386\ttotal: 12.2s\tremaining: 3.72s\n",
      "766:\tlearn: 0.0233376\ttotal: 12.2s\tremaining: 3.7s\n",
      "767:\tlearn: 0.0233367\ttotal: 12.2s\tremaining: 3.69s\n",
      "768:\tlearn: 0.0233336\ttotal: 12.2s\tremaining: 3.67s\n",
      "769:\tlearn: 0.0233333\ttotal: 12.2s\tremaining: 3.66s\n",
      "770:\tlearn: 0.0233323\ttotal: 12.3s\tremaining: 3.64s\n",
      "771:\tlearn: 0.0233284\ttotal: 12.3s\tremaining: 3.62s\n",
      "772:\tlearn: 0.0233281\ttotal: 12.3s\tremaining: 3.61s\n",
      "773:\tlearn: 0.0233231\ttotal: 12.3s\tremaining: 3.59s\n",
      "774:\tlearn: 0.0233191\ttotal: 12.3s\tremaining: 3.58s\n",
      "775:\tlearn: 0.0233186\ttotal: 12.3s\tremaining: 3.56s\n",
      "776:\tlearn: 0.0233180\ttotal: 12.3s\tremaining: 3.54s\n",
      "777:\tlearn: 0.0233173\ttotal: 12.4s\tremaining: 3.53s\n",
      "778:\tlearn: 0.0233140\ttotal: 12.4s\tremaining: 3.51s\n",
      "779:\tlearn: 0.0233094\ttotal: 12.4s\tremaining: 3.5s\n",
      "780:\tlearn: 0.0233089\ttotal: 12.4s\tremaining: 3.48s\n",
      "781:\tlearn: 0.0233086\ttotal: 12.4s\tremaining: 3.46s\n",
      "782:\tlearn: 0.0233039\ttotal: 12.4s\tremaining: 3.45s\n",
      "783:\tlearn: 0.0233026\ttotal: 12.5s\tremaining: 3.43s\n",
      "784:\tlearn: 0.0232974\ttotal: 12.5s\tremaining: 3.42s\n",
      "785:\tlearn: 0.0232927\ttotal: 12.5s\tremaining: 3.4s\n",
      "786:\tlearn: 0.0232923\ttotal: 12.5s\tremaining: 3.39s\n",
      "787:\tlearn: 0.0232916\ttotal: 12.5s\tremaining: 3.37s\n",
      "788:\tlearn: 0.0232882\ttotal: 12.6s\tremaining: 3.36s\n",
      "789:\tlearn: 0.0232831\ttotal: 12.6s\tremaining: 3.34s\n",
      "790:\tlearn: 0.0232792\ttotal: 12.6s\tremaining: 3.33s\n",
      "791:\tlearn: 0.0232776\ttotal: 12.6s\tremaining: 3.31s\n",
      "792:\tlearn: 0.0232770\ttotal: 12.6s\tremaining: 3.29s\n",
      "793:\tlearn: 0.0232765\ttotal: 12.6s\tremaining: 3.28s\n",
      "794:\tlearn: 0.0232760\ttotal: 12.6s\tremaining: 3.26s\n",
      "795:\tlearn: 0.0232697\ttotal: 12.7s\tremaining: 3.24s\n",
      "796:\tlearn: 0.0232693\ttotal: 12.7s\tremaining: 3.23s\n",
      "797:\tlearn: 0.0232684\ttotal: 12.7s\tremaining: 3.21s\n",
      "798:\tlearn: 0.0232680\ttotal: 12.7s\tremaining: 3.2s\n",
      "799:\tlearn: 0.0232642\ttotal: 12.7s\tremaining: 3.18s\n",
      "800:\tlearn: 0.0232640\ttotal: 12.7s\tremaining: 3.16s\n",
      "801:\tlearn: 0.0232637\ttotal: 12.7s\tremaining: 3.15s\n",
      "802:\tlearn: 0.0232625\ttotal: 12.8s\tremaining: 3.13s\n",
      "803:\tlearn: 0.0232604\ttotal: 12.8s\tremaining: 3.12s\n",
      "804:\tlearn: 0.0232573\ttotal: 12.8s\tremaining: 3.1s\n",
      "805:\tlearn: 0.0232521\ttotal: 12.8s\tremaining: 3.08s\n",
      "806:\tlearn: 0.0232508\ttotal: 12.8s\tremaining: 3.07s\n",
      "807:\tlearn: 0.0232460\ttotal: 12.8s\tremaining: 3.05s\n",
      "808:\tlearn: 0.0232452\ttotal: 12.9s\tremaining: 3.04s\n",
      "809:\tlearn: 0.0232440\ttotal: 12.9s\tremaining: 3.02s\n",
      "810:\tlearn: 0.0232429\ttotal: 12.9s\tremaining: 3s\n",
      "811:\tlearn: 0.0232425\ttotal: 12.9s\tremaining: 2.99s\n",
      "812:\tlearn: 0.0232412\ttotal: 12.9s\tremaining: 2.97s\n",
      "813:\tlearn: 0.0232397\ttotal: 12.9s\tremaining: 2.96s\n",
      "814:\tlearn: 0.0232395\ttotal: 13s\tremaining: 2.94s\n",
      "815:\tlearn: 0.0232380\ttotal: 13s\tremaining: 2.94s\n",
      "816:\tlearn: 0.0232377\ttotal: 13.1s\tremaining: 2.92s\n",
      "817:\tlearn: 0.0232359\ttotal: 13.1s\tremaining: 2.91s\n",
      "818:\tlearn: 0.0232346\ttotal: 13.1s\tremaining: 2.89s\n",
      "819:\tlearn: 0.0232325\ttotal: 13.1s\tremaining: 2.88s\n",
      "820:\tlearn: 0.0232312\ttotal: 13.1s\tremaining: 2.86s\n",
      "821:\tlearn: 0.0232260\ttotal: 13.1s\tremaining: 2.84s\n",
      "822:\tlearn: 0.0232254\ttotal: 13.2s\tremaining: 2.83s\n",
      "823:\tlearn: 0.0232240\ttotal: 13.2s\tremaining: 2.81s\n",
      "824:\tlearn: 0.0232232\ttotal: 13.2s\tremaining: 2.8s\n",
      "825:\tlearn: 0.0232229\ttotal: 13.2s\tremaining: 2.78s\n",
      "826:\tlearn: 0.0232228\ttotal: 13.2s\tremaining: 2.76s\n",
      "827:\tlearn: 0.0232191\ttotal: 13.2s\tremaining: 2.75s\n",
      "828:\tlearn: 0.0232189\ttotal: 13.2s\tremaining: 2.73s\n",
      "829:\tlearn: 0.0232182\ttotal: 13.3s\tremaining: 2.71s\n",
      "830:\tlearn: 0.0232164\ttotal: 13.3s\tremaining: 2.7s\n",
      "831:\tlearn: 0.0232142\ttotal: 13.3s\tremaining: 2.68s\n",
      "832:\tlearn: 0.0232137\ttotal: 13.3s\tremaining: 2.67s\n",
      "833:\tlearn: 0.0232132\ttotal: 13.3s\tremaining: 2.65s\n",
      "834:\tlearn: 0.0232108\ttotal: 13.3s\tremaining: 2.63s\n",
      "835:\tlearn: 0.0232103\ttotal: 13.3s\tremaining: 2.62s\n",
      "836:\tlearn: 0.0232101\ttotal: 13.3s\tremaining: 2.6s\n",
      "837:\tlearn: 0.0232089\ttotal: 13.4s\tremaining: 2.58s\n",
      "838:\tlearn: 0.0232061\ttotal: 13.4s\tremaining: 2.57s\n",
      "839:\tlearn: 0.0232058\ttotal: 13.4s\tremaining: 2.55s\n",
      "840:\tlearn: 0.0232052\ttotal: 13.4s\tremaining: 2.53s\n",
      "841:\tlearn: 0.0232050\ttotal: 13.4s\tremaining: 2.52s\n",
      "842:\tlearn: 0.0232045\ttotal: 13.4s\tremaining: 2.5s\n",
      "843:\tlearn: 0.0232008\ttotal: 13.4s\tremaining: 2.48s\n",
      "844:\tlearn: 0.0231989\ttotal: 13.5s\tremaining: 2.47s\n",
      "845:\tlearn: 0.0231946\ttotal: 13.5s\tremaining: 2.45s\n",
      "846:\tlearn: 0.0231939\ttotal: 13.5s\tremaining: 2.44s\n",
      "847:\tlearn: 0.0231931\ttotal: 13.5s\tremaining: 2.42s\n",
      "848:\tlearn: 0.0231915\ttotal: 13.5s\tremaining: 2.41s\n",
      "849:\tlearn: 0.0231848\ttotal: 13.6s\tremaining: 2.39s\n",
      "850:\tlearn: 0.0231843\ttotal: 13.6s\tremaining: 2.38s\n",
      "851:\tlearn: 0.0231795\ttotal: 13.6s\tremaining: 2.36s\n",
      "852:\tlearn: 0.0231788\ttotal: 13.6s\tremaining: 2.35s\n",
      "853:\tlearn: 0.0231785\ttotal: 13.6s\tremaining: 2.33s\n",
      "854:\tlearn: 0.0231777\ttotal: 13.6s\tremaining: 2.31s\n",
      "855:\tlearn: 0.0231740\ttotal: 13.7s\tremaining: 2.3s\n",
      "856:\tlearn: 0.0231702\ttotal: 13.7s\tremaining: 2.28s\n",
      "857:\tlearn: 0.0231674\ttotal: 13.7s\tremaining: 2.27s\n",
      "858:\tlearn: 0.0231661\ttotal: 13.7s\tremaining: 2.25s\n",
      "859:\tlearn: 0.0231606\ttotal: 13.7s\tremaining: 2.23s\n",
      "860:\tlearn: 0.0231601\ttotal: 13.7s\tremaining: 2.22s\n",
      "861:\tlearn: 0.0231599\ttotal: 13.7s\tremaining: 2.2s\n",
      "862:\tlearn: 0.0231593\ttotal: 13.8s\tremaining: 2.18s\n",
      "863:\tlearn: 0.0231591\ttotal: 13.8s\tremaining: 2.17s\n",
      "864:\tlearn: 0.0231576\ttotal: 13.8s\tremaining: 2.15s\n",
      "865:\tlearn: 0.0231530\ttotal: 13.8s\tremaining: 2.13s\n",
      "866:\tlearn: 0.0231496\ttotal: 13.8s\tremaining: 2.12s\n",
      "867:\tlearn: 0.0231493\ttotal: 13.8s\tremaining: 2.1s\n",
      "868:\tlearn: 0.0231470\ttotal: 13.8s\tremaining: 2.08s\n",
      "869:\tlearn: 0.0231467\ttotal: 13.8s\tremaining: 2.07s\n",
      "870:\tlearn: 0.0231463\ttotal: 13.8s\tremaining: 2.05s\n",
      "871:\tlearn: 0.0231457\ttotal: 13.9s\tremaining: 2.03s\n",
      "872:\tlearn: 0.0231455\ttotal: 13.9s\tremaining: 2.02s\n",
      "873:\tlearn: 0.0231409\ttotal: 13.9s\tremaining: 2s\n",
      "874:\tlearn: 0.0231405\ttotal: 13.9s\tremaining: 1.99s\n",
      "875:\tlearn: 0.0231367\ttotal: 13.9s\tremaining: 1.97s\n",
      "876:\tlearn: 0.0231321\ttotal: 13.9s\tremaining: 1.96s\n",
      "877:\tlearn: 0.0231287\ttotal: 14s\tremaining: 1.94s\n",
      "878:\tlearn: 0.0231281\ttotal: 14s\tremaining: 1.92s\n",
      "879:\tlearn: 0.0231273\ttotal: 14s\tremaining: 1.91s\n",
      "880:\tlearn: 0.0231248\ttotal: 14s\tremaining: 1.89s\n",
      "881:\tlearn: 0.0231234\ttotal: 14s\tremaining: 1.88s\n",
      "882:\tlearn: 0.0231219\ttotal: 14s\tremaining: 1.86s\n",
      "883:\tlearn: 0.0231217\ttotal: 14s\tremaining: 1.84s\n",
      "884:\tlearn: 0.0231177\ttotal: 14.1s\tremaining: 1.83s\n",
      "885:\tlearn: 0.0231131\ttotal: 14.1s\tremaining: 1.81s\n",
      "886:\tlearn: 0.0231115\ttotal: 14.1s\tremaining: 1.79s\n",
      "887:\tlearn: 0.0231075\ttotal: 14.1s\tremaining: 1.78s\n",
      "888:\tlearn: 0.0231031\ttotal: 14.1s\tremaining: 1.76s\n",
      "889:\tlearn: 0.0231029\ttotal: 14.1s\tremaining: 1.75s\n",
      "890:\tlearn: 0.0231024\ttotal: 14.1s\tremaining: 1.73s\n",
      "891:\tlearn: 0.0231019\ttotal: 14.2s\tremaining: 1.71s\n",
      "892:\tlearn: 0.0231018\ttotal: 14.2s\tremaining: 1.7s\n",
      "893:\tlearn: 0.0231013\ttotal: 14.2s\tremaining: 1.68s\n",
      "894:\tlearn: 0.0231009\ttotal: 14.2s\tremaining: 1.67s\n",
      "895:\tlearn: 0.0230961\ttotal: 14.2s\tremaining: 1.65s\n",
      "896:\tlearn: 0.0230947\ttotal: 14.2s\tremaining: 1.64s\n",
      "897:\tlearn: 0.0230933\ttotal: 14.3s\tremaining: 1.62s\n",
      "898:\tlearn: 0.0230887\ttotal: 14.3s\tremaining: 1.6s\n",
      "899:\tlearn: 0.0230872\ttotal: 14.3s\tremaining: 1.59s\n",
      "900:\tlearn: 0.0230868\ttotal: 14.3s\tremaining: 1.57s\n",
      "901:\tlearn: 0.0230829\ttotal: 14.3s\tremaining: 1.56s\n",
      "902:\tlearn: 0.0230800\ttotal: 14.3s\tremaining: 1.54s\n",
      "903:\tlearn: 0.0230789\ttotal: 14.4s\tremaining: 1.52s\n",
      "904:\tlearn: 0.0230728\ttotal: 14.4s\tremaining: 1.51s\n",
      "905:\tlearn: 0.0230713\ttotal: 14.4s\tremaining: 1.49s\n",
      "906:\tlearn: 0.0230680\ttotal: 14.4s\tremaining: 1.48s\n",
      "907:\tlearn: 0.0230668\ttotal: 14.4s\tremaining: 1.46s\n",
      "908:\tlearn: 0.0230666\ttotal: 14.4s\tremaining: 1.45s\n",
      "909:\tlearn: 0.0230663\ttotal: 14.5s\tremaining: 1.43s\n",
      "910:\tlearn: 0.0230648\ttotal: 14.5s\tremaining: 1.41s\n",
      "911:\tlearn: 0.0230641\ttotal: 14.5s\tremaining: 1.4s\n",
      "912:\tlearn: 0.0230639\ttotal: 14.5s\tremaining: 1.38s\n",
      "913:\tlearn: 0.0230636\ttotal: 14.5s\tremaining: 1.36s\n",
      "914:\tlearn: 0.0230621\ttotal: 14.5s\tremaining: 1.35s\n",
      "915:\tlearn: 0.0230577\ttotal: 14.5s\tremaining: 1.33s\n",
      "916:\tlearn: 0.0230539\ttotal: 14.5s\tremaining: 1.32s\n",
      "917:\tlearn: 0.0230537\ttotal: 14.6s\tremaining: 1.3s\n",
      "918:\tlearn: 0.0230532\ttotal: 14.6s\tremaining: 1.28s\n",
      "919:\tlearn: 0.0230498\ttotal: 14.6s\tremaining: 1.27s\n",
      "920:\tlearn: 0.0230490\ttotal: 14.6s\tremaining: 1.25s\n",
      "921:\tlearn: 0.0230484\ttotal: 14.6s\tremaining: 1.24s\n",
      "922:\tlearn: 0.0230480\ttotal: 14.6s\tremaining: 1.22s\n",
      "923:\tlearn: 0.0230442\ttotal: 14.6s\tremaining: 1.2s\n",
      "924:\tlearn: 0.0230407\ttotal: 14.7s\tremaining: 1.19s\n",
      "925:\tlearn: 0.0230392\ttotal: 14.7s\tremaining: 1.17s\n",
      "926:\tlearn: 0.0230380\ttotal: 14.7s\tremaining: 1.16s\n",
      "927:\tlearn: 0.0230378\ttotal: 14.7s\tremaining: 1.14s\n",
      "928:\tlearn: 0.0230367\ttotal: 14.7s\tremaining: 1.13s\n",
      "929:\tlearn: 0.0230317\ttotal: 14.7s\tremaining: 1.11s\n",
      "930:\tlearn: 0.0230306\ttotal: 14.8s\tremaining: 1.09s\n",
      "931:\tlearn: 0.0230297\ttotal: 14.8s\tremaining: 1.08s\n",
      "932:\tlearn: 0.0230276\ttotal: 14.8s\tremaining: 1.06s\n",
      "933:\tlearn: 0.0230249\ttotal: 14.8s\tremaining: 1.04s\n",
      "934:\tlearn: 0.0230242\ttotal: 14.8s\tremaining: 1.03s\n",
      "935:\tlearn: 0.0230235\ttotal: 14.8s\tremaining: 1.01s\n",
      "936:\tlearn: 0.0230228\ttotal: 14.8s\tremaining: 998ms\n",
      "937:\tlearn: 0.0230222\ttotal: 14.9s\tremaining: 982ms\n",
      "938:\tlearn: 0.0230217\ttotal: 14.9s\tremaining: 966ms\n",
      "939:\tlearn: 0.0230206\ttotal: 14.9s\tremaining: 950ms\n",
      "940:\tlearn: 0.0230205\ttotal: 14.9s\tremaining: 934ms\n",
      "941:\tlearn: 0.0230158\ttotal: 14.9s\tremaining: 917ms\n",
      "942:\tlearn: 0.0230151\ttotal: 14.9s\tremaining: 902ms\n",
      "943:\tlearn: 0.0230131\ttotal: 14.9s\tremaining: 886ms\n",
      "944:\tlearn: 0.0230130\ttotal: 14.9s\tremaining: 870ms\n",
      "945:\tlearn: 0.0230077\ttotal: 15s\tremaining: 854ms\n",
      "946:\tlearn: 0.0230070\ttotal: 15s\tremaining: 838ms\n",
      "947:\tlearn: 0.0230066\ttotal: 15s\tremaining: 822ms\n",
      "948:\tlearn: 0.0230025\ttotal: 15s\tremaining: 806ms\n",
      "949:\tlearn: 0.0230012\ttotal: 15.1s\tremaining: 795ms\n",
      "950:\tlearn: 0.0229972\ttotal: 15.1s\tremaining: 779ms\n",
      "951:\tlearn: 0.0229960\ttotal: 15.2s\tremaining: 767ms\n",
      "952:\tlearn: 0.0229951\ttotal: 15.2s\tremaining: 752ms\n",
      "953:\tlearn: 0.0229945\ttotal: 15.3s\tremaining: 735ms\n",
      "954:\tlearn: 0.0229914\ttotal: 15.3s\tremaining: 719ms\n",
      "955:\tlearn: 0.0229901\ttotal: 15.3s\tremaining: 703ms\n",
      "956:\tlearn: 0.0229870\ttotal: 15.3s\tremaining: 687ms\n",
      "957:\tlearn: 0.0229858\ttotal: 15.3s\tremaining: 671ms\n",
      "958:\tlearn: 0.0229845\ttotal: 15.3s\tremaining: 655ms\n",
      "959:\tlearn: 0.0229844\ttotal: 15.3s\tremaining: 639ms\n",
      "960:\tlearn: 0.0229829\ttotal: 15.3s\tremaining: 623ms\n",
      "961:\tlearn: 0.0229822\ttotal: 15.4s\tremaining: 607ms\n",
      "962:\tlearn: 0.0229794\ttotal: 15.4s\tremaining: 591ms\n",
      "963:\tlearn: 0.0229793\ttotal: 15.4s\tremaining: 574ms\n",
      "964:\tlearn: 0.0229792\ttotal: 15.4s\tremaining: 558ms\n",
      "965:\tlearn: 0.0229791\ttotal: 15.4s\tremaining: 542ms\n",
      "966:\tlearn: 0.0229786\ttotal: 15.4s\tremaining: 526ms\n",
      "967:\tlearn: 0.0229781\ttotal: 15.4s\tremaining: 510ms\n",
      "968:\tlearn: 0.0229780\ttotal: 15.4s\tremaining: 493ms\n",
      "969:\tlearn: 0.0229740\ttotal: 15.4s\tremaining: 478ms\n",
      "970:\tlearn: 0.0229729\ttotal: 15.5s\tremaining: 462ms\n",
      "971:\tlearn: 0.0229725\ttotal: 15.5s\tremaining: 446ms\n",
      "972:\tlearn: 0.0229691\ttotal: 15.5s\tremaining: 430ms\n",
      "973:\tlearn: 0.0229645\ttotal: 15.5s\tremaining: 414ms\n",
      "974:\tlearn: 0.0229611\ttotal: 15.5s\tremaining: 398ms\n",
      "975:\tlearn: 0.0229599\ttotal: 15.5s\tremaining: 382ms\n",
      "976:\tlearn: 0.0229596\ttotal: 15.5s\tremaining: 366ms\n",
      "977:\tlearn: 0.0229554\ttotal: 15.6s\tremaining: 350ms\n",
      "978:\tlearn: 0.0229536\ttotal: 15.6s\tremaining: 334ms\n",
      "979:\tlearn: 0.0229491\ttotal: 15.6s\tremaining: 318ms\n",
      "980:\tlearn: 0.0229457\ttotal: 15.6s\tremaining: 302ms\n",
      "981:\tlearn: 0.0229452\ttotal: 15.6s\tremaining: 286ms\n",
      "982:\tlearn: 0.0229444\ttotal: 15.6s\tremaining: 270ms\n",
      "983:\tlearn: 0.0229435\ttotal: 15.7s\tremaining: 255ms\n",
      "984:\tlearn: 0.0229425\ttotal: 15.7s\tremaining: 239ms\n",
      "985:\tlearn: 0.0229423\ttotal: 15.7s\tremaining: 223ms\n",
      "986:\tlearn: 0.0229410\ttotal: 15.7s\tremaining: 207ms\n",
      "987:\tlearn: 0.0229395\ttotal: 15.7s\tremaining: 191ms\n",
      "988:\tlearn: 0.0229384\ttotal: 15.7s\tremaining: 175ms\n",
      "989:\tlearn: 0.0229380\ttotal: 15.7s\tremaining: 159ms\n",
      "990:\tlearn: 0.0229359\ttotal: 15.8s\tremaining: 143ms\n",
      "991:\tlearn: 0.0229301\ttotal: 15.8s\tremaining: 127ms\n",
      "992:\tlearn: 0.0229297\ttotal: 15.8s\tremaining: 111ms\n",
      "993:\tlearn: 0.0229284\ttotal: 15.8s\tremaining: 95.4ms\n",
      "994:\tlearn: 0.0229265\ttotal: 15.8s\tremaining: 79.5ms\n",
      "995:\tlearn: 0.0229223\ttotal: 15.8s\tremaining: 63.6ms\n",
      "996:\tlearn: 0.0229170\ttotal: 15.9s\tremaining: 47.7ms\n",
      "997:\tlearn: 0.0229164\ttotal: 15.9s\tremaining: 31.8ms\n",
      "998:\tlearn: 0.0229152\ttotal: 15.9s\tremaining: 15.9ms\n",
      "999:\tlearn: 0.0229147\ttotal: 15.9s\tremaining: 0us\n",
      "Final RMSE on the test set:  0.016010797412101666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\PC\\anaconda3-2\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Fit the final model with the best parameters\n",
    "best_model = CatBoostRegressor(**study.best_params)\n",
    "best_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions and calculate RMSE on the test set\n",
    "y_pred = best_model.predict(X_test)\n",
    "final_score = mean_squared_error(y_test, y_pred, squared=False)\n",
    "\n",
    "print(\"Final RMSE on the test set: \", final_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boost_predictions = best_model.predict(scaled_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>54273</td>\n",
       "      <td>0.007077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>54274</td>\n",
       "      <td>0.005938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>54275</td>\n",
       "      <td>0.007820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>54276</td>\n",
       "      <td>0.019559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>54277</td>\n",
       "      <td>0.011912</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id     price\n",
       "0  54273  0.007077\n",
       "1  54274  0.005938\n",
       "2  54275  0.007820\n",
       "3  54276  0.019559\n",
       "4  54277  0.011912"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create submission file\n",
    "sub = pd.DataFrame({'id': submission['id'], 'price': boost_predictions})\n",
    "\n",
    "# Preview sub file\n",
    "sub.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a csv file\n",
    "#sub.to_csv('submission5.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We will save the model performance metrics in a DataFrame\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "import numpy as np\n",
    "Model = []\n",
    "RMSE = []\n",
    "R_sq = []\n",
    "cv = KFold(5)\n",
    "\n",
    "#Creating a Function to append the cross validation scores of the algorithms\n",
    "def input_scores(name, model, x, y):\n",
    "    Model.append(name)\n",
    "    RMSE.append(np.sqrt((-1) * cross_val_score(model, x, y, cv=cv, \n",
    "                                               scoring='neg_mean_squared_error').mean()))\n",
    "    R_sq.append(cross_val_score(model, x, y, cv=cv, scoring='r2').mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009138 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 620\n",
      "[LightGBM] [Info] Number of data points in the train set: 34734, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 39512.634882\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003482 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 618\n",
      "[LightGBM] [Info] Number of data points in the train set: 34734, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 38964.973455\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002107 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 618\n",
      "[LightGBM] [Info] Number of data points in the train set: 34734, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 39284.240658\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004311 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 614\n",
      "[LightGBM] [Info] Number of data points in the train set: 34735, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 39485.990557\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002598 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 617\n",
      "[LightGBM] [Info] Number of data points in the train set: 34735, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 39400.815748\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002798 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 620\n",
      "[LightGBM] [Info] Number of data points in the train set: 34734, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 39512.634882\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002789 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 618\n",
      "[LightGBM] [Info] Number of data points in the train set: 34734, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 38964.973455\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002837 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 618\n",
      "[LightGBM] [Info] Number of data points in the train set: 34734, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 39284.240658\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003095 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 614\n",
      "[LightGBM] [Info] Number of data points in the train set: 34735, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 39485.990557\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001998 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 617\n",
      "[LightGBM] [Info] Number of data points in the train set: 34735, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 39400.815748\n",
      "Learning rate set to 0.071716\n",
      "0:\tlearn: 76006.9653711\ttotal: 39.2ms\tremaining: 39.2s\n",
      "1:\tlearn: 75585.1930581\ttotal: 53.9ms\tremaining: 26.9s\n",
      "2:\tlearn: 75121.6230612\ttotal: 69.1ms\tremaining: 23s\n",
      "3:\tlearn: 74775.4916917\ttotal: 84ms\tremaining: 20.9s\n",
      "4:\tlearn: 74410.2354600\ttotal: 97ms\tremaining: 19.3s\n",
      "5:\tlearn: 74063.4505324\ttotal: 106ms\tremaining: 17.5s\n",
      "6:\tlearn: 73817.1225008\ttotal: 121ms\tremaining: 17.2s\n",
      "7:\tlearn: 73580.9465091\ttotal: 138ms\tremaining: 17.1s\n",
      "8:\tlearn: 73375.1723792\ttotal: 167ms\tremaining: 18.4s\n",
      "9:\tlearn: 73200.8421276\ttotal: 182ms\tremaining: 18s\n",
      "10:\tlearn: 73047.0690984\ttotal: 339ms\tremaining: 30.5s\n",
      "11:\tlearn: 72874.1423997\ttotal: 454ms\tremaining: 37.4s\n",
      "12:\tlearn: 72689.8937699\ttotal: 493ms\tremaining: 37.4s\n",
      "13:\tlearn: 72558.6253804\ttotal: 521ms\tremaining: 36.7s\n",
      "14:\tlearn: 72447.8751717\ttotal: 571ms\tremaining: 37.5s\n",
      "15:\tlearn: 72304.4633172\ttotal: 587ms\tremaining: 36.1s\n",
      "16:\tlearn: 72201.0485682\ttotal: 604ms\tremaining: 34.9s\n",
      "17:\tlearn: 72088.4791413\ttotal: 618ms\tremaining: 33.7s\n",
      "18:\tlearn: 71848.3841419\ttotal: 631ms\tremaining: 32.6s\n",
      "19:\tlearn: 71762.9214642\ttotal: 638ms\tremaining: 31.2s\n",
      "20:\tlearn: 71689.5411359\ttotal: 654ms\tremaining: 30.5s\n",
      "21:\tlearn: 71631.8763756\ttotal: 669ms\tremaining: 29.7s\n",
      "22:\tlearn: 71479.9076988\ttotal: 703ms\tremaining: 29.9s\n",
      "23:\tlearn: 71350.7434551\ttotal: 718ms\tremaining: 29.2s\n",
      "24:\tlearn: 71233.7949217\ttotal: 733ms\tremaining: 28.6s\n",
      "25:\tlearn: 71159.2384236\ttotal: 748ms\tremaining: 28s\n",
      "26:\tlearn: 71111.5072205\ttotal: 758ms\tremaining: 27.3s\n",
      "27:\tlearn: 71046.4302622\ttotal: 770ms\tremaining: 26.7s\n",
      "28:\tlearn: 71005.1775565\ttotal: 783ms\tremaining: 26.2s\n",
      "29:\tlearn: 70969.1762616\ttotal: 798ms\tremaining: 25.8s\n",
      "30:\tlearn: 70951.3294424\ttotal: 813ms\tremaining: 25.4s\n",
      "31:\tlearn: 70873.5109127\ttotal: 824ms\tremaining: 24.9s\n",
      "32:\tlearn: 70810.5128918\ttotal: 834ms\tremaining: 24.5s\n",
      "33:\tlearn: 70747.2303820\ttotal: 849ms\tremaining: 24.1s\n",
      "34:\tlearn: 70705.8466397\ttotal: 940ms\tremaining: 25.9s\n",
      "35:\tlearn: 70683.9082164\ttotal: 951ms\tremaining: 25.5s\n",
      "36:\tlearn: 70634.2159670\ttotal: 964ms\tremaining: 25.1s\n",
      "37:\tlearn: 70563.6713895\ttotal: 976ms\tremaining: 24.7s\n",
      "38:\tlearn: 70541.2487753\ttotal: 984ms\tremaining: 24.2s\n",
      "39:\tlearn: 70509.6999314\ttotal: 1.01s\tremaining: 24.2s\n",
      "40:\tlearn: 70491.1067901\ttotal: 1.02s\tremaining: 23.9s\n",
      "41:\tlearn: 70438.2691963\ttotal: 1.03s\tremaining: 23.5s\n",
      "42:\tlearn: 70425.9356966\ttotal: 1.04s\tremaining: 23.2s\n",
      "43:\tlearn: 70378.8792822\ttotal: 1.05s\tremaining: 22.9s\n",
      "44:\tlearn: 70294.5515698\ttotal: 1.07s\tremaining: 22.6s\n",
      "45:\tlearn: 70273.9828382\ttotal: 1.08s\tremaining: 22.5s\n",
      "46:\tlearn: 70239.7153967\ttotal: 1.1s\tremaining: 22.4s\n",
      "47:\tlearn: 70228.9093357\ttotal: 1.11s\tremaining: 22s\n",
      "48:\tlearn: 70182.7083570\ttotal: 1.13s\tremaining: 21.9s\n",
      "49:\tlearn: 70172.4910516\ttotal: 1.14s\tremaining: 21.6s\n",
      "50:\tlearn: 70121.0565512\ttotal: 1.16s\tremaining: 21.5s\n",
      "51:\tlearn: 70098.1074916\ttotal: 1.17s\tremaining: 21.3s\n",
      "52:\tlearn: 70088.5541915\ttotal: 1.17s\tremaining: 21s\n",
      "53:\tlearn: 70064.8768038\ttotal: 1.19s\tremaining: 20.9s\n",
      "54:\tlearn: 70043.0714750\ttotal: 1.21s\tremaining: 20.9s\n",
      "55:\tlearn: 69988.2886582\ttotal: 1.23s\tremaining: 20.7s\n",
      "56:\tlearn: 69977.5841725\ttotal: 1.24s\tremaining: 20.5s\n",
      "57:\tlearn: 69949.4497705\ttotal: 1.25s\tremaining: 20.4s\n",
      "58:\tlearn: 69917.9074731\ttotal: 1.26s\tremaining: 20.2s\n",
      "59:\tlearn: 69823.9035599\ttotal: 1.27s\tremaining: 19.9s\n",
      "60:\tlearn: 69762.3327907\ttotal: 1.29s\tremaining: 19.8s\n",
      "61:\tlearn: 69726.5826389\ttotal: 1.29s\tremaining: 19.6s\n",
      "62:\tlearn: 69682.0589593\ttotal: 1.31s\tremaining: 19.5s\n",
      "63:\tlearn: 69653.2295649\ttotal: 1.32s\tremaining: 19.3s\n",
      "64:\tlearn: 69550.7559541\ttotal: 1.33s\tremaining: 19.2s\n",
      "65:\tlearn: 69540.1008562\ttotal: 1.35s\tremaining: 19.1s\n",
      "66:\tlearn: 69529.4261706\ttotal: 1.37s\tremaining: 19s\n",
      "67:\tlearn: 69517.1951460\ttotal: 1.42s\tremaining: 19.5s\n",
      "68:\tlearn: 69491.2091881\ttotal: 1.43s\tremaining: 19.3s\n",
      "69:\tlearn: 69410.3274332\ttotal: 1.45s\tremaining: 19.2s\n",
      "70:\tlearn: 69328.5192843\ttotal: 1.47s\tremaining: 19.2s\n",
      "71:\tlearn: 69309.7297437\ttotal: 1.48s\tremaining: 19.1s\n",
      "72:\tlearn: 69253.6887573\ttotal: 1.5s\tremaining: 19s\n",
      "73:\tlearn: 69246.8081637\ttotal: 1.51s\tremaining: 18.9s\n",
      "74:\tlearn: 69238.5747176\ttotal: 1.52s\tremaining: 18.7s\n",
      "75:\tlearn: 69230.9164870\ttotal: 1.53s\tremaining: 18.6s\n",
      "76:\tlearn: 69213.6675014\ttotal: 1.54s\tremaining: 18.5s\n",
      "77:\tlearn: 69205.8173150\ttotal: 1.55s\tremaining: 18.4s\n",
      "78:\tlearn: 69195.6976152\ttotal: 1.56s\tremaining: 18.2s\n",
      "79:\tlearn: 69131.4213753\ttotal: 1.58s\tremaining: 18.1s\n",
      "80:\tlearn: 69079.0513095\ttotal: 1.59s\tremaining: 18.1s\n",
      "81:\tlearn: 69069.1113143\ttotal: 1.63s\tremaining: 18.2s\n",
      "82:\tlearn: 69050.5349781\ttotal: 1.64s\tremaining: 18.1s\n",
      "83:\tlearn: 69000.6926504\ttotal: 1.66s\tremaining: 18.1s\n",
      "84:\tlearn: 68912.1515682\ttotal: 1.67s\tremaining: 17.9s\n",
      "85:\tlearn: 68898.7403094\ttotal: 1.68s\tremaining: 17.8s\n",
      "86:\tlearn: 68892.6873643\ttotal: 1.69s\tremaining: 17.8s\n",
      "87:\tlearn: 68886.5177502\ttotal: 1.7s\tremaining: 17.6s\n",
      "88:\tlearn: 68801.6676622\ttotal: 1.72s\tremaining: 17.6s\n",
      "89:\tlearn: 68752.5444484\ttotal: 1.73s\tremaining: 17.5s\n",
      "90:\tlearn: 68746.4140082\ttotal: 1.75s\tremaining: 17.4s\n",
      "91:\tlearn: 68727.5910935\ttotal: 1.76s\tremaining: 17.4s\n",
      "92:\tlearn: 68681.9790938\ttotal: 1.78s\tremaining: 17.3s\n",
      "93:\tlearn: 68676.1198715\ttotal: 1.79s\tremaining: 17.2s\n",
      "94:\tlearn: 68664.1365147\ttotal: 1.8s\tremaining: 17.1s\n",
      "95:\tlearn: 68651.9137862\ttotal: 1.81s\tremaining: 17.1s\n",
      "96:\tlearn: 68606.7028396\ttotal: 1.83s\tremaining: 17s\n",
      "97:\tlearn: 68564.6424144\ttotal: 1.86s\tremaining: 17.1s\n",
      "98:\tlearn: 68559.3211929\ttotal: 1.88s\tremaining: 17.1s\n",
      "99:\tlearn: 68497.0634457\ttotal: 1.91s\tremaining: 17.2s\n",
      "100:\tlearn: 68492.5854612\ttotal: 1.93s\tremaining: 17.2s\n",
      "101:\tlearn: 68405.8242745\ttotal: 1.95s\tremaining: 17.2s\n",
      "102:\tlearn: 68336.8824419\ttotal: 1.97s\tremaining: 17.1s\n",
      "103:\tlearn: 68331.2366696\ttotal: 1.99s\tremaining: 17.1s\n",
      "104:\tlearn: 68291.7822681\ttotal: 2.02s\tremaining: 17.2s\n",
      "105:\tlearn: 68188.2582570\ttotal: 2.05s\tremaining: 17.3s\n",
      "106:\tlearn: 68109.3675917\ttotal: 2.09s\tremaining: 17.5s\n",
      "107:\tlearn: 68088.8825217\ttotal: 2.12s\tremaining: 17.5s\n",
      "108:\tlearn: 68069.0200663\ttotal: 2.13s\tremaining: 17.5s\n",
      "109:\tlearn: 68039.2215758\ttotal: 2.19s\tremaining: 17.7s\n",
      "110:\tlearn: 67977.8299009\ttotal: 2.21s\tremaining: 17.7s\n",
      "111:\tlearn: 67856.5170825\ttotal: 2.23s\tremaining: 17.6s\n",
      "112:\tlearn: 67793.8933892\ttotal: 2.25s\tremaining: 17.6s\n",
      "113:\tlearn: 67789.6068624\ttotal: 2.27s\tremaining: 17.6s\n",
      "114:\tlearn: 67744.5897128\ttotal: 2.31s\tremaining: 17.8s\n",
      "115:\tlearn: 67722.5424855\ttotal: 2.32s\tremaining: 17.7s\n",
      "116:\tlearn: 67707.6455500\ttotal: 2.34s\tremaining: 17.6s\n",
      "117:\tlearn: 67688.7650696\ttotal: 2.35s\tremaining: 17.6s\n",
      "118:\tlearn: 67619.5353067\ttotal: 2.36s\tremaining: 17.5s\n",
      "119:\tlearn: 67587.3226058\ttotal: 2.38s\tremaining: 17.4s\n",
      "120:\tlearn: 67580.5573079\ttotal: 2.39s\tremaining: 17.3s\n",
      "121:\tlearn: 67562.7304401\ttotal: 2.4s\tremaining: 17.3s\n",
      "122:\tlearn: 67524.5992524\ttotal: 2.42s\tremaining: 17.3s\n",
      "123:\tlearn: 67425.9801236\ttotal: 2.44s\tremaining: 17.2s\n",
      "124:\tlearn: 67390.3370916\ttotal: 2.46s\tremaining: 17.2s\n",
      "125:\tlearn: 67386.1657931\ttotal: 2.47s\tremaining: 17.1s\n",
      "126:\tlearn: 67380.5438359\ttotal: 2.48s\tremaining: 17.1s\n",
      "127:\tlearn: 67351.4989930\ttotal: 2.52s\tremaining: 17.1s\n",
      "128:\tlearn: 67316.4757083\ttotal: 2.54s\tremaining: 17.1s\n",
      "129:\tlearn: 67292.3491611\ttotal: 2.54s\tremaining: 17s\n",
      "130:\tlearn: 67284.4803257\ttotal: 2.56s\tremaining: 17s\n",
      "131:\tlearn: 67258.5315667\ttotal: 2.57s\tremaining: 16.9s\n",
      "132:\tlearn: 67236.0623887\ttotal: 2.58s\tremaining: 16.8s\n",
      "133:\tlearn: 67215.0564858\ttotal: 2.59s\tremaining: 16.7s\n",
      "134:\tlearn: 67155.2112725\ttotal: 2.6s\tremaining: 16.7s\n",
      "135:\tlearn: 67151.7667010\ttotal: 2.62s\tremaining: 16.6s\n",
      "136:\tlearn: 67129.2198845\ttotal: 2.63s\tremaining: 16.6s\n",
      "137:\tlearn: 67093.0384215\ttotal: 2.64s\tremaining: 16.5s\n",
      "138:\tlearn: 67083.3047772\ttotal: 2.65s\tremaining: 16.5s\n",
      "139:\tlearn: 67057.8026021\ttotal: 2.67s\tremaining: 16.4s\n",
      "140:\tlearn: 66976.7461721\ttotal: 2.69s\tremaining: 16.4s\n",
      "141:\tlearn: 66973.0111321\ttotal: 2.72s\tremaining: 16.4s\n",
      "142:\tlearn: 66958.0989405\ttotal: 2.73s\tremaining: 16.4s\n",
      "143:\tlearn: 66935.6104564\ttotal: 2.75s\tremaining: 16.4s\n",
      "144:\tlearn: 66858.1635932\ttotal: 2.77s\tremaining: 16.3s\n",
      "145:\tlearn: 66843.1487782\ttotal: 2.78s\tremaining: 16.2s\n",
      "146:\tlearn: 66842.6247147\ttotal: 2.79s\tremaining: 16.2s\n",
      "147:\tlearn: 66833.9974354\ttotal: 2.8s\tremaining: 16.1s\n",
      "148:\tlearn: 66767.0713340\ttotal: 2.81s\tremaining: 16s\n",
      "149:\tlearn: 66734.6141659\ttotal: 2.83s\tremaining: 16s\n",
      "150:\tlearn: 66716.1193317\ttotal: 2.84s\tremaining: 16s\n",
      "151:\tlearn: 66703.2382263\ttotal: 2.86s\tremaining: 15.9s\n",
      "152:\tlearn: 66686.8835493\ttotal: 2.87s\tremaining: 15.9s\n",
      "153:\tlearn: 66661.0360852\ttotal: 2.88s\tremaining: 15.8s\n",
      "154:\tlearn: 66616.3988323\ttotal: 2.9s\tremaining: 15.8s\n",
      "155:\tlearn: 66610.8037914\ttotal: 2.9s\tremaining: 15.7s\n",
      "156:\tlearn: 66606.2746536\ttotal: 2.92s\tremaining: 15.7s\n",
      "157:\tlearn: 66602.5590487\ttotal: 2.93s\tremaining: 15.6s\n",
      "158:\tlearn: 66599.1155112\ttotal: 2.97s\tremaining: 15.7s\n",
      "159:\tlearn: 66518.7444412\ttotal: 2.98s\tremaining: 15.7s\n",
      "160:\tlearn: 66489.1419945\ttotal: 2.99s\tremaining: 15.6s\n",
      "161:\tlearn: 66459.9780082\ttotal: 3s\tremaining: 15.5s\n",
      "162:\tlearn: 66457.1682890\ttotal: 3.01s\tremaining: 15.5s\n",
      "163:\tlearn: 66446.3606833\ttotal: 3.02s\tremaining: 15.4s\n",
      "164:\tlearn: 66435.6514244\ttotal: 3.03s\tremaining: 15.4s\n",
      "165:\tlearn: 66407.5850104\ttotal: 3.05s\tremaining: 15.3s\n",
      "166:\tlearn: 66361.7023734\ttotal: 3.06s\tremaining: 15.3s\n",
      "167:\tlearn: 66343.2937321\ttotal: 3.08s\tremaining: 15.2s\n",
      "168:\tlearn: 66283.2911902\ttotal: 3.09s\tremaining: 15.2s\n",
      "169:\tlearn: 66230.9767151\ttotal: 3.11s\tremaining: 15.2s\n",
      "170:\tlearn: 66228.7764460\ttotal: 3.13s\tremaining: 15.2s\n",
      "171:\tlearn: 66226.2964226\ttotal: 3.13s\tremaining: 15.1s\n",
      "172:\tlearn: 66198.0279723\ttotal: 3.15s\tremaining: 15.1s\n",
      "173:\tlearn: 66171.3980102\ttotal: 3.18s\tremaining: 15.1s\n",
      "174:\tlearn: 66145.3442516\ttotal: 3.2s\tremaining: 15.1s\n",
      "175:\tlearn: 66081.9247501\ttotal: 3.21s\tremaining: 15s\n",
      "176:\tlearn: 66056.8207538\ttotal: 3.22s\tremaining: 15s\n",
      "177:\tlearn: 66032.6625158\ttotal: 3.23s\tremaining: 14.9s\n",
      "178:\tlearn: 65979.2640420\ttotal: 3.24s\tremaining: 14.9s\n",
      "179:\tlearn: 65934.7720986\ttotal: 3.26s\tremaining: 14.9s\n",
      "180:\tlearn: 65911.7196910\ttotal: 3.27s\tremaining: 14.8s\n",
      "181:\tlearn: 65844.6938979\ttotal: 3.28s\tremaining: 14.8s\n",
      "182:\tlearn: 65842.7456367\ttotal: 3.29s\tremaining: 14.7s\n",
      "183:\tlearn: 65822.6903864\ttotal: 3.31s\tremaining: 14.7s\n",
      "184:\tlearn: 65757.7975924\ttotal: 3.31s\tremaining: 14.6s\n",
      "185:\tlearn: 65738.2644061\ttotal: 3.33s\tremaining: 14.6s\n",
      "186:\tlearn: 65732.6651122\ttotal: 3.33s\tremaining: 14.5s\n",
      "187:\tlearn: 65710.4735156\ttotal: 3.35s\tremaining: 14.5s\n",
      "188:\tlearn: 65667.2940269\ttotal: 3.36s\tremaining: 14.4s\n",
      "189:\tlearn: 65613.6137113\ttotal: 3.38s\tremaining: 14.4s\n",
      "190:\tlearn: 65592.2357115\ttotal: 3.41s\tremaining: 14.4s\n",
      "191:\tlearn: 65573.5235970\ttotal: 3.41s\tremaining: 14.4s\n",
      "192:\tlearn: 65552.7857264\ttotal: 3.43s\tremaining: 14.3s\n",
      "193:\tlearn: 65484.8473197\ttotal: 3.44s\tremaining: 14.3s\n",
      "194:\tlearn: 65464.8107748\ttotal: 3.45s\tremaining: 14.2s\n",
      "195:\tlearn: 65446.8863493\ttotal: 3.46s\tremaining: 14.2s\n",
      "196:\tlearn: 65430.3852948\ttotal: 3.48s\tremaining: 14.2s\n",
      "197:\tlearn: 65413.1118201\ttotal: 3.49s\tremaining: 14.2s\n",
      "198:\tlearn: 65393.9863837\ttotal: 3.51s\tremaining: 14.1s\n",
      "199:\tlearn: 65344.0057784\ttotal: 3.52s\tremaining: 14.1s\n",
      "200:\tlearn: 65327.3783348\ttotal: 3.54s\tremaining: 14.1s\n",
      "201:\tlearn: 65311.4534868\ttotal: 3.54s\tremaining: 14s\n",
      "202:\tlearn: 65296.1406491\ttotal: 3.56s\tremaining: 14s\n",
      "203:\tlearn: 65280.8071114\ttotal: 3.57s\tremaining: 13.9s\n",
      "204:\tlearn: 65264.3153995\ttotal: 3.61s\tremaining: 14s\n",
      "205:\tlearn: 65245.6706310\ttotal: 3.62s\tremaining: 14s\n",
      "206:\tlearn: 65155.6649590\ttotal: 3.63s\tremaining: 13.9s\n",
      "207:\tlearn: 65137.8635970\ttotal: 3.64s\tremaining: 13.9s\n",
      "208:\tlearn: 65069.0319214\ttotal: 3.68s\tremaining: 13.9s\n",
      "209:\tlearn: 65054.2691399\ttotal: 3.71s\tremaining: 13.9s\n",
      "210:\tlearn: 65040.0874718\ttotal: 3.72s\tremaining: 13.9s\n",
      "211:\tlearn: 65022.8006112\ttotal: 3.73s\tremaining: 13.9s\n",
      "212:\tlearn: 64955.3249279\ttotal: 3.75s\tremaining: 13.8s\n",
      "213:\tlearn: 64938.6237483\ttotal: 3.77s\tremaining: 13.9s\n",
      "214:\tlearn: 64924.9721851\ttotal: 3.79s\tremaining: 13.9s\n",
      "215:\tlearn: 64859.3078994\ttotal: 3.81s\tremaining: 13.8s\n",
      "216:\tlearn: 64794.0854773\ttotal: 3.83s\tremaining: 13.8s\n",
      "217:\tlearn: 64778.0976336\ttotal: 3.84s\tremaining: 13.8s\n",
      "218:\tlearn: 64765.1228721\ttotal: 3.85s\tremaining: 13.7s\n",
      "219:\tlearn: 64751.9785839\ttotal: 3.87s\tremaining: 13.7s\n",
      "220:\tlearn: 64653.1996076\ttotal: 3.88s\tremaining: 13.7s\n",
      "221:\tlearn: 64572.3572104\ttotal: 3.9s\tremaining: 13.7s\n",
      "222:\tlearn: 64520.4988895\ttotal: 3.92s\tremaining: 13.6s\n",
      "223:\tlearn: 64503.8043319\ttotal: 3.93s\tremaining: 13.6s\n",
      "224:\tlearn: 64488.2520049\ttotal: 3.94s\tremaining: 13.6s\n",
      "225:\tlearn: 64425.3290591\ttotal: 3.96s\tremaining: 13.6s\n",
      "226:\tlearn: 64412.6157314\ttotal: 3.97s\tremaining: 13.5s\n",
      "227:\tlearn: 64400.3901976\ttotal: 3.99s\tremaining: 13.5s\n",
      "228:\tlearn: 64386.7810902\ttotal: 4s\tremaining: 13.5s\n",
      "229:\tlearn: 64344.0255218\ttotal: 4.04s\tremaining: 13.5s\n",
      "230:\tlearn: 64272.9285291\ttotal: 4.05s\tremaining: 13.5s\n",
      "231:\tlearn: 64253.3677907\ttotal: 4.07s\tremaining: 13.5s\n",
      "232:\tlearn: 64151.8774592\ttotal: 4.08s\tremaining: 13.4s\n",
      "233:\tlearn: 64136.8098446\ttotal: 4.1s\tremaining: 13.4s\n",
      "234:\tlearn: 64125.0320688\ttotal: 4.1s\tremaining: 13.4s\n",
      "235:\tlearn: 64109.8877550\ttotal: 4.12s\tremaining: 13.3s\n",
      "236:\tlearn: 64095.3599494\ttotal: 4.13s\tremaining: 13.3s\n",
      "237:\tlearn: 64037.7338896\ttotal: 4.14s\tremaining: 13.3s\n",
      "238:\tlearn: 63974.4330137\ttotal: 4.15s\tremaining: 13.2s\n",
      "239:\tlearn: 63872.1911823\ttotal: 4.17s\tremaining: 13.2s\n",
      "240:\tlearn: 63858.1291882\ttotal: 4.18s\tremaining: 13.2s\n",
      "241:\tlearn: 63846.7513989\ttotal: 4.23s\tremaining: 13.3s\n",
      "242:\tlearn: 63806.9648106\ttotal: 4.26s\tremaining: 13.3s\n",
      "243:\tlearn: 63768.2728316\ttotal: 4.28s\tremaining: 13.3s\n",
      "244:\tlearn: 63758.0601541\ttotal: 4.29s\tremaining: 13.2s\n",
      "245:\tlearn: 63694.7656631\ttotal: 4.3s\tremaining: 13.2s\n",
      "246:\tlearn: 63684.2161358\ttotal: 4.32s\tremaining: 13.2s\n",
      "247:\tlearn: 63670.7478155\ttotal: 4.33s\tremaining: 13.1s\n",
      "248:\tlearn: 63655.9907720\ttotal: 4.35s\tremaining: 13.1s\n",
      "249:\tlearn: 63634.0411816\ttotal: 4.36s\tremaining: 13.1s\n",
      "250:\tlearn: 63574.2047612\ttotal: 4.37s\tremaining: 13s\n",
      "251:\tlearn: 63541.2111077\ttotal: 4.38s\tremaining: 13s\n",
      "252:\tlearn: 63444.5934185\ttotal: 4.4s\tremaining: 13s\n",
      "253:\tlearn: 63432.7593008\ttotal: 4.42s\tremaining: 13s\n",
      "254:\tlearn: 63386.6646394\ttotal: 4.43s\tremaining: 12.9s\n",
      "255:\tlearn: 63332.1303660\ttotal: 4.45s\tremaining: 12.9s\n",
      "256:\tlearn: 63318.9884026\ttotal: 4.46s\tremaining: 12.9s\n",
      "257:\tlearn: 63257.8598960\ttotal: 4.49s\tremaining: 12.9s\n",
      "258:\tlearn: 63245.1811844\ttotal: 4.51s\tremaining: 12.9s\n",
      "259:\tlearn: 63141.8288438\ttotal: 4.53s\tremaining: 12.9s\n",
      "260:\tlearn: 63118.9797547\ttotal: 4.54s\tremaining: 12.8s\n",
      "261:\tlearn: 63109.6358095\ttotal: 4.55s\tremaining: 12.8s\n",
      "262:\tlearn: 63058.0926690\ttotal: 4.56s\tremaining: 12.8s\n",
      "263:\tlearn: 63026.4460508\ttotal: 4.58s\tremaining: 12.8s\n",
      "264:\tlearn: 63006.4696012\ttotal: 4.59s\tremaining: 12.7s\n",
      "265:\tlearn: 62997.4329900\ttotal: 4.6s\tremaining: 12.7s\n",
      "266:\tlearn: 62982.3561639\ttotal: 4.61s\tremaining: 12.7s\n",
      "267:\tlearn: 62975.9016526\ttotal: 4.63s\tremaining: 12.6s\n",
      "268:\tlearn: 62942.3507103\ttotal: 4.64s\tremaining: 12.6s\n",
      "269:\tlearn: 62874.0828418\ttotal: 4.66s\tremaining: 12.6s\n",
      "270:\tlearn: 62863.6939357\ttotal: 4.67s\tremaining: 12.6s\n",
      "271:\tlearn: 62815.9685132\ttotal: 4.68s\tremaining: 12.5s\n",
      "272:\tlearn: 62791.5414347\ttotal: 4.71s\tremaining: 12.5s\n",
      "273:\tlearn: 62783.1686390\ttotal: 4.72s\tremaining: 12.5s\n",
      "274:\tlearn: 62674.3786217\ttotal: 4.74s\tremaining: 12.5s\n",
      "275:\tlearn: 62620.5599634\ttotal: 4.76s\tremaining: 12.5s\n",
      "276:\tlearn: 62553.3147204\ttotal: 4.78s\tremaining: 12.5s\n",
      "277:\tlearn: 62451.5258573\ttotal: 4.79s\tremaining: 12.4s\n",
      "278:\tlearn: 62443.3547058\ttotal: 4.8s\tremaining: 12.4s\n",
      "279:\tlearn: 62347.7368807\ttotal: 4.81s\tremaining: 12.4s\n",
      "280:\tlearn: 62324.1375445\ttotal: 4.83s\tremaining: 12.3s\n",
      "281:\tlearn: 62260.4672392\ttotal: 4.84s\tremaining: 12.3s\n",
      "282:\tlearn: 62196.5948279\ttotal: 4.86s\tremaining: 12.3s\n",
      "283:\tlearn: 62153.9077563\ttotal: 4.89s\tremaining: 12.3s\n",
      "284:\tlearn: 62060.3108470\ttotal: 4.91s\tremaining: 12.3s\n",
      "285:\tlearn: 62011.0009684\ttotal: 4.92s\tremaining: 12.3s\n",
      "286:\tlearn: 61959.5408125\ttotal: 4.94s\tremaining: 12.3s\n",
      "287:\tlearn: 61900.2994012\ttotal: 4.95s\tremaining: 12.2s\n",
      "288:\tlearn: 61884.9474035\ttotal: 4.97s\tremaining: 12.2s\n",
      "289:\tlearn: 61874.1059386\ttotal: 4.97s\tremaining: 12.2s\n",
      "290:\tlearn: 61843.5956551\ttotal: 4.99s\tremaining: 12.2s\n",
      "291:\tlearn: 61783.9591503\ttotal: 5s\tremaining: 12.1s\n",
      "292:\tlearn: 61773.8818963\ttotal: 5.01s\tremaining: 12.1s\n",
      "293:\tlearn: 61712.5429582\ttotal: 5.04s\tremaining: 12.1s\n",
      "294:\tlearn: 61653.6657712\ttotal: 5.05s\tremaining: 12.1s\n",
      "295:\tlearn: 61592.3855181\ttotal: 5.06s\tremaining: 12s\n",
      "296:\tlearn: 61533.6738254\ttotal: 5.07s\tremaining: 12s\n",
      "297:\tlearn: 61480.9060424\ttotal: 5.09s\tremaining: 12s\n",
      "298:\tlearn: 61430.2300432\ttotal: 5.1s\tremaining: 12s\n",
      "299:\tlearn: 61377.4469016\ttotal: 5.11s\tremaining: 11.9s\n",
      "300:\tlearn: 61330.4158682\ttotal: 5.14s\tremaining: 11.9s\n",
      "301:\tlearn: 61281.4066639\ttotal: 5.16s\tremaining: 11.9s\n",
      "302:\tlearn: 61234.4141819\ttotal: 5.17s\tremaining: 11.9s\n",
      "303:\tlearn: 61201.1772445\ttotal: 5.18s\tremaining: 11.9s\n",
      "304:\tlearn: 61160.9085378\ttotal: 5.19s\tremaining: 11.8s\n",
      "305:\tlearn: 61120.1099169\ttotal: 5.2s\tremaining: 11.8s\n",
      "306:\tlearn: 61111.4674230\ttotal: 5.21s\tremaining: 11.8s\n",
      "307:\tlearn: 61072.2632874\ttotal: 5.22s\tremaining: 11.7s\n",
      "308:\tlearn: 61031.2202721\ttotal: 5.24s\tremaining: 11.7s\n",
      "309:\tlearn: 61019.1757841\ttotal: 5.27s\tremaining: 11.7s\n",
      "310:\tlearn: 60963.2627546\ttotal: 5.28s\tremaining: 11.7s\n",
      "311:\tlearn: 60913.5078195\ttotal: 5.29s\tremaining: 11.7s\n",
      "312:\tlearn: 60903.5853592\ttotal: 5.3s\tremaining: 11.6s\n",
      "313:\tlearn: 60864.1164844\ttotal: 5.32s\tremaining: 11.6s\n",
      "314:\tlearn: 60852.0175776\ttotal: 5.33s\tremaining: 11.6s\n",
      "315:\tlearn: 60786.6181182\ttotal: 5.36s\tremaining: 11.6s\n",
      "316:\tlearn: 60751.3011865\ttotal: 5.39s\tremaining: 11.6s\n",
      "317:\tlearn: 60717.3590273\ttotal: 5.4s\tremaining: 11.6s\n",
      "318:\tlearn: 60684.7326341\ttotal: 5.41s\tremaining: 11.6s\n",
      "319:\tlearn: 60673.7799012\ttotal: 5.42s\tremaining: 11.5s\n",
      "320:\tlearn: 60611.7897333\ttotal: 5.44s\tremaining: 11.5s\n",
      "321:\tlearn: 60586.3425849\ttotal: 5.45s\tremaining: 11.5s\n",
      "322:\tlearn: 60532.4978382\ttotal: 5.48s\tremaining: 11.5s\n",
      "323:\tlearn: 60505.3792128\ttotal: 5.5s\tremaining: 11.5s\n",
      "324:\tlearn: 60497.4496899\ttotal: 5.51s\tremaining: 11.5s\n",
      "325:\tlearn: 60475.9895011\ttotal: 5.53s\tremaining: 11.4s\n",
      "326:\tlearn: 60412.6229697\ttotal: 5.54s\tremaining: 11.4s\n",
      "327:\tlearn: 60411.0738901\ttotal: 5.55s\tremaining: 11.4s\n",
      "328:\tlearn: 60383.2159440\ttotal: 5.59s\tremaining: 11.4s\n",
      "329:\tlearn: 60351.6644464\ttotal: 5.6s\tremaining: 11.4s\n",
      "330:\tlearn: 60321.3272760\ttotal: 5.61s\tremaining: 11.3s\n",
      "331:\tlearn: 60319.8505587\ttotal: 5.63s\tremaining: 11.3s\n",
      "332:\tlearn: 60293.0840287\ttotal: 5.64s\tremaining: 11.3s\n",
      "333:\tlearn: 60267.4506499\ttotal: 5.66s\tremaining: 11.3s\n",
      "334:\tlearn: 60226.8691403\ttotal: 5.67s\tremaining: 11.3s\n",
      "335:\tlearn: 60209.8888912\ttotal: 5.68s\tremaining: 11.2s\n",
      "336:\tlearn: 60205.2084910\ttotal: 5.69s\tremaining: 11.2s\n",
      "337:\tlearn: 60175.9588798\ttotal: 5.71s\tremaining: 11.2s\n",
      "338:\tlearn: 60116.2820786\ttotal: 5.71s\tremaining: 11.1s\n",
      "339:\tlearn: 60084.2686228\ttotal: 5.73s\tremaining: 11.1s\n",
      "340:\tlearn: 60052.6518236\ttotal: 5.74s\tremaining: 11.1s\n",
      "341:\tlearn: 60045.5954930\ttotal: 5.76s\tremaining: 11.1s\n",
      "342:\tlearn: 60041.1257472\ttotal: 5.79s\tremaining: 11.1s\n",
      "343:\tlearn: 60021.5151449\ttotal: 5.81s\tremaining: 11.1s\n",
      "344:\tlearn: 60008.0261011\ttotal: 5.82s\tremaining: 11.1s\n",
      "345:\tlearn: 59969.7223433\ttotal: 5.84s\tremaining: 11s\n",
      "346:\tlearn: 59933.3699008\ttotal: 5.85s\tremaining: 11s\n",
      "347:\tlearn: 59924.0506903\ttotal: 5.86s\tremaining: 11s\n",
      "348:\tlearn: 59893.6528794\ttotal: 5.88s\tremaining: 11s\n",
      "349:\tlearn: 59867.2932733\ttotal: 5.89s\tremaining: 10.9s\n",
      "350:\tlearn: 59812.6115828\ttotal: 5.91s\tremaining: 10.9s\n",
      "351:\tlearn: 59793.7473207\ttotal: 5.92s\tremaining: 10.9s\n",
      "352:\tlearn: 59768.3686521\ttotal: 5.93s\tremaining: 10.9s\n",
      "353:\tlearn: 59763.3985393\ttotal: 5.94s\tremaining: 10.8s\n",
      "354:\tlearn: 59735.1360288\ttotal: 5.96s\tremaining: 10.8s\n",
      "355:\tlearn: 59676.3838851\ttotal: 5.97s\tremaining: 10.8s\n",
      "356:\tlearn: 59667.1724727\ttotal: 6s\tremaining: 10.8s\n",
      "357:\tlearn: 59610.7962974\ttotal: 6.02s\tremaining: 10.8s\n",
      "358:\tlearn: 59586.3166313\ttotal: 6.03s\tremaining: 10.8s\n",
      "359:\tlearn: 59571.8837964\ttotal: 6.05s\tremaining: 10.8s\n",
      "360:\tlearn: 59531.0433800\ttotal: 6.06s\tremaining: 10.7s\n",
      "361:\tlearn: 59507.4695436\ttotal: 6.07s\tremaining: 10.7s\n",
      "362:\tlearn: 59494.0611726\ttotal: 6.08s\tremaining: 10.7s\n",
      "363:\tlearn: 59489.5105395\ttotal: 6.09s\tremaining: 10.6s\n",
      "364:\tlearn: 59466.8218398\ttotal: 6.1s\tremaining: 10.6s\n",
      "365:\tlearn: 59462.4714109\ttotal: 6.12s\tremaining: 10.6s\n",
      "366:\tlearn: 59437.3576757\ttotal: 6.13s\tremaining: 10.6s\n",
      "367:\tlearn: 59397.2106062\ttotal: 6.15s\tremaining: 10.6s\n",
      "368:\tlearn: 59340.3732101\ttotal: 6.16s\tremaining: 10.5s\n",
      "369:\tlearn: 59333.1365746\ttotal: 6.17s\tremaining: 10.5s\n",
      "370:\tlearn: 59315.1064987\ttotal: 6.18s\tremaining: 10.5s\n",
      "371:\tlearn: 59291.0737404\ttotal: 6.2s\tremaining: 10.5s\n",
      "372:\tlearn: 59234.0560741\ttotal: 6.21s\tremaining: 10.4s\n",
      "373:\tlearn: 59198.8278159\ttotal: 6.23s\tremaining: 10.4s\n",
      "374:\tlearn: 59174.0803110\ttotal: 6.28s\tremaining: 10.5s\n",
      "375:\tlearn: 59120.0433446\ttotal: 6.31s\tremaining: 10.5s\n",
      "376:\tlearn: 59115.7647961\ttotal: 6.32s\tremaining: 10.4s\n",
      "377:\tlearn: 59078.7702418\ttotal: 6.33s\tremaining: 10.4s\n",
      "378:\tlearn: 59057.7360267\ttotal: 6.35s\tremaining: 10.4s\n",
      "379:\tlearn: 59051.9933928\ttotal: 6.36s\tremaining: 10.4s\n",
      "380:\tlearn: 59012.7852427\ttotal: 6.37s\tremaining: 10.3s\n",
      "381:\tlearn: 58993.3684398\ttotal: 6.38s\tremaining: 10.3s\n",
      "382:\tlearn: 58953.3128746\ttotal: 6.39s\tremaining: 10.3s\n",
      "383:\tlearn: 58943.2466843\ttotal: 6.44s\tremaining: 10.3s\n",
      "384:\tlearn: 58867.7568511\ttotal: 6.46s\tremaining: 10.3s\n",
      "385:\tlearn: 58851.7680318\ttotal: 6.47s\tremaining: 10.3s\n",
      "386:\tlearn: 58847.7512487\ttotal: 6.48s\tremaining: 10.3s\n",
      "387:\tlearn: 58842.0220480\ttotal: 6.49s\tremaining: 10.2s\n",
      "388:\tlearn: 58833.3206719\ttotal: 6.5s\tremaining: 10.2s\n",
      "389:\tlearn: 58781.0957733\ttotal: 6.52s\tremaining: 10.2s\n",
      "390:\tlearn: 58758.6718733\ttotal: 6.53s\tremaining: 10.2s\n",
      "391:\tlearn: 58751.1739810\ttotal: 6.54s\tremaining: 10.1s\n",
      "392:\tlearn: 58729.6782975\ttotal: 6.56s\tremaining: 10.1s\n",
      "393:\tlearn: 58710.4400739\ttotal: 6.57s\tremaining: 10.1s\n",
      "394:\tlearn: 58688.2199604\ttotal: 6.58s\tremaining: 10.1s\n",
      "395:\tlearn: 58669.0989549\ttotal: 6.59s\tremaining: 10.1s\n",
      "396:\tlearn: 58665.1254357\ttotal: 6.61s\tremaining: 10s\n",
      "397:\tlearn: 58646.9888070\ttotal: 6.62s\tremaining: 10s\n",
      "398:\tlearn: 58639.3962827\ttotal: 6.63s\tremaining: 9.99s\n",
      "399:\tlearn: 58576.1374003\ttotal: 6.65s\tremaining: 9.98s\n",
      "400:\tlearn: 58565.8304802\ttotal: 6.66s\tremaining: 9.95s\n",
      "401:\tlearn: 58535.2949056\ttotal: 6.68s\tremaining: 9.94s\n",
      "402:\tlearn: 58522.8614114\ttotal: 6.69s\tremaining: 9.92s\n",
      "403:\tlearn: 58469.9657578\ttotal: 6.72s\tremaining: 9.91s\n",
      "404:\tlearn: 58414.4912240\ttotal: 6.73s\tremaining: 9.89s\n",
      "405:\tlearn: 58373.6851824\ttotal: 6.74s\tremaining: 9.86s\n",
      "406:\tlearn: 58356.3571344\ttotal: 6.75s\tremaining: 9.84s\n",
      "407:\tlearn: 58335.6094932\ttotal: 6.76s\tremaining: 9.81s\n",
      "408:\tlearn: 58316.1284640\ttotal: 6.79s\tremaining: 9.81s\n",
      "409:\tlearn: 58296.6317876\ttotal: 6.8s\tremaining: 9.79s\n",
      "410:\tlearn: 58245.9486440\ttotal: 6.82s\tremaining: 9.77s\n",
      "411:\tlearn: 58192.3855089\ttotal: 6.83s\tremaining: 9.76s\n",
      "412:\tlearn: 58171.4543609\ttotal: 6.85s\tremaining: 9.73s\n",
      "413:\tlearn: 58122.5509994\ttotal: 6.86s\tremaining: 9.7s\n",
      "414:\tlearn: 58092.9204312\ttotal: 6.87s\tremaining: 9.69s\n",
      "415:\tlearn: 58086.5371259\ttotal: 6.9s\tremaining: 9.68s\n",
      "416:\tlearn: 58079.8415948\ttotal: 6.91s\tremaining: 9.66s\n",
      "417:\tlearn: 58063.4521147\ttotal: 6.92s\tremaining: 9.64s\n",
      "418:\tlearn: 58024.6177166\ttotal: 6.93s\tremaining: 9.61s\n",
      "419:\tlearn: 57997.3557633\ttotal: 6.95s\tremaining: 9.59s\n",
      "420:\tlearn: 57985.4215504\ttotal: 6.95s\tremaining: 9.56s\n",
      "421:\tlearn: 57962.9640161\ttotal: 6.97s\tremaining: 9.54s\n",
      "422:\tlearn: 57949.8715827\ttotal: 6.98s\tremaining: 9.53s\n",
      "423:\tlearn: 57885.2046338\ttotal: 7s\tremaining: 9.51s\n",
      "424:\tlearn: 57877.1650333\ttotal: 7.01s\tremaining: 9.49s\n",
      "425:\tlearn: 57860.5562468\ttotal: 7.03s\tremaining: 9.47s\n",
      "426:\tlearn: 57849.0618843\ttotal: 7.03s\tremaining: 9.44s\n",
      "427:\tlearn: 57838.0016022\ttotal: 7.05s\tremaining: 9.42s\n",
      "428:\tlearn: 57800.6965610\ttotal: 7.06s\tremaining: 9.4s\n",
      "429:\tlearn: 57784.8816462\ttotal: 7.07s\tremaining: 9.37s\n",
      "430:\tlearn: 57771.7957388\ttotal: 7.08s\tremaining: 9.35s\n",
      "431:\tlearn: 57767.0981525\ttotal: 7.12s\tremaining: 9.36s\n",
      "432:\tlearn: 57715.1969636\ttotal: 7.13s\tremaining: 9.34s\n",
      "433:\tlearn: 57704.5668201\ttotal: 7.15s\tremaining: 9.32s\n",
      "434:\tlearn: 57690.8025696\ttotal: 7.16s\tremaining: 9.29s\n",
      "435:\tlearn: 57684.9679333\ttotal: 7.17s\tremaining: 9.27s\n",
      "436:\tlearn: 57680.1447888\ttotal: 7.18s\tremaining: 9.25s\n",
      "437:\tlearn: 57620.4141995\ttotal: 7.19s\tremaining: 9.23s\n",
      "438:\tlearn: 57601.7445945\ttotal: 7.2s\tremaining: 9.2s\n",
      "439:\tlearn: 57571.2546773\ttotal: 7.22s\tremaining: 9.19s\n",
      "440:\tlearn: 57553.2669383\ttotal: 7.23s\tremaining: 9.16s\n",
      "441:\tlearn: 57516.1795949\ttotal: 7.24s\tremaining: 9.14s\n",
      "442:\tlearn: 57469.8211155\ttotal: 7.25s\tremaining: 9.12s\n",
      "443:\tlearn: 57463.3944869\ttotal: 7.26s\tremaining: 9.1s\n",
      "444:\tlearn: 57452.2526209\ttotal: 7.28s\tremaining: 9.08s\n",
      "445:\tlearn: 57442.2785752\ttotal: 7.29s\tremaining: 9.05s\n",
      "446:\tlearn: 57426.3523774\ttotal: 7.3s\tremaining: 9.04s\n",
      "447:\tlearn: 57405.2642475\ttotal: 7.34s\tremaining: 9.05s\n",
      "448:\tlearn: 57395.0347621\ttotal: 7.35s\tremaining: 9.02s\n",
      "449:\tlearn: 57344.5719602\ttotal: 7.36s\tremaining: 9s\n",
      "450:\tlearn: 57330.3173420\ttotal: 7.39s\tremaining: 8.99s\n",
      "451:\tlearn: 57285.8938133\ttotal: 7.4s\tremaining: 8.97s\n",
      "452:\tlearn: 57275.5468124\ttotal: 7.41s\tremaining: 8.95s\n",
      "453:\tlearn: 57265.9547115\ttotal: 7.43s\tremaining: 8.93s\n",
      "454:\tlearn: 57256.5101346\ttotal: 7.44s\tremaining: 8.91s\n",
      "455:\tlearn: 57211.6485332\ttotal: 7.46s\tremaining: 8.89s\n",
      "456:\tlearn: 57202.4147514\ttotal: 7.46s\tremaining: 8.87s\n",
      "457:\tlearn: 57193.5219154\ttotal: 7.48s\tremaining: 8.85s\n",
      "458:\tlearn: 57150.2563628\ttotal: 7.49s\tremaining: 8.83s\n",
      "459:\tlearn: 57141.6830625\ttotal: 7.5s\tremaining: 8.81s\n",
      "460:\tlearn: 57137.6850308\ttotal: 7.51s\tremaining: 8.78s\n",
      "461:\tlearn: 57121.7663136\ttotal: 7.53s\tremaining: 8.77s\n",
      "462:\tlearn: 57072.9783238\ttotal: 7.55s\tremaining: 8.76s\n",
      "463:\tlearn: 57031.2078316\ttotal: 7.58s\tremaining: 8.75s\n",
      "464:\tlearn: 57024.8519511\ttotal: 7.6s\tremaining: 8.74s\n",
      "465:\tlearn: 57018.4163606\ttotal: 7.62s\tremaining: 8.73s\n",
      "466:\tlearn: 56992.6215013\ttotal: 7.64s\tremaining: 8.72s\n",
      "467:\tlearn: 56977.9611511\ttotal: 7.64s\tremaining: 8.69s\n",
      "468:\tlearn: 56952.5802336\ttotal: 7.66s\tremaining: 8.67s\n",
      "469:\tlearn: 56944.0259584\ttotal: 7.67s\tremaining: 8.65s\n",
      "470:\tlearn: 56924.1184513\ttotal: 7.69s\tremaining: 8.64s\n",
      "471:\tlearn: 56883.7566518\ttotal: 7.7s\tremaining: 8.62s\n",
      "472:\tlearn: 56867.5095470\ttotal: 7.71s\tremaining: 8.59s\n",
      "473:\tlearn: 56828.8544421\ttotal: 7.73s\tremaining: 8.57s\n",
      "474:\tlearn: 56821.1707801\ttotal: 7.74s\tremaining: 8.55s\n",
      "475:\tlearn: 56748.1249839\ttotal: 7.76s\tremaining: 8.54s\n",
      "476:\tlearn: 56714.9157792\ttotal: 7.79s\tremaining: 8.54s\n",
      "477:\tlearn: 56707.9706684\ttotal: 7.81s\tremaining: 8.53s\n",
      "478:\tlearn: 56694.4308811\ttotal: 7.82s\tremaining: 8.51s\n",
      "479:\tlearn: 56636.5908244\ttotal: 7.83s\tremaining: 8.49s\n",
      "480:\tlearn: 56617.6236758\ttotal: 7.85s\tremaining: 8.47s\n",
      "481:\tlearn: 56575.9177212\ttotal: 7.87s\tremaining: 8.46s\n",
      "482:\tlearn: 56560.3860042\ttotal: 7.88s\tremaining: 8.44s\n",
      "483:\tlearn: 56555.3768785\ttotal: 7.89s\tremaining: 8.41s\n",
      "484:\tlearn: 56547.1249178\ttotal: 7.91s\tremaining: 8.39s\n",
      "485:\tlearn: 56535.1883550\ttotal: 7.92s\tremaining: 8.37s\n",
      "486:\tlearn: 56518.4361599\ttotal: 7.93s\tremaining: 8.35s\n",
      "487:\tlearn: 56480.6689290\ttotal: 7.95s\tremaining: 8.34s\n",
      "488:\tlearn: 56472.7080286\ttotal: 7.96s\tremaining: 8.31s\n",
      "489:\tlearn: 56465.3937085\ttotal: 7.98s\tremaining: 8.31s\n",
      "490:\tlearn: 56409.7272549\ttotal: 7.99s\tremaining: 8.29s\n",
      "491:\tlearn: 56386.3347027\ttotal: 8.03s\tremaining: 8.29s\n",
      "492:\tlearn: 56382.3910030\ttotal: 8.05s\tremaining: 8.28s\n",
      "493:\tlearn: 56368.7942786\ttotal: 8.07s\tremaining: 8.26s\n",
      "494:\tlearn: 56366.0306791\ttotal: 8.08s\tremaining: 8.24s\n",
      "495:\tlearn: 56362.3226421\ttotal: 8.09s\tremaining: 8.22s\n",
      "496:\tlearn: 56354.6339779\ttotal: 8.1s\tremaining: 8.2s\n",
      "497:\tlearn: 56337.6106324\ttotal: 8.11s\tremaining: 8.18s\n",
      "498:\tlearn: 56330.1981389\ttotal: 8.12s\tremaining: 8.15s\n",
      "499:\tlearn: 56322.0768411\ttotal: 8.14s\tremaining: 8.14s\n",
      "500:\tlearn: 56314.9403086\ttotal: 8.15s\tremaining: 8.12s\n",
      "501:\tlearn: 56308.0618476\ttotal: 8.16s\tremaining: 8.1s\n",
      "502:\tlearn: 56301.4316485\ttotal: 8.18s\tremaining: 8.08s\n",
      "503:\tlearn: 56295.0403380\ttotal: 8.19s\tremaining: 8.06s\n",
      "504:\tlearn: 56291.2604639\ttotal: 8.23s\tremaining: 8.07s\n",
      "505:\tlearn: 56260.5998174\ttotal: 8.25s\tremaining: 8.05s\n",
      "506:\tlearn: 56212.8606183\ttotal: 8.26s\tremaining: 8.03s\n",
      "507:\tlearn: 56177.4124059\ttotal: 8.27s\tremaining: 8.01s\n",
      "508:\tlearn: 56174.9668714\ttotal: 8.28s\tremaining: 7.99s\n",
      "509:\tlearn: 56168.6618674\ttotal: 8.29s\tremaining: 7.97s\n",
      "510:\tlearn: 56117.7271548\ttotal: 8.31s\tremaining: 7.95s\n",
      "511:\tlearn: 56111.0100143\ttotal: 8.31s\tremaining: 7.92s\n",
      "512:\tlearn: 56071.4801142\ttotal: 8.33s\tremaining: 7.91s\n",
      "513:\tlearn: 56053.8440569\ttotal: 8.35s\tremaining: 7.89s\n",
      "514:\tlearn: 55981.9428153\ttotal: 8.36s\tremaining: 7.87s\n",
      "515:\tlearn: 55978.1967646\ttotal: 8.37s\tremaining: 7.85s\n",
      "516:\tlearn: 55953.1896394\ttotal: 8.38s\tremaining: 7.83s\n",
      "517:\tlearn: 55947.0115948\ttotal: 8.39s\tremaining: 7.81s\n",
      "518:\tlearn: 55898.2325000\ttotal: 8.41s\tremaining: 7.79s\n",
      "519:\tlearn: 55892.2706404\ttotal: 8.42s\tremaining: 7.78s\n",
      "520:\tlearn: 55888.6188501\ttotal: 8.45s\tremaining: 7.76s\n",
      "521:\tlearn: 55882.8709888\ttotal: 8.46s\tremaining: 7.75s\n",
      "522:\tlearn: 55837.9855459\ttotal: 8.49s\tremaining: 7.74s\n",
      "523:\tlearn: 55830.1955821\ttotal: 8.51s\tremaining: 7.73s\n",
      "524:\tlearn: 55790.8732504\ttotal: 8.51s\tremaining: 7.7s\n",
      "525:\tlearn: 55785.3164806\ttotal: 8.52s\tremaining: 7.68s\n",
      "526:\tlearn: 55783.1069203\ttotal: 8.54s\tremaining: 7.66s\n",
      "527:\tlearn: 55777.6191259\ttotal: 8.55s\tremaining: 7.64s\n",
      "528:\tlearn: 55774.8034038\ttotal: 8.56s\tremaining: 7.62s\n",
      "529:\tlearn: 55768.8315715\ttotal: 8.57s\tremaining: 7.6s\n",
      "530:\tlearn: 55748.3303582\ttotal: 8.58s\tremaining: 7.58s\n",
      "531:\tlearn: 55721.4507341\ttotal: 8.6s\tremaining: 7.56s\n",
      "532:\tlearn: 55718.7717350\ttotal: 8.61s\tremaining: 7.54s\n",
      "533:\tlearn: 55699.5144782\ttotal: 8.63s\tremaining: 7.53s\n",
      "534:\tlearn: 55664.5792667\ttotal: 8.65s\tremaining: 7.52s\n",
      "535:\tlearn: 55645.2660905\ttotal: 8.68s\tremaining: 7.51s\n",
      "536:\tlearn: 55577.0247936\ttotal: 8.69s\tremaining: 7.49s\n",
      "537:\tlearn: 55556.1862078\ttotal: 8.7s\tremaining: 7.47s\n",
      "538:\tlearn: 55547.1635182\ttotal: 8.71s\tremaining: 7.45s\n",
      "539:\tlearn: 55478.2184211\ttotal: 8.73s\tremaining: 7.43s\n",
      "540:\tlearn: 55455.5988668\ttotal: 8.74s\tremaining: 7.41s\n",
      "541:\tlearn: 55449.9591516\ttotal: 8.75s\tremaining: 7.4s\n",
      "542:\tlearn: 55435.5137282\ttotal: 8.77s\tremaining: 7.38s\n",
      "543:\tlearn: 55421.4871210\ttotal: 8.78s\tremaining: 7.36s\n",
      "544:\tlearn: 55374.8309088\ttotal: 8.83s\tremaining: 7.37s\n",
      "545:\tlearn: 55368.3020320\ttotal: 8.83s\tremaining: 7.35s\n",
      "546:\tlearn: 55355.0840878\ttotal: 8.87s\tremaining: 7.34s\n",
      "547:\tlearn: 55351.1828204\ttotal: 8.9s\tremaining: 7.34s\n",
      "548:\tlearn: 55342.6111315\ttotal: 8.91s\tremaining: 7.32s\n",
      "549:\tlearn: 55297.4731988\ttotal: 8.93s\tremaining: 7.3s\n",
      "550:\tlearn: 55264.2996344\ttotal: 8.95s\tremaining: 7.29s\n",
      "551:\tlearn: 55258.9341455\ttotal: 8.97s\tremaining: 7.28s\n",
      "552:\tlearn: 55246.3314787\ttotal: 8.98s\tremaining: 7.26s\n",
      "553:\tlearn: 55227.6425427\ttotal: 9s\tremaining: 7.25s\n",
      "554:\tlearn: 55165.8353098\ttotal: 9.02s\tremaining: 7.23s\n",
      "555:\tlearn: 55160.8816942\ttotal: 9.04s\tremaining: 7.22s\n",
      "556:\tlearn: 55147.5463763\ttotal: 9.05s\tremaining: 7.2s\n",
      "557:\tlearn: 55117.3592795\ttotal: 9.07s\tremaining: 7.18s\n",
      "558:\tlearn: 55094.6977738\ttotal: 9.09s\tremaining: 7.17s\n",
      "559:\tlearn: 55055.3324406\ttotal: 9.11s\tremaining: 7.16s\n",
      "560:\tlearn: 55052.7945477\ttotal: 9.12s\tremaining: 7.14s\n",
      "561:\tlearn: 55049.5018437\ttotal: 9.13s\tremaining: 7.12s\n",
      "562:\tlearn: 55046.6227834\ttotal: 9.14s\tremaining: 7.1s\n",
      "563:\tlearn: 55025.9758698\ttotal: 9.17s\tremaining: 7.09s\n",
      "564:\tlearn: 55009.3172642\ttotal: 9.18s\tremaining: 7.07s\n",
      "565:\tlearn: 54990.8011277\ttotal: 9.19s\tremaining: 7.05s\n",
      "566:\tlearn: 54945.4962182\ttotal: 9.21s\tremaining: 7.03s\n",
      "567:\tlearn: 54942.1914748\ttotal: 9.22s\tremaining: 7.01s\n",
      "568:\tlearn: 54930.3316783\ttotal: 9.22s\tremaining: 6.99s\n",
      "569:\tlearn: 54901.9900515\ttotal: 9.24s\tremaining: 6.97s\n",
      "570:\tlearn: 54875.1232501\ttotal: 9.26s\tremaining: 6.95s\n",
      "571:\tlearn: 54858.3513623\ttotal: 9.27s\tremaining: 6.94s\n",
      "572:\tlearn: 54854.9753039\ttotal: 9.28s\tremaining: 6.92s\n",
      "573:\tlearn: 54847.9259987\ttotal: 9.29s\tremaining: 6.89s\n",
      "574:\tlearn: 54841.0754185\ttotal: 9.3s\tremaining: 6.88s\n",
      "575:\tlearn: 54823.2080631\ttotal: 9.33s\tremaining: 6.87s\n",
      "576:\tlearn: 54806.0215791\ttotal: 9.34s\tremaining: 6.85s\n",
      "577:\tlearn: 54756.5957982\ttotal: 9.35s\tremaining: 6.83s\n",
      "578:\tlearn: 54743.7428176\ttotal: 9.37s\tremaining: 6.81s\n",
      "579:\tlearn: 54726.5205656\ttotal: 9.38s\tremaining: 6.79s\n",
      "580:\tlearn: 54713.5415878\ttotal: 9.39s\tremaining: 6.78s\n",
      "581:\tlearn: 54669.5403689\ttotal: 9.4s\tremaining: 6.75s\n",
      "582:\tlearn: 54657.9503476\ttotal: 9.42s\tremaining: 6.74s\n",
      "583:\tlearn: 54644.3840257\ttotal: 9.43s\tremaining: 6.72s\n",
      "584:\tlearn: 54641.1219889\ttotal: 9.45s\tremaining: 6.7s\n",
      "585:\tlearn: 54605.4107199\ttotal: 9.46s\tremaining: 6.68s\n",
      "586:\tlearn: 54598.4126017\ttotal: 9.48s\tremaining: 6.67s\n",
      "587:\tlearn: 54591.3033952\ttotal: 9.5s\tremaining: 6.65s\n",
      "588:\tlearn: 54575.2100891\ttotal: 9.51s\tremaining: 6.64s\n",
      "589:\tlearn: 54549.1586238\ttotal: 9.52s\tremaining: 6.61s\n",
      "590:\tlearn: 54481.0147857\ttotal: 9.55s\tremaining: 6.61s\n",
      "591:\tlearn: 54445.7894464\ttotal: 9.56s\tremaining: 6.59s\n",
      "592:\tlearn: 54440.8026983\ttotal: 9.58s\tremaining: 6.58s\n",
      "593:\tlearn: 54414.9681174\ttotal: 9.6s\tremaining: 6.56s\n",
      "594:\tlearn: 54372.4281322\ttotal: 9.61s\tremaining: 6.54s\n",
      "595:\tlearn: 54352.3228139\ttotal: 9.62s\tremaining: 6.52s\n",
      "596:\tlearn: 54297.6962053\ttotal: 9.63s\tremaining: 6.5s\n",
      "597:\tlearn: 54264.3920159\ttotal: 9.65s\tremaining: 6.48s\n",
      "598:\tlearn: 54258.3224386\ttotal: 9.66s\tremaining: 6.47s\n",
      "599:\tlearn: 54255.3936470\ttotal: 9.67s\tremaining: 6.45s\n",
      "600:\tlearn: 54249.1611714\ttotal: 9.71s\tremaining: 6.45s\n",
      "601:\tlearn: 54244.5899023\ttotal: 9.75s\tremaining: 6.44s\n",
      "602:\tlearn: 54233.5927575\ttotal: 9.76s\tremaining: 6.43s\n",
      "603:\tlearn: 54201.0232107\ttotal: 9.78s\tremaining: 6.41s\n",
      "604:\tlearn: 54198.3653873\ttotal: 9.78s\tremaining: 6.39s\n",
      "605:\tlearn: 54183.7384375\ttotal: 9.8s\tremaining: 6.37s\n",
      "606:\tlearn: 54177.7979056\ttotal: 9.81s\tremaining: 6.35s\n",
      "607:\tlearn: 54136.5018101\ttotal: 9.82s\tremaining: 6.33s\n",
      "608:\tlearn: 54130.3338581\ttotal: 9.84s\tremaining: 6.32s\n",
      "609:\tlearn: 54126.1878358\ttotal: 9.85s\tremaining: 6.3s\n",
      "610:\tlearn: 54100.7681530\ttotal: 9.86s\tremaining: 6.28s\n",
      "611:\tlearn: 54088.7727475\ttotal: 9.87s\tremaining: 6.26s\n",
      "612:\tlearn: 54013.1093567\ttotal: 9.89s\tremaining: 6.24s\n",
      "613:\tlearn: 53998.0852432\ttotal: 9.9s\tremaining: 6.22s\n",
      "614:\tlearn: 53936.3272246\ttotal: 9.91s\tremaining: 6.2s\n",
      "615:\tlearn: 53931.5157019\ttotal: 9.92s\tremaining: 6.18s\n",
      "616:\tlearn: 53908.6327594\ttotal: 9.94s\tremaining: 6.17s\n",
      "617:\tlearn: 53850.3298449\ttotal: 9.95s\tremaining: 6.15s\n",
      "618:\tlearn: 53846.9833261\ttotal: 10s\tremaining: 6.15s\n",
      "619:\tlearn: 53844.5220771\ttotal: 10s\tremaining: 6.14s\n",
      "620:\tlearn: 53837.7568835\ttotal: 10s\tremaining: 6.12s\n",
      "621:\tlearn: 53826.3041802\ttotal: 10s\tremaining: 6.1s\n",
      "622:\tlearn: 53810.5784414\ttotal: 10.1s\tremaining: 6.08s\n",
      "623:\tlearn: 53795.5010035\ttotal: 10.1s\tremaining: 6.07s\n",
      "624:\tlearn: 53788.2353120\ttotal: 10.1s\tremaining: 6.05s\n",
      "625:\tlearn: 53779.3177390\ttotal: 10.1s\tremaining: 6.03s\n",
      "626:\tlearn: 53776.9212364\ttotal: 10.1s\tremaining: 6.01s\n",
      "627:\tlearn: 53725.2415104\ttotal: 10.1s\tremaining: 5.99s\n",
      "628:\tlearn: 53720.9596187\ttotal: 10.1s\tremaining: 5.98s\n",
      "629:\tlearn: 53680.8331422\ttotal: 10.2s\tremaining: 5.96s\n",
      "630:\tlearn: 53658.1537444\ttotal: 10.2s\tremaining: 5.95s\n",
      "631:\tlearn: 53646.1681983\ttotal: 10.2s\tremaining: 5.93s\n",
      "632:\tlearn: 53634.7013225\ttotal: 10.2s\tremaining: 5.92s\n",
      "633:\tlearn: 53595.2301303\ttotal: 10.2s\tremaining: 5.9s\n",
      "634:\tlearn: 53570.0041896\ttotal: 10.2s\tremaining: 5.89s\n",
      "635:\tlearn: 53557.5686456\ttotal: 10.2s\tremaining: 5.87s\n",
      "636:\tlearn: 53535.4185647\ttotal: 10.3s\tremaining: 5.85s\n",
      "637:\tlearn: 53479.8955634\ttotal: 10.3s\tremaining: 5.83s\n",
      "638:\tlearn: 53460.7490679\ttotal: 10.3s\tremaining: 5.81s\n",
      "639:\tlearn: 53439.3285127\ttotal: 10.3s\tremaining: 5.79s\n",
      "640:\tlearn: 53389.2066742\ttotal: 10.3s\tremaining: 5.78s\n",
      "641:\tlearn: 53346.3655052\ttotal: 10.3s\tremaining: 5.76s\n",
      "642:\tlearn: 53325.4567604\ttotal: 10.3s\tremaining: 5.74s\n",
      "643:\tlearn: 53315.1585441\ttotal: 10.4s\tremaining: 5.72s\n",
      "644:\tlearn: 53309.3786807\ttotal: 10.4s\tremaining: 5.71s\n",
      "645:\tlearn: 53307.4892452\ttotal: 10.4s\tremaining: 5.7s\n",
      "646:\tlearn: 53304.5865235\ttotal: 10.4s\tremaining: 5.69s\n",
      "647:\tlearn: 53300.5499736\ttotal: 10.4s\tremaining: 5.67s\n",
      "648:\tlearn: 53280.7958346\ttotal: 10.5s\tremaining: 5.66s\n",
      "649:\tlearn: 53245.0302459\ttotal: 10.5s\tremaining: 5.64s\n",
      "650:\tlearn: 53235.2063691\ttotal: 10.5s\tremaining: 5.62s\n",
      "651:\tlearn: 53218.1501352\ttotal: 10.5s\tremaining: 5.61s\n",
      "652:\tlearn: 53209.9284975\ttotal: 10.5s\tremaining: 5.59s\n",
      "653:\tlearn: 53176.7466980\ttotal: 10.5s\tremaining: 5.57s\n",
      "654:\tlearn: 53174.3210781\ttotal: 10.5s\tremaining: 5.55s\n",
      "655:\tlearn: 53160.9019934\ttotal: 10.6s\tremaining: 5.53s\n",
      "656:\tlearn: 53148.0915302\ttotal: 10.6s\tremaining: 5.52s\n",
      "657:\tlearn: 53146.1018359\ttotal: 10.6s\tremaining: 5.5s\n",
      "658:\tlearn: 53141.6570693\ttotal: 10.6s\tremaining: 5.49s\n",
      "659:\tlearn: 53107.1344396\ttotal: 10.6s\tremaining: 5.48s\n",
      "660:\tlearn: 53096.6510721\ttotal: 10.6s\tremaining: 5.46s\n",
      "661:\tlearn: 53089.8867605\ttotal: 10.7s\tremaining: 5.44s\n",
      "662:\tlearn: 53040.8457206\ttotal: 10.7s\tremaining: 5.42s\n",
      "663:\tlearn: 53021.3830272\ttotal: 10.7s\tremaining: 5.4s\n",
      "664:\tlearn: 53006.0036565\ttotal: 10.7s\tremaining: 5.38s\n",
      "665:\tlearn: 52998.3068850\ttotal: 10.7s\tremaining: 5.37s\n",
      "666:\tlearn: 52966.4017802\ttotal: 10.7s\tremaining: 5.35s\n",
      "667:\tlearn: 52955.4150309\ttotal: 10.7s\tremaining: 5.33s\n",
      "668:\tlearn: 52881.2058774\ttotal: 10.7s\tremaining: 5.32s\n",
      "669:\tlearn: 52875.0660219\ttotal: 10.8s\tremaining: 5.29s\n",
      "670:\tlearn: 52873.2380852\ttotal: 10.8s\tremaining: 5.28s\n",
      "671:\tlearn: 52866.1261519\ttotal: 10.8s\tremaining: 5.26s\n",
      "672:\tlearn: 52823.8758544\ttotal: 10.8s\tremaining: 5.24s\n",
      "673:\tlearn: 52804.5353201\ttotal: 10.8s\tremaining: 5.22s\n",
      "674:\tlearn: 52769.1067195\ttotal: 10.8s\tremaining: 5.22s\n",
      "675:\tlearn: 52753.7392127\ttotal: 10.8s\tremaining: 5.2s\n",
      "676:\tlearn: 52745.9841972\ttotal: 10.9s\tremaining: 5.18s\n",
      "677:\tlearn: 52727.2437684\ttotal: 10.9s\tremaining: 5.16s\n",
      "678:\tlearn: 52685.9858820\ttotal: 10.9s\tremaining: 5.14s\n",
      "679:\tlearn: 52638.5429835\ttotal: 10.9s\tremaining: 5.13s\n",
      "680:\tlearn: 52592.9078411\ttotal: 10.9s\tremaining: 5.11s\n",
      "681:\tlearn: 52578.2277901\ttotal: 11s\tremaining: 5.11s\n",
      "682:\tlearn: 52570.5101533\ttotal: 11s\tremaining: 5.09s\n",
      "683:\tlearn: 52526.4519443\ttotal: 11s\tremaining: 5.07s\n",
      "684:\tlearn: 52486.7517281\ttotal: 11s\tremaining: 5.05s\n",
      "685:\tlearn: 52468.7744544\ttotal: 11s\tremaining: 5.04s\n",
      "686:\tlearn: 52426.2001150\ttotal: 11s\tremaining: 5.03s\n",
      "687:\tlearn: 52415.1495268\ttotal: 11.1s\tremaining: 5.01s\n",
      "688:\tlearn: 52403.0083933\ttotal: 11.1s\tremaining: 5s\n",
      "689:\tlearn: 52398.0445343\ttotal: 11.1s\tremaining: 4.98s\n",
      "690:\tlearn: 52365.0026160\ttotal: 11.1s\tremaining: 4.96s\n",
      "691:\tlearn: 52323.8782791\ttotal: 11.1s\tremaining: 4.94s\n",
      "692:\tlearn: 52315.8653758\ttotal: 11.1s\tremaining: 4.93s\n",
      "693:\tlearn: 52276.1739800\ttotal: 11.1s\tremaining: 4.91s\n",
      "694:\tlearn: 52243.1734625\ttotal: 11.1s\tremaining: 4.89s\n",
      "695:\tlearn: 52205.1393050\ttotal: 11.2s\tremaining: 4.87s\n",
      "696:\tlearn: 52189.8832079\ttotal: 11.2s\tremaining: 4.86s\n",
      "697:\tlearn: 52151.5119974\ttotal: 11.2s\tremaining: 4.84s\n",
      "698:\tlearn: 52113.1172119\ttotal: 11.2s\tremaining: 4.82s\n",
      "699:\tlearn: 52071.4054231\ttotal: 11.2s\tremaining: 4.8s\n",
      "700:\tlearn: 52034.3195586\ttotal: 11.2s\tremaining: 4.79s\n",
      "701:\tlearn: 52030.6655480\ttotal: 11.2s\tremaining: 4.77s\n",
      "702:\tlearn: 51975.8126197\ttotal: 11.3s\tremaining: 4.76s\n",
      "703:\tlearn: 51966.1896748\ttotal: 11.3s\tremaining: 4.75s\n",
      "704:\tlearn: 51919.1608195\ttotal: 11.3s\tremaining: 4.73s\n",
      "705:\tlearn: 51882.4718357\ttotal: 11.3s\tremaining: 4.71s\n",
      "706:\tlearn: 51842.0207624\ttotal: 11.3s\tremaining: 4.7s\n",
      "707:\tlearn: 51834.5783078\ttotal: 11.4s\tremaining: 4.68s\n",
      "708:\tlearn: 51803.9049316\ttotal: 11.4s\tremaining: 4.66s\n",
      "709:\tlearn: 51769.2259934\ttotal: 11.4s\tremaining: 4.65s\n",
      "710:\tlearn: 51751.9890461\ttotal: 11.4s\tremaining: 4.63s\n",
      "711:\tlearn: 51748.1674132\ttotal: 11.4s\tremaining: 4.61s\n",
      "712:\tlearn: 51742.2623670\ttotal: 11.4s\tremaining: 4.59s\n",
      "713:\tlearn: 51738.5764932\ttotal: 11.4s\tremaining: 4.58s\n",
      "714:\tlearn: 51721.0698273\ttotal: 11.5s\tremaining: 4.56s\n",
      "715:\tlearn: 51716.5518916\ttotal: 11.5s\tremaining: 4.55s\n",
      "716:\tlearn: 51703.7658911\ttotal: 11.5s\tremaining: 4.54s\n",
      "717:\tlearn: 51700.5858973\ttotal: 11.5s\tremaining: 4.52s\n",
      "718:\tlearn: 51684.1384263\ttotal: 11.5s\tremaining: 4.5s\n",
      "719:\tlearn: 51679.5116586\ttotal: 11.5s\tremaining: 4.49s\n",
      "720:\tlearn: 51672.9005873\ttotal: 11.6s\tremaining: 4.47s\n",
      "721:\tlearn: 51668.4436707\ttotal: 11.6s\tremaining: 4.45s\n",
      "722:\tlearn: 51651.5654245\ttotal: 11.6s\tremaining: 4.43s\n",
      "723:\tlearn: 51594.4846661\ttotal: 11.6s\tremaining: 4.42s\n",
      "724:\tlearn: 51520.3105110\ttotal: 11.6s\tremaining: 4.4s\n",
      "725:\tlearn: 51518.6769225\ttotal: 11.6s\tremaining: 4.38s\n",
      "726:\tlearn: 51484.7947462\ttotal: 11.6s\tremaining: 4.36s\n",
      "727:\tlearn: 51480.5535772\ttotal: 11.6s\tremaining: 4.35s\n",
      "728:\tlearn: 51470.2772956\ttotal: 11.6s\tremaining: 4.33s\n",
      "729:\tlearn: 51461.4926746\ttotal: 11.7s\tremaining: 4.31s\n",
      "730:\tlearn: 51459.8877140\ttotal: 11.7s\tremaining: 4.29s\n",
      "731:\tlearn: 51455.9913260\ttotal: 11.7s\tremaining: 4.28s\n",
      "732:\tlearn: 51423.5023283\ttotal: 11.7s\tremaining: 4.27s\n",
      "733:\tlearn: 51419.2523337\ttotal: 11.7s\tremaining: 4.25s\n",
      "734:\tlearn: 51381.7218681\ttotal: 11.7s\tremaining: 4.23s\n",
      "735:\tlearn: 51377.9747302\ttotal: 11.8s\tremaining: 4.22s\n",
      "736:\tlearn: 51369.7393683\ttotal: 11.8s\tremaining: 4.2s\n",
      "737:\tlearn: 51338.3600273\ttotal: 11.8s\tremaining: 4.19s\n",
      "738:\tlearn: 51331.8093497\ttotal: 11.8s\tremaining: 4.17s\n",
      "739:\tlearn: 51310.8551004\ttotal: 11.8s\tremaining: 4.15s\n",
      "740:\tlearn: 51278.9701796\ttotal: 11.8s\tremaining: 4.13s\n",
      "741:\tlearn: 51242.6988507\ttotal: 11.8s\tremaining: 4.12s\n",
      "742:\tlearn: 51211.3824039\ttotal: 11.9s\tremaining: 4.1s\n",
      "743:\tlearn: 51195.0334387\ttotal: 11.9s\tremaining: 4.08s\n",
      "744:\tlearn: 51178.2477826\ttotal: 11.9s\tremaining: 4.07s\n",
      "745:\tlearn: 51162.3553594\ttotal: 11.9s\tremaining: 4.06s\n",
      "746:\tlearn: 51158.5968645\ttotal: 11.9s\tremaining: 4.04s\n",
      "747:\tlearn: 51120.5907969\ttotal: 11.9s\tremaining: 4.02s\n",
      "748:\tlearn: 51105.7952362\ttotal: 12s\tremaining: 4.01s\n",
      "749:\tlearn: 51100.3969988\ttotal: 12s\tremaining: 3.99s\n",
      "750:\tlearn: 51075.9645850\ttotal: 12s\tremaining: 3.97s\n",
      "751:\tlearn: 51061.9534472\ttotal: 12s\tremaining: 3.95s\n",
      "752:\tlearn: 51010.8928536\ttotal: 12s\tremaining: 3.94s\n",
      "753:\tlearn: 50974.5201861\ttotal: 12s\tremaining: 3.92s\n",
      "754:\tlearn: 50957.9090762\ttotal: 12s\tremaining: 3.9s\n",
      "755:\tlearn: 50952.8440490\ttotal: 12s\tremaining: 3.88s\n",
      "756:\tlearn: 50933.8621640\ttotal: 12.1s\tremaining: 3.87s\n",
      "757:\tlearn: 50930.3938327\ttotal: 12.1s\tremaining: 3.85s\n",
      "758:\tlearn: 50926.8148405\ttotal: 12.1s\tremaining: 3.83s\n",
      "759:\tlearn: 50894.6283261\ttotal: 12.1s\tremaining: 3.82s\n",
      "760:\tlearn: 50883.1371762\ttotal: 12.1s\tremaining: 3.8s\n",
      "761:\tlearn: 50879.0980264\ttotal: 12.1s\tremaining: 3.78s\n",
      "762:\tlearn: 50873.0270947\ttotal: 12.1s\tremaining: 3.77s\n",
      "763:\tlearn: 50856.7652104\ttotal: 12.2s\tremaining: 3.75s\n",
      "764:\tlearn: 50853.6445561\ttotal: 12.2s\tremaining: 3.74s\n",
      "765:\tlearn: 50843.4614201\ttotal: 12.2s\tremaining: 3.72s\n",
      "766:\tlearn: 50837.9127382\ttotal: 12.2s\tremaining: 3.71s\n",
      "767:\tlearn: 50833.5972230\ttotal: 12.2s\tremaining: 3.69s\n",
      "768:\tlearn: 50816.6929172\ttotal: 12.2s\tremaining: 3.67s\n",
      "769:\tlearn: 50780.4684914\ttotal: 12.2s\tremaining: 3.65s\n",
      "770:\tlearn: 50770.0243454\ttotal: 12.2s\tremaining: 3.64s\n",
      "771:\tlearn: 50767.0250741\ttotal: 12.3s\tremaining: 3.62s\n",
      "772:\tlearn: 50719.4090612\ttotal: 12.3s\tremaining: 3.61s\n",
      "773:\tlearn: 50715.3220345\ttotal: 12.3s\tremaining: 3.59s\n",
      "774:\tlearn: 50708.2192453\ttotal: 12.3s\tremaining: 3.58s\n",
      "775:\tlearn: 50702.5529551\ttotal: 12.3s\tremaining: 3.56s\n",
      "776:\tlearn: 50687.2909195\ttotal: 12.4s\tremaining: 3.54s\n",
      "777:\tlearn: 50672.5981497\ttotal: 12.4s\tremaining: 3.53s\n",
      "778:\tlearn: 50630.4361525\ttotal: 12.4s\tremaining: 3.51s\n",
      "779:\tlearn: 50627.4828105\ttotal: 12.4s\tremaining: 3.5s\n",
      "780:\tlearn: 50597.8396506\ttotal: 12.4s\tremaining: 3.48s\n",
      "781:\tlearn: 50587.4101986\ttotal: 12.4s\tremaining: 3.46s\n",
      "782:\tlearn: 50583.8424951\ttotal: 12.4s\tremaining: 3.45s\n",
      "783:\tlearn: 50571.0105327\ttotal: 12.4s\tremaining: 3.43s\n",
      "784:\tlearn: 50500.7879443\ttotal: 12.5s\tremaining: 3.41s\n",
      "785:\tlearn: 50490.3842914\ttotal: 12.5s\tremaining: 3.39s\n",
      "786:\tlearn: 50474.9301803\ttotal: 12.5s\tremaining: 3.38s\n",
      "787:\tlearn: 50461.0209095\ttotal: 12.5s\tremaining: 3.36s\n",
      "788:\tlearn: 50458.2700486\ttotal: 12.5s\tremaining: 3.35s\n",
      "789:\tlearn: 50454.2974645\ttotal: 12.5s\tremaining: 3.33s\n",
      "790:\tlearn: 50440.4528121\ttotal: 12.5s\tremaining: 3.31s\n",
      "791:\tlearn: 50408.7574187\ttotal: 12.6s\tremaining: 3.3s\n",
      "792:\tlearn: 50399.2307703\ttotal: 12.6s\tremaining: 3.28s\n",
      "793:\tlearn: 50395.1664815\ttotal: 12.6s\tremaining: 3.27s\n",
      "794:\tlearn: 50367.2254793\ttotal: 12.6s\tremaining: 3.25s\n",
      "795:\tlearn: 50336.3169648\ttotal: 12.6s\tremaining: 3.23s\n",
      "796:\tlearn: 50332.4970455\ttotal: 12.6s\tremaining: 3.22s\n",
      "797:\tlearn: 50330.0259571\ttotal: 12.6s\tremaining: 3.2s\n",
      "798:\tlearn: 50313.8793397\ttotal: 12.6s\tremaining: 3.18s\n",
      "799:\tlearn: 50284.7290703\ttotal: 12.7s\tremaining: 3.17s\n",
      "800:\tlearn: 50266.4464248\ttotal: 12.7s\tremaining: 3.15s\n",
      "801:\tlearn: 50258.8583965\ttotal: 12.7s\tremaining: 3.13s\n",
      "802:\tlearn: 50229.6941469\ttotal: 12.7s\tremaining: 3.12s\n",
      "803:\tlearn: 50226.9176844\ttotal: 12.7s\tremaining: 3.1s\n",
      "804:\tlearn: 50213.6598712\ttotal: 12.7s\tremaining: 3.08s\n",
      "805:\tlearn: 50198.6307652\ttotal: 12.7s\tremaining: 3.06s\n",
      "806:\tlearn: 50153.9993764\ttotal: 12.8s\tremaining: 3.05s\n",
      "807:\tlearn: 50149.4962451\ttotal: 12.9s\tremaining: 3.07s\n",
      "808:\tlearn: 50136.7369666\ttotal: 12.9s\tremaining: 3.05s\n",
      "809:\tlearn: 50133.0374787\ttotal: 13s\tremaining: 3.04s\n",
      "810:\tlearn: 50107.4862461\ttotal: 13.3s\tremaining: 3.09s\n",
      "811:\tlearn: 50099.6205127\ttotal: 13.3s\tremaining: 3.08s\n",
      "812:\tlearn: 50062.4846355\ttotal: 13.7s\tremaining: 3.15s\n",
      "813:\tlearn: 50057.9375230\ttotal: 13.7s\tremaining: 3.13s\n",
      "814:\tlearn: 50050.2064840\ttotal: 13.9s\tremaining: 3.17s\n",
      "815:\tlearn: 50046.4143138\ttotal: 14s\tremaining: 3.15s\n",
      "816:\tlearn: 50041.3361278\ttotal: 14s\tremaining: 3.14s\n",
      "817:\tlearn: 50027.3802340\ttotal: 14s\tremaining: 3.12s\n",
      "818:\tlearn: 50014.2001894\ttotal: 14s\tremaining: 3.1s\n",
      "819:\tlearn: 50000.8905403\ttotal: 14.1s\tremaining: 3.09s\n",
      "820:\tlearn: 49998.4847565\ttotal: 14.1s\tremaining: 3.07s\n",
      "821:\tlearn: 49994.4458600\ttotal: 14.1s\tremaining: 3.05s\n",
      "822:\tlearn: 49967.4851035\ttotal: 14.1s\tremaining: 3.03s\n",
      "823:\tlearn: 49963.7577732\ttotal: 14.1s\tremaining: 3.02s\n",
      "824:\tlearn: 49943.2440436\ttotal: 14.1s\tremaining: 3s\n",
      "825:\tlearn: 49917.1687445\ttotal: 14.2s\tremaining: 2.98s\n",
      "826:\tlearn: 49908.4189510\ttotal: 14.2s\tremaining: 2.97s\n",
      "827:\tlearn: 49903.4476012\ttotal: 14.3s\tremaining: 2.96s\n",
      "828:\tlearn: 49893.9314495\ttotal: 14.3s\tremaining: 2.94s\n",
      "829:\tlearn: 49864.4437438\ttotal: 14.3s\tremaining: 2.92s\n",
      "830:\tlearn: 49838.7368218\ttotal: 14.3s\tremaining: 2.91s\n",
      "831:\tlearn: 49833.8216340\ttotal: 14.3s\tremaining: 2.89s\n",
      "832:\tlearn: 49827.7866724\ttotal: 14.3s\tremaining: 2.87s\n",
      "833:\tlearn: 49788.8788207\ttotal: 14.3s\tremaining: 2.85s\n",
      "834:\tlearn: 49784.2426831\ttotal: 14.3s\tremaining: 2.83s\n",
      "835:\tlearn: 49748.1377604\ttotal: 14.4s\tremaining: 2.82s\n",
      "836:\tlearn: 49731.3581316\ttotal: 14.4s\tremaining: 2.8s\n",
      "837:\tlearn: 49723.7839491\ttotal: 14.4s\tremaining: 2.78s\n",
      "838:\tlearn: 49720.3598940\ttotal: 14.4s\tremaining: 2.77s\n",
      "839:\tlearn: 49695.1501584\ttotal: 14.4s\tremaining: 2.75s\n",
      "840:\tlearn: 49669.0651242\ttotal: 14.4s\tremaining: 2.73s\n",
      "841:\tlearn: 49660.0991445\ttotal: 14.5s\tremaining: 2.71s\n",
      "842:\tlearn: 49635.3684616\ttotal: 14.5s\tremaining: 2.69s\n",
      "843:\tlearn: 49616.6966242\ttotal: 14.5s\tremaining: 2.68s\n",
      "844:\tlearn: 49604.4782302\ttotal: 14.5s\tremaining: 2.66s\n",
      "845:\tlearn: 49601.6743408\ttotal: 14.5s\tremaining: 2.64s\n",
      "846:\tlearn: 49577.2310392\ttotal: 14.5s\tremaining: 2.62s\n",
      "847:\tlearn: 49573.6163278\ttotal: 14.5s\tremaining: 2.6s\n",
      "848:\tlearn: 49563.6373761\ttotal: 14.5s\tremaining: 2.59s\n",
      "849:\tlearn: 49558.1972694\ttotal: 14.6s\tremaining: 2.57s\n",
      "850:\tlearn: 49554.6100806\ttotal: 14.6s\tremaining: 2.55s\n",
      "851:\tlearn: 49518.8185472\ttotal: 14.6s\tremaining: 2.53s\n",
      "852:\tlearn: 49512.0914342\ttotal: 14.6s\tremaining: 2.52s\n",
      "853:\tlearn: 49498.9180377\ttotal: 14.6s\tremaining: 2.5s\n",
      "854:\tlearn: 49493.8337638\ttotal: 14.6s\tremaining: 2.48s\n",
      "855:\tlearn: 49490.7126326\ttotal: 14.7s\tremaining: 2.47s\n",
      "856:\tlearn: 49485.8654745\ttotal: 14.7s\tremaining: 2.45s\n",
      "857:\tlearn: 49481.0313660\ttotal: 14.7s\tremaining: 2.43s\n",
      "858:\tlearn: 49478.2595197\ttotal: 14.7s\tremaining: 2.41s\n",
      "859:\tlearn: 49459.0738961\ttotal: 14.7s\tremaining: 2.4s\n",
      "860:\tlearn: 49446.9487439\ttotal: 14.7s\tremaining: 2.38s\n",
      "861:\tlearn: 49435.4758223\ttotal: 14.7s\tremaining: 2.36s\n",
      "862:\tlearn: 49425.0641113\ttotal: 14.8s\tremaining: 2.34s\n",
      "863:\tlearn: 49420.1319956\ttotal: 14.8s\tremaining: 2.33s\n",
      "864:\tlearn: 49402.6931016\ttotal: 14.8s\tremaining: 2.31s\n",
      "865:\tlearn: 49386.7360323\ttotal: 14.8s\tremaining: 2.29s\n",
      "866:\tlearn: 49380.6634343\ttotal: 14.8s\tremaining: 2.27s\n",
      "867:\tlearn: 49378.8890230\ttotal: 14.8s\tremaining: 2.26s\n",
      "868:\tlearn: 49372.9627188\ttotal: 14.9s\tremaining: 2.24s\n",
      "869:\tlearn: 49362.2850620\ttotal: 14.9s\tremaining: 2.22s\n",
      "870:\tlearn: 49346.7886504\ttotal: 14.9s\tremaining: 2.2s\n",
      "871:\tlearn: 49340.0023585\ttotal: 14.9s\tremaining: 2.19s\n",
      "872:\tlearn: 49329.9064702\ttotal: 14.9s\tremaining: 2.17s\n",
      "873:\tlearn: 49318.8939544\ttotal: 14.9s\tremaining: 2.15s\n",
      "874:\tlearn: 49315.5730262\ttotal: 14.9s\tremaining: 2.13s\n",
      "875:\tlearn: 49299.0050827\ttotal: 14.9s\tremaining: 2.11s\n",
      "876:\tlearn: 49296.0228396\ttotal: 15s\tremaining: 2.1s\n",
      "877:\tlearn: 49291.9790272\ttotal: 15s\tremaining: 2.08s\n",
      "878:\tlearn: 49286.7923806\ttotal: 15s\tremaining: 2.06s\n",
      "879:\tlearn: 49283.2499789\ttotal: 15s\tremaining: 2.04s\n",
      "880:\tlearn: 49279.1529222\ttotal: 15s\tremaining: 2.03s\n",
      "881:\tlearn: 49248.3047179\ttotal: 15s\tremaining: 2.01s\n",
      "882:\tlearn: 49238.9124167\ttotal: 15.1s\tremaining: 1.99s\n",
      "883:\tlearn: 49236.2360656\ttotal: 15.1s\tremaining: 1.98s\n",
      "884:\tlearn: 49229.7835404\ttotal: 15.1s\tremaining: 1.96s\n",
      "885:\tlearn: 49226.2574574\ttotal: 15.1s\tremaining: 1.94s\n",
      "886:\tlearn: 49216.9991399\ttotal: 15.1s\tremaining: 1.92s\n",
      "887:\tlearn: 49214.8119234\ttotal: 15.1s\tremaining: 1.91s\n",
      "888:\tlearn: 49202.7413978\ttotal: 15.1s\tremaining: 1.89s\n",
      "889:\tlearn: 49191.6445794\ttotal: 15.1s\tremaining: 1.87s\n",
      "890:\tlearn: 49167.7667649\ttotal: 15.2s\tremaining: 1.85s\n",
      "891:\tlearn: 49098.2893202\ttotal: 15.2s\tremaining: 1.84s\n",
      "892:\tlearn: 49097.1637164\ttotal: 15.2s\tremaining: 1.82s\n",
      "893:\tlearn: 49090.5628285\ttotal: 15.2s\tremaining: 1.8s\n",
      "894:\tlearn: 49068.4121020\ttotal: 15.2s\tremaining: 1.78s\n",
      "895:\tlearn: 49061.0161144\ttotal: 15.2s\tremaining: 1.76s\n",
      "896:\tlearn: 49059.9756241\ttotal: 15.2s\tremaining: 1.75s\n",
      "897:\tlearn: 49056.2147966\ttotal: 15.2s\tremaining: 1.73s\n",
      "898:\tlearn: 49052.5781699\ttotal: 15.3s\tremaining: 1.72s\n",
      "899:\tlearn: 49050.4146886\ttotal: 15.3s\tremaining: 1.7s\n",
      "900:\tlearn: 49041.0329862\ttotal: 15.3s\tremaining: 1.68s\n",
      "901:\tlearn: 49035.2628361\ttotal: 15.3s\tremaining: 1.67s\n",
      "902:\tlearn: 49028.4193772\ttotal: 15.4s\tremaining: 1.65s\n",
      "903:\tlearn: 49018.0484368\ttotal: 15.4s\tremaining: 1.63s\n",
      "904:\tlearn: 48977.5501016\ttotal: 15.4s\tremaining: 1.61s\n",
      "905:\tlearn: 48948.3018902\ttotal: 15.4s\tremaining: 1.6s\n",
      "906:\tlearn: 48933.1960874\ttotal: 15.4s\tremaining: 1.58s\n",
      "907:\tlearn: 48928.3621506\ttotal: 15.4s\tremaining: 1.56s\n",
      "908:\tlearn: 48919.4237805\ttotal: 15.4s\tremaining: 1.54s\n",
      "909:\tlearn: 48910.8363439\ttotal: 15.4s\tremaining: 1.53s\n",
      "910:\tlearn: 48907.6712616\ttotal: 15.5s\tremaining: 1.51s\n",
      "911:\tlearn: 48902.3712104\ttotal: 15.5s\tremaining: 1.49s\n",
      "912:\tlearn: 48833.6267809\ttotal: 15.5s\tremaining: 1.48s\n",
      "913:\tlearn: 48831.0861842\ttotal: 15.5s\tremaining: 1.46s\n",
      "914:\tlearn: 48823.2184105\ttotal: 15.5s\tremaining: 1.44s\n",
      "915:\tlearn: 48819.3918960\ttotal: 15.5s\tremaining: 1.43s\n",
      "916:\tlearn: 48812.0452511\ttotal: 15.6s\tremaining: 1.41s\n",
      "917:\tlearn: 48807.7106316\ttotal: 15.6s\tremaining: 1.39s\n",
      "918:\tlearn: 48795.4470580\ttotal: 15.6s\tremaining: 1.37s\n",
      "919:\tlearn: 48788.3083015\ttotal: 15.6s\tremaining: 1.36s\n",
      "920:\tlearn: 48721.9569384\ttotal: 15.6s\tremaining: 1.34s\n",
      "921:\tlearn: 48717.2088254\ttotal: 15.6s\tremaining: 1.32s\n",
      "922:\tlearn: 48695.7398065\ttotal: 15.6s\tremaining: 1.3s\n",
      "923:\tlearn: 48689.5917294\ttotal: 15.7s\tremaining: 1.29s\n",
      "924:\tlearn: 48675.0372321\ttotal: 15.7s\tremaining: 1.27s\n",
      "925:\tlearn: 48612.0500810\ttotal: 15.7s\tremaining: 1.25s\n",
      "926:\tlearn: 48550.1677674\ttotal: 15.7s\tremaining: 1.24s\n",
      "927:\tlearn: 48544.2337281\ttotal: 15.7s\tremaining: 1.22s\n",
      "928:\tlearn: 48540.4415427\ttotal: 15.8s\tremaining: 1.2s\n",
      "929:\tlearn: 48481.9720458\ttotal: 15.8s\tremaining: 1.19s\n",
      "930:\tlearn: 48474.7325059\ttotal: 15.8s\tremaining: 1.17s\n",
      "931:\tlearn: 48460.4039281\ttotal: 15.8s\tremaining: 1.15s\n",
      "932:\tlearn: 48403.7932858\ttotal: 15.8s\tremaining: 1.14s\n",
      "933:\tlearn: 48347.9994491\ttotal: 15.8s\tremaining: 1.12s\n",
      "934:\tlearn: 48295.2648673\ttotal: 15.8s\tremaining: 1.1s\n",
      "935:\tlearn: 48294.2771552\ttotal: 15.9s\tremaining: 1.08s\n",
      "936:\tlearn: 48282.0371508\ttotal: 15.9s\tremaining: 1.07s\n",
      "937:\tlearn: 48231.3273891\ttotal: 15.9s\tremaining: 1.05s\n",
      "938:\tlearn: 48182.2605841\ttotal: 15.9s\tremaining: 1.03s\n",
      "939:\tlearn: 48134.9415317\ttotal: 15.9s\tremaining: 1.02s\n",
      "940:\tlearn: 48123.1136652\ttotal: 15.9s\tremaining: 999ms\n",
      "941:\tlearn: 48111.7222866\ttotal: 15.9s\tremaining: 982ms\n",
      "942:\tlearn: 48066.0610185\ttotal: 16s\tremaining: 965ms\n",
      "943:\tlearn: 48047.7881275\ttotal: 16s\tremaining: 948ms\n",
      "944:\tlearn: 48046.5380885\ttotal: 16s\tremaining: 931ms\n",
      "945:\tlearn: 48038.6158179\ttotal: 16s\tremaining: 914ms\n",
      "946:\tlearn: 48027.7606736\ttotal: 16s\tremaining: 896ms\n",
      "947:\tlearn: 48013.3054304\ttotal: 16s\tremaining: 879ms\n",
      "948:\tlearn: 47969.2114011\ttotal: 16s\tremaining: 862ms\n",
      "949:\tlearn: 47962.5130996\ttotal: 16.1s\tremaining: 845ms\n",
      "950:\tlearn: 47941.4730293\ttotal: 16.1s\tremaining: 828ms\n",
      "951:\tlearn: 47938.4148204\ttotal: 16.1s\tremaining: 811ms\n",
      "952:\tlearn: 47934.7408011\ttotal: 16.1s\tremaining: 793ms\n",
      "953:\tlearn: 47931.1970934\ttotal: 16.1s\tremaining: 777ms\n",
      "954:\tlearn: 47888.6260013\ttotal: 16.1s\tremaining: 760ms\n",
      "955:\tlearn: 47882.2011794\ttotal: 16.1s\tremaining: 743ms\n",
      "956:\tlearn: 47879.5386347\ttotal: 16.2s\tremaining: 726ms\n",
      "957:\tlearn: 47836.9717519\ttotal: 16.2s\tremaining: 709ms\n",
      "958:\tlearn: 47826.8985112\ttotal: 16.2s\tremaining: 692ms\n",
      "959:\tlearn: 47787.2267727\ttotal: 16.2s\tremaining: 675ms\n",
      "960:\tlearn: 47776.1834348\ttotal: 16.2s\tremaining: 658ms\n",
      "961:\tlearn: 47768.1195899\ttotal: 16.2s\tremaining: 641ms\n",
      "962:\tlearn: 47767.1141005\ttotal: 16.2s\tremaining: 624ms\n",
      "963:\tlearn: 47763.7791581\ttotal: 16.2s\tremaining: 607ms\n",
      "964:\tlearn: 47739.3953902\ttotal: 16.3s\tremaining: 590ms\n",
      "965:\tlearn: 47734.3635923\ttotal: 16.3s\tremaining: 573ms\n",
      "966:\tlearn: 47696.1041886\ttotal: 16.3s\tremaining: 556ms\n",
      "967:\tlearn: 47690.1371085\ttotal: 16.3s\tremaining: 539ms\n",
      "968:\tlearn: 47657.2342503\ttotal: 16.3s\tremaining: 523ms\n",
      "969:\tlearn: 47647.4657280\ttotal: 16.4s\tremaining: 506ms\n",
      "970:\tlearn: 47610.4584744\ttotal: 16.4s\tremaining: 489ms\n",
      "971:\tlearn: 47592.4760490\ttotal: 16.4s\tremaining: 472ms\n",
      "972:\tlearn: 47591.3320580\ttotal: 16.4s\tremaining: 455ms\n",
      "973:\tlearn: 47555.6735124\ttotal: 16.4s\tremaining: 438ms\n",
      "974:\tlearn: 47521.2186017\ttotal: 16.4s\tremaining: 421ms\n",
      "975:\tlearn: 47488.0277998\ttotal: 16.4s\tremaining: 404ms\n",
      "976:\tlearn: 47486.4042383\ttotal: 16.5s\tremaining: 387ms\n",
      "977:\tlearn: 47477.8134177\ttotal: 16.5s\tremaining: 371ms\n",
      "978:\tlearn: 47453.1192213\ttotal: 16.5s\tremaining: 354ms\n",
      "979:\tlearn: 47440.2811866\ttotal: 16.5s\tremaining: 337ms\n",
      "980:\tlearn: 47434.7479906\ttotal: 16.5s\tremaining: 320ms\n",
      "981:\tlearn: 47426.6438816\ttotal: 16.5s\tremaining: 303ms\n",
      "982:\tlearn: 47395.1831231\ttotal: 16.5s\tremaining: 286ms\n",
      "983:\tlearn: 47379.9276976\ttotal: 16.6s\tremaining: 269ms\n",
      "984:\tlearn: 47371.5692497\ttotal: 16.6s\tremaining: 252ms\n",
      "985:\tlearn: 47369.9569241\ttotal: 16.6s\tremaining: 235ms\n",
      "986:\tlearn: 47364.5915997\ttotal: 16.6s\tremaining: 219ms\n",
      "987:\tlearn: 47360.8660911\ttotal: 16.6s\tremaining: 202ms\n",
      "988:\tlearn: 47337.0534947\ttotal: 16.6s\tremaining: 185ms\n",
      "989:\tlearn: 47307.2484557\ttotal: 16.6s\tremaining: 168ms\n",
      "990:\tlearn: 47302.0013069\ttotal: 16.7s\tremaining: 151ms\n",
      "991:\tlearn: 47278.3589013\ttotal: 16.7s\tremaining: 134ms\n",
      "992:\tlearn: 47276.8582717\ttotal: 16.7s\tremaining: 118ms\n",
      "993:\tlearn: 47240.1907890\ttotal: 16.7s\tremaining: 101ms\n",
      "994:\tlearn: 47231.6802157\ttotal: 16.7s\tremaining: 83.9ms\n",
      "995:\tlearn: 47195.5047015\ttotal: 16.7s\tremaining: 67.1ms\n",
      "996:\tlearn: 47161.3626086\ttotal: 16.7s\tremaining: 50.3ms\n",
      "997:\tlearn: 47160.3190764\ttotal: 16.7s\tremaining: 33.5ms\n",
      "998:\tlearn: 47128.0671970\ttotal: 16.7s\tremaining: 16.8ms\n",
      "999:\tlearn: 47123.5523681\ttotal: 16.8s\tremaining: 0us\n",
      "Learning rate set to 0.071716\n",
      "0:\tlearn: 72684.9974535\ttotal: 22.9ms\tremaining: 22.9s\n",
      "1:\tlearn: 72240.6215101\ttotal: 58.5ms\tremaining: 29.2s\n",
      "2:\tlearn: 71852.8442612\ttotal: 76.9ms\tremaining: 25.5s\n",
      "3:\tlearn: 71481.3734187\ttotal: 94.1ms\tremaining: 23.4s\n",
      "4:\tlearn: 71154.0343161\ttotal: 110ms\tremaining: 22s\n",
      "5:\tlearn: 70796.3380153\ttotal: 125ms\tremaining: 20.7s\n",
      "6:\tlearn: 70511.8357371\ttotal: 145ms\tremaining: 20.6s\n",
      "7:\tlearn: 70298.6125396\ttotal: 173ms\tremaining: 21.4s\n",
      "8:\tlearn: 70079.8647658\ttotal: 191ms\tremaining: 21s\n",
      "9:\tlearn: 69850.2415197\ttotal: 208ms\tremaining: 20.6s\n",
      "10:\tlearn: 69693.8722178\ttotal: 228ms\tremaining: 20.5s\n",
      "11:\tlearn: 69497.0093173\ttotal: 263ms\tremaining: 21.7s\n",
      "12:\tlearn: 69366.8596044\ttotal: 278ms\tremaining: 21.1s\n",
      "13:\tlearn: 69203.4454898\ttotal: 298ms\tremaining: 21s\n",
      "14:\tlearn: 69084.7849569\ttotal: 313ms\tremaining: 20.6s\n",
      "15:\tlearn: 68969.2470278\ttotal: 328ms\tremaining: 20.2s\n",
      "16:\tlearn: 68883.7111105\ttotal: 341ms\tremaining: 19.7s\n",
      "17:\tlearn: 68800.4082710\ttotal: 355ms\tremaining: 19.3s\n",
      "18:\tlearn: 68712.5203676\ttotal: 401ms\tremaining: 20.7s\n",
      "19:\tlearn: 68633.2979765\ttotal: 451ms\tremaining: 22.1s\n",
      "20:\tlearn: 68568.5917638\ttotal: 484ms\tremaining: 22.6s\n",
      "21:\tlearn: 68472.8602992\ttotal: 517ms\tremaining: 23s\n",
      "22:\tlearn: 68403.4789848\ttotal: 533ms\tremaining: 22.6s\n",
      "23:\tlearn: 68334.5325746\ttotal: 548ms\tremaining: 22.3s\n",
      "24:\tlearn: 68269.2477650\ttotal: 571ms\tremaining: 22.3s\n",
      "25:\tlearn: 68179.5019632\ttotal: 587ms\tremaining: 22s\n",
      "26:\tlearn: 68136.7644393\ttotal: 604ms\tremaining: 21.8s\n",
      "27:\tlearn: 68085.4957680\ttotal: 617ms\tremaining: 21.4s\n",
      "28:\tlearn: 68046.1255315\ttotal: 629ms\tremaining: 21.1s\n",
      "29:\tlearn: 68004.9082604\ttotal: 645ms\tremaining: 20.8s\n",
      "30:\tlearn: 67957.7940082\ttotal: 664ms\tremaining: 20.7s\n",
      "31:\tlearn: 67929.3533207\ttotal: 684ms\tremaining: 20.7s\n",
      "32:\tlearn: 67887.9442609\ttotal: 703ms\tremaining: 20.6s\n",
      "33:\tlearn: 67855.3286280\ttotal: 719ms\tremaining: 20.4s\n",
      "34:\tlearn: 67809.5032679\ttotal: 729ms\tremaining: 20.1s\n",
      "35:\tlearn: 67783.3474149\ttotal: 744ms\tremaining: 19.9s\n",
      "36:\tlearn: 67771.5136156\ttotal: 756ms\tremaining: 19.7s\n",
      "37:\tlearn: 67738.0386862\ttotal: 771ms\tremaining: 19.5s\n",
      "38:\tlearn: 67670.5902136\ttotal: 784ms\tremaining: 19.3s\n",
      "39:\tlearn: 67643.7951680\ttotal: 800ms\tremaining: 19.2s\n",
      "40:\tlearn: 67633.2682199\ttotal: 808ms\tremaining: 18.9s\n",
      "41:\tlearn: 67555.0533373\ttotal: 823ms\tremaining: 18.8s\n",
      "42:\tlearn: 67536.7492418\ttotal: 836ms\tremaining: 18.6s\n",
      "43:\tlearn: 67461.8347619\ttotal: 848ms\tremaining: 18.4s\n",
      "44:\tlearn: 67438.7713870\ttotal: 866ms\tremaining: 18.4s\n",
      "45:\tlearn: 67412.1676907\ttotal: 886ms\tremaining: 18.4s\n",
      "46:\tlearn: 67384.0778434\ttotal: 914ms\tremaining: 18.5s\n",
      "47:\tlearn: 67359.9237222\ttotal: 936ms\tremaining: 18.6s\n",
      "48:\tlearn: 67352.4908072\ttotal: 943ms\tremaining: 18.3s\n",
      "49:\tlearn: 67329.0126292\ttotal: 958ms\tremaining: 18.2s\n",
      "50:\tlearn: 67298.5874290\ttotal: 971ms\tremaining: 18.1s\n",
      "51:\tlearn: 67284.4636947\ttotal: 990ms\tremaining: 18s\n",
      "52:\tlearn: 67269.8249134\ttotal: 1.01s\tremaining: 18s\n",
      "53:\tlearn: 67227.8563090\ttotal: 1.02s\tremaining: 17.9s\n",
      "54:\tlearn: 67209.8244492\ttotal: 1.04s\tremaining: 17.9s\n",
      "55:\tlearn: 67197.0149048\ttotal: 1.05s\tremaining: 17.8s\n",
      "56:\tlearn: 67179.6284491\ttotal: 1.07s\tremaining: 17.6s\n",
      "57:\tlearn: 67164.9609062\ttotal: 1.07s\tremaining: 17.5s\n",
      "58:\tlearn: 67098.6108931\ttotal: 1.09s\tremaining: 17.4s\n",
      "59:\tlearn: 67036.1682129\ttotal: 1.11s\tremaining: 17.5s\n",
      "60:\tlearn: 67016.8515024\ttotal: 1.15s\tremaining: 17.7s\n",
      "61:\tlearn: 66957.7727249\ttotal: 1.17s\tremaining: 17.6s\n",
      "62:\tlearn: 66929.9003083\ttotal: 1.19s\tremaining: 17.8s\n",
      "63:\tlearn: 66906.2444611\ttotal: 1.21s\tremaining: 17.6s\n",
      "64:\tlearn: 66790.8738409\ttotal: 1.23s\tremaining: 17.7s\n",
      "65:\tlearn: 66769.2781113\ttotal: 1.25s\tremaining: 17.7s\n",
      "66:\tlearn: 66762.2441450\ttotal: 1.27s\tremaining: 17.6s\n",
      "67:\tlearn: 66635.9147245\ttotal: 1.28s\tremaining: 17.6s\n",
      "68:\tlearn: 66629.3449860\ttotal: 1.3s\tremaining: 17.5s\n",
      "69:\tlearn: 66566.7457465\ttotal: 1.31s\tremaining: 17.5s\n",
      "70:\tlearn: 66485.9542990\ttotal: 1.33s\tremaining: 17.5s\n",
      "71:\tlearn: 66474.8191086\ttotal: 1.35s\tremaining: 17.4s\n",
      "72:\tlearn: 66402.5804125\ttotal: 1.37s\tremaining: 17.4s\n",
      "73:\tlearn: 66342.2879162\ttotal: 1.41s\tremaining: 17.7s\n",
      "74:\tlearn: 66263.9522926\ttotal: 1.43s\tremaining: 17.6s\n",
      "75:\tlearn: 66250.7971562\ttotal: 1.45s\tremaining: 17.6s\n",
      "76:\tlearn: 66126.0956212\ttotal: 1.46s\tremaining: 17.5s\n",
      "77:\tlearn: 65931.5392392\ttotal: 1.48s\tremaining: 17.5s\n",
      "78:\tlearn: 65854.8183110\ttotal: 1.49s\tremaining: 17.4s\n",
      "79:\tlearn: 65843.4154703\ttotal: 1.5s\tremaining: 17.2s\n",
      "80:\tlearn: 65803.8895131\ttotal: 1.51s\tremaining: 17.1s\n",
      "81:\tlearn: 65714.3954459\ttotal: 1.53s\tremaining: 17.1s\n",
      "82:\tlearn: 65709.8996900\ttotal: 1.53s\tremaining: 17s\n",
      "83:\tlearn: 65684.7940574\ttotal: 1.56s\tremaining: 17s\n",
      "84:\tlearn: 65673.6372734\ttotal: 1.59s\tremaining: 17.1s\n",
      "85:\tlearn: 65618.9579945\ttotal: 1.6s\tremaining: 17s\n",
      "86:\tlearn: 65602.4478388\ttotal: 1.61s\tremaining: 16.9s\n",
      "87:\tlearn: 65584.9012231\ttotal: 1.63s\tremaining: 16.9s\n",
      "88:\tlearn: 65578.9084723\ttotal: 1.64s\tremaining: 16.8s\n",
      "89:\tlearn: 65533.1528812\ttotal: 1.66s\tremaining: 16.8s\n",
      "90:\tlearn: 65511.3927203\ttotal: 1.67s\tremaining: 16.6s\n",
      "91:\tlearn: 65497.8021013\ttotal: 1.68s\tremaining: 16.5s\n",
      "92:\tlearn: 65387.3894196\ttotal: 1.69s\tremaining: 16.5s\n",
      "93:\tlearn: 65313.8246368\ttotal: 1.7s\tremaining: 16.3s\n",
      "94:\tlearn: 65282.3531742\ttotal: 1.72s\tremaining: 16.4s\n",
      "95:\tlearn: 65236.5597723\ttotal: 1.73s\tremaining: 16.3s\n",
      "96:\tlearn: 65209.7064000\ttotal: 1.75s\tremaining: 16.2s\n",
      "97:\tlearn: 65209.2971734\ttotal: 1.75s\tremaining: 16.1s\n",
      "98:\tlearn: 65156.7828603\ttotal: 1.76s\tremaining: 16s\n",
      "99:\tlearn: 65101.6133398\ttotal: 1.78s\tremaining: 16.1s\n",
      "100:\tlearn: 65089.6504301\ttotal: 1.79s\tremaining: 16s\n",
      "101:\tlearn: 65084.3370988\ttotal: 1.84s\tremaining: 16.2s\n",
      "102:\tlearn: 65034.6767618\ttotal: 1.86s\tremaining: 16.2s\n",
      "103:\tlearn: 64975.5883559\ttotal: 1.87s\tremaining: 16.1s\n",
      "104:\tlearn: 64920.9780094\ttotal: 1.89s\tremaining: 16.1s\n",
      "105:\tlearn: 64919.5851299\ttotal: 1.89s\tremaining: 16s\n",
      "106:\tlearn: 64916.4116731\ttotal: 1.9s\tremaining: 15.9s\n",
      "107:\tlearn: 64862.6490115\ttotal: 1.92s\tremaining: 15.8s\n",
      "108:\tlearn: 64787.2981848\ttotal: 1.93s\tremaining: 15.8s\n",
      "109:\tlearn: 64777.0464578\ttotal: 1.94s\tremaining: 15.7s\n",
      "110:\tlearn: 64651.0527331\ttotal: 1.96s\tremaining: 15.7s\n",
      "111:\tlearn: 64632.7351320\ttotal: 1.97s\tremaining: 15.6s\n",
      "112:\tlearn: 64474.5179089\ttotal: 1.99s\tremaining: 15.6s\n",
      "113:\tlearn: 64425.0289872\ttotal: 2s\tremaining: 15.5s\n",
      "114:\tlearn: 64397.9916359\ttotal: 2.02s\tremaining: 15.5s\n",
      "115:\tlearn: 64371.9341281\ttotal: 2.05s\tremaining: 15.6s\n",
      "116:\tlearn: 64341.5042498\ttotal: 2.07s\tremaining: 15.6s\n",
      "117:\tlearn: 64335.7347628\ttotal: 2.08s\tremaining: 15.5s\n",
      "118:\tlearn: 64318.6023978\ttotal: 2.09s\tremaining: 15.5s\n",
      "119:\tlearn: 64290.5080233\ttotal: 2.1s\tremaining: 15.4s\n",
      "120:\tlearn: 64181.3073281\ttotal: 2.13s\tremaining: 15.5s\n",
      "121:\tlearn: 64131.9108013\ttotal: 2.14s\tremaining: 15.4s\n",
      "122:\tlearn: 64122.8296741\ttotal: 2.15s\tremaining: 15.4s\n",
      "123:\tlearn: 63992.8202389\ttotal: 2.17s\tremaining: 15.3s\n",
      "124:\tlearn: 63870.4183608\ttotal: 2.18s\tremaining: 15.3s\n",
      "125:\tlearn: 63828.6969176\ttotal: 2.19s\tremaining: 15.2s\n",
      "126:\tlearn: 63680.0279237\ttotal: 2.21s\tremaining: 15.2s\n",
      "127:\tlearn: 63629.0040752\ttotal: 2.24s\tremaining: 15.3s\n",
      "128:\tlearn: 63554.4982843\ttotal: 2.26s\tremaining: 15.3s\n",
      "129:\tlearn: 63536.5885782\ttotal: 2.27s\tremaining: 15.2s\n",
      "130:\tlearn: 63495.5464321\ttotal: 2.28s\tremaining: 15.1s\n",
      "131:\tlearn: 63451.9580446\ttotal: 2.3s\tremaining: 15.1s\n",
      "132:\tlearn: 63399.4984482\ttotal: 2.31s\tremaining: 15.1s\n",
      "133:\tlearn: 63391.0337812\ttotal: 2.32s\tremaining: 15s\n",
      "134:\tlearn: 63326.9164157\ttotal: 2.33s\tremaining: 14.9s\n",
      "135:\tlearn: 63283.1874132\ttotal: 2.35s\tremaining: 14.9s\n",
      "136:\tlearn: 63271.9567266\ttotal: 2.36s\tremaining: 14.9s\n",
      "137:\tlearn: 63228.4023554\ttotal: 2.38s\tremaining: 14.9s\n",
      "138:\tlearn: 63160.3644736\ttotal: 2.39s\tremaining: 14.8s\n",
      "139:\tlearn: 63137.0361390\ttotal: 2.41s\tremaining: 14.8s\n",
      "140:\tlearn: 63134.6248262\ttotal: 2.42s\tremaining: 14.7s\n",
      "141:\tlearn: 63118.6759945\ttotal: 2.43s\tremaining: 14.7s\n",
      "142:\tlearn: 63116.3334752\ttotal: 2.44s\tremaining: 14.6s\n",
      "143:\tlearn: 63111.7403570\ttotal: 2.47s\tremaining: 14.7s\n",
      "144:\tlearn: 63068.2869933\ttotal: 2.5s\tremaining: 14.8s\n",
      "145:\tlearn: 63026.8561428\ttotal: 2.53s\tremaining: 14.8s\n",
      "146:\tlearn: 62986.5257019\ttotal: 2.54s\tremaining: 14.7s\n",
      "147:\tlearn: 62928.6599527\ttotal: 2.55s\tremaining: 14.7s\n",
      "148:\tlearn: 62818.5818664\ttotal: 2.56s\tremaining: 14.6s\n",
      "149:\tlearn: 62765.2754235\ttotal: 2.58s\tremaining: 14.6s\n",
      "150:\tlearn: 62714.6641667\ttotal: 2.59s\tremaining: 14.6s\n",
      "151:\tlearn: 62686.2743137\ttotal: 2.6s\tremaining: 14.5s\n",
      "152:\tlearn: 62648.9273309\ttotal: 2.61s\tremaining: 14.5s\n",
      "153:\tlearn: 62636.7471113\ttotal: 2.65s\tremaining: 14.6s\n",
      "154:\tlearn: 62596.2051008\ttotal: 2.68s\tremaining: 14.6s\n",
      "155:\tlearn: 62563.5262310\ttotal: 2.7s\tremaining: 14.6s\n",
      "156:\tlearn: 62542.4966292\ttotal: 2.71s\tremaining: 14.5s\n",
      "157:\tlearn: 62538.4420080\ttotal: 2.73s\tremaining: 14.6s\n",
      "158:\tlearn: 62408.1468174\ttotal: 2.74s\tremaining: 14.5s\n",
      "159:\tlearn: 62402.0540003\ttotal: 2.76s\tremaining: 14.5s\n",
      "160:\tlearn: 62370.3515081\ttotal: 2.77s\tremaining: 14.4s\n",
      "161:\tlearn: 62366.3930461\ttotal: 2.78s\tremaining: 14.4s\n",
      "162:\tlearn: 62314.0240818\ttotal: 2.79s\tremaining: 14.3s\n",
      "163:\tlearn: 62308.1247324\ttotal: 2.8s\tremaining: 14.3s\n",
      "164:\tlearn: 62306.9367058\ttotal: 2.81s\tremaining: 14.2s\n",
      "165:\tlearn: 62275.6513278\ttotal: 2.82s\tremaining: 14.2s\n",
      "166:\tlearn: 62269.9765328\ttotal: 2.83s\tremaining: 14.1s\n",
      "167:\tlearn: 62252.6505880\ttotal: 2.84s\tremaining: 14.1s\n",
      "168:\tlearn: 62243.6128067\ttotal: 2.85s\tremaining: 14s\n",
      "169:\tlearn: 62169.5402592\ttotal: 2.87s\tremaining: 14s\n",
      "170:\tlearn: 62139.3797642\ttotal: 2.89s\tremaining: 14s\n",
      "171:\tlearn: 62110.4721307\ttotal: 2.9s\tremaining: 14s\n",
      "172:\tlearn: 62082.9005191\ttotal: 2.94s\tremaining: 14s\n",
      "173:\tlearn: 62055.2525849\ttotal: 3.02s\tremaining: 14.3s\n",
      "174:\tlearn: 62020.8638404\ttotal: 3.03s\tremaining: 14.3s\n",
      "175:\tlearn: 62001.0836824\ttotal: 3.04s\tremaining: 14.2s\n",
      "176:\tlearn: 61968.0672344\ttotal: 3.05s\tremaining: 14.2s\n",
      "177:\tlearn: 61942.3697862\ttotal: 3.07s\tremaining: 14.2s\n",
      "178:\tlearn: 61924.8905034\ttotal: 3.09s\tremaining: 14.2s\n",
      "179:\tlearn: 61881.8348345\ttotal: 3.12s\tremaining: 14.2s\n",
      "180:\tlearn: 61760.3875396\ttotal: 3.13s\tremaining: 14.1s\n",
      "181:\tlearn: 61735.6432857\ttotal: 3.14s\tremaining: 14.1s\n",
      "182:\tlearn: 61696.6582716\ttotal: 3.15s\tremaining: 14.1s\n",
      "183:\tlearn: 61591.9940089\ttotal: 3.16s\tremaining: 14s\n",
      "184:\tlearn: 61493.2759620\ttotal: 3.18s\tremaining: 14s\n",
      "185:\tlearn: 61480.7580704\ttotal: 3.19s\tremaining: 14s\n",
      "186:\tlearn: 61458.8184680\ttotal: 3.2s\tremaining: 13.9s\n",
      "187:\tlearn: 61450.8923588\ttotal: 3.21s\tremaining: 13.9s\n",
      "188:\tlearn: 61394.9272062\ttotal: 3.23s\tremaining: 13.9s\n",
      "189:\tlearn: 61374.9037043\ttotal: 3.23s\tremaining: 13.8s\n",
      "190:\tlearn: 61359.2907879\ttotal: 3.25s\tremaining: 13.8s\n",
      "191:\tlearn: 61328.0358078\ttotal: 3.26s\tremaining: 13.7s\n",
      "192:\tlearn: 61315.0455399\ttotal: 3.28s\tremaining: 13.7s\n",
      "193:\tlearn: 61304.4440668\ttotal: 3.31s\tremaining: 13.8s\n",
      "194:\tlearn: 61189.8013111\ttotal: 3.32s\tremaining: 13.7s\n",
      "195:\tlearn: 61149.2735775\ttotal: 3.33s\tremaining: 13.7s\n",
      "196:\tlearn: 61079.1311773\ttotal: 3.34s\tremaining: 13.6s\n",
      "197:\tlearn: 61065.4401826\ttotal: 3.35s\tremaining: 13.6s\n",
      "198:\tlearn: 61062.6947881\ttotal: 3.36s\tremaining: 13.5s\n",
      "199:\tlearn: 61053.4021655\ttotal: 3.37s\tremaining: 13.5s\n",
      "200:\tlearn: 61035.9218016\ttotal: 3.38s\tremaining: 13.4s\n",
      "201:\tlearn: 60948.2887891\ttotal: 3.41s\tremaining: 13.5s\n",
      "202:\tlearn: 60931.0432314\ttotal: 3.42s\tremaining: 13.4s\n",
      "203:\tlearn: 60864.2336968\ttotal: 3.43s\tremaining: 13.4s\n",
      "204:\tlearn: 60846.8082482\ttotal: 3.44s\tremaining: 13.3s\n",
      "205:\tlearn: 60815.6570595\ttotal: 3.45s\tremaining: 13.3s\n",
      "206:\tlearn: 60802.2946695\ttotal: 3.46s\tremaining: 13.3s\n",
      "207:\tlearn: 60773.1038202\ttotal: 3.48s\tremaining: 13.2s\n",
      "208:\tlearn: 60757.3941831\ttotal: 3.49s\tremaining: 13.2s\n",
      "209:\tlearn: 60736.5621864\ttotal: 3.51s\tremaining: 13.2s\n",
      "210:\tlearn: 60714.2951083\ttotal: 3.53s\tremaining: 13.2s\n",
      "211:\tlearn: 60637.5781827\ttotal: 3.55s\tremaining: 13.2s\n",
      "212:\tlearn: 60575.3418180\ttotal: 3.56s\tremaining: 13.2s\n",
      "213:\tlearn: 60559.8296663\ttotal: 3.58s\tremaining: 13.1s\n",
      "214:\tlearn: 60489.9989310\ttotal: 3.59s\tremaining: 13.1s\n",
      "215:\tlearn: 60427.1366132\ttotal: 3.6s\tremaining: 13.1s\n",
      "216:\tlearn: 60399.4225952\ttotal: 3.62s\tremaining: 13.1s\n",
      "217:\tlearn: 60383.7161931\ttotal: 3.63s\tremaining: 13s\n",
      "218:\tlearn: 60377.9849485\ttotal: 3.64s\tremaining: 13s\n",
      "219:\tlearn: 60366.3895488\ttotal: 3.65s\tremaining: 12.9s\n",
      "220:\tlearn: 60308.2002477\ttotal: 3.66s\tremaining: 12.9s\n",
      "221:\tlearn: 60296.0282267\ttotal: 3.67s\tremaining: 12.9s\n",
      "222:\tlearn: 60231.5084275\ttotal: 3.68s\tremaining: 12.8s\n",
      "223:\tlearn: 60218.2829857\ttotal: 3.69s\tremaining: 12.8s\n",
      "224:\tlearn: 60158.3215285\ttotal: 3.71s\tremaining: 12.8s\n",
      "225:\tlearn: 60104.1269751\ttotal: 3.74s\tremaining: 12.8s\n",
      "226:\tlearn: 60051.9992456\ttotal: 3.76s\tremaining: 12.8s\n",
      "227:\tlearn: 60012.8585393\ttotal: 3.77s\tremaining: 12.8s\n",
      "228:\tlearn: 59980.0627545\ttotal: 3.78s\tremaining: 12.7s\n",
      "229:\tlearn: 59968.1881591\ttotal: 3.79s\tremaining: 12.7s\n",
      "230:\tlearn: 59966.6473818\ttotal: 3.82s\tremaining: 12.7s\n",
      "231:\tlearn: 59916.9979069\ttotal: 3.83s\tremaining: 12.7s\n",
      "232:\tlearn: 59888.2235007\ttotal: 3.84s\tremaining: 12.6s\n",
      "233:\tlearn: 59872.7148293\ttotal: 3.85s\tremaining: 12.6s\n",
      "234:\tlearn: 59861.3750992\ttotal: 3.86s\tremaining: 12.6s\n",
      "235:\tlearn: 59859.9420701\ttotal: 3.87s\tremaining: 12.5s\n",
      "236:\tlearn: 59845.0695992\ttotal: 3.88s\tremaining: 12.5s\n",
      "237:\tlearn: 59824.1868428\ttotal: 3.89s\tremaining: 12.5s\n",
      "238:\tlearn: 59809.9627992\ttotal: 3.91s\tremaining: 12.4s\n",
      "239:\tlearn: 59799.0401436\ttotal: 3.92s\tremaining: 12.4s\n",
      "240:\tlearn: 59773.1523311\ttotal: 3.94s\tremaining: 12.4s\n",
      "241:\tlearn: 59730.9485843\ttotal: 3.96s\tremaining: 12.4s\n",
      "242:\tlearn: 59716.6098415\ttotal: 3.98s\tremaining: 12.4s\n",
      "243:\tlearn: 59700.1950422\ttotal: 3.99s\tremaining: 12.4s\n",
      "244:\tlearn: 59650.0728681\ttotal: 4s\tremaining: 12.3s\n",
      "245:\tlearn: 59633.7720558\ttotal: 4.02s\tremaining: 12.3s\n",
      "246:\tlearn: 59624.4317253\ttotal: 4.03s\tremaining: 12.3s\n",
      "247:\tlearn: 59605.8394913\ttotal: 4.04s\tremaining: 12.2s\n",
      "248:\tlearn: 59588.9287776\ttotal: 4.05s\tremaining: 12.2s\n",
      "249:\tlearn: 59548.0900769\ttotal: 4.07s\tremaining: 12.2s\n",
      "250:\tlearn: 59527.0923318\ttotal: 4.08s\tremaining: 12.2s\n",
      "251:\tlearn: 59517.4908550\ttotal: 4.09s\tremaining: 12.2s\n",
      "252:\tlearn: 59507.1483441\ttotal: 4.11s\tremaining: 12.1s\n",
      "253:\tlearn: 59481.4076147\ttotal: 4.12s\tremaining: 12.1s\n",
      "254:\tlearn: 59471.4271112\ttotal: 4.17s\tremaining: 12.2s\n",
      "255:\tlearn: 59416.6854847\ttotal: 4.18s\tremaining: 12.1s\n",
      "256:\tlearn: 59390.3973811\ttotal: 4.19s\tremaining: 12.1s\n",
      "257:\tlearn: 59378.6496494\ttotal: 4.21s\tremaining: 12.1s\n",
      "258:\tlearn: 59356.9638990\ttotal: 4.23s\tremaining: 12.1s\n",
      "259:\tlearn: 59298.2629704\ttotal: 4.24s\tremaining: 12.1s\n",
      "260:\tlearn: 59288.5542975\ttotal: 4.25s\tremaining: 12s\n",
      "261:\tlearn: 59278.7359894\ttotal: 4.26s\tremaining: 12s\n",
      "262:\tlearn: 59174.3858328\ttotal: 4.28s\tremaining: 12s\n",
      "263:\tlearn: 59163.2001020\ttotal: 4.29s\tremaining: 12s\n",
      "264:\tlearn: 59158.7324806\ttotal: 4.31s\tremaining: 11.9s\n",
      "265:\tlearn: 59140.5180199\ttotal: 4.32s\tremaining: 11.9s\n",
      "266:\tlearn: 59066.0188755\ttotal: 4.33s\tremaining: 11.9s\n",
      "267:\tlearn: 59057.0937083\ttotal: 4.34s\tremaining: 11.9s\n",
      "268:\tlearn: 59030.5382548\ttotal: 4.36s\tremaining: 11.8s\n",
      "269:\tlearn: 59025.1067718\ttotal: 4.37s\tremaining: 11.8s\n",
      "270:\tlearn: 58997.8421612\ttotal: 4.39s\tremaining: 11.8s\n",
      "271:\tlearn: 58994.5554521\ttotal: 4.4s\tremaining: 11.8s\n",
      "272:\tlearn: 58896.7185852\ttotal: 4.43s\tremaining: 11.8s\n",
      "273:\tlearn: 58878.0704508\ttotal: 4.45s\tremaining: 11.8s\n",
      "274:\tlearn: 58840.1986358\ttotal: 4.46s\tremaining: 11.8s\n",
      "275:\tlearn: 58815.6932513\ttotal: 4.47s\tremaining: 11.7s\n",
      "276:\tlearn: 58812.5257364\ttotal: 4.48s\tremaining: 11.7s\n",
      "277:\tlearn: 58803.2912659\ttotal: 4.49s\tremaining: 11.7s\n",
      "278:\tlearn: 58760.2663369\ttotal: 4.5s\tremaining: 11.6s\n",
      "279:\tlearn: 58718.8090107\ttotal: 4.51s\tremaining: 11.6s\n",
      "280:\tlearn: 58716.8240986\ttotal: 4.52s\tremaining: 11.6s\n",
      "281:\tlearn: 58673.6643841\ttotal: 4.54s\tremaining: 11.6s\n",
      "282:\tlearn: 58634.6234260\ttotal: 4.55s\tremaining: 11.5s\n",
      "283:\tlearn: 58608.0951001\ttotal: 4.57s\tremaining: 11.5s\n",
      "284:\tlearn: 58582.6783638\ttotal: 4.58s\tremaining: 11.5s\n",
      "285:\tlearn: 58569.0370480\ttotal: 4.59s\tremaining: 11.5s\n",
      "286:\tlearn: 58527.1029298\ttotal: 4.6s\tremaining: 11.4s\n",
      "287:\tlearn: 58520.5697406\ttotal: 4.64s\tremaining: 11.5s\n",
      "288:\tlearn: 58491.9879370\ttotal: 4.65s\tremaining: 11.4s\n",
      "289:\tlearn: 58485.4377972\ttotal: 4.66s\tremaining: 11.4s\n",
      "290:\tlearn: 58412.9081587\ttotal: 4.68s\tremaining: 11.4s\n",
      "291:\tlearn: 58404.6069427\ttotal: 4.69s\tremaining: 11.4s\n",
      "292:\tlearn: 58347.6904587\ttotal: 4.7s\tremaining: 11.3s\n",
      "293:\tlearn: 58307.2377220\ttotal: 4.71s\tremaining: 11.3s\n",
      "294:\tlearn: 58293.9418786\ttotal: 4.72s\tremaining: 11.3s\n",
      "295:\tlearn: 58260.7050494\ttotal: 4.74s\tremaining: 11.3s\n",
      "296:\tlearn: 58244.3637950\ttotal: 4.75s\tremaining: 11.2s\n",
      "297:\tlearn: 58223.5377962\ttotal: 4.76s\tremaining: 11.2s\n",
      "298:\tlearn: 58186.9508777\ttotal: 4.78s\tremaining: 11.2s\n",
      "299:\tlearn: 58169.6835545\ttotal: 4.79s\tremaining: 11.2s\n",
      "300:\tlearn: 58134.4132113\ttotal: 4.8s\tremaining: 11.1s\n",
      "301:\tlearn: 58088.3516640\ttotal: 4.81s\tremaining: 11.1s\n",
      "302:\tlearn: 58013.1790350\ttotal: 4.83s\tremaining: 11.1s\n",
      "303:\tlearn: 57968.8913891\ttotal: 4.86s\tremaining: 11.1s\n",
      "304:\tlearn: 57964.6780317\ttotal: 4.87s\tremaining: 11.1s\n",
      "305:\tlearn: 57930.5974693\ttotal: 4.88s\tremaining: 11.1s\n",
      "306:\tlearn: 57929.5343206\ttotal: 4.89s\tremaining: 11s\n",
      "307:\tlearn: 57928.5110051\ttotal: 4.9s\tremaining: 11s\n",
      "308:\tlearn: 57927.7299958\ttotal: 4.91s\tremaining: 11s\n",
      "309:\tlearn: 57894.8725931\ttotal: 4.92s\tremaining: 11s\n",
      "310:\tlearn: 57872.3042813\ttotal: 4.93s\tremaining: 10.9s\n",
      "311:\tlearn: 57865.3036291\ttotal: 4.94s\tremaining: 10.9s\n",
      "312:\tlearn: 57840.7479636\ttotal: 4.96s\tremaining: 10.9s\n",
      "313:\tlearn: 57832.2930962\ttotal: 4.98s\tremaining: 10.9s\n",
      "314:\tlearn: 57790.2165036\ttotal: 4.99s\tremaining: 10.8s\n",
      "315:\tlearn: 57776.8334093\ttotal: 5s\tremaining: 10.8s\n",
      "316:\tlearn: 57764.5642523\ttotal: 5.01s\tremaining: 10.8s\n",
      "317:\tlearn: 57720.6171174\ttotal: 5.02s\tremaining: 10.8s\n",
      "318:\tlearn: 57720.0125595\ttotal: 5.05s\tremaining: 10.8s\n",
      "319:\tlearn: 57708.9644186\ttotal: 5.07s\tremaining: 10.8s\n",
      "320:\tlearn: 57697.2927353\ttotal: 5.09s\tremaining: 10.8s\n",
      "321:\tlearn: 57684.4396213\ttotal: 5.09s\tremaining: 10.7s\n",
      "322:\tlearn: 57683.5547169\ttotal: 5.1s\tremaining: 10.7s\n",
      "323:\tlearn: 57682.7026864\ttotal: 5.12s\tremaining: 10.7s\n",
      "324:\tlearn: 57662.5799449\ttotal: 5.13s\tremaining: 10.6s\n",
      "325:\tlearn: 57655.1170872\ttotal: 5.14s\tremaining: 10.6s\n",
      "326:\tlearn: 57654.2964791\ttotal: 5.15s\tremaining: 10.6s\n",
      "327:\tlearn: 57645.3457109\ttotal: 5.17s\tremaining: 10.6s\n",
      "328:\tlearn: 57615.0327178\ttotal: 5.17s\tremaining: 10.6s\n",
      "329:\tlearn: 57575.1132786\ttotal: 5.19s\tremaining: 10.5s\n",
      "330:\tlearn: 57567.0722226\ttotal: 5.2s\tremaining: 10.5s\n",
      "331:\tlearn: 57529.6525149\ttotal: 5.21s\tremaining: 10.5s\n",
      "332:\tlearn: 57517.4004621\ttotal: 5.22s\tremaining: 10.5s\n",
      "333:\tlearn: 57505.6063563\ttotal: 5.24s\tremaining: 10.4s\n",
      "334:\tlearn: 57491.0037678\ttotal: 5.28s\tremaining: 10.5s\n",
      "335:\tlearn: 57473.3809156\ttotal: 5.28s\tremaining: 10.4s\n",
      "336:\tlearn: 57466.7944293\ttotal: 5.3s\tremaining: 10.4s\n",
      "337:\tlearn: 57411.9301583\ttotal: 5.31s\tremaining: 10.4s\n",
      "338:\tlearn: 57393.2474136\ttotal: 5.32s\tremaining: 10.4s\n",
      "339:\tlearn: 57356.5341660\ttotal: 5.33s\tremaining: 10.4s\n",
      "340:\tlearn: 57350.7635262\ttotal: 5.36s\tremaining: 10.3s\n",
      "341:\tlearn: 57318.8395762\ttotal: 5.37s\tremaining: 10.3s\n",
      "342:\tlearn: 57310.6966408\ttotal: 5.38s\tremaining: 10.3s\n",
      "343:\tlearn: 57301.6908987\ttotal: 5.39s\tremaining: 10.3s\n",
      "344:\tlearn: 57270.7133409\ttotal: 5.4s\tremaining: 10.2s\n",
      "345:\tlearn: 57235.8707741\ttotal: 5.41s\tremaining: 10.2s\n",
      "346:\tlearn: 57227.4427416\ttotal: 5.42s\tremaining: 10.2s\n",
      "347:\tlearn: 57215.2239488\ttotal: 5.43s\tremaining: 10.2s\n",
      "348:\tlearn: 57181.7336838\ttotal: 5.45s\tremaining: 10.2s\n",
      "349:\tlearn: 57140.7256582\ttotal: 5.48s\tremaining: 10.2s\n",
      "350:\tlearn: 57083.1045395\ttotal: 5.5s\tremaining: 10.2s\n",
      "351:\tlearn: 57075.5066646\ttotal: 5.51s\tremaining: 10.1s\n",
      "352:\tlearn: 57021.4485219\ttotal: 5.53s\tremaining: 10.1s\n",
      "353:\tlearn: 57016.1585395\ttotal: 5.54s\tremaining: 10.1s\n",
      "354:\tlearn: 56996.8667995\ttotal: 5.55s\tremaining: 10.1s\n",
      "355:\tlearn: 56967.4288944\ttotal: 5.56s\tremaining: 10.1s\n",
      "356:\tlearn: 56961.1883461\ttotal: 5.58s\tremaining: 10s\n",
      "357:\tlearn: 56930.7738371\ttotal: 5.59s\tremaining: 10s\n",
      "358:\tlearn: 56907.5592326\ttotal: 5.6s\tremaining: 10s\n",
      "359:\tlearn: 56893.4473082\ttotal: 5.61s\tremaining: 9.97s\n",
      "360:\tlearn: 56865.5896441\ttotal: 5.62s\tremaining: 9.95s\n",
      "361:\tlearn: 56841.2958754\ttotal: 5.63s\tremaining: 9.93s\n",
      "362:\tlearn: 56791.7490772\ttotal: 5.64s\tremaining: 9.9s\n",
      "363:\tlearn: 56770.3219263\ttotal: 5.67s\tremaining: 9.9s\n",
      "364:\tlearn: 56746.6259051\ttotal: 5.69s\tremaining: 9.9s\n",
      "365:\tlearn: 56741.1833283\ttotal: 5.71s\tremaining: 9.88s\n",
      "366:\tlearn: 56722.3697343\ttotal: 5.72s\tremaining: 9.86s\n",
      "367:\tlearn: 56713.8285184\ttotal: 5.73s\tremaining: 9.84s\n",
      "368:\tlearn: 56640.5644753\ttotal: 5.74s\tremaining: 9.82s\n",
      "369:\tlearn: 56611.0950605\ttotal: 5.76s\tremaining: 9.8s\n",
      "370:\tlearn: 56559.0985725\ttotal: 5.78s\tremaining: 9.79s\n",
      "371:\tlearn: 56538.9590222\ttotal: 5.79s\tremaining: 9.78s\n",
      "372:\tlearn: 56526.8747175\ttotal: 5.81s\tremaining: 9.76s\n",
      "373:\tlearn: 56453.4887562\ttotal: 5.82s\tremaining: 9.74s\n",
      "374:\tlearn: 56424.9998286\ttotal: 5.84s\tremaining: 9.73s\n",
      "375:\tlearn: 56415.4384448\ttotal: 5.86s\tremaining: 9.72s\n",
      "376:\tlearn: 56408.4012246\ttotal: 5.88s\tremaining: 9.71s\n",
      "377:\tlearn: 56377.1001484\ttotal: 5.9s\tremaining: 9.71s\n",
      "378:\tlearn: 56371.4078807\ttotal: 5.93s\tremaining: 9.72s\n",
      "379:\tlearn: 56356.1379289\ttotal: 5.95s\tremaining: 9.7s\n",
      "380:\tlearn: 56351.5094726\ttotal: 5.96s\tremaining: 9.68s\n",
      "381:\tlearn: 56347.2307122\ttotal: 5.97s\tremaining: 9.66s\n",
      "382:\tlearn: 56321.7566748\ttotal: 5.98s\tremaining: 9.64s\n",
      "383:\tlearn: 56307.0528223\ttotal: 6s\tremaining: 9.62s\n",
      "384:\tlearn: 56301.0483703\ttotal: 6.01s\tremaining: 9.6s\n",
      "385:\tlearn: 56271.0866019\ttotal: 6.02s\tremaining: 9.58s\n",
      "386:\tlearn: 56170.6298259\ttotal: 6.04s\tremaining: 9.57s\n",
      "387:\tlearn: 56166.5397644\ttotal: 6.05s\tremaining: 9.54s\n",
      "388:\tlearn: 56151.7344896\ttotal: 6.06s\tremaining: 9.52s\n",
      "389:\tlearn: 56138.4569001\ttotal: 6.07s\tremaining: 9.5s\n",
      "390:\tlearn: 56043.8513351\ttotal: 6.09s\tremaining: 9.49s\n",
      "391:\tlearn: 56040.2226899\ttotal: 6.1s\tremaining: 9.46s\n",
      "392:\tlearn: 55990.0941709\ttotal: 6.12s\tremaining: 9.45s\n",
      "393:\tlearn: 55966.5807533\ttotal: 6.14s\tremaining: 9.45s\n",
      "394:\tlearn: 55956.8630787\ttotal: 6.16s\tremaining: 9.44s\n",
      "395:\tlearn: 55952.0310538\ttotal: 6.17s\tremaining: 9.41s\n",
      "396:\tlearn: 55924.4262619\ttotal: 6.18s\tremaining: 9.39s\n",
      "397:\tlearn: 55921.8925620\ttotal: 6.19s\tremaining: 9.37s\n",
      "398:\tlearn: 55916.4070856\ttotal: 6.2s\tremaining: 9.34s\n",
      "399:\tlearn: 55902.3121226\ttotal: 6.21s\tremaining: 9.32s\n",
      "400:\tlearn: 55885.7184324\ttotal: 6.23s\tremaining: 9.31s\n",
      "401:\tlearn: 55873.3295067\ttotal: 6.25s\tremaining: 9.29s\n",
      "402:\tlearn: 55856.0239349\ttotal: 6.26s\tremaining: 9.27s\n",
      "403:\tlearn: 55767.4205017\ttotal: 6.26s\tremaining: 9.24s\n",
      "404:\tlearn: 55719.4845439\ttotal: 6.29s\tremaining: 9.24s\n",
      "405:\tlearn: 55699.1312565\ttotal: 6.3s\tremaining: 9.21s\n",
      "406:\tlearn: 55683.6455654\ttotal: 6.31s\tremaining: 9.2s\n",
      "407:\tlearn: 55657.3250931\ttotal: 6.33s\tremaining: 9.18s\n",
      "408:\tlearn: 55588.2844427\ttotal: 6.34s\tremaining: 9.16s\n",
      "409:\tlearn: 55542.6839604\ttotal: 6.38s\tremaining: 9.18s\n",
      "410:\tlearn: 55527.8314054\ttotal: 6.39s\tremaining: 9.16s\n",
      "411:\tlearn: 55518.9853606\ttotal: 6.41s\tremaining: 9.14s\n",
      "412:\tlearn: 55495.8796888\ttotal: 6.42s\tremaining: 9.12s\n",
      "413:\tlearn: 55484.9429949\ttotal: 6.43s\tremaining: 9.1s\n",
      "414:\tlearn: 55457.5718083\ttotal: 6.44s\tremaining: 9.08s\n",
      "415:\tlearn: 55390.7696261\ttotal: 6.46s\tremaining: 9.06s\n",
      "416:\tlearn: 55365.7174978\ttotal: 6.46s\tremaining: 9.04s\n",
      "417:\tlearn: 55342.6547459\ttotal: 6.48s\tremaining: 9.02s\n",
      "418:\tlearn: 55337.9062057\ttotal: 6.49s\tremaining: 9s\n",
      "419:\tlearn: 55315.5728186\ttotal: 6.51s\tremaining: 8.98s\n",
      "420:\tlearn: 55239.5441907\ttotal: 6.52s\tremaining: 8.97s\n",
      "421:\tlearn: 55215.4482745\ttotal: 6.53s\tremaining: 8.94s\n",
      "422:\tlearn: 55189.3745243\ttotal: 6.54s\tremaining: 8.92s\n",
      "423:\tlearn: 55132.4909300\ttotal: 6.56s\tremaining: 8.91s\n",
      "424:\tlearn: 55107.6389417\ttotal: 6.58s\tremaining: 8.9s\n",
      "425:\tlearn: 55101.5264954\ttotal: 6.6s\tremaining: 8.89s\n",
      "426:\tlearn: 55079.9236592\ttotal: 6.61s\tremaining: 8.87s\n",
      "427:\tlearn: 55056.4148942\ttotal: 6.62s\tremaining: 8.85s\n",
      "428:\tlearn: 55043.2166450\ttotal: 6.64s\tremaining: 8.84s\n",
      "429:\tlearn: 54978.3356862\ttotal: 6.65s\tremaining: 8.82s\n",
      "430:\tlearn: 54972.9138995\ttotal: 6.67s\tremaining: 8.81s\n",
      "431:\tlearn: 54969.5538951\ttotal: 6.68s\tremaining: 8.78s\n",
      "432:\tlearn: 54947.2045960\ttotal: 6.69s\tremaining: 8.76s\n",
      "433:\tlearn: 54936.0990421\ttotal: 6.71s\tremaining: 8.75s\n",
      "434:\tlearn: 54914.6333669\ttotal: 6.72s\tremaining: 8.73s\n",
      "435:\tlearn: 54870.0098837\ttotal: 6.74s\tremaining: 8.72s\n",
      "436:\tlearn: 54851.0633458\ttotal: 6.75s\tremaining: 8.7s\n",
      "437:\tlearn: 54826.9885889\ttotal: 6.76s\tremaining: 8.67s\n",
      "438:\tlearn: 54803.4648705\ttotal: 6.77s\tremaining: 8.65s\n",
      "439:\tlearn: 54783.9937567\ttotal: 6.79s\tremaining: 8.64s\n",
      "440:\tlearn: 54768.8984141\ttotal: 6.82s\tremaining: 8.64s\n",
      "441:\tlearn: 54760.5224166\ttotal: 6.83s\tremaining: 8.62s\n",
      "442:\tlearn: 54741.0261184\ttotal: 6.84s\tremaining: 8.6s\n",
      "443:\tlearn: 54727.1482595\ttotal: 6.85s\tremaining: 8.58s\n",
      "444:\tlearn: 54692.7612187\ttotal: 6.87s\tremaining: 8.57s\n",
      "445:\tlearn: 54662.7496187\ttotal: 6.88s\tremaining: 8.55s\n",
      "446:\tlearn: 54607.7237531\ttotal: 6.89s\tremaining: 8.52s\n",
      "447:\tlearn: 54586.7937101\ttotal: 6.9s\tremaining: 8.51s\n",
      "448:\tlearn: 54565.2697116\ttotal: 6.92s\tremaining: 8.49s\n",
      "449:\tlearn: 54484.1875645\ttotal: 6.93s\tremaining: 8.47s\n",
      "450:\tlearn: 54465.9017492\ttotal: 6.94s\tremaining: 8.45s\n",
      "451:\tlearn: 54458.4545626\ttotal: 6.95s\tremaining: 8.43s\n",
      "452:\tlearn: 54448.0945120\ttotal: 6.97s\tremaining: 8.41s\n",
      "453:\tlearn: 54427.9499981\ttotal: 6.98s\tremaining: 8.4s\n",
      "454:\tlearn: 54419.7467571\ttotal: 7s\tremaining: 8.38s\n",
      "455:\tlearn: 54405.9640261\ttotal: 7.03s\tremaining: 8.38s\n",
      "456:\tlearn: 54387.1346450\ttotal: 7.04s\tremaining: 8.36s\n",
      "457:\tlearn: 54374.8411190\ttotal: 7.05s\tremaining: 8.34s\n",
      "458:\tlearn: 54357.6132490\ttotal: 7.06s\tremaining: 8.32s\n",
      "459:\tlearn: 54346.7817619\ttotal: 7.07s\tremaining: 8.3s\n",
      "460:\tlearn: 54336.3563344\ttotal: 7.08s\tremaining: 8.28s\n",
      "461:\tlearn: 54323.4839821\ttotal: 7.09s\tremaining: 8.25s\n",
      "462:\tlearn: 54309.6423032\ttotal: 7.11s\tremaining: 8.24s\n",
      "463:\tlearn: 54295.2820332\ttotal: 7.12s\tremaining: 8.23s\n",
      "464:\tlearn: 54271.8427558\ttotal: 7.13s\tremaining: 8.21s\n",
      "465:\tlearn: 54261.7941978\ttotal: 7.15s\tremaining: 8.19s\n",
      "466:\tlearn: 54251.0089433\ttotal: 7.16s\tremaining: 8.17s\n",
      "467:\tlearn: 54228.4667508\ttotal: 7.17s\tremaining: 8.15s\n",
      "468:\tlearn: 54210.4623401\ttotal: 7.18s\tremaining: 8.13s\n",
      "469:\tlearn: 54198.9570058\ttotal: 7.2s\tremaining: 8.12s\n",
      "470:\tlearn: 54134.0645651\ttotal: 7.23s\tremaining: 8.12s\n",
      "471:\tlearn: 54124.3620367\ttotal: 7.25s\tremaining: 8.11s\n",
      "472:\tlearn: 54118.0368155\ttotal: 7.26s\tremaining: 8.09s\n",
      "473:\tlearn: 54101.3437360\ttotal: 7.28s\tremaining: 8.08s\n",
      "474:\tlearn: 54082.6843724\ttotal: 7.29s\tremaining: 8.06s\n",
      "475:\tlearn: 54072.4950092\ttotal: 7.32s\tremaining: 8.05s\n",
      "476:\tlearn: 54067.9633923\ttotal: 7.33s\tremaining: 8.04s\n",
      "477:\tlearn: 53994.0161869\ttotal: 7.36s\tremaining: 8.04s\n",
      "478:\tlearn: 53931.3953456\ttotal: 7.37s\tremaining: 8.02s\n",
      "479:\tlearn: 53917.9816991\ttotal: 7.38s\tremaining: 8s\n",
      "480:\tlearn: 53842.0607135\ttotal: 7.4s\tremaining: 7.98s\n",
      "481:\tlearn: 53825.1720993\ttotal: 7.41s\tremaining: 7.97s\n",
      "482:\tlearn: 53809.0218084\ttotal: 7.51s\tremaining: 8.04s\n",
      "483:\tlearn: 53799.6503897\ttotal: 7.54s\tremaining: 8.04s\n",
      "484:\tlearn: 53788.6392624\ttotal: 7.55s\tremaining: 8.02s\n",
      "485:\tlearn: 53776.2378283\ttotal: 7.56s\tremaining: 8s\n",
      "486:\tlearn: 53767.2265749\ttotal: 7.58s\tremaining: 7.98s\n",
      "487:\tlearn: 53753.7359728\ttotal: 7.59s\tremaining: 7.97s\n",
      "488:\tlearn: 53710.7416494\ttotal: 7.61s\tremaining: 7.95s\n",
      "489:\tlearn: 53702.0527151\ttotal: 7.63s\tremaining: 7.94s\n",
      "490:\tlearn: 53686.6053388\ttotal: 7.66s\tremaining: 7.94s\n",
      "491:\tlearn: 53678.2359971\ttotal: 7.67s\tremaining: 7.92s\n",
      "492:\tlearn: 53617.6846052\ttotal: 7.68s\tremaining: 7.9s\n",
      "493:\tlearn: 53544.1331171\ttotal: 7.7s\tremaining: 7.88s\n",
      "494:\tlearn: 53522.2008808\ttotal: 7.71s\tremaining: 7.87s\n",
      "495:\tlearn: 53507.0660941\ttotal: 7.72s\tremaining: 7.85s\n",
      "496:\tlearn: 53495.6690945\ttotal: 7.74s\tremaining: 7.83s\n",
      "497:\tlearn: 53454.5386230\ttotal: 7.75s\tremaining: 7.82s\n",
      "498:\tlearn: 53445.2497993\ttotal: 7.76s\tremaining: 7.79s\n",
      "499:\tlearn: 53434.0598369\ttotal: 7.78s\tremaining: 7.78s\n",
      "500:\tlearn: 53420.4751378\ttotal: 7.79s\tremaining: 7.76s\n",
      "501:\tlearn: 53412.3950222\ttotal: 7.8s\tremaining: 7.74s\n",
      "502:\tlearn: 53404.8942794\ttotal: 7.81s\tremaining: 7.72s\n",
      "503:\tlearn: 53397.4070092\ttotal: 7.83s\tremaining: 7.7s\n",
      "504:\tlearn: 53382.9051455\ttotal: 7.86s\tremaining: 7.71s\n",
      "505:\tlearn: 53366.7595881\ttotal: 7.88s\tremaining: 7.7s\n",
      "506:\tlearn: 53348.1260652\ttotal: 7.89s\tremaining: 7.67s\n",
      "507:\tlearn: 53340.3298024\ttotal: 7.91s\tremaining: 7.66s\n",
      "508:\tlearn: 53281.7229040\ttotal: 7.92s\tremaining: 7.64s\n",
      "509:\tlearn: 53260.9177725\ttotal: 7.95s\tremaining: 7.63s\n",
      "510:\tlearn: 53247.4250866\ttotal: 7.96s\tremaining: 7.62s\n",
      "511:\tlearn: 53232.6100958\ttotal: 7.97s\tremaining: 7.6s\n",
      "512:\tlearn: 53228.3315882\ttotal: 7.99s\tremaining: 7.58s\n",
      "513:\tlearn: 53217.1778432\ttotal: 8s\tremaining: 7.57s\n",
      "514:\tlearn: 53160.6352353\ttotal: 8.02s\tremaining: 7.55s\n",
      "515:\tlearn: 53148.9416066\ttotal: 8.03s\tremaining: 7.53s\n",
      "516:\tlearn: 53136.7992060\ttotal: 8.04s\tremaining: 7.51s\n",
      "517:\tlearn: 53125.5209967\ttotal: 8.05s\tremaining: 7.49s\n",
      "518:\tlearn: 53107.2685334\ttotal: 8.07s\tremaining: 7.48s\n",
      "519:\tlearn: 53089.7362574\ttotal: 8.08s\tremaining: 7.46s\n",
      "520:\tlearn: 53072.8887138\ttotal: 8.1s\tremaining: 7.45s\n",
      "521:\tlearn: 53057.3914666\ttotal: 8.11s\tremaining: 7.43s\n",
      "522:\tlearn: 53049.1866391\ttotal: 8.13s\tremaining: 7.41s\n",
      "523:\tlearn: 53032.9813290\ttotal: 8.14s\tremaining: 7.39s\n",
      "524:\tlearn: 53017.3985258\ttotal: 8.16s\tremaining: 7.38s\n",
      "525:\tlearn: 53002.4096380\ttotal: 8.17s\tremaining: 7.36s\n",
      "526:\tlearn: 52987.9879713\ttotal: 8.18s\tremaining: 7.34s\n",
      "527:\tlearn: 52949.8468301\ttotal: 8.19s\tremaining: 7.32s\n",
      "528:\tlearn: 52942.2758845\ttotal: 8.2s\tremaining: 7.3s\n",
      "529:\tlearn: 52927.4052931\ttotal: 8.21s\tremaining: 7.28s\n",
      "530:\tlearn: 52920.1090534\ttotal: 8.22s\tremaining: 7.26s\n",
      "531:\tlearn: 52900.7648986\ttotal: 8.23s\tremaining: 7.24s\n",
      "532:\tlearn: 52893.7316556\ttotal: 8.24s\tremaining: 7.22s\n",
      "533:\tlearn: 52875.9850170\ttotal: 8.26s\tremaining: 7.21s\n",
      "534:\tlearn: 52867.7666295\ttotal: 8.28s\tremaining: 7.19s\n",
      "535:\tlearn: 52853.1489991\ttotal: 8.3s\tremaining: 7.18s\n",
      "536:\tlearn: 52845.6208073\ttotal: 8.33s\tremaining: 7.18s\n",
      "537:\tlearn: 52841.0548029\ttotal: 8.36s\tremaining: 7.18s\n",
      "538:\tlearn: 52822.3866778\ttotal: 8.38s\tremaining: 7.16s\n",
      "539:\tlearn: 52810.4830535\ttotal: 8.39s\tremaining: 7.15s\n",
      "540:\tlearn: 52804.8195560\ttotal: 8.4s\tremaining: 7.13s\n",
      "541:\tlearn: 52796.8645105\ttotal: 8.41s\tremaining: 7.11s\n",
      "542:\tlearn: 52779.0470095\ttotal: 8.42s\tremaining: 7.09s\n",
      "543:\tlearn: 52725.0100443\ttotal: 8.44s\tremaining: 7.07s\n",
      "544:\tlearn: 52706.7693702\ttotal: 8.45s\tremaining: 7.05s\n",
      "545:\tlearn: 52667.7604123\ttotal: 8.46s\tremaining: 7.03s\n",
      "546:\tlearn: 52628.3774862\ttotal: 8.48s\tremaining: 7.03s\n",
      "547:\tlearn: 52615.2383407\ttotal: 8.52s\tremaining: 7.03s\n",
      "548:\tlearn: 52601.6016144\ttotal: 8.55s\tremaining: 7.02s\n",
      "549:\tlearn: 52595.3432072\ttotal: 8.58s\tremaining: 7.02s\n",
      "550:\tlearn: 52578.2536225\ttotal: 8.61s\tremaining: 7.02s\n",
      "551:\tlearn: 52571.4585603\ttotal: 8.62s\tremaining: 7s\n",
      "552:\tlearn: 52533.5457855\ttotal: 8.65s\tremaining: 6.99s\n",
      "553:\tlearn: 52527.0225997\ttotal: 8.67s\tremaining: 6.98s\n",
      "554:\tlearn: 52446.1427558\ttotal: 8.7s\tremaining: 6.98s\n",
      "555:\tlearn: 52439.6568149\ttotal: 8.75s\tremaining: 6.99s\n",
      "556:\tlearn: 52419.9512080\ttotal: 8.77s\tremaining: 6.97s\n",
      "557:\tlearn: 52403.6602379\ttotal: 8.78s\tremaining: 6.96s\n",
      "558:\tlearn: 52396.7756787\ttotal: 8.8s\tremaining: 6.94s\n",
      "559:\tlearn: 52390.8688144\ttotal: 8.81s\tremaining: 6.92s\n",
      "560:\tlearn: 52375.2576732\ttotal: 8.82s\tremaining: 6.9s\n",
      "561:\tlearn: 52302.7621791\ttotal: 8.83s\tremaining: 6.88s\n",
      "562:\tlearn: 52285.0517802\ttotal: 8.85s\tremaining: 6.87s\n",
      "563:\tlearn: 52227.8884382\ttotal: 8.85s\tremaining: 6.84s\n",
      "564:\tlearn: 52222.6444137\ttotal: 8.87s\tremaining: 6.83s\n",
      "565:\tlearn: 52146.8795079\ttotal: 8.88s\tremaining: 6.81s\n",
      "566:\tlearn: 52129.3325556\ttotal: 8.89s\tremaining: 6.79s\n",
      "567:\tlearn: 52121.3850548\ttotal: 8.91s\tremaining: 6.78s\n",
      "568:\tlearn: 52047.8346702\ttotal: 8.94s\tremaining: 6.77s\n",
      "569:\tlearn: 51998.8521691\ttotal: 8.95s\tremaining: 6.75s\n",
      "570:\tlearn: 51984.1796221\ttotal: 8.97s\tremaining: 6.74s\n",
      "571:\tlearn: 51969.6326163\ttotal: 8.98s\tremaining: 6.72s\n",
      "572:\tlearn: 51955.7896422\ttotal: 9s\tremaining: 6.71s\n",
      "573:\tlearn: 51943.0781406\ttotal: 9.01s\tremaining: 6.69s\n",
      "574:\tlearn: 51916.6678936\ttotal: 9.03s\tremaining: 6.67s\n",
      "575:\tlearn: 51905.5572337\ttotal: 9.03s\tremaining: 6.65s\n",
      "576:\tlearn: 51834.4501607\ttotal: 9.05s\tremaining: 6.63s\n",
      "577:\tlearn: 51827.9311658\ttotal: 9.06s\tremaining: 6.62s\n",
      "578:\tlearn: 51805.1235457\ttotal: 9.07s\tremaining: 6.59s\n",
      "579:\tlearn: 51736.5202429\ttotal: 9.08s\tremaining: 6.58s\n",
      "580:\tlearn: 51723.0323084\ttotal: 9.1s\tremaining: 6.56s\n",
      "581:\tlearn: 51710.4810960\ttotal: 9.11s\tremaining: 6.54s\n",
      "582:\tlearn: 51703.6651961\ttotal: 9.12s\tremaining: 6.53s\n",
      "583:\tlearn: 51689.9133903\ttotal: 9.13s\tremaining: 6.5s\n",
      "584:\tlearn: 51681.1882245\ttotal: 9.14s\tremaining: 6.49s\n",
      "585:\tlearn: 51614.9393741\ttotal: 9.16s\tremaining: 6.47s\n",
      "586:\tlearn: 51544.0839668\ttotal: 9.21s\tremaining: 6.48s\n",
      "587:\tlearn: 51489.7536199\ttotal: 9.22s\tremaining: 6.46s\n",
      "588:\tlearn: 51425.7089824\ttotal: 9.24s\tremaining: 6.45s\n",
      "589:\tlearn: 51420.7477194\ttotal: 9.25s\tremaining: 6.43s\n",
      "590:\tlearn: 51396.0424134\ttotal: 9.26s\tremaining: 6.41s\n",
      "591:\tlearn: 51389.3348621\ttotal: 9.28s\tremaining: 6.39s\n",
      "592:\tlearn: 51379.1338144\ttotal: 9.29s\tremaining: 6.38s\n",
      "593:\tlearn: 51362.3964369\ttotal: 9.3s\tremaining: 6.36s\n",
      "594:\tlearn: 51349.1318768\ttotal: 9.31s\tremaining: 6.34s\n",
      "595:\tlearn: 51343.8751698\ttotal: 9.33s\tremaining: 6.32s\n",
      "596:\tlearn: 51323.9948400\ttotal: 9.35s\tremaining: 6.31s\n",
      "597:\tlearn: 51262.0655801\ttotal: 9.36s\tremaining: 6.29s\n",
      "598:\tlearn: 51202.2990534\ttotal: 9.38s\tremaining: 6.28s\n",
      "599:\tlearn: 51156.8668626\ttotal: 9.4s\tremaining: 6.27s\n",
      "600:\tlearn: 51115.8562565\ttotal: 9.42s\tremaining: 6.25s\n",
      "601:\tlearn: 51099.6466685\ttotal: 9.43s\tremaining: 6.23s\n",
      "602:\tlearn: 51041.8260046\ttotal: 9.44s\tremaining: 6.22s\n",
      "603:\tlearn: 50990.5442135\ttotal: 9.46s\tremaining: 6.2s\n",
      "604:\tlearn: 50934.6950991\ttotal: 9.47s\tremaining: 6.18s\n",
      "605:\tlearn: 50885.2068154\ttotal: 9.48s\tremaining: 6.16s\n",
      "606:\tlearn: 50875.2815806\ttotal: 9.49s\tremaining: 6.15s\n",
      "607:\tlearn: 50861.0754935\ttotal: 9.51s\tremaining: 6.13s\n",
      "608:\tlearn: 50807.0926155\ttotal: 9.53s\tremaining: 6.12s\n",
      "609:\tlearn: 50782.7440186\ttotal: 9.54s\tremaining: 6.1s\n",
      "610:\tlearn: 50713.2818379\ttotal: 9.55s\tremaining: 6.08s\n",
      "611:\tlearn: 50675.6253557\ttotal: 9.56s\tremaining: 6.06s\n",
      "612:\tlearn: 50659.8669575\ttotal: 9.58s\tremaining: 6.05s\n",
      "613:\tlearn: 50647.0313930\ttotal: 9.6s\tremaining: 6.04s\n",
      "614:\tlearn: 50594.7964163\ttotal: 9.64s\tremaining: 6.03s\n",
      "615:\tlearn: 50589.8251550\ttotal: 9.65s\tremaining: 6.01s\n",
      "616:\tlearn: 50578.1036272\ttotal: 9.66s\tremaining: 6s\n",
      "617:\tlearn: 50565.4879886\ttotal: 9.67s\tremaining: 5.98s\n",
      "618:\tlearn: 50514.9664074\ttotal: 9.69s\tremaining: 5.96s\n",
      "619:\tlearn: 50467.9501911\ttotal: 9.71s\tremaining: 5.95s\n",
      "620:\tlearn: 50455.7721573\ttotal: 9.72s\tremaining: 5.93s\n",
      "621:\tlearn: 50444.0493380\ttotal: 9.74s\tremaining: 5.92s\n",
      "622:\tlearn: 50438.8327383\ttotal: 9.75s\tremaining: 5.9s\n",
      "623:\tlearn: 50423.6682001\ttotal: 9.76s\tremaining: 5.88s\n",
      "624:\tlearn: 50376.5602953\ttotal: 9.77s\tremaining: 5.86s\n",
      "625:\tlearn: 50361.4420471\ttotal: 9.79s\tremaining: 5.85s\n",
      "626:\tlearn: 50315.5569630\ttotal: 9.9s\tremaining: 5.89s\n",
      "627:\tlearn: 50279.0611812\ttotal: 9.94s\tremaining: 5.88s\n",
      "628:\tlearn: 50266.2000244\ttotal: 10.3s\tremaining: 6.07s\n",
      "629:\tlearn: 50260.5649725\ttotal: 10.4s\tremaining: 6.12s\n",
      "630:\tlearn: 50248.4401442\ttotal: 10.4s\tremaining: 6.1s\n",
      "631:\tlearn: 50180.7277767\ttotal: 10.7s\tremaining: 6.23s\n",
      "632:\tlearn: 50169.9021727\ttotal: 10.7s\tremaining: 6.22s\n",
      "633:\tlearn: 50155.7221670\ttotal: 10.7s\tremaining: 6.2s\n",
      "634:\tlearn: 50107.3547277\ttotal: 10.8s\tremaining: 6.18s\n",
      "635:\tlearn: 50100.1411955\ttotal: 10.8s\tremaining: 6.16s\n",
      "636:\tlearn: 50056.0811351\ttotal: 10.8s\tremaining: 6.14s\n",
      "637:\tlearn: 50050.2905577\ttotal: 10.8s\tremaining: 6.13s\n",
      "638:\tlearn: 50038.9660872\ttotal: 10.8s\tremaining: 6.11s\n",
      "639:\tlearn: 50032.6388894\ttotal: 10.8s\tremaining: 6.09s\n",
      "640:\tlearn: 49957.4927554\ttotal: 10.8s\tremaining: 6.07s\n",
      "641:\tlearn: 49945.5769606\ttotal: 10.8s\tremaining: 6.05s\n",
      "642:\tlearn: 49922.3393388\ttotal: 10.9s\tremaining: 6.03s\n",
      "643:\tlearn: 49917.8972589\ttotal: 10.9s\tremaining: 6.01s\n",
      "644:\tlearn: 49907.4697904\ttotal: 10.9s\tremaining: 6s\n",
      "645:\tlearn: 49860.6558504\ttotal: 10.9s\tremaining: 5.98s\n",
      "646:\tlearn: 49849.3470961\ttotal: 10.9s\tremaining: 5.96s\n",
      "647:\tlearn: 49840.6962724\ttotal: 11s\tremaining: 5.95s\n",
      "648:\tlearn: 49826.8460150\ttotal: 11s\tremaining: 5.93s\n",
      "649:\tlearn: 49819.4949424\ttotal: 11s\tremaining: 5.91s\n",
      "650:\tlearn: 49813.1673799\ttotal: 11s\tremaining: 5.9s\n",
      "651:\tlearn: 49801.7709286\ttotal: 11s\tremaining: 5.88s\n",
      "652:\tlearn: 49790.5211456\ttotal: 11s\tremaining: 5.86s\n",
      "653:\tlearn: 49747.7888740\ttotal: 11s\tremaining: 5.84s\n",
      "654:\tlearn: 49681.8815182\ttotal: 11.1s\tremaining: 5.82s\n",
      "655:\tlearn: 49674.4379351\ttotal: 11.1s\tremaining: 5.8s\n",
      "656:\tlearn: 49633.1528181\ttotal: 11.1s\tremaining: 5.79s\n",
      "657:\tlearn: 49623.0293224\ttotal: 11.1s\tremaining: 5.77s\n",
      "658:\tlearn: 49577.6915608\ttotal: 11.1s\tremaining: 5.75s\n",
      "659:\tlearn: 49574.3262999\ttotal: 11.1s\tremaining: 5.73s\n",
      "660:\tlearn: 49564.8146624\ttotal: 11.1s\tremaining: 5.72s\n",
      "661:\tlearn: 49521.1040938\ttotal: 11.2s\tremaining: 5.71s\n",
      "662:\tlearn: 49515.4517998\ttotal: 11.2s\tremaining: 5.69s\n",
      "663:\tlearn: 49507.0689161\ttotal: 11.2s\tremaining: 5.67s\n",
      "664:\tlearn: 49468.5182193\ttotal: 11.2s\tremaining: 5.65s\n",
      "665:\tlearn: 49444.7457265\ttotal: 11.2s\tremaining: 5.63s\n",
      "666:\tlearn: 49436.0011768\ttotal: 11.2s\tremaining: 5.62s\n",
      "667:\tlearn: 49428.5508390\ttotal: 11.3s\tremaining: 5.6s\n",
      "668:\tlearn: 49414.1151896\ttotal: 11.3s\tremaining: 5.58s\n",
      "669:\tlearn: 49406.7163718\ttotal: 11.3s\tremaining: 5.56s\n",
      "670:\tlearn: 49366.7258305\ttotal: 11.3s\tremaining: 5.54s\n",
      "671:\tlearn: 49357.1592293\ttotal: 11.3s\tremaining: 5.52s\n",
      "672:\tlearn: 49343.9840432\ttotal: 11.3s\tremaining: 5.5s\n",
      "673:\tlearn: 49333.6466732\ttotal: 11.3s\tremaining: 5.49s\n",
      "674:\tlearn: 49322.7032854\ttotal: 11.4s\tremaining: 5.47s\n",
      "675:\tlearn: 49279.3365090\ttotal: 11.4s\tremaining: 5.46s\n",
      "676:\tlearn: 49269.1366932\ttotal: 11.4s\tremaining: 5.44s\n",
      "677:\tlearn: 49258.3282088\ttotal: 11.4s\tremaining: 5.42s\n",
      "678:\tlearn: 49247.7881018\ttotal: 11.4s\tremaining: 5.41s\n",
      "679:\tlearn: 49238.3218172\ttotal: 11.4s\tremaining: 5.39s\n",
      "680:\tlearn: 49222.0897868\ttotal: 11.5s\tremaining: 5.37s\n",
      "681:\tlearn: 49203.5009606\ttotal: 11.5s\tremaining: 5.35s\n",
      "682:\tlearn: 49129.3327923\ttotal: 11.5s\tremaining: 5.33s\n",
      "683:\tlearn: 49116.0819008\ttotal: 11.5s\tremaining: 5.31s\n",
      "684:\tlearn: 49106.2355540\ttotal: 11.5s\tremaining: 5.29s\n",
      "685:\tlearn: 49069.5726111\ttotal: 11.5s\tremaining: 5.28s\n",
      "686:\tlearn: 49059.6993720\ttotal: 11.5s\tremaining: 5.26s\n",
      "687:\tlearn: 49020.8699985\ttotal: 11.6s\tremaining: 5.24s\n",
      "688:\tlearn: 49012.9958180\ttotal: 11.6s\tremaining: 5.24s\n",
      "689:\tlearn: 49007.7411906\ttotal: 11.6s\tremaining: 5.22s\n",
      "690:\tlearn: 48988.1034869\ttotal: 11.6s\tremaining: 5.21s\n",
      "691:\tlearn: 48979.3886415\ttotal: 11.7s\tremaining: 5.18s\n",
      "692:\tlearn: 48936.2412952\ttotal: 11.7s\tremaining: 5.17s\n",
      "693:\tlearn: 48926.4186083\ttotal: 11.7s\tremaining: 5.15s\n",
      "694:\tlearn: 48891.7070743\ttotal: 11.7s\tremaining: 5.13s\n",
      "695:\tlearn: 48880.3208143\ttotal: 11.7s\tremaining: 5.11s\n",
      "696:\tlearn: 48871.1371580\ttotal: 11.7s\tremaining: 5.09s\n",
      "697:\tlearn: 48833.5551213\ttotal: 11.7s\tremaining: 5.07s\n",
      "698:\tlearn: 48820.2045133\ttotal: 11.7s\tremaining: 5.06s\n",
      "699:\tlearn: 48783.9350235\ttotal: 11.8s\tremaining: 5.04s\n",
      "700:\tlearn: 48776.8881625\ttotal: 11.8s\tremaining: 5.02s\n",
      "701:\tlearn: 48771.0620893\ttotal: 11.8s\tremaining: 5.01s\n",
      "702:\tlearn: 48758.2020883\ttotal: 11.8s\tremaining: 4.99s\n",
      "703:\tlearn: 48723.1932184\ttotal: 11.8s\tremaining: 4.98s\n",
      "704:\tlearn: 48714.2508071\ttotal: 11.8s\tremaining: 4.96s\n",
      "705:\tlearn: 48710.0778003\ttotal: 11.9s\tremaining: 4.94s\n",
      "706:\tlearn: 48699.1957734\ttotal: 11.9s\tremaining: 4.92s\n",
      "707:\tlearn: 48687.6169719\ttotal: 11.9s\tremaining: 4.9s\n",
      "708:\tlearn: 48683.4438013\ttotal: 11.9s\tremaining: 4.88s\n",
      "709:\tlearn: 48659.3758085\ttotal: 11.9s\tremaining: 4.86s\n",
      "710:\tlearn: 48651.7701593\ttotal: 11.9s\tremaining: 4.84s\n",
      "711:\tlearn: 48623.7298462\ttotal: 11.9s\tremaining: 4.83s\n",
      "712:\tlearn: 48582.4150439\ttotal: 11.9s\tremaining: 4.81s\n",
      "713:\tlearn: 48578.1151344\ttotal: 12s\tremaining: 4.79s\n",
      "714:\tlearn: 48542.0329301\ttotal: 12s\tremaining: 4.77s\n",
      "715:\tlearn: 48529.2839460\ttotal: 12s\tremaining: 4.75s\n",
      "716:\tlearn: 48464.1955104\ttotal: 12.1s\tremaining: 4.77s\n",
      "717:\tlearn: 48455.9027378\ttotal: 12.1s\tremaining: 4.75s\n",
      "718:\tlearn: 48450.0622089\ttotal: 12.1s\tremaining: 4.73s\n",
      "719:\tlearn: 48445.5238121\ttotal: 12.1s\tremaining: 4.71s\n",
      "720:\tlearn: 48433.2074738\ttotal: 12.1s\tremaining: 4.7s\n",
      "721:\tlearn: 48392.3357798\ttotal: 12.2s\tremaining: 4.68s\n",
      "722:\tlearn: 48386.2352052\ttotal: 12.2s\tremaining: 4.66s\n",
      "723:\tlearn: 48381.2942835\ttotal: 12.2s\tremaining: 4.64s\n",
      "724:\tlearn: 48342.7313730\ttotal: 12.2s\tremaining: 4.62s\n",
      "725:\tlearn: 48334.7294561\ttotal: 12.2s\tremaining: 4.6s\n",
      "726:\tlearn: 48322.4226499\ttotal: 12.2s\tremaining: 4.58s\n",
      "727:\tlearn: 48316.1895918\ttotal: 12.2s\tremaining: 4.57s\n",
      "728:\tlearn: 48304.7107427\ttotal: 12.3s\tremaining: 4.56s\n",
      "729:\tlearn: 48297.2510080\ttotal: 12.3s\tremaining: 4.54s\n",
      "730:\tlearn: 48275.3511530\ttotal: 12.3s\tremaining: 4.52s\n",
      "731:\tlearn: 48269.4927022\ttotal: 12.3s\tremaining: 4.5s\n",
      "732:\tlearn: 48232.2263597\ttotal: 12.3s\tremaining: 4.48s\n",
      "733:\tlearn: 48221.1347296\ttotal: 12.3s\tremaining: 4.47s\n",
      "734:\tlearn: 48209.4649414\ttotal: 12.3s\tremaining: 4.45s\n",
      "735:\tlearn: 48173.4959214\ttotal: 12.4s\tremaining: 4.43s\n",
      "736:\tlearn: 48167.9224982\ttotal: 12.4s\tremaining: 4.41s\n",
      "737:\tlearn: 48163.2279734\ttotal: 12.4s\tremaining: 4.39s\n",
      "738:\tlearn: 48151.9652241\ttotal: 12.4s\tremaining: 4.38s\n",
      "739:\tlearn: 48117.1027721\ttotal: 12.4s\tremaining: 4.36s\n",
      "740:\tlearn: 48082.9077657\ttotal: 12.4s\tremaining: 4.34s\n",
      "741:\tlearn: 48049.9156446\ttotal: 12.5s\tremaining: 4.33s\n",
      "742:\tlearn: 48044.2552373\ttotal: 12.5s\tremaining: 4.31s\n",
      "743:\tlearn: 48033.5157451\ttotal: 12.5s\tremaining: 4.29s\n",
      "744:\tlearn: 48001.6708406\ttotal: 12.5s\tremaining: 4.28s\n",
      "745:\tlearn: 47988.7447907\ttotal: 12.5s\tremaining: 4.26s\n",
      "746:\tlearn: 47983.1869060\ttotal: 12.5s\tremaining: 4.24s\n",
      "747:\tlearn: 47913.4056100\ttotal: 12.5s\tremaining: 4.22s\n",
      "748:\tlearn: 47879.6731553\ttotal: 12.6s\tremaining: 4.21s\n",
      "749:\tlearn: 47869.3848159\ttotal: 12.6s\tremaining: 4.19s\n",
      "750:\tlearn: 47858.6210926\ttotal: 12.6s\tremaining: 4.18s\n",
      "751:\tlearn: 47848.5934132\ttotal: 12.6s\tremaining: 4.16s\n",
      "752:\tlearn: 47842.7175604\ttotal: 12.6s\tremaining: 4.14s\n",
      "753:\tlearn: 47811.8920691\ttotal: 12.6s\tremaining: 4.12s\n",
      "754:\tlearn: 47802.2251273\ttotal: 12.7s\tremaining: 4.11s\n",
      "755:\tlearn: 47778.9794232\ttotal: 12.7s\tremaining: 4.09s\n",
      "756:\tlearn: 47773.5579913\ttotal: 12.7s\tremaining: 4.08s\n",
      "757:\tlearn: 47709.8310395\ttotal: 12.7s\tremaining: 4.06s\n",
      "758:\tlearn: 47704.6085049\ttotal: 12.7s\tremaining: 4.04s\n",
      "759:\tlearn: 47640.4409315\ttotal: 12.7s\tremaining: 4.02s\n",
      "760:\tlearn: 47610.5803968\ttotal: 12.7s\tremaining: 4s\n",
      "761:\tlearn: 47601.3772437\ttotal: 12.8s\tremaining: 3.99s\n",
      "762:\tlearn: 47572.5612222\ttotal: 12.8s\tremaining: 3.97s\n",
      "763:\tlearn: 47549.0695597\ttotal: 12.8s\tremaining: 3.95s\n",
      "764:\tlearn: 47488.6365825\ttotal: 12.8s\tremaining: 3.93s\n",
      "765:\tlearn: 47460.7843248\ttotal: 12.8s\tremaining: 3.92s\n",
      "766:\tlearn: 47451.8129149\ttotal: 12.8s\tremaining: 3.9s\n",
      "767:\tlearn: 47424.9361313\ttotal: 12.9s\tremaining: 3.88s\n",
      "768:\tlearn: 47389.4826895\ttotal: 12.9s\tremaining: 3.87s\n",
      "769:\tlearn: 47363.5300492\ttotal: 12.9s\tremaining: 3.85s\n",
      "770:\tlearn: 47354.9387516\ttotal: 12.9s\tremaining: 3.84s\n",
      "771:\tlearn: 47344.0082352\ttotal: 12.9s\tremaining: 3.82s\n",
      "772:\tlearn: 47336.9949651\ttotal: 12.9s\tremaining: 3.8s\n",
      "773:\tlearn: 47311.9441492\ttotal: 13s\tremaining: 3.78s\n",
      "774:\tlearn: 47279.8895046\ttotal: 13s\tremaining: 3.77s\n",
      "775:\tlearn: 47245.7914969\ttotal: 13s\tremaining: 3.75s\n",
      "776:\tlearn: 47236.6036477\ttotal: 13s\tremaining: 3.73s\n",
      "777:\tlearn: 47179.5059654\ttotal: 13s\tremaining: 3.71s\n",
      "778:\tlearn: 47173.8063794\ttotal: 13s\tremaining: 3.69s\n",
      "779:\tlearn: 47169.7640879\ttotal: 13s\tremaining: 3.67s\n",
      "780:\tlearn: 47163.2046338\ttotal: 13s\tremaining: 3.66s\n",
      "781:\tlearn: 47092.3886401\ttotal: 13.1s\tremaining: 3.64s\n",
      "782:\tlearn: 47072.7008577\ttotal: 13.1s\tremaining: 3.63s\n",
      "783:\tlearn: 47063.8404568\ttotal: 13.1s\tremaining: 3.62s\n",
      "784:\tlearn: 47054.5317149\ttotal: 13.1s\tremaining: 3.6s\n",
      "785:\tlearn: 47049.6284284\ttotal: 13.2s\tremaining: 3.58s\n",
      "786:\tlearn: 47041.1025847\ttotal: 13.2s\tremaining: 3.56s\n",
      "787:\tlearn: 47032.0330146\ttotal: 13.2s\tremaining: 3.55s\n",
      "788:\tlearn: 47026.9123328\ttotal: 13.2s\tremaining: 3.53s\n",
      "789:\tlearn: 47018.2805179\ttotal: 13.2s\tremaining: 3.51s\n",
      "790:\tlearn: 47010.0929260\ttotal: 13.2s\tremaining: 3.49s\n",
      "791:\tlearn: 46987.2772156\ttotal: 13.2s\tremaining: 3.48s\n",
      "792:\tlearn: 46978.4972944\ttotal: 13.2s\tremaining: 3.46s\n",
      "793:\tlearn: 46969.7902753\ttotal: 13.3s\tremaining: 3.44s\n",
      "794:\tlearn: 46947.2982454\ttotal: 13.3s\tremaining: 3.42s\n",
      "795:\tlearn: 46922.9163296\ttotal: 13.3s\tremaining: 3.4s\n",
      "796:\tlearn: 46913.1275615\ttotal: 13.3s\tremaining: 3.39s\n",
      "797:\tlearn: 46908.3937817\ttotal: 13.3s\tremaining: 3.37s\n",
      "798:\tlearn: 46900.5072004\ttotal: 13.3s\tremaining: 3.35s\n",
      "799:\tlearn: 46891.4600678\ttotal: 13.3s\tremaining: 3.33s\n",
      "800:\tlearn: 46883.8681770\ttotal: 13.4s\tremaining: 3.32s\n",
      "801:\tlearn: 46876.5590486\ttotal: 13.4s\tremaining: 3.31s\n",
      "802:\tlearn: 46869.5208302\ttotal: 13.4s\tremaining: 3.29s\n",
      "803:\tlearn: 46860.5369379\ttotal: 13.4s\tremaining: 3.27s\n",
      "804:\tlearn: 46836.9624971\ttotal: 13.4s\tremaining: 3.25s\n",
      "805:\tlearn: 46830.6160823\ttotal: 13.4s\tremaining: 3.23s\n",
      "806:\tlearn: 46795.0809416\ttotal: 13.4s\tremaining: 3.21s\n",
      "807:\tlearn: 46760.1116765\ttotal: 13.5s\tremaining: 3.2s\n",
      "808:\tlearn: 46750.3343162\ttotal: 13.5s\tremaining: 3.18s\n",
      "809:\tlearn: 46721.3372494\ttotal: 13.5s\tremaining: 3.16s\n",
      "810:\tlearn: 46716.0246864\ttotal: 13.5s\tremaining: 3.15s\n",
      "811:\tlearn: 46704.6104450\ttotal: 13.5s\tremaining: 3.13s\n",
      "812:\tlearn: 46700.0369278\ttotal: 13.5s\tremaining: 3.11s\n",
      "813:\tlearn: 46686.0989138\ttotal: 13.5s\tremaining: 3.09s\n",
      "814:\tlearn: 46677.4923155\ttotal: 13.6s\tremaining: 3.08s\n",
      "815:\tlearn: 46671.0323417\ttotal: 13.6s\tremaining: 3.06s\n",
      "816:\tlearn: 46663.1294783\ttotal: 13.6s\tremaining: 3.04s\n",
      "817:\tlearn: 46655.5958253\ttotal: 13.6s\tremaining: 3.03s\n",
      "818:\tlearn: 46621.1752711\ttotal: 13.6s\tremaining: 3.01s\n",
      "819:\tlearn: 46614.2620126\ttotal: 13.6s\tremaining: 2.99s\n",
      "820:\tlearn: 46607.0895352\ttotal: 13.7s\tremaining: 2.98s\n",
      "821:\tlearn: 46575.4868998\ttotal: 13.7s\tremaining: 2.96s\n",
      "822:\tlearn: 46568.6348652\ttotal: 13.7s\tremaining: 2.94s\n",
      "823:\tlearn: 46562.0903027\ttotal: 13.7s\tremaining: 2.92s\n",
      "824:\tlearn: 46555.8358727\ttotal: 13.7s\tremaining: 2.91s\n",
      "825:\tlearn: 46538.2358775\ttotal: 13.7s\tremaining: 2.89s\n",
      "826:\tlearn: 46531.8679957\ttotal: 13.7s\tremaining: 2.87s\n",
      "827:\tlearn: 46525.8930879\ttotal: 13.7s\tremaining: 2.85s\n",
      "828:\tlearn: 46519.2900216\ttotal: 13.8s\tremaining: 2.84s\n",
      "829:\tlearn: 46496.9577777\ttotal: 13.8s\tremaining: 2.82s\n",
      "830:\tlearn: 46465.3948367\ttotal: 13.9s\tremaining: 2.82s\n",
      "831:\tlearn: 46459.6332967\ttotal: 13.9s\tremaining: 2.81s\n",
      "832:\tlearn: 46431.5310448\ttotal: 13.9s\tremaining: 2.79s\n",
      "833:\tlearn: 46426.0153405\ttotal: 14s\tremaining: 2.78s\n",
      "834:\tlearn: 46420.7356159\ttotal: 14s\tremaining: 2.77s\n",
      "835:\tlearn: 46411.8386681\ttotal: 14s\tremaining: 2.75s\n",
      "836:\tlearn: 46399.8381222\ttotal: 14.1s\tremaining: 2.74s\n",
      "837:\tlearn: 46369.9102052\ttotal: 14.1s\tremaining: 2.73s\n",
      "838:\tlearn: 46339.3167026\ttotal: 14.2s\tremaining: 2.71s\n",
      "839:\tlearn: 46332.8756623\ttotal: 14.2s\tremaining: 2.7s\n",
      "840:\tlearn: 46323.7292734\ttotal: 14.2s\tremaining: 2.68s\n",
      "841:\tlearn: 46314.6422577\ttotal: 14.2s\tremaining: 2.66s\n",
      "842:\tlearn: 46253.3012506\ttotal: 14.2s\tremaining: 2.65s\n",
      "843:\tlearn: 46235.9443425\ttotal: 14.3s\tremaining: 2.63s\n",
      "844:\tlearn: 46226.9969677\ttotal: 14.3s\tremaining: 2.62s\n",
      "845:\tlearn: 46195.6157117\ttotal: 14.3s\tremaining: 2.6s\n",
      "846:\tlearn: 46136.0136496\ttotal: 14.3s\tremaining: 2.58s\n",
      "847:\tlearn: 46060.8564619\ttotal: 14.3s\tremaining: 2.57s\n",
      "848:\tlearn: 46056.1857475\ttotal: 14.3s\tremaining: 2.55s\n",
      "849:\tlearn: 46046.5706649\ttotal: 14.3s\tremaining: 2.53s\n",
      "850:\tlearn: 46038.0484275\ttotal: 14.4s\tremaining: 2.52s\n",
      "851:\tlearn: 46007.6992224\ttotal: 14.4s\tremaining: 2.5s\n",
      "852:\tlearn: 46004.4760528\ttotal: 14.4s\tremaining: 2.48s\n",
      "853:\tlearn: 45995.5192973\ttotal: 14.4s\tremaining: 2.47s\n",
      "854:\tlearn: 45990.5845233\ttotal: 14.5s\tremaining: 2.45s\n",
      "855:\tlearn: 45979.9133375\ttotal: 14.5s\tremaining: 2.44s\n",
      "856:\tlearn: 45973.6131821\ttotal: 14.5s\tremaining: 2.42s\n",
      "857:\tlearn: 45967.8938040\ttotal: 14.5s\tremaining: 2.41s\n",
      "858:\tlearn: 45963.3799835\ttotal: 14.6s\tremaining: 2.39s\n",
      "859:\tlearn: 45958.7642012\ttotal: 14.6s\tremaining: 2.38s\n",
      "860:\tlearn: 45937.2000724\ttotal: 14.6s\tremaining: 2.36s\n",
      "861:\tlearn: 45933.7685649\ttotal: 14.7s\tremaining: 2.35s\n",
      "862:\tlearn: 45881.6642165\ttotal: 14.7s\tremaining: 2.33s\n",
      "863:\tlearn: 45877.2390914\ttotal: 14.8s\tremaining: 2.33s\n",
      "864:\tlearn: 45856.4122730\ttotal: 14.8s\tremaining: 2.31s\n",
      "865:\tlearn: 45847.2334399\ttotal: 14.8s\tremaining: 2.29s\n",
      "866:\tlearn: 45827.1391140\ttotal: 14.9s\tremaining: 2.28s\n",
      "867:\tlearn: 45823.3971295\ttotal: 14.9s\tremaining: 2.26s\n",
      "868:\tlearn: 45819.3561838\ttotal: 14.9s\tremaining: 2.25s\n",
      "869:\tlearn: 45808.1803216\ttotal: 15s\tremaining: 2.24s\n",
      "870:\tlearn: 45800.9304996\ttotal: 15s\tremaining: 2.22s\n",
      "871:\tlearn: 45799.1725943\ttotal: 15.1s\tremaining: 2.21s\n",
      "872:\tlearn: 45769.9111545\ttotal: 15.1s\tremaining: 2.2s\n",
      "873:\tlearn: 45750.5087295\ttotal: 15.1s\tremaining: 2.18s\n",
      "874:\tlearn: 45741.6352617\ttotal: 15.2s\tremaining: 2.17s\n",
      "875:\tlearn: 45710.1984147\ttotal: 15.2s\tremaining: 2.15s\n",
      "876:\tlearn: 45691.4571453\ttotal: 15.2s\tremaining: 2.14s\n",
      "877:\tlearn: 45661.3384726\ttotal: 15.2s\tremaining: 2.12s\n",
      "878:\tlearn: 45643.2462017\ttotal: 15.3s\tremaining: 2.1s\n",
      "879:\tlearn: 45625.4325009\ttotal: 15.3s\tremaining: 2.08s\n",
      "880:\tlearn: 45615.7922423\ttotal: 15.3s\tremaining: 2.06s\n",
      "881:\tlearn: 45592.4149128\ttotal: 15.3s\tremaining: 2.05s\n",
      "882:\tlearn: 45586.5524255\ttotal: 15.3s\tremaining: 2.03s\n",
      "883:\tlearn: 45578.2294835\ttotal: 15.3s\tremaining: 2.01s\n",
      "884:\tlearn: 45569.6445631\ttotal: 15.3s\tremaining: 1.99s\n",
      "885:\tlearn: 45500.5091694\ttotal: 15.4s\tremaining: 1.98s\n",
      "886:\tlearn: 45483.6064831\ttotal: 15.4s\tremaining: 1.96s\n",
      "887:\tlearn: 45456.4996626\ttotal: 15.4s\tremaining: 1.94s\n",
      "888:\tlearn: 45434.7024822\ttotal: 15.4s\tremaining: 1.93s\n",
      "889:\tlearn: 45409.1747916\ttotal: 15.4s\tremaining: 1.91s\n",
      "890:\tlearn: 45398.9180821\ttotal: 15.5s\tremaining: 1.89s\n",
      "891:\tlearn: 45390.8828245\ttotal: 15.5s\tremaining: 1.87s\n",
      "892:\tlearn: 45325.5188111\ttotal: 15.5s\tremaining: 1.85s\n",
      "893:\tlearn: 45321.3274288\ttotal: 15.5s\tremaining: 1.84s\n",
      "894:\tlearn: 45318.5759249\ttotal: 15.5s\tremaining: 1.82s\n",
      "895:\tlearn: 45315.3112787\ttotal: 15.5s\tremaining: 1.8s\n",
      "896:\tlearn: 45312.2102035\ttotal: 15.5s\tremaining: 1.78s\n",
      "897:\tlearn: 45306.3389872\ttotal: 15.5s\tremaining: 1.76s\n",
      "898:\tlearn: 45300.4263659\ttotal: 15.6s\tremaining: 1.75s\n",
      "899:\tlearn: 45271.9302450\ttotal: 15.6s\tremaining: 1.73s\n",
      "900:\tlearn: 45260.6772492\ttotal: 15.6s\tremaining: 1.71s\n",
      "901:\tlearn: 45254.4295002\ttotal: 15.6s\tremaining: 1.69s\n",
      "902:\tlearn: 45251.4038127\ttotal: 15.6s\tremaining: 1.68s\n",
      "903:\tlearn: 45246.6594413\ttotal: 15.6s\tremaining: 1.66s\n",
      "904:\tlearn: 45222.6307512\ttotal: 15.7s\tremaining: 1.65s\n",
      "905:\tlearn: 45195.1457775\ttotal: 15.8s\tremaining: 1.63s\n",
      "906:\tlearn: 45166.2101231\ttotal: 15.8s\tremaining: 1.62s\n",
      "907:\tlearn: 45161.2171232\ttotal: 15.8s\tremaining: 1.6s\n",
      "908:\tlearn: 45154.4460936\ttotal: 15.8s\tremaining: 1.58s\n",
      "909:\tlearn: 45146.2660038\ttotal: 15.8s\tremaining: 1.56s\n",
      "910:\tlearn: 45142.4630894\ttotal: 15.8s\tremaining: 1.54s\n",
      "911:\tlearn: 45126.6036436\ttotal: 15.8s\tremaining: 1.53s\n",
      "912:\tlearn: 45082.2437240\ttotal: 15.9s\tremaining: 1.51s\n",
      "913:\tlearn: 45079.5495640\ttotal: 15.9s\tremaining: 1.5s\n",
      "914:\tlearn: 45024.3736407\ttotal: 15.9s\tremaining: 1.48s\n",
      "915:\tlearn: 45020.5208028\ttotal: 15.9s\tremaining: 1.46s\n",
      "916:\tlearn: 45016.7249299\ttotal: 15.9s\tremaining: 1.44s\n",
      "917:\tlearn: 44956.6832927\ttotal: 15.9s\tremaining: 1.42s\n",
      "918:\tlearn: 44898.8088114\ttotal: 16s\tremaining: 1.41s\n",
      "919:\tlearn: 44843.0163814\ttotal: 16s\tremaining: 1.39s\n",
      "920:\tlearn: 44789.1421354\ttotal: 16s\tremaining: 1.37s\n",
      "921:\tlearn: 44737.2304241\ttotal: 16s\tremaining: 1.35s\n",
      "922:\tlearn: 44719.2830441\ttotal: 16s\tremaining: 1.34s\n",
      "923:\tlearn: 44710.9409228\ttotal: 16s\tremaining: 1.32s\n",
      "924:\tlearn: 44660.8031226\ttotal: 16s\tremaining: 1.3s\n",
      "925:\tlearn: 44612.3738983\ttotal: 16.1s\tremaining: 1.28s\n",
      "926:\tlearn: 44565.6830696\ttotal: 16.1s\tremaining: 1.26s\n",
      "927:\tlearn: 44538.8311502\ttotal: 16.1s\tremaining: 1.25s\n",
      "928:\tlearn: 44516.0085520\ttotal: 16.1s\tremaining: 1.23s\n",
      "929:\tlearn: 44514.2364315\ttotal: 16.1s\tremaining: 1.21s\n",
      "930:\tlearn: 44469.1693288\ttotal: 16.1s\tremaining: 1.2s\n",
      "931:\tlearn: 44440.9147787\ttotal: 16.1s\tremaining: 1.18s\n",
      "932:\tlearn: 44397.4250362\ttotal: 16.1s\tremaining: 1.16s\n",
      "933:\tlearn: 44394.7490341\ttotal: 16.2s\tremaining: 1.14s\n",
      "934:\tlearn: 44351.3399922\ttotal: 16.2s\tremaining: 1.13s\n",
      "935:\tlearn: 44309.4936735\ttotal: 16.2s\tremaining: 1.11s\n",
      "936:\tlearn: 44270.4241798\ttotal: 16.2s\tremaining: 1.09s\n",
      "937:\tlearn: 44232.7459134\ttotal: 16.3s\tremaining: 1.07s\n",
      "938:\tlearn: 44224.6472801\ttotal: 16.3s\tremaining: 1.06s\n",
      "939:\tlearn: 44187.0206869\ttotal: 16.3s\tremaining: 1.04s\n",
      "940:\tlearn: 44150.8007013\ttotal: 16.3s\tremaining: 1.02s\n",
      "941:\tlearn: 44143.5269443\ttotal: 16.3s\tremaining: 1.01s\n",
      "942:\tlearn: 44109.6575560\ttotal: 16.3s\tremaining: 988ms\n",
      "943:\tlearn: 44076.9923096\ttotal: 16.4s\tremaining: 971ms\n",
      "944:\tlearn: 44044.8546399\ttotal: 16.4s\tremaining: 953ms\n",
      "945:\tlearn: 44036.2962715\ttotal: 16.4s\tremaining: 937ms\n",
      "946:\tlearn: 44004.9337919\ttotal: 16.4s\tremaining: 920ms\n",
      "947:\tlearn: 43988.6577972\ttotal: 16.4s\tremaining: 902ms\n",
      "948:\tlearn: 43983.6681505\ttotal: 16.5s\tremaining: 884ms\n",
      "949:\tlearn: 43977.0656804\ttotal: 16.5s\tremaining: 867ms\n",
      "950:\tlearn: 43966.6252775\ttotal: 16.5s\tremaining: 849ms\n",
      "951:\tlearn: 43963.0100375\ttotal: 16.5s\tremaining: 833ms\n",
      "952:\tlearn: 43956.9223402\ttotal: 16.5s\tremaining: 816ms\n",
      "953:\tlearn: 43948.3674661\ttotal: 16.6s\tremaining: 799ms\n",
      "954:\tlearn: 43887.0660247\ttotal: 16.6s\tremaining: 781ms\n",
      "955:\tlearn: 43880.6084515\ttotal: 16.6s\tremaining: 764ms\n",
      "956:\tlearn: 43854.3801071\ttotal: 16.6s\tremaining: 747ms\n",
      "957:\tlearn: 43850.9143905\ttotal: 16.6s\tremaining: 729ms\n",
      "958:\tlearn: 43847.8250836\ttotal: 16.6s\tremaining: 711ms\n",
      "959:\tlearn: 43816.0339219\ttotal: 16.6s\tremaining: 694ms\n",
      "960:\tlearn: 43758.1205821\ttotal: 16.7s\tremaining: 676ms\n",
      "961:\tlearn: 43741.0029812\ttotal: 16.7s\tremaining: 659ms\n",
      "962:\tlearn: 43686.3556149\ttotal: 16.7s\tremaining: 641ms\n",
      "963:\tlearn: 43677.7143196\ttotal: 16.7s\tremaining: 624ms\n",
      "964:\tlearn: 43656.1615220\ttotal: 16.7s\tremaining: 606ms\n",
      "965:\tlearn: 43654.0228437\ttotal: 16.7s\tremaining: 589ms\n",
      "966:\tlearn: 43639.7848148\ttotal: 16.7s\tremaining: 572ms\n",
      "967:\tlearn: 43619.7236907\ttotal: 16.8s\tremaining: 554ms\n",
      "968:\tlearn: 43615.8761768\ttotal: 16.8s\tremaining: 537ms\n",
      "969:\tlearn: 43607.3225652\ttotal: 16.8s\tremaining: 519ms\n",
      "970:\tlearn: 43597.7442864\ttotal: 16.8s\tremaining: 502ms\n",
      "971:\tlearn: 43589.8487237\ttotal: 16.8s\tremaining: 485ms\n",
      "972:\tlearn: 43569.3412310\ttotal: 16.8s\tremaining: 467ms\n",
      "973:\tlearn: 43517.6852843\ttotal: 16.9s\tremaining: 450ms\n",
      "974:\tlearn: 43516.2364950\ttotal: 16.9s\tremaining: 432ms\n",
      "975:\tlearn: 43500.9144850\ttotal: 16.9s\tremaining: 415ms\n",
      "976:\tlearn: 43493.5368467\ttotal: 16.9s\tremaining: 398ms\n",
      "977:\tlearn: 43468.7388464\ttotal: 16.9s\tremaining: 380ms\n",
      "978:\tlearn: 43461.5410382\ttotal: 16.9s\tremaining: 363ms\n",
      "979:\tlearn: 43442.6008027\ttotal: 17s\tremaining: 346ms\n",
      "980:\tlearn: 43435.1404825\ttotal: 17s\tremaining: 329ms\n",
      "981:\tlearn: 43429.6542593\ttotal: 17s\tremaining: 312ms\n",
      "982:\tlearn: 43380.8330699\ttotal: 17s\tremaining: 294ms\n",
      "983:\tlearn: 43355.7091208\ttotal: 17s\tremaining: 277ms\n",
      "984:\tlearn: 43342.6458205\ttotal: 17s\tremaining: 260ms\n",
      "985:\tlearn: 43313.0620861\ttotal: 17.1s\tremaining: 242ms\n",
      "986:\tlearn: 43284.5725663\ttotal: 17.1s\tremaining: 225ms\n",
      "987:\tlearn: 43282.1633425\ttotal: 17.1s\tremaining: 207ms\n",
      "988:\tlearn: 43280.4123979\ttotal: 17.1s\tremaining: 190ms\n",
      "989:\tlearn: 43253.8247396\ttotal: 17.1s\tremaining: 173ms\n",
      "990:\tlearn: 43185.9647273\ttotal: 17.1s\tremaining: 155ms\n",
      "991:\tlearn: 43173.8469412\ttotal: 17.1s\tremaining: 138ms\n",
      "992:\tlearn: 43164.5028592\ttotal: 17.2s\tremaining: 121ms\n",
      "993:\tlearn: 43137.5779680\ttotal: 17.2s\tremaining: 104ms\n",
      "994:\tlearn: 43112.7740643\ttotal: 17.2s\tremaining: 86.4ms\n",
      "995:\tlearn: 43088.0156651\ttotal: 17.2s\tremaining: 69.1ms\n",
      "996:\tlearn: 43068.2135886\ttotal: 17.2s\tremaining: 51.8ms\n",
      "997:\tlearn: 43042.9352422\ttotal: 17.2s\tremaining: 34.5ms\n",
      "998:\tlearn: 43030.1095710\ttotal: 17.2s\tremaining: 17.3ms\n",
      "999:\tlearn: 43005.8902134\ttotal: 17.3s\tremaining: 0us\n",
      "Learning rate set to 0.071716\n",
      "0:\tlearn: 76826.7812223\ttotal: 23.4ms\tremaining: 23.4s\n",
      "1:\tlearn: 76416.2657673\ttotal: 36.6ms\tremaining: 18.2s\n",
      "2:\tlearn: 76013.7153049\ttotal: 55ms\tremaining: 18.3s\n",
      "3:\tlearn: 75661.8139763\ttotal: 67.5ms\tremaining: 16.8s\n",
      "4:\tlearn: 75347.7353537\ttotal: 89.1ms\tremaining: 17.7s\n",
      "5:\tlearn: 75058.6172790\ttotal: 108ms\tremaining: 17.9s\n",
      "6:\tlearn: 74817.5670340\ttotal: 121ms\tremaining: 17.1s\n",
      "7:\tlearn: 74596.2817689\ttotal: 128ms\tremaining: 15.8s\n",
      "8:\tlearn: 74395.8452152\ttotal: 140ms\tremaining: 15.5s\n",
      "9:\tlearn: 74211.5860965\ttotal: 155ms\tremaining: 15.3s\n",
      "10:\tlearn: 74065.3794413\ttotal: 172ms\tremaining: 15.5s\n",
      "11:\tlearn: 73874.2543700\ttotal: 187ms\tremaining: 15.4s\n",
      "12:\tlearn: 73713.6579468\ttotal: 203ms\tremaining: 15.4s\n",
      "13:\tlearn: 73549.1232446\ttotal: 224ms\tremaining: 15.8s\n",
      "14:\tlearn: 73414.2286776\ttotal: 240ms\tremaining: 15.8s\n",
      "15:\tlearn: 73314.3602932\ttotal: 256ms\tremaining: 15.8s\n",
      "16:\tlearn: 73204.8496623\ttotal: 279ms\tremaining: 16.1s\n",
      "17:\tlearn: 73112.9617407\ttotal: 291ms\tremaining: 15.9s\n",
      "18:\tlearn: 73017.2897576\ttotal: 305ms\tremaining: 15.7s\n",
      "19:\tlearn: 72933.3642155\ttotal: 318ms\tremaining: 15.6s\n",
      "20:\tlearn: 72680.5662674\ttotal: 325ms\tremaining: 15.2s\n",
      "21:\tlearn: 72614.4295885\ttotal: 338ms\tremaining: 15s\n",
      "22:\tlearn: 72546.3994390\ttotal: 352ms\tremaining: 15s\n",
      "23:\tlearn: 72476.8920885\ttotal: 364ms\tremaining: 14.8s\n",
      "24:\tlearn: 72373.7391055\ttotal: 382ms\tremaining: 14.9s\n",
      "25:\tlearn: 72303.5971992\ttotal: 390ms\tremaining: 14.6s\n",
      "26:\tlearn: 72250.5317013\ttotal: 405ms\tremaining: 14.6s\n",
      "27:\tlearn: 72233.8933182\ttotal: 419ms\tremaining: 14.5s\n",
      "28:\tlearn: 72139.7065797\ttotal: 437ms\tremaining: 14.6s\n",
      "29:\tlearn: 72095.2074202\ttotal: 460ms\tremaining: 14.9s\n",
      "30:\tlearn: 72079.7624689\ttotal: 478ms\tremaining: 14.9s\n",
      "31:\tlearn: 71853.1738897\ttotal: 493ms\tremaining: 14.9s\n",
      "32:\tlearn: 71837.0266634\ttotal: 505ms\tremaining: 14.8s\n",
      "33:\tlearn: 71776.0036667\ttotal: 517ms\tremaining: 14.7s\n",
      "34:\tlearn: 71729.0506771\ttotal: 530ms\tremaining: 14.6s\n",
      "35:\tlearn: 71695.8682799\ttotal: 538ms\tremaining: 14.4s\n",
      "36:\tlearn: 71665.3520059\ttotal: 552ms\tremaining: 14.4s\n",
      "37:\tlearn: 71638.3629611\ttotal: 572ms\tremaining: 14.5s\n",
      "38:\tlearn: 71599.9766068\ttotal: 587ms\tremaining: 14.5s\n",
      "39:\tlearn: 71398.6467140\ttotal: 603ms\tremaining: 14.5s\n",
      "40:\tlearn: 71209.1528749\ttotal: 616ms\tremaining: 14.4s\n",
      "41:\tlearn: 71163.6589879\ttotal: 633ms\tremaining: 14.4s\n",
      "42:\tlearn: 71153.7920649\ttotal: 642ms\tremaining: 14.3s\n",
      "43:\tlearn: 71098.0798906\ttotal: 651ms\tremaining: 14.1s\n",
      "44:\tlearn: 71089.0176013\ttotal: 671ms\tremaining: 14.2s\n",
      "45:\tlearn: 71020.8656182\ttotal: 694ms\tremaining: 14.4s\n",
      "46:\tlearn: 70975.0536036\ttotal: 704ms\tremaining: 14.3s\n",
      "47:\tlearn: 70948.6371505\ttotal: 713ms\tremaining: 14.1s\n",
      "48:\tlearn: 70875.0721297\ttotal: 726ms\tremaining: 14.1s\n",
      "49:\tlearn: 70866.6016471\ttotal: 732ms\tremaining: 13.9s\n",
      "50:\tlearn: 70830.3574538\ttotal: 744ms\tremaining: 13.8s\n",
      "51:\tlearn: 70797.3220701\ttotal: 754ms\tremaining: 13.8s\n",
      "52:\tlearn: 70743.1140955\ttotal: 765ms\tremaining: 13.7s\n",
      "53:\tlearn: 70735.5734179\ttotal: 777ms\tremaining: 13.6s\n",
      "54:\tlearn: 70701.3555955\ttotal: 788ms\tremaining: 13.5s\n",
      "55:\tlearn: 70678.7739188\ttotal: 817ms\tremaining: 13.8s\n",
      "56:\tlearn: 70651.0407336\ttotal: 900ms\tremaining: 14.9s\n",
      "57:\tlearn: 70618.3036002\ttotal: 924ms\tremaining: 15s\n",
      "58:\tlearn: 70473.2945299\ttotal: 937ms\tremaining: 15s\n",
      "59:\tlearn: 70435.8921707\ttotal: 951ms\tremaining: 14.9s\n",
      "60:\tlearn: 70426.3910383\ttotal: 965ms\tremaining: 14.9s\n",
      "61:\tlearn: 70399.6244995\ttotal: 978ms\tremaining: 14.8s\n",
      "62:\tlearn: 70392.3382432\ttotal: 998ms\tremaining: 14.8s\n",
      "63:\tlearn: 70347.7362064\ttotal: 1.01s\tremaining: 14.8s\n",
      "64:\tlearn: 70324.4829136\ttotal: 1.02s\tremaining: 14.7s\n",
      "65:\tlearn: 70261.4509369\ttotal: 1.03s\tremaining: 14.6s\n",
      "66:\tlearn: 70237.0761851\ttotal: 1.05s\tremaining: 14.7s\n",
      "67:\tlearn: 70228.3360640\ttotal: 1.07s\tremaining: 14.6s\n",
      "68:\tlearn: 70217.7129661\ttotal: 1.08s\tremaining: 14.6s\n",
      "69:\tlearn: 70205.7187879\ttotal: 1.08s\tremaining: 14.4s\n",
      "70:\tlearn: 70189.8446667\ttotal: 1.1s\tremaining: 14.4s\n",
      "71:\tlearn: 70024.9347951\ttotal: 1.12s\tremaining: 14.4s\n",
      "72:\tlearn: 70009.2352283\ttotal: 1.16s\tremaining: 14.7s\n",
      "73:\tlearn: 69825.2026444\ttotal: 1.17s\tremaining: 14.6s\n",
      "74:\tlearn: 69774.9232435\ttotal: 1.18s\tremaining: 14.5s\n",
      "75:\tlearn: 69764.3786713\ttotal: 1.19s\tremaining: 14.5s\n",
      "76:\tlearn: 69748.7093126\ttotal: 1.21s\tremaining: 14.5s\n",
      "77:\tlearn: 69732.7741108\ttotal: 1.22s\tremaining: 14.5s\n",
      "78:\tlearn: 69707.1214602\ttotal: 1.24s\tremaining: 14.4s\n",
      "79:\tlearn: 69698.0997532\ttotal: 1.25s\tremaining: 14.4s\n",
      "80:\tlearn: 69681.3971487\ttotal: 1.27s\tremaining: 14.4s\n",
      "81:\tlearn: 69674.0977503\ttotal: 1.28s\tremaining: 14.3s\n",
      "82:\tlearn: 69660.2976747\ttotal: 1.3s\tremaining: 14.3s\n",
      "83:\tlearn: 69651.5193871\ttotal: 1.31s\tremaining: 14.3s\n",
      "84:\tlearn: 69618.4570284\ttotal: 1.33s\tremaining: 14.3s\n",
      "85:\tlearn: 69610.7045760\ttotal: 1.36s\tremaining: 14.4s\n",
      "86:\tlearn: 69508.2847009\ttotal: 1.37s\tremaining: 14.4s\n",
      "87:\tlearn: 69502.3289362\ttotal: 1.39s\tremaining: 14.4s\n",
      "88:\tlearn: 69495.1261585\ttotal: 1.4s\tremaining: 14.3s\n",
      "89:\tlearn: 69315.1751850\ttotal: 1.41s\tremaining: 14.3s\n",
      "90:\tlearn: 69301.1089748\ttotal: 1.42s\tremaining: 14.2s\n",
      "91:\tlearn: 69253.7116347\ttotal: 1.44s\tremaining: 14.2s\n",
      "92:\tlearn: 69123.4606491\ttotal: 1.45s\tremaining: 14.1s\n",
      "93:\tlearn: 68994.2522134\ttotal: 1.46s\tremaining: 14.1s\n",
      "94:\tlearn: 68988.0580214\ttotal: 1.47s\tremaining: 14s\n",
      "95:\tlearn: 68951.6859565\ttotal: 1.48s\tremaining: 14s\n",
      "96:\tlearn: 68833.6073076\ttotal: 1.49s\tremaining: 13.9s\n",
      "97:\tlearn: 68724.5825430\ttotal: 1.5s\tremaining: 13.9s\n",
      "98:\tlearn: 68699.1525511\ttotal: 1.52s\tremaining: 13.8s\n",
      "99:\tlearn: 68631.4999249\ttotal: 1.53s\tremaining: 13.8s\n",
      "100:\tlearn: 68494.0094621\ttotal: 1.55s\tremaining: 13.8s\n",
      "101:\tlearn: 68392.6922660\ttotal: 1.57s\tremaining: 13.8s\n",
      "102:\tlearn: 68384.0313400\ttotal: 1.67s\tremaining: 14.6s\n",
      "103:\tlearn: 68301.2297593\ttotal: 1.69s\tremaining: 14.5s\n",
      "104:\tlearn: 68297.3536719\ttotal: 1.7s\tremaining: 14.5s\n",
      "105:\tlearn: 68244.0428861\ttotal: 1.71s\tremaining: 14.4s\n",
      "106:\tlearn: 68211.1938189\ttotal: 1.72s\tremaining: 14.3s\n",
      "107:\tlearn: 68201.0293124\ttotal: 1.73s\tremaining: 14.3s\n",
      "108:\tlearn: 68171.5098930\ttotal: 1.75s\tremaining: 14.3s\n",
      "109:\tlearn: 68168.0304690\ttotal: 1.75s\tremaining: 14.2s\n",
      "110:\tlearn: 68096.3950463\ttotal: 1.77s\tremaining: 14.2s\n",
      "111:\tlearn: 68084.3181874\ttotal: 1.79s\tremaining: 14.2s\n",
      "112:\tlearn: 68067.9101105\ttotal: 1.81s\tremaining: 14.2s\n",
      "113:\tlearn: 68063.5699615\ttotal: 1.82s\tremaining: 14.2s\n",
      "114:\tlearn: 68057.5069438\ttotal: 1.83s\tremaining: 14.1s\n",
      "115:\tlearn: 68002.3797615\ttotal: 1.85s\tremaining: 14.1s\n",
      "116:\tlearn: 67943.8018632\ttotal: 1.86s\tremaining: 14s\n",
      "117:\tlearn: 67852.7931389\ttotal: 1.87s\tremaining: 14s\n",
      "118:\tlearn: 67737.9136446\ttotal: 1.88s\tremaining: 13.9s\n",
      "119:\tlearn: 67668.2251666\ttotal: 1.89s\tremaining: 13.9s\n",
      "120:\tlearn: 67656.1192489\ttotal: 1.9s\tremaining: 13.8s\n",
      "121:\tlearn: 67627.3643527\ttotal: 1.92s\tremaining: 13.8s\n",
      "122:\tlearn: 67611.8370994\ttotal: 1.93s\tremaining: 13.8s\n",
      "123:\tlearn: 67592.3255766\ttotal: 1.95s\tremaining: 13.8s\n",
      "124:\tlearn: 67546.3037704\ttotal: 1.96s\tremaining: 13.7s\n",
      "125:\tlearn: 67487.2934224\ttotal: 1.97s\tremaining: 13.7s\n",
      "126:\tlearn: 67406.3323612\ttotal: 2s\tremaining: 13.8s\n",
      "127:\tlearn: 67402.8706086\ttotal: 2.01s\tremaining: 13.7s\n",
      "128:\tlearn: 67399.7701997\ttotal: 2.02s\tremaining: 13.7s\n",
      "129:\tlearn: 67391.8259896\ttotal: 2.04s\tremaining: 13.6s\n",
      "130:\tlearn: 67384.8912197\ttotal: 2.06s\tremaining: 13.7s\n",
      "131:\tlearn: 67274.8997127\ttotal: 2.08s\tremaining: 13.7s\n",
      "132:\tlearn: 67196.3224926\ttotal: 2.08s\tremaining: 13.6s\n",
      "133:\tlearn: 67161.5247852\ttotal: 2.1s\tremaining: 13.6s\n",
      "134:\tlearn: 67088.4512890\ttotal: 2.11s\tremaining: 13.5s\n",
      "135:\tlearn: 67055.0822073\ttotal: 2.13s\tremaining: 13.5s\n",
      "136:\tlearn: 67051.4455415\ttotal: 2.15s\tremaining: 13.5s\n",
      "137:\tlearn: 67048.7265917\ttotal: 2.16s\tremaining: 13.5s\n",
      "138:\tlearn: 66956.4605190\ttotal: 2.18s\tremaining: 13.5s\n",
      "139:\tlearn: 66915.0121288\ttotal: 2.2s\tremaining: 13.5s\n",
      "140:\tlearn: 66780.9600113\ttotal: 2.22s\tremaining: 13.5s\n",
      "141:\tlearn: 66657.1109845\ttotal: 2.24s\tremaining: 13.5s\n",
      "142:\tlearn: 66592.3664066\ttotal: 2.25s\tremaining: 13.5s\n",
      "143:\tlearn: 66586.0092210\ttotal: 2.26s\tremaining: 13.4s\n",
      "144:\tlearn: 66545.3341544\ttotal: 2.27s\tremaining: 13.4s\n",
      "145:\tlearn: 66524.0071273\ttotal: 2.29s\tremaining: 13.4s\n",
      "146:\tlearn: 66466.1840807\ttotal: 2.29s\tremaining: 13.3s\n",
      "147:\tlearn: 66378.5989232\ttotal: 2.31s\tremaining: 13.3s\n",
      "148:\tlearn: 66295.2780872\ttotal: 2.33s\tremaining: 13.3s\n",
      "149:\tlearn: 66215.7961895\ttotal: 2.34s\tremaining: 13.3s\n",
      "150:\tlearn: 66150.6244261\ttotal: 2.35s\tremaining: 13.2s\n",
      "151:\tlearn: 66145.7099030\ttotal: 2.36s\tremaining: 13.2s\n",
      "152:\tlearn: 66143.0340503\ttotal: 2.37s\tremaining: 13.1s\n",
      "153:\tlearn: 66070.0201172\ttotal: 2.39s\tremaining: 13.1s\n",
      "154:\tlearn: 65988.8387779\ttotal: 2.39s\tremaining: 13.1s\n",
      "155:\tlearn: 65972.2356459\ttotal: 2.41s\tremaining: 13s\n",
      "156:\tlearn: 65970.0769737\ttotal: 2.44s\tremaining: 13.1s\n",
      "157:\tlearn: 65866.6641856\ttotal: 2.46s\tremaining: 13.1s\n",
      "158:\tlearn: 65786.8716980\ttotal: 2.48s\tremaining: 13.1s\n",
      "159:\tlearn: 65725.2998568\ttotal: 2.49s\tremaining: 13.1s\n",
      "160:\tlearn: 65668.1531002\ttotal: 2.5s\tremaining: 13s\n",
      "161:\tlearn: 65614.7348641\ttotal: 2.51s\tremaining: 13s\n",
      "162:\tlearn: 65564.4050638\ttotal: 2.52s\tremaining: 12.9s\n",
      "163:\tlearn: 65499.0776539\ttotal: 2.54s\tremaining: 12.9s\n",
      "164:\tlearn: 65496.4191686\ttotal: 2.55s\tremaining: 12.9s\n",
      "165:\tlearn: 65494.3563448\ttotal: 2.56s\tremaining: 12.8s\n",
      "166:\tlearn: 65466.6388282\ttotal: 2.57s\tremaining: 12.8s\n",
      "167:\tlearn: 65437.6081137\ttotal: 2.58s\tremaining: 12.8s\n",
      "168:\tlearn: 65378.2680232\ttotal: 2.6s\tremaining: 12.8s\n",
      "169:\tlearn: 65376.3123506\ttotal: 2.61s\tremaining: 12.7s\n",
      "170:\tlearn: 65278.8218692\ttotal: 2.62s\tremaining: 12.7s\n",
      "171:\tlearn: 65236.3552951\ttotal: 2.63s\tremaining: 12.7s\n",
      "172:\tlearn: 65166.0646595\ttotal: 2.65s\tremaining: 12.7s\n",
      "173:\tlearn: 65108.2766439\ttotal: 2.68s\tremaining: 12.7s\n",
      "174:\tlearn: 65082.2916479\ttotal: 2.69s\tremaining: 12.7s\n",
      "175:\tlearn: 65055.9474755\ttotal: 2.71s\tremaining: 12.7s\n",
      "176:\tlearn: 64967.1244000\ttotal: 2.72s\tremaining: 12.6s\n",
      "177:\tlearn: 64917.4940171\ttotal: 2.73s\tremaining: 12.6s\n",
      "178:\tlearn: 64888.0763778\ttotal: 2.74s\tremaining: 12.6s\n",
      "179:\tlearn: 64882.0591899\ttotal: 2.76s\tremaining: 12.6s\n",
      "180:\tlearn: 64864.7457787\ttotal: 2.76s\tremaining: 12.5s\n",
      "181:\tlearn: 64818.1312651\ttotal: 2.77s\tremaining: 12.5s\n",
      "182:\tlearn: 64804.5199110\ttotal: 2.79s\tremaining: 12.4s\n",
      "183:\tlearn: 64801.8783332\ttotal: 2.79s\tremaining: 12.4s\n",
      "184:\tlearn: 64759.2511164\ttotal: 2.81s\tremaining: 12.4s\n",
      "185:\tlearn: 64744.8582597\ttotal: 2.82s\tremaining: 12.3s\n",
      "186:\tlearn: 64743.2693443\ttotal: 2.83s\tremaining: 12.3s\n",
      "187:\tlearn: 64718.4519957\ttotal: 2.85s\tremaining: 12.3s\n",
      "188:\tlearn: 64716.4825484\ttotal: 2.87s\tremaining: 12.3s\n",
      "189:\tlearn: 64709.9305467\ttotal: 2.88s\tremaining: 12.3s\n",
      "190:\tlearn: 64696.1153052\ttotal: 2.89s\tremaining: 12.2s\n",
      "191:\tlearn: 64668.6280834\ttotal: 2.92s\tremaining: 12.3s\n",
      "192:\tlearn: 64587.4926041\ttotal: 2.94s\tremaining: 12.3s\n",
      "193:\tlearn: 64571.4144509\ttotal: 2.95s\tremaining: 12.2s\n",
      "194:\tlearn: 64510.8667871\ttotal: 2.96s\tremaining: 12.2s\n",
      "195:\tlearn: 64467.7882308\ttotal: 2.97s\tremaining: 12.2s\n",
      "196:\tlearn: 64421.3648195\ttotal: 2.98s\tremaining: 12.2s\n",
      "197:\tlearn: 64393.8507766\ttotal: 3s\tremaining: 12.1s\n",
      "198:\tlearn: 64303.5176970\ttotal: 3s\tremaining: 12.1s\n",
      "199:\tlearn: 64262.3143687\ttotal: 3.02s\tremaining: 12.1s\n",
      "200:\tlearn: 64250.6820655\ttotal: 3.05s\tremaining: 12.1s\n",
      "201:\tlearn: 64217.3200477\ttotal: 3.05s\tremaining: 12.1s\n",
      "202:\tlearn: 64215.0140671\ttotal: 3.07s\tremaining: 12s\n",
      "203:\tlearn: 64109.2127433\ttotal: 3.08s\tremaining: 12s\n",
      "204:\tlearn: 64103.7238470\ttotal: 3.09s\tremaining: 12s\n",
      "205:\tlearn: 64101.6909981\ttotal: 3.1s\tremaining: 12s\n",
      "206:\tlearn: 64097.8598984\ttotal: 3.13s\tremaining: 12s\n",
      "207:\tlearn: 64085.5628466\ttotal: 3.15s\tremaining: 12s\n",
      "208:\tlearn: 64073.7322806\ttotal: 3.16s\tremaining: 12s\n",
      "209:\tlearn: 64060.4230663\ttotal: 3.17s\tremaining: 11.9s\n",
      "210:\tlearn: 64037.2900327\ttotal: 3.18s\tremaining: 11.9s\n",
      "211:\tlearn: 64033.4824163\ttotal: 3.19s\tremaining: 11.9s\n",
      "212:\tlearn: 63991.5589804\ttotal: 3.21s\tremaining: 11.9s\n",
      "213:\tlearn: 63988.3891661\ttotal: 3.21s\tremaining: 11.8s\n",
      "214:\tlearn: 63982.5467557\ttotal: 3.23s\tremaining: 11.8s\n",
      "215:\tlearn: 63979.5317122\ttotal: 3.25s\tremaining: 11.8s\n",
      "216:\tlearn: 63883.0391755\ttotal: 3.26s\tremaining: 11.8s\n",
      "217:\tlearn: 63879.6750779\ttotal: 3.27s\tremaining: 11.7s\n",
      "218:\tlearn: 63878.1036835\ttotal: 3.29s\tremaining: 11.7s\n",
      "219:\tlearn: 63853.0421381\ttotal: 3.31s\tremaining: 11.7s\n",
      "220:\tlearn: 63842.3252611\ttotal: 3.33s\tremaining: 11.7s\n",
      "221:\tlearn: 63830.0682508\ttotal: 3.35s\tremaining: 11.8s\n",
      "222:\tlearn: 63819.6491881\ttotal: 3.38s\tremaining: 11.8s\n",
      "223:\tlearn: 63810.3396780\ttotal: 3.39s\tremaining: 11.8s\n",
      "224:\tlearn: 63749.4592256\ttotal: 3.41s\tremaining: 11.7s\n",
      "225:\tlearn: 63747.9218905\ttotal: 3.42s\tremaining: 11.7s\n",
      "226:\tlearn: 63681.5401605\ttotal: 3.43s\tremaining: 11.7s\n",
      "227:\tlearn: 63656.2068869\ttotal: 3.44s\tremaining: 11.7s\n",
      "228:\tlearn: 63529.7850908\ttotal: 3.46s\tremaining: 11.6s\n",
      "229:\tlearn: 63491.8836373\ttotal: 3.47s\tremaining: 11.6s\n",
      "230:\tlearn: 63480.6157039\ttotal: 3.49s\tremaining: 11.6s\n",
      "231:\tlearn: 63458.0520749\ttotal: 3.51s\tremaining: 11.6s\n",
      "232:\tlearn: 63455.2752120\ttotal: 3.52s\tremaining: 11.6s\n",
      "233:\tlearn: 63390.9967631\ttotal: 3.52s\tremaining: 11.5s\n",
      "234:\tlearn: 63378.7274891\ttotal: 3.54s\tremaining: 11.5s\n",
      "235:\tlearn: 63372.4012291\ttotal: 3.57s\tremaining: 11.6s\n",
      "236:\tlearn: 63350.1013843\ttotal: 3.59s\tremaining: 11.6s\n",
      "237:\tlearn: 63336.8080924\ttotal: 3.6s\tremaining: 11.5s\n",
      "238:\tlearn: 63301.7528391\ttotal: 3.62s\tremaining: 11.5s\n",
      "239:\tlearn: 63292.4638903\ttotal: 3.62s\tremaining: 11.5s\n",
      "240:\tlearn: 63285.4387651\ttotal: 3.64s\tremaining: 11.5s\n",
      "241:\tlearn: 63228.7539897\ttotal: 3.65s\tremaining: 11.4s\n",
      "242:\tlearn: 63220.2780455\ttotal: 3.67s\tremaining: 11.4s\n",
      "243:\tlearn: 63211.6902893\ttotal: 3.68s\tremaining: 11.4s\n",
      "244:\tlearn: 63203.7333581\ttotal: 3.69s\tremaining: 11.4s\n",
      "245:\tlearn: 63201.2976304\ttotal: 3.7s\tremaining: 11.3s\n",
      "246:\tlearn: 63199.0453408\ttotal: 3.72s\tremaining: 11.3s\n",
      "247:\tlearn: 63184.0894967\ttotal: 3.73s\tremaining: 11.3s\n",
      "248:\tlearn: 63125.8927191\ttotal: 3.75s\tremaining: 11.3s\n",
      "249:\tlearn: 63123.9921482\ttotal: 3.77s\tremaining: 11.3s\n",
      "250:\tlearn: 63023.2162481\ttotal: 3.78s\tremaining: 11.3s\n",
      "251:\tlearn: 63003.5263623\ttotal: 3.8s\tremaining: 11.3s\n",
      "252:\tlearn: 62971.0499175\ttotal: 3.82s\tremaining: 11.3s\n",
      "253:\tlearn: 62969.2968393\ttotal: 3.83s\tremaining: 11.3s\n",
      "254:\tlearn: 62935.4337894\ttotal: 3.85s\tremaining: 11.2s\n",
      "255:\tlearn: 62927.9997155\ttotal: 3.87s\tremaining: 11.2s\n",
      "256:\tlearn: 62926.6362059\ttotal: 3.89s\tremaining: 11.2s\n",
      "257:\tlearn: 62917.6271821\ttotal: 3.9s\tremaining: 11.2s\n",
      "258:\tlearn: 62846.3407207\ttotal: 3.91s\tremaining: 11.2s\n",
      "259:\tlearn: 62840.5497357\ttotal: 3.92s\tremaining: 11.2s\n",
      "260:\tlearn: 62759.5239592\ttotal: 3.93s\tremaining: 11.1s\n",
      "261:\tlearn: 62743.2578636\ttotal: 3.95s\tremaining: 11.1s\n",
      "262:\tlearn: 62718.8308186\ttotal: 3.99s\tremaining: 11.2s\n",
      "263:\tlearn: 62643.2003721\ttotal: 4.01s\tremaining: 11.2s\n",
      "264:\tlearn: 62593.3583129\ttotal: 4.04s\tremaining: 11.2s\n",
      "265:\tlearn: 62525.0605656\ttotal: 4.04s\tremaining: 11.2s\n",
      "266:\tlearn: 62516.5532105\ttotal: 4.06s\tremaining: 11.2s\n",
      "267:\tlearn: 62455.6651413\ttotal: 4.08s\tremaining: 11.1s\n",
      "268:\tlearn: 62405.3579651\ttotal: 4.09s\tremaining: 11.1s\n",
      "269:\tlearn: 62335.3147192\ttotal: 4.11s\tremaining: 11.1s\n",
      "270:\tlearn: 62292.6891142\ttotal: 4.12s\tremaining: 11.1s\n",
      "271:\tlearn: 62289.1301986\ttotal: 4.13s\tremaining: 11s\n",
      "272:\tlearn: 62240.5676549\ttotal: 4.14s\tremaining: 11s\n",
      "273:\tlearn: 62193.7412148\ttotal: 4.15s\tremaining: 11s\n",
      "274:\tlearn: 62115.7325139\ttotal: 4.16s\tremaining: 11s\n",
      "275:\tlearn: 62092.1085146\ttotal: 4.18s\tremaining: 11s\n",
      "276:\tlearn: 62044.4324242\ttotal: 4.2s\tremaining: 11s\n",
      "277:\tlearn: 62037.6958442\ttotal: 4.22s\tremaining: 11s\n",
      "278:\tlearn: 62015.0007077\ttotal: 4.24s\tremaining: 11s\n",
      "279:\tlearn: 61936.9959560\ttotal: 4.25s\tremaining: 10.9s\n",
      "280:\tlearn: 61914.6650462\ttotal: 4.26s\tremaining: 10.9s\n",
      "281:\tlearn: 61911.4116262\ttotal: 4.28s\tremaining: 10.9s\n",
      "282:\tlearn: 61883.8729447\ttotal: 4.29s\tremaining: 10.9s\n",
      "283:\tlearn: 61815.9980835\ttotal: 4.3s\tremaining: 10.9s\n",
      "284:\tlearn: 61794.2847868\ttotal: 4.32s\tremaining: 10.8s\n",
      "285:\tlearn: 61779.2786892\ttotal: 4.33s\tremaining: 10.8s\n",
      "286:\tlearn: 61761.0668076\ttotal: 4.34s\tremaining: 10.8s\n",
      "287:\tlearn: 61693.6945551\ttotal: 4.35s\tremaining: 10.8s\n",
      "288:\tlearn: 61654.2962832\ttotal: 4.36s\tremaining: 10.7s\n",
      "289:\tlearn: 61588.7947826\ttotal: 4.38s\tremaining: 10.7s\n",
      "290:\tlearn: 61515.5920558\ttotal: 4.39s\tremaining: 10.7s\n",
      "291:\tlearn: 61452.4030730\ttotal: 4.4s\tremaining: 10.7s\n",
      "292:\tlearn: 61413.5806733\ttotal: 4.42s\tremaining: 10.7s\n",
      "293:\tlearn: 61352.6473888\ttotal: 4.43s\tremaining: 10.7s\n",
      "294:\tlearn: 61283.0025133\ttotal: 4.46s\tremaining: 10.7s\n",
      "295:\tlearn: 61264.8468704\ttotal: 4.47s\tremaining: 10.6s\n",
      "296:\tlearn: 61219.8305006\ttotal: 4.49s\tremaining: 10.6s\n",
      "297:\tlearn: 61177.0344522\ttotal: 4.5s\tremaining: 10.6s\n",
      "298:\tlearn: 61174.3006122\ttotal: 4.51s\tremaining: 10.6s\n",
      "299:\tlearn: 61135.6076057\ttotal: 4.52s\tremaining: 10.5s\n",
      "300:\tlearn: 61070.8322621\ttotal: 4.54s\tremaining: 10.5s\n",
      "301:\tlearn: 61068.3642255\ttotal: 4.55s\tremaining: 10.5s\n",
      "302:\tlearn: 61034.4770512\ttotal: 4.56s\tremaining: 10.5s\n",
      "303:\tlearn: 61008.2934917\ttotal: 4.58s\tremaining: 10.5s\n",
      "304:\tlearn: 60975.6273011\ttotal: 4.59s\tremaining: 10.5s\n",
      "305:\tlearn: 60916.5713109\ttotal: 4.6s\tremaining: 10.4s\n",
      "306:\tlearn: 60885.7191504\ttotal: 4.61s\tremaining: 10.4s\n",
      "307:\tlearn: 60874.2405170\ttotal: 4.63s\tremaining: 10.4s\n",
      "308:\tlearn: 60867.0676193\ttotal: 4.63s\tremaining: 10.4s\n",
      "309:\tlearn: 60860.7272071\ttotal: 4.64s\tremaining: 10.3s\n",
      "310:\tlearn: 60842.1896339\ttotal: 4.67s\tremaining: 10.4s\n",
      "311:\tlearn: 60811.7639800\ttotal: 4.69s\tremaining: 10.3s\n",
      "312:\tlearn: 60750.5836250\ttotal: 4.7s\tremaining: 10.3s\n",
      "313:\tlearn: 60691.6364159\ttotal: 4.71s\tremaining: 10.3s\n",
      "314:\tlearn: 60675.4266600\ttotal: 4.72s\tremaining: 10.3s\n",
      "315:\tlearn: 60649.3643142\ttotal: 4.74s\tremaining: 10.3s\n",
      "316:\tlearn: 60586.4910220\ttotal: 4.75s\tremaining: 10.2s\n",
      "317:\tlearn: 60529.2837174\ttotal: 4.76s\tremaining: 10.2s\n",
      "318:\tlearn: 60474.1297092\ttotal: 4.78s\tremaining: 10.2s\n",
      "319:\tlearn: 60433.2456389\ttotal: 4.79s\tremaining: 10.2s\n",
      "320:\tlearn: 60380.0333168\ttotal: 4.81s\tremaining: 10.2s\n",
      "321:\tlearn: 60324.3445561\ttotal: 4.81s\tremaining: 10.1s\n",
      "322:\tlearn: 60282.5022132\ttotal: 4.83s\tremaining: 10.1s\n",
      "323:\tlearn: 60277.0421846\ttotal: 4.84s\tremaining: 10.1s\n",
      "324:\tlearn: 60271.8306586\ttotal: 4.98s\tremaining: 10.3s\n",
      "325:\tlearn: 60258.5470332\ttotal: 5s\tremaining: 10.3s\n",
      "326:\tlearn: 60253.6982412\ttotal: 5.03s\tremaining: 10.3s\n",
      "327:\tlearn: 60173.3102407\ttotal: 5.05s\tremaining: 10.3s\n",
      "328:\tlearn: 60143.0897478\ttotal: 5.07s\tremaining: 10.3s\n",
      "329:\tlearn: 60091.6304890\ttotal: 5.09s\tremaining: 10.3s\n",
      "330:\tlearn: 60042.0083426\ttotal: 5.11s\tremaining: 10.3s\n",
      "331:\tlearn: 60003.5719941\ttotal: 5.13s\tremaining: 10.3s\n",
      "332:\tlearn: 59960.9610430\ttotal: 5.14s\tremaining: 10.3s\n",
      "333:\tlearn: 59935.8058949\ttotal: 5.15s\tremaining: 10.3s\n",
      "334:\tlearn: 59897.6722079\ttotal: 5.16s\tremaining: 10.3s\n",
      "335:\tlearn: 59852.5567053\ttotal: 5.18s\tremaining: 10.2s\n",
      "336:\tlearn: 59816.8507386\ttotal: 5.19s\tremaining: 10.2s\n",
      "337:\tlearn: 59787.8224656\ttotal: 5.21s\tremaining: 10.2s\n",
      "338:\tlearn: 59782.7357425\ttotal: 5.21s\tremaining: 10.2s\n",
      "339:\tlearn: 59706.5365809\ttotal: 5.23s\tremaining: 10.1s\n",
      "340:\tlearn: 59663.9755491\ttotal: 5.24s\tremaining: 10.1s\n",
      "341:\tlearn: 59624.9570523\ttotal: 5.25s\tremaining: 10.1s\n",
      "342:\tlearn: 59589.4354431\ttotal: 5.26s\tremaining: 10.1s\n",
      "343:\tlearn: 59581.9783992\ttotal: 5.28s\tremaining: 10.1s\n",
      "344:\tlearn: 59534.3512664\ttotal: 5.3s\tremaining: 10.1s\n",
      "345:\tlearn: 59527.5875743\ttotal: 5.31s\tremaining: 10s\n",
      "346:\tlearn: 59479.4076966\ttotal: 5.33s\tremaining: 10s\n",
      "347:\tlearn: 59455.8788643\ttotal: 5.34s\tremaining: 10s\n",
      "348:\tlearn: 59427.8718126\ttotal: 5.36s\tremaining: 9.99s\n",
      "349:\tlearn: 59355.3573395\ttotal: 5.37s\tremaining: 9.98s\n",
      "350:\tlearn: 59335.7835297\ttotal: 5.39s\tremaining: 9.96s\n",
      "351:\tlearn: 59266.4461004\ttotal: 5.39s\tremaining: 9.93s\n",
      "352:\tlearn: 59225.3442421\ttotal: 5.41s\tremaining: 9.91s\n",
      "353:\tlearn: 59186.9961955\ttotal: 5.42s\tremaining: 9.89s\n",
      "354:\tlearn: 59120.5660027\ttotal: 5.44s\tremaining: 9.88s\n",
      "355:\tlearn: 59097.4589703\ttotal: 5.45s\tremaining: 9.86s\n",
      "356:\tlearn: 59047.8610982\ttotal: 5.46s\tremaining: 9.84s\n",
      "357:\tlearn: 59023.7085084\ttotal: 5.47s\tremaining: 9.81s\n",
      "358:\tlearn: 59003.7245522\ttotal: 5.49s\tremaining: 9.8s\n",
      "359:\tlearn: 58957.1192782\ttotal: 5.52s\tremaining: 9.81s\n",
      "360:\tlearn: 58947.0374585\ttotal: 5.54s\tremaining: 9.8s\n",
      "361:\tlearn: 58916.6860582\ttotal: 5.55s\tremaining: 9.78s\n",
      "362:\tlearn: 58895.0458847\ttotal: 5.56s\tremaining: 9.76s\n",
      "363:\tlearn: 58832.6631955\ttotal: 5.58s\tremaining: 9.74s\n",
      "364:\tlearn: 58787.6143909\ttotal: 5.58s\tremaining: 9.71s\n",
      "365:\tlearn: 58743.5587304\ttotal: 5.6s\tremaining: 9.7s\n",
      "366:\tlearn: 58734.1035815\ttotal: 5.61s\tremaining: 9.67s\n",
      "367:\tlearn: 58692.1477420\ttotal: 5.63s\tremaining: 9.66s\n",
      "368:\tlearn: 58653.4844111\ttotal: 5.64s\tremaining: 9.64s\n",
      "369:\tlearn: 58614.6558872\ttotal: 5.65s\tremaining: 9.62s\n",
      "370:\tlearn: 58572.1810967\ttotal: 5.66s\tremaining: 9.6s\n",
      "371:\tlearn: 58497.8757942\ttotal: 5.67s\tremaining: 9.58s\n",
      "372:\tlearn: 58480.4812374\ttotal: 5.68s\tremaining: 9.55s\n",
      "373:\tlearn: 58439.8680498\ttotal: 5.69s\tremaining: 9.53s\n",
      "374:\tlearn: 58436.7420753\ttotal: 5.71s\tremaining: 9.53s\n",
      "375:\tlearn: 58428.5136440\ttotal: 5.73s\tremaining: 9.51s\n",
      "376:\tlearn: 58397.3588762\ttotal: 5.75s\tremaining: 9.51s\n",
      "377:\tlearn: 58333.3301435\ttotal: 5.78s\tremaining: 9.52s\n",
      "378:\tlearn: 58306.5850669\ttotal: 5.8s\tremaining: 9.5s\n",
      "379:\tlearn: 58275.3485814\ttotal: 5.81s\tremaining: 9.48s\n",
      "380:\tlearn: 58206.9380095\ttotal: 5.83s\tremaining: 9.47s\n",
      "381:\tlearn: 58189.3058401\ttotal: 5.84s\tremaining: 9.45s\n",
      "382:\tlearn: 58163.0726967\ttotal: 5.85s\tremaining: 9.43s\n",
      "383:\tlearn: 58143.9000213\ttotal: 5.86s\tremaining: 9.41s\n",
      "384:\tlearn: 58083.0341695\ttotal: 5.88s\tremaining: 9.39s\n",
      "385:\tlearn: 58070.0694726\ttotal: 5.89s\tremaining: 9.37s\n",
      "386:\tlearn: 58063.0487625\ttotal: 5.9s\tremaining: 9.35s\n",
      "387:\tlearn: 58058.0546670\ttotal: 5.91s\tremaining: 9.33s\n",
      "388:\tlearn: 58047.3732193\ttotal: 5.95s\tremaining: 9.35s\n",
      "389:\tlearn: 57975.2992500\ttotal: 5.97s\tremaining: 9.34s\n",
      "390:\tlearn: 57959.3063866\ttotal: 5.99s\tremaining: 9.32s\n",
      "391:\tlearn: 57952.7394069\ttotal: 6s\tremaining: 9.3s\n",
      "392:\tlearn: 57914.3561017\ttotal: 6.01s\tremaining: 9.28s\n",
      "393:\tlearn: 57913.0333026\ttotal: 6.02s\tremaining: 9.27s\n",
      "394:\tlearn: 57876.0028572\ttotal: 6.04s\tremaining: 9.25s\n",
      "395:\tlearn: 57851.9093551\ttotal: 6.05s\tremaining: 9.23s\n",
      "396:\tlearn: 57790.2102638\ttotal: 6.09s\tremaining: 9.25s\n",
      "397:\tlearn: 57787.8855883\ttotal: 6.09s\tremaining: 9.22s\n",
      "398:\tlearn: 57780.3634164\ttotal: 6.11s\tremaining: 9.2s\n",
      "399:\tlearn: 57731.4922218\ttotal: 6.12s\tremaining: 9.18s\n",
      "400:\tlearn: 57670.5059366\ttotal: 6.13s\tremaining: 9.16s\n",
      "401:\tlearn: 57641.0331970\ttotal: 6.15s\tremaining: 9.15s\n",
      "402:\tlearn: 57570.1796758\ttotal: 6.16s\tremaining: 9.12s\n",
      "403:\tlearn: 57510.9382229\ttotal: 6.18s\tremaining: 9.11s\n",
      "404:\tlearn: 57483.9064834\ttotal: 6.22s\tremaining: 9.13s\n",
      "405:\tlearn: 57456.6389989\ttotal: 6.23s\tremaining: 9.11s\n",
      "406:\tlearn: 57420.6475067\ttotal: 6.25s\tremaining: 9.1s\n",
      "407:\tlearn: 57404.9989081\ttotal: 6.26s\tremaining: 9.08s\n",
      "408:\tlearn: 57370.2666005\ttotal: 6.27s\tremaining: 9.06s\n",
      "409:\tlearn: 57366.0696919\ttotal: 6.28s\tremaining: 9.04s\n",
      "410:\tlearn: 57344.1322631\ttotal: 6.29s\tremaining: 9.02s\n",
      "411:\tlearn: 57310.6096760\ttotal: 6.31s\tremaining: 9s\n",
      "412:\tlearn: 57279.3764082\ttotal: 6.32s\tremaining: 8.99s\n",
      "413:\tlearn: 57268.9944719\ttotal: 6.34s\tremaining: 8.97s\n",
      "414:\tlearn: 57260.4909877\ttotal: 6.35s\tremaining: 8.95s\n",
      "415:\tlearn: 57232.7439890\ttotal: 6.36s\tremaining: 8.93s\n",
      "416:\tlearn: 57196.5250815\ttotal: 6.37s\tremaining: 8.91s\n",
      "417:\tlearn: 57126.1143409\ttotal: 6.39s\tremaining: 8.89s\n",
      "418:\tlearn: 57093.6769780\ttotal: 6.51s\tremaining: 9.03s\n",
      "419:\tlearn: 57063.8751848\ttotal: 6.54s\tremaining: 9.03s\n",
      "420:\tlearn: 57032.0329176\ttotal: 6.57s\tremaining: 9.03s\n",
      "421:\tlearn: 57025.1507996\ttotal: 6.89s\tremaining: 9.44s\n",
      "422:\tlearn: 56994.9298621\ttotal: 7.04s\tremaining: 9.61s\n",
      "423:\tlearn: 56974.2434451\ttotal: 7.36s\tremaining: 10s\n",
      "424:\tlearn: 56917.5477848\ttotal: 7.39s\tremaining: 10s\n",
      "425:\tlearn: 56898.0095834\ttotal: 7.41s\tremaining: 9.99s\n",
      "426:\tlearn: 56829.7994912\ttotal: 7.44s\tremaining: 9.98s\n",
      "427:\tlearn: 56805.4928130\ttotal: 7.45s\tremaining: 9.96s\n",
      "428:\tlearn: 56781.6704735\ttotal: 7.46s\tremaining: 9.94s\n",
      "429:\tlearn: 56727.1414582\ttotal: 7.48s\tremaining: 9.92s\n",
      "430:\tlearn: 56724.7088511\ttotal: 7.5s\tremaining: 9.9s\n",
      "431:\tlearn: 56697.1718561\ttotal: 7.51s\tremaining: 9.88s\n",
      "432:\tlearn: 56679.2770255\ttotal: 7.53s\tremaining: 9.85s\n",
      "433:\tlearn: 56615.1735234\ttotal: 7.54s\tremaining: 9.83s\n",
      "434:\tlearn: 56604.8169275\ttotal: 7.55s\tremaining: 9.8s\n",
      "435:\tlearn: 56598.1357920\ttotal: 7.56s\tremaining: 9.78s\n",
      "436:\tlearn: 56580.1045398\ttotal: 7.57s\tremaining: 9.76s\n",
      "437:\tlearn: 56577.7616506\ttotal: 7.58s\tremaining: 9.73s\n",
      "438:\tlearn: 56536.2028486\ttotal: 7.6s\tremaining: 9.71s\n",
      "439:\tlearn: 56532.6701363\ttotal: 7.62s\tremaining: 9.69s\n",
      "440:\tlearn: 56471.9758698\ttotal: 7.63s\tremaining: 9.68s\n",
      "441:\tlearn: 56459.4039842\ttotal: 7.65s\tremaining: 9.66s\n",
      "442:\tlearn: 56419.5049521\ttotal: 7.66s\tremaining: 9.63s\n",
      "443:\tlearn: 56417.2500090\ttotal: 7.67s\tremaining: 9.61s\n",
      "444:\tlearn: 56394.2603517\ttotal: 7.69s\tremaining: 9.59s\n",
      "445:\tlearn: 56372.0212719\ttotal: 7.71s\tremaining: 9.57s\n",
      "446:\tlearn: 56342.5261469\ttotal: 7.72s\tremaining: 9.55s\n",
      "447:\tlearn: 56295.4461790\ttotal: 7.73s\tremaining: 9.53s\n",
      "448:\tlearn: 56266.9658170\ttotal: 7.75s\tremaining: 9.51s\n",
      "449:\tlearn: 56200.5239809\ttotal: 7.76s\tremaining: 9.48s\n",
      "450:\tlearn: 56180.4104406\ttotal: 7.77s\tremaining: 9.46s\n",
      "451:\tlearn: 56178.3058084\ttotal: 7.79s\tremaining: 9.44s\n",
      "452:\tlearn: 56150.7847699\ttotal: 7.82s\tremaining: 9.44s\n",
      "453:\tlearn: 56083.6717470\ttotal: 7.85s\tremaining: 9.44s\n",
      "454:\tlearn: 56067.2185758\ttotal: 7.86s\tremaining: 9.41s\n",
      "455:\tlearn: 56060.9810323\ttotal: 7.88s\tremaining: 9.4s\n",
      "456:\tlearn: 56034.0643698\ttotal: 7.89s\tremaining: 9.38s\n",
      "457:\tlearn: 56013.3324124\ttotal: 7.9s\tremaining: 9.35s\n",
      "458:\tlearn: 55991.6792901\ttotal: 7.91s\tremaining: 9.32s\n",
      "459:\tlearn: 55969.4486839\ttotal: 7.92s\tremaining: 9.3s\n",
      "460:\tlearn: 55947.9420261\ttotal: 7.94s\tremaining: 9.28s\n",
      "461:\tlearn: 55931.9250857\ttotal: 7.95s\tremaining: 9.26s\n",
      "462:\tlearn: 55924.1289875\ttotal: 7.96s\tremaining: 9.23s\n",
      "463:\tlearn: 55918.4194308\ttotal: 7.97s\tremaining: 9.21s\n",
      "464:\tlearn: 55883.8588723\ttotal: 7.99s\tremaining: 9.19s\n",
      "465:\tlearn: 55832.5396967\ttotal: 8.01s\tremaining: 9.18s\n",
      "466:\tlearn: 55798.9556326\ttotal: 8.02s\tremaining: 9.15s\n",
      "467:\tlearn: 55786.7464904\ttotal: 8.03s\tremaining: 9.12s\n",
      "468:\tlearn: 55766.0604146\ttotal: 8.04s\tremaining: 9.11s\n",
      "469:\tlearn: 55740.7409449\ttotal: 8.07s\tremaining: 9.11s\n",
      "470:\tlearn: 55716.2420463\ttotal: 8.09s\tremaining: 9.09s\n",
      "471:\tlearn: 55666.5448274\ttotal: 8.11s\tremaining: 9.07s\n",
      "472:\tlearn: 55641.8928868\ttotal: 8.12s\tremaining: 9.05s\n",
      "473:\tlearn: 55616.8213693\ttotal: 8.13s\tremaining: 9.03s\n",
      "474:\tlearn: 55608.6545626\ttotal: 8.14s\tremaining: 9s\n",
      "475:\tlearn: 55592.9524153\ttotal: 8.15s\tremaining: 8.97s\n",
      "476:\tlearn: 55573.8895311\ttotal: 8.16s\tremaining: 8.95s\n",
      "477:\tlearn: 55561.4968245\ttotal: 8.18s\tremaining: 8.93s\n",
      "478:\tlearn: 55535.8684472\ttotal: 8.2s\tremaining: 8.91s\n",
      "479:\tlearn: 55517.0056396\ttotal: 8.21s\tremaining: 8.9s\n",
      "480:\tlearn: 55495.7806400\ttotal: 8.23s\tremaining: 8.88s\n",
      "481:\tlearn: 55493.9888193\ttotal: 8.23s\tremaining: 8.85s\n",
      "482:\tlearn: 55470.6038856\ttotal: 8.25s\tremaining: 8.83s\n",
      "483:\tlearn: 55413.5391488\ttotal: 8.33s\tremaining: 8.88s\n",
      "484:\tlearn: 55399.7414275\ttotal: 8.35s\tremaining: 8.86s\n",
      "485:\tlearn: 55379.5068689\ttotal: 8.36s\tremaining: 8.84s\n",
      "486:\tlearn: 55377.8192422\ttotal: 8.37s\tremaining: 8.82s\n",
      "487:\tlearn: 55349.8343494\ttotal: 8.39s\tremaining: 8.8s\n",
      "488:\tlearn: 55327.2179871\ttotal: 8.4s\tremaining: 8.78s\n",
      "489:\tlearn: 55305.4002458\ttotal: 8.41s\tremaining: 8.76s\n",
      "490:\tlearn: 55261.2462104\ttotal: 8.43s\tremaining: 8.74s\n",
      "491:\tlearn: 55241.5624344\ttotal: 8.44s\tremaining: 8.72s\n",
      "492:\tlearn: 55230.4673494\ttotal: 8.46s\tremaining: 8.7s\n",
      "493:\tlearn: 55228.8545628\ttotal: 8.46s\tremaining: 8.67s\n",
      "494:\tlearn: 55213.0883681\ttotal: 8.48s\tremaining: 8.65s\n",
      "495:\tlearn: 55199.9199909\ttotal: 8.49s\tremaining: 8.63s\n",
      "496:\tlearn: 55181.8218499\ttotal: 8.51s\tremaining: 8.61s\n",
      "497:\tlearn: 55180.3037746\ttotal: 8.52s\tremaining: 8.59s\n",
      "498:\tlearn: 55156.7909136\ttotal: 8.54s\tremaining: 8.57s\n",
      "499:\tlearn: 55110.5848532\ttotal: 8.56s\tremaining: 8.56s\n",
      "500:\tlearn: 55084.2703063\ttotal: 8.58s\tremaining: 8.54s\n",
      "501:\tlearn: 55066.9789972\ttotal: 8.59s\tremaining: 8.52s\n",
      "502:\tlearn: 55043.0684972\ttotal: 8.6s\tremaining: 8.49s\n",
      "503:\tlearn: 54964.0197969\ttotal: 8.61s\tremaining: 8.47s\n",
      "504:\tlearn: 54945.7171639\ttotal: 8.62s\tremaining: 8.45s\n",
      "505:\tlearn: 54892.4310066\ttotal: 8.64s\tremaining: 8.43s\n",
      "506:\tlearn: 54881.2737839\ttotal: 8.65s\tremaining: 8.41s\n",
      "507:\tlearn: 54864.9806191\ttotal: 8.66s\tremaining: 8.39s\n",
      "508:\tlearn: 54856.4913931\ttotal: 8.68s\tremaining: 8.37s\n",
      "509:\tlearn: 54838.8386246\ttotal: 8.69s\tremaining: 8.35s\n",
      "510:\tlearn: 54778.5341406\ttotal: 8.7s\tremaining: 8.33s\n",
      "511:\tlearn: 54777.0907616\ttotal: 8.72s\tremaining: 8.31s\n",
      "512:\tlearn: 54738.3677618\ttotal: 8.73s\tremaining: 8.28s\n",
      "513:\tlearn: 54716.0172939\ttotal: 8.74s\tremaining: 8.26s\n",
      "514:\tlearn: 54693.6813848\ttotal: 8.75s\tremaining: 8.24s\n",
      "515:\tlearn: 54676.6386253\ttotal: 8.78s\tremaining: 8.24s\n",
      "516:\tlearn: 54662.1408910\ttotal: 8.79s\tremaining: 8.21s\n",
      "517:\tlearn: 54640.6708502\ttotal: 8.81s\tremaining: 8.2s\n",
      "518:\tlearn: 54623.6550901\ttotal: 8.82s\tremaining: 8.17s\n",
      "519:\tlearn: 54602.8632815\ttotal: 8.83s\tremaining: 8.15s\n",
      "520:\tlearn: 54578.4586459\ttotal: 8.85s\tremaining: 8.13s\n",
      "521:\tlearn: 54563.9698693\ttotal: 8.87s\tremaining: 8.13s\n",
      "522:\tlearn: 54531.4522249\ttotal: 8.89s\tremaining: 8.11s\n",
      "523:\tlearn: 54516.5193664\ttotal: 8.9s\tremaining: 8.09s\n",
      "524:\tlearn: 54505.4536254\ttotal: 8.92s\tremaining: 8.07s\n",
      "525:\tlearn: 54495.0950132\ttotal: 8.93s\tremaining: 8.05s\n",
      "526:\tlearn: 54489.5791571\ttotal: 8.95s\tremaining: 8.03s\n",
      "527:\tlearn: 54485.4448424\ttotal: 8.97s\tremaining: 8.02s\n",
      "528:\tlearn: 54441.0143704\ttotal: 8.99s\tremaining: 8.01s\n",
      "529:\tlearn: 54427.0294328\ttotal: 9s\tremaining: 7.98s\n",
      "530:\tlearn: 54348.5714477\ttotal: 9.02s\tremaining: 7.96s\n",
      "531:\tlearn: 54343.2712250\ttotal: 9.03s\tremaining: 7.94s\n",
      "532:\tlearn: 54284.3585525\ttotal: 9.04s\tremaining: 7.92s\n",
      "533:\tlearn: 54208.6686624\ttotal: 9.05s\tremaining: 7.9s\n",
      "534:\tlearn: 54134.9056922\ttotal: 9.06s\tremaining: 7.88s\n",
      "535:\tlearn: 54121.7403300\ttotal: 9.08s\tremaining: 7.86s\n",
      "536:\tlearn: 54048.4900527\ttotal: 9.09s\tremaining: 7.84s\n",
      "537:\tlearn: 54041.7394292\ttotal: 9.11s\tremaining: 7.82s\n",
      "538:\tlearn: 54025.1360690\ttotal: 9.12s\tremaining: 7.8s\n",
      "539:\tlearn: 54008.2299663\ttotal: 9.13s\tremaining: 7.78s\n",
      "540:\tlearn: 53951.7119472\ttotal: 9.14s\tremaining: 7.76s\n",
      "541:\tlearn: 53930.5135062\ttotal: 9.15s\tremaining: 7.74s\n",
      "542:\tlearn: 53910.4073401\ttotal: 9.19s\tremaining: 7.73s\n",
      "543:\tlearn: 53839.5798923\ttotal: 9.2s\tremaining: 7.71s\n",
      "544:\tlearn: 53824.1169889\ttotal: 9.22s\tremaining: 7.7s\n",
      "545:\tlearn: 53817.0104356\ttotal: 9.23s\tremaining: 7.67s\n",
      "546:\tlearn: 53748.6430257\ttotal: 9.24s\tremaining: 7.65s\n",
      "547:\tlearn: 53693.9017525\ttotal: 9.25s\tremaining: 7.63s\n",
      "548:\tlearn: 53687.9113344\ttotal: 9.27s\tremaining: 7.61s\n",
      "549:\tlearn: 53644.6486685\ttotal: 9.28s\tremaining: 7.59s\n",
      "550:\tlearn: 53638.3236940\ttotal: 9.29s\tremaining: 7.57s\n",
      "551:\tlearn: 53630.9786124\ttotal: 9.3s\tremaining: 7.55s\n",
      "552:\tlearn: 53616.0759576\ttotal: 9.31s\tremaining: 7.53s\n",
      "553:\tlearn: 53601.7234411\ttotal: 9.33s\tremaining: 7.51s\n",
      "554:\tlearn: 53582.6684579\ttotal: 9.33s\tremaining: 7.48s\n",
      "555:\tlearn: 53578.9613536\ttotal: 9.35s\tremaining: 7.47s\n",
      "556:\tlearn: 53562.8773350\ttotal: 9.36s\tremaining: 7.45s\n",
      "557:\tlearn: 53534.4269163\ttotal: 9.38s\tremaining: 7.43s\n",
      "558:\tlearn: 53468.2128681\ttotal: 9.4s\tremaining: 7.42s\n",
      "559:\tlearn: 53452.3766425\ttotal: 9.41s\tremaining: 7.4s\n",
      "560:\tlearn: 53435.7216122\ttotal: 9.44s\tremaining: 7.39s\n",
      "561:\tlearn: 53371.7966723\ttotal: 9.46s\tremaining: 7.37s\n",
      "562:\tlearn: 53353.5973976\ttotal: 9.47s\tremaining: 7.35s\n",
      "563:\tlearn: 53300.5184110\ttotal: 9.48s\tremaining: 7.33s\n",
      "564:\tlearn: 53292.8143418\ttotal: 9.5s\tremaining: 7.31s\n",
      "565:\tlearn: 53267.3042875\ttotal: 9.52s\tremaining: 7.3s\n",
      "566:\tlearn: 53250.3542747\ttotal: 9.53s\tremaining: 7.28s\n",
      "567:\tlearn: 53227.9788055\ttotal: 9.54s\tremaining: 7.26s\n",
      "568:\tlearn: 53221.1705353\ttotal: 9.55s\tremaining: 7.24s\n",
      "569:\tlearn: 53216.3435054\ttotal: 9.56s\tremaining: 7.21s\n",
      "570:\tlearn: 53208.6766024\ttotal: 9.58s\tremaining: 7.2s\n",
      "571:\tlearn: 53146.7886046\ttotal: 9.59s\tremaining: 7.18s\n",
      "572:\tlearn: 53126.4072103\ttotal: 9.61s\tremaining: 7.16s\n",
      "573:\tlearn: 53108.0855247\ttotal: 9.64s\tremaining: 7.15s\n",
      "574:\tlearn: 53101.2974285\ttotal: 9.66s\tremaining: 7.14s\n",
      "575:\tlearn: 53095.2536452\ttotal: 9.66s\tremaining: 7.11s\n",
      "576:\tlearn: 53079.8532551\ttotal: 9.68s\tremaining: 7.09s\n",
      "577:\tlearn: 53037.7324893\ttotal: 9.69s\tremaining: 7.08s\n",
      "578:\tlearn: 53021.4572288\ttotal: 9.71s\tremaining: 7.06s\n",
      "579:\tlearn: 53003.1994017\ttotal: 9.72s\tremaining: 7.04s\n",
      "580:\tlearn: 52943.2944228\ttotal: 9.73s\tremaining: 7.02s\n",
      "581:\tlearn: 52885.4908009\ttotal: 9.74s\tremaining: 7s\n",
      "582:\tlearn: 52866.6224234\ttotal: 9.76s\tremaining: 6.98s\n",
      "583:\tlearn: 52846.1324395\ttotal: 9.78s\tremaining: 6.96s\n",
      "584:\tlearn: 52809.9616531\ttotal: 9.79s\tremaining: 6.94s\n",
      "585:\tlearn: 52797.8310341\ttotal: 9.8s\tremaining: 6.92s\n",
      "586:\tlearn: 52741.9541531\ttotal: 9.81s\tremaining: 6.91s\n",
      "587:\tlearn: 52721.3828870\ttotal: 9.84s\tremaining: 6.89s\n",
      "588:\tlearn: 52667.4272158\ttotal: 9.87s\tremaining: 6.89s\n",
      "589:\tlearn: 52638.1546647\ttotal: 9.88s\tremaining: 6.87s\n",
      "590:\tlearn: 52633.0370505\ttotal: 9.89s\tremaining: 6.85s\n",
      "591:\tlearn: 52574.0911993\ttotal: 9.91s\tremaining: 6.83s\n",
      "592:\tlearn: 52521.9326197\ttotal: 9.93s\tremaining: 6.82s\n",
      "593:\tlearn: 52506.6402709\ttotal: 9.94s\tremaining: 6.79s\n",
      "594:\tlearn: 52501.6153434\ttotal: 9.95s\tremaining: 6.78s\n",
      "595:\tlearn: 52491.8208408\ttotal: 9.96s\tremaining: 6.75s\n",
      "596:\tlearn: 52475.4324887\ttotal: 9.97s\tremaining: 6.73s\n",
      "597:\tlearn: 52441.5735964\ttotal: 9.99s\tremaining: 6.71s\n",
      "598:\tlearn: 52433.9375169\ttotal: 10s\tremaining: 6.7s\n",
      "599:\tlearn: 52420.2398576\ttotal: 10s\tremaining: 6.67s\n",
      "600:\tlearn: 52410.0211848\ttotal: 10s\tremaining: 6.66s\n",
      "601:\tlearn: 52402.6812549\ttotal: 10s\tremaining: 6.64s\n",
      "602:\tlearn: 52357.7773299\ttotal: 10s\tremaining: 6.62s\n",
      "603:\tlearn: 52339.8879743\ttotal: 10.1s\tremaining: 6.6s\n",
      "604:\tlearn: 52321.5018287\ttotal: 10.1s\tremaining: 6.58s\n",
      "605:\tlearn: 52314.4395665\ttotal: 10.1s\tremaining: 6.57s\n",
      "606:\tlearn: 52308.4072532\ttotal: 10.1s\tremaining: 6.55s\n",
      "607:\tlearn: 52301.6083997\ttotal: 10.1s\tremaining: 6.53s\n",
      "608:\tlearn: 52284.0444240\ttotal: 10.1s\tremaining: 6.51s\n",
      "609:\tlearn: 52263.8276510\ttotal: 10.2s\tremaining: 6.5s\n",
      "610:\tlearn: 52258.5505820\ttotal: 10.2s\tremaining: 6.48s\n",
      "611:\tlearn: 52241.7104156\ttotal: 10.2s\tremaining: 6.46s\n",
      "612:\tlearn: 52225.8586140\ttotal: 10.2s\tremaining: 6.44s\n",
      "613:\tlearn: 52208.9461276\ttotal: 10.2s\tremaining: 6.43s\n",
      "614:\tlearn: 52189.0940885\ttotal: 10.2s\tremaining: 6.41s\n",
      "615:\tlearn: 52138.4505604\ttotal: 10.2s\tremaining: 6.39s\n",
      "616:\tlearn: 52131.9073562\ttotal: 10.3s\tremaining: 6.37s\n",
      "617:\tlearn: 52126.9009940\ttotal: 10.3s\tremaining: 6.35s\n",
      "618:\tlearn: 52071.6322901\ttotal: 10.3s\tremaining: 6.33s\n",
      "619:\tlearn: 52058.3420543\ttotal: 10.3s\tremaining: 6.32s\n",
      "620:\tlearn: 52020.2027405\ttotal: 10.3s\tremaining: 6.3s\n",
      "621:\tlearn: 52015.2474271\ttotal: 10.3s\tremaining: 6.28s\n",
      "622:\tlearn: 51992.1077784\ttotal: 10.3s\tremaining: 6.26s\n",
      "623:\tlearn: 51984.4274078\ttotal: 10.4s\tremaining: 6.24s\n",
      "624:\tlearn: 51980.2347134\ttotal: 10.4s\tremaining: 6.22s\n",
      "625:\tlearn: 51965.4202768\ttotal: 10.4s\tremaining: 6.2s\n",
      "626:\tlearn: 51960.5940195\ttotal: 10.4s\tremaining: 6.18s\n",
      "627:\tlearn: 51956.9105220\ttotal: 10.4s\tremaining: 6.16s\n",
      "628:\tlearn: 51916.7928619\ttotal: 10.4s\tremaining: 6.14s\n",
      "629:\tlearn: 51886.0152247\ttotal: 10.4s\tremaining: 6.13s\n",
      "630:\tlearn: 51862.5007210\ttotal: 10.4s\tremaining: 6.11s\n",
      "631:\tlearn: 51837.5889749\ttotal: 10.5s\tremaining: 6.09s\n",
      "632:\tlearn: 51788.4178031\ttotal: 10.5s\tremaining: 6.07s\n",
      "633:\tlearn: 51735.7410360\ttotal: 10.5s\tremaining: 6.05s\n",
      "634:\tlearn: 51712.0735086\ttotal: 10.5s\tremaining: 6.04s\n",
      "635:\tlearn: 51700.0329107\ttotal: 10.5s\tremaining: 6.03s\n",
      "636:\tlearn: 51684.1213325\ttotal: 10.6s\tremaining: 6.01s\n",
      "637:\tlearn: 51668.0190677\ttotal: 10.6s\tremaining: 6s\n",
      "638:\tlearn: 51634.6094338\ttotal: 10.6s\tremaining: 5.98s\n",
      "639:\tlearn: 51594.3007332\ttotal: 10.6s\tremaining: 5.96s\n",
      "640:\tlearn: 51588.4485684\ttotal: 10.6s\tremaining: 5.94s\n",
      "641:\tlearn: 51572.8930070\ttotal: 10.6s\tremaining: 5.92s\n",
      "642:\tlearn: 51566.3340289\ttotal: 10.6s\tremaining: 5.9s\n",
      "643:\tlearn: 51547.9384572\ttotal: 10.6s\tremaining: 5.88s\n",
      "644:\tlearn: 51499.7196930\ttotal: 10.7s\tremaining: 5.86s\n",
      "645:\tlearn: 51484.6894664\ttotal: 10.7s\tremaining: 5.84s\n",
      "646:\tlearn: 51479.0462860\ttotal: 10.7s\tremaining: 5.83s\n",
      "647:\tlearn: 51433.1299083\ttotal: 10.7s\tremaining: 5.81s\n",
      "648:\tlearn: 51418.6144610\ttotal: 10.7s\tremaining: 5.79s\n",
      "649:\tlearn: 51389.6742544\ttotal: 10.7s\tremaining: 5.78s\n",
      "650:\tlearn: 51382.1794357\ttotal: 10.8s\tremaining: 5.76s\n",
      "651:\tlearn: 51369.5392977\ttotal: 10.8s\tremaining: 5.75s\n",
      "652:\tlearn: 51321.6758916\ttotal: 10.8s\tremaining: 5.73s\n",
      "653:\tlearn: 51275.4917495\ttotal: 10.8s\tremaining: 5.71s\n",
      "654:\tlearn: 51272.1593550\ttotal: 10.8s\tremaining: 5.69s\n",
      "655:\tlearn: 51266.7043164\ttotal: 10.8s\tremaining: 5.67s\n",
      "656:\tlearn: 51253.6808233\ttotal: 10.8s\tremaining: 5.65s\n",
      "657:\tlearn: 51248.7216928\ttotal: 10.8s\tremaining: 5.64s\n",
      "658:\tlearn: 51218.9048817\ttotal: 10.9s\tremaining: 5.62s\n",
      "659:\tlearn: 51207.1675005\ttotal: 10.9s\tremaining: 5.6s\n",
      "660:\tlearn: 51193.0939403\ttotal: 10.9s\tremaining: 5.58s\n",
      "661:\tlearn: 51177.5875583\ttotal: 10.9s\tremaining: 5.56s\n",
      "662:\tlearn: 51172.4929696\ttotal: 10.9s\tremaining: 5.54s\n",
      "663:\tlearn: 51167.9930787\ttotal: 10.9s\tremaining: 5.52s\n",
      "664:\tlearn: 51128.0358924\ttotal: 10.9s\tremaining: 5.5s\n",
      "665:\tlearn: 51121.9546406\ttotal: 10.9s\tremaining: 5.49s\n",
      "666:\tlearn: 51107.7478498\ttotal: 11s\tremaining: 5.51s\n",
      "667:\tlearn: 51103.1396320\ttotal: 11.1s\tremaining: 5.5s\n",
      "668:\tlearn: 51058.4229692\ttotal: 11.1s\tremaining: 5.48s\n",
      "669:\tlearn: 51052.5470070\ttotal: 11.1s\tremaining: 5.46s\n",
      "670:\tlearn: 51009.3961671\ttotal: 11.1s\tremaining: 5.44s\n",
      "671:\tlearn: 50995.8731551\ttotal: 11.1s\tremaining: 5.42s\n",
      "672:\tlearn: 50976.8384361\ttotal: 11.1s\tremaining: 5.41s\n",
      "673:\tlearn: 50962.3361146\ttotal: 11.1s\tremaining: 5.39s\n",
      "674:\tlearn: 50943.1388205\ttotal: 11.2s\tremaining: 5.37s\n",
      "675:\tlearn: 50940.1354109\ttotal: 11.2s\tremaining: 5.35s\n",
      "676:\tlearn: 50937.2913133\ttotal: 11.2s\tremaining: 5.33s\n",
      "677:\tlearn: 50920.7578431\ttotal: 11.2s\tremaining: 5.31s\n",
      "678:\tlearn: 50876.7625126\ttotal: 11.2s\tremaining: 5.29s\n",
      "679:\tlearn: 50835.0083513\ttotal: 11.2s\tremaining: 5.27s\n",
      "680:\tlearn: 50819.5694293\ttotal: 11.2s\tremaining: 5.26s\n",
      "681:\tlearn: 50809.6784526\ttotal: 11.2s\tremaining: 5.24s\n",
      "682:\tlearn: 50760.8498437\ttotal: 11.3s\tremaining: 5.22s\n",
      "683:\tlearn: 50754.4228010\ttotal: 11.3s\tremaining: 5.21s\n",
      "684:\tlearn: 50745.7089971\ttotal: 11.3s\tremaining: 5.19s\n",
      "685:\tlearn: 50705.3454023\ttotal: 11.3s\tremaining: 5.18s\n",
      "686:\tlearn: 50695.5390997\ttotal: 11.3s\tremaining: 5.16s\n",
      "687:\tlearn: 50656.5697594\ttotal: 11.3s\tremaining: 5.14s\n",
      "688:\tlearn: 50651.7844818\ttotal: 11.4s\tremaining: 5.13s\n",
      "689:\tlearn: 50634.8940681\ttotal: 11.4s\tremaining: 5.11s\n",
      "690:\tlearn: 50620.3362413\ttotal: 11.4s\tremaining: 5.09s\n",
      "691:\tlearn: 50605.2720539\ttotal: 11.4s\tremaining: 5.07s\n",
      "692:\tlearn: 50567.6332167\ttotal: 11.4s\tremaining: 5.05s\n",
      "693:\tlearn: 50554.2588392\ttotal: 11.4s\tremaining: 5.04s\n",
      "694:\tlearn: 50519.1391323\ttotal: 11.5s\tremaining: 5.03s\n",
      "695:\tlearn: 50492.6429172\ttotal: 11.5s\tremaining: 5.01s\n",
      "696:\tlearn: 50486.8863616\ttotal: 11.5s\tremaining: 4.99s\n",
      "697:\tlearn: 50470.7931887\ttotal: 11.5s\tremaining: 4.97s\n",
      "698:\tlearn: 50457.2771305\ttotal: 11.5s\tremaining: 4.95s\n",
      "699:\tlearn: 50441.9037811\ttotal: 11.5s\tremaining: 4.94s\n",
      "700:\tlearn: 50439.7213033\ttotal: 11.6s\tremaining: 4.93s\n",
      "701:\tlearn: 50427.0065289\ttotal: 11.6s\tremaining: 4.91s\n",
      "702:\tlearn: 50412.3123845\ttotal: 11.6s\tremaining: 4.89s\n",
      "703:\tlearn: 50396.4157112\ttotal: 11.6s\tremaining: 4.87s\n",
      "704:\tlearn: 50359.5452116\ttotal: 11.6s\tremaining: 4.85s\n",
      "705:\tlearn: 50299.2765266\ttotal: 11.6s\tremaining: 4.84s\n",
      "706:\tlearn: 50264.0168046\ttotal: 11.6s\tremaining: 4.82s\n",
      "707:\tlearn: 50252.3876159\ttotal: 11.6s\tremaining: 4.8s\n",
      "708:\tlearn: 50240.3689735\ttotal: 11.7s\tremaining: 4.78s\n",
      "709:\tlearn: 50226.2726547\ttotal: 11.7s\tremaining: 4.76s\n",
      "710:\tlearn: 50178.6295118\ttotal: 11.7s\tremaining: 4.75s\n",
      "711:\tlearn: 50153.8881804\ttotal: 11.7s\tremaining: 4.73s\n",
      "712:\tlearn: 50141.1041740\ttotal: 11.7s\tremaining: 4.71s\n",
      "713:\tlearn: 50125.5276726\ttotal: 11.7s\tremaining: 4.69s\n",
      "714:\tlearn: 50113.2321344\ttotal: 11.7s\tremaining: 4.68s\n",
      "715:\tlearn: 50076.1002383\ttotal: 11.8s\tremaining: 4.67s\n",
      "716:\tlearn: 50038.4338037\ttotal: 11.8s\tremaining: 4.65s\n",
      "717:\tlearn: 50032.3344076\ttotal: 11.8s\tremaining: 4.63s\n",
      "718:\tlearn: 50019.3881011\ttotal: 11.8s\tremaining: 4.61s\n",
      "719:\tlearn: 50004.5052802\ttotal: 11.8s\tremaining: 4.59s\n",
      "720:\tlearn: 49992.1436292\ttotal: 11.8s\tremaining: 4.58s\n",
      "721:\tlearn: 49959.1232583\ttotal: 11.9s\tremaining: 4.56s\n",
      "722:\tlearn: 49922.7867619\ttotal: 11.9s\tremaining: 4.54s\n",
      "723:\tlearn: 49915.4168895\ttotal: 11.9s\tremaining: 4.53s\n",
      "724:\tlearn: 49896.4775635\ttotal: 11.9s\tremaining: 4.51s\n",
      "725:\tlearn: 49892.0091387\ttotal: 11.9s\tremaining: 4.49s\n",
      "726:\tlearn: 49869.1292177\ttotal: 11.9s\tremaining: 4.47s\n",
      "727:\tlearn: 49864.8564431\ttotal: 11.9s\tremaining: 4.46s\n",
      "728:\tlearn: 49850.4270471\ttotal: 12s\tremaining: 4.45s\n",
      "729:\tlearn: 49836.0598639\ttotal: 12s\tremaining: 4.43s\n",
      "730:\tlearn: 49832.0807081\ttotal: 12s\tremaining: 4.41s\n",
      "731:\tlearn: 49800.1364365\ttotal: 12s\tremaining: 4.39s\n",
      "732:\tlearn: 49767.7591888\ttotal: 12s\tremaining: 4.38s\n",
      "733:\tlearn: 49743.9794399\ttotal: 12s\tremaining: 4.36s\n",
      "734:\tlearn: 49726.4054961\ttotal: 12s\tremaining: 4.34s\n",
      "735:\tlearn: 49713.1452357\ttotal: 12s\tremaining: 4.32s\n",
      "736:\tlearn: 49682.2652029\ttotal: 12.1s\tremaining: 4.31s\n",
      "737:\tlearn: 49659.3546843\ttotal: 12.1s\tremaining: 4.29s\n",
      "738:\tlearn: 49637.3044906\ttotal: 12.1s\tremaining: 4.28s\n",
      "739:\tlearn: 49626.1074139\ttotal: 12.1s\tremaining: 4.26s\n",
      "740:\tlearn: 49580.1611356\ttotal: 12.1s\tremaining: 4.25s\n",
      "741:\tlearn: 49569.3818966\ttotal: 12.2s\tremaining: 4.24s\n",
      "742:\tlearn: 49540.4082426\ttotal: 12.3s\tremaining: 4.24s\n",
      "743:\tlearn: 49530.6988148\ttotal: 12.3s\tremaining: 4.22s\n",
      "744:\tlearn: 49513.6768632\ttotal: 12.3s\tremaining: 4.2s\n",
      "745:\tlearn: 49479.1767538\ttotal: 12.3s\tremaining: 4.19s\n",
      "746:\tlearn: 49475.4583167\ttotal: 12.3s\tremaining: 4.17s\n",
      "747:\tlearn: 49439.6053968\ttotal: 12.3s\tremaining: 4.15s\n",
      "748:\tlearn: 49425.0615518\ttotal: 12.3s\tremaining: 4.13s\n",
      "749:\tlearn: 49410.7066808\ttotal: 12.4s\tremaining: 4.12s\n",
      "750:\tlearn: 49388.3753200\ttotal: 12.4s\tremaining: 4.11s\n",
      "751:\tlearn: 49373.5527373\ttotal: 12.4s\tremaining: 4.09s\n",
      "752:\tlearn: 49344.2231857\ttotal: 12.4s\tremaining: 4.08s\n",
      "753:\tlearn: 49319.8000613\ttotal: 12.4s\tremaining: 4.06s\n",
      "754:\tlearn: 49306.3116884\ttotal: 12.4s\tremaining: 4.04s\n",
      "755:\tlearn: 49276.2541193\ttotal: 12.5s\tremaining: 4.02s\n",
      "756:\tlearn: 49272.5377218\ttotal: 12.5s\tremaining: 4s\n",
      "757:\tlearn: 49228.3936470\ttotal: 12.5s\tremaining: 3.99s\n",
      "758:\tlearn: 49191.8456188\ttotal: 12.5s\tremaining: 3.97s\n",
      "759:\tlearn: 49178.2316597\ttotal: 12.5s\tremaining: 3.95s\n",
      "760:\tlearn: 49163.0045787\ttotal: 12.5s\tremaining: 3.93s\n",
      "761:\tlearn: 49152.7220125\ttotal: 12.5s\tremaining: 3.92s\n",
      "762:\tlearn: 49141.5855494\ttotal: 12.5s\tremaining: 3.9s\n",
      "763:\tlearn: 49121.0896023\ttotal: 12.6s\tremaining: 3.88s\n",
      "764:\tlearn: 49115.4880315\ttotal: 12.6s\tremaining: 3.86s\n",
      "765:\tlearn: 49106.6207152\ttotal: 12.6s\tremaining: 3.85s\n",
      "766:\tlearn: 49063.9324053\ttotal: 12.6s\tremaining: 3.83s\n",
      "767:\tlearn: 49054.0313982\ttotal: 12.6s\tremaining: 3.82s\n",
      "768:\tlearn: 49019.1424882\ttotal: 12.7s\tremaining: 3.8s\n",
      "769:\tlearn: 49008.6734124\ttotal: 12.7s\tremaining: 3.78s\n",
      "770:\tlearn: 48995.6179106\ttotal: 12.7s\tremaining: 3.76s\n",
      "771:\tlearn: 48985.2691727\ttotal: 12.7s\tremaining: 3.75s\n",
      "772:\tlearn: 48968.6632738\ttotal: 12.7s\tremaining: 3.73s\n",
      "773:\tlearn: 48965.1381159\ttotal: 12.7s\tremaining: 3.71s\n",
      "774:\tlearn: 48958.5467684\ttotal: 12.7s\tremaining: 3.69s\n",
      "775:\tlearn: 48955.1528258\ttotal: 12.7s\tremaining: 3.68s\n",
      "776:\tlearn: 48949.4990608\ttotal: 12.7s\tremaining: 3.66s\n",
      "777:\tlearn: 48915.9312177\ttotal: 12.8s\tremaining: 3.64s\n",
      "778:\tlearn: 48885.1979070\ttotal: 12.8s\tremaining: 3.62s\n",
      "779:\tlearn: 48865.9458877\ttotal: 12.8s\tremaining: 3.61s\n",
      "780:\tlearn: 48862.8117799\ttotal: 12.8s\tremaining: 3.6s\n",
      "781:\tlearn: 48845.5823336\ttotal: 12.8s\tremaining: 3.58s\n",
      "782:\tlearn: 48842.6814111\ttotal: 12.8s\tremaining: 3.56s\n",
      "783:\tlearn: 48815.8107540\ttotal: 12.9s\tremaining: 3.54s\n",
      "784:\tlearn: 48802.9469134\ttotal: 12.9s\tremaining: 3.53s\n",
      "785:\tlearn: 48799.3509818\ttotal: 12.9s\tremaining: 3.51s\n",
      "786:\tlearn: 48787.6274974\ttotal: 12.9s\tremaining: 3.49s\n",
      "787:\tlearn: 48781.6432805\ttotal: 12.9s\tremaining: 3.47s\n",
      "788:\tlearn: 48757.8789663\ttotal: 12.9s\tremaining: 3.46s\n",
      "789:\tlearn: 48740.9713329\ttotal: 12.9s\tremaining: 3.44s\n",
      "790:\tlearn: 48727.0021769\ttotal: 13s\tremaining: 3.42s\n",
      "791:\tlearn: 48646.8888695\ttotal: 13s\tremaining: 3.4s\n",
      "792:\tlearn: 48605.8978397\ttotal: 13s\tremaining: 3.39s\n",
      "793:\tlearn: 48591.1543136\ttotal: 13s\tremaining: 3.37s\n",
      "794:\tlearn: 48588.3500987\ttotal: 13s\tremaining: 3.35s\n",
      "795:\tlearn: 48579.2294133\ttotal: 13s\tremaining: 3.34s\n",
      "796:\tlearn: 48568.3104198\ttotal: 13.1s\tremaining: 3.33s\n",
      "797:\tlearn: 48561.1704434\ttotal: 13.1s\tremaining: 3.31s\n",
      "798:\tlearn: 48552.3376707\ttotal: 13.1s\tremaining: 3.29s\n",
      "799:\tlearn: 48546.4393455\ttotal: 13.1s\tremaining: 3.28s\n",
      "800:\tlearn: 48535.4866238\ttotal: 13.1s\tremaining: 3.26s\n",
      "801:\tlearn: 48525.8795263\ttotal: 13.1s\tremaining: 3.24s\n",
      "802:\tlearn: 48515.2824207\ttotal: 13.2s\tremaining: 3.23s\n",
      "803:\tlearn: 48502.1659311\ttotal: 13.2s\tremaining: 3.21s\n",
      "804:\tlearn: 48462.8794317\ttotal: 13.2s\tremaining: 3.19s\n",
      "805:\tlearn: 48456.2544270\ttotal: 13.2s\tremaining: 3.17s\n",
      "806:\tlearn: 48446.4886304\ttotal: 13.2s\tremaining: 3.16s\n",
      "807:\tlearn: 48435.5097714\ttotal: 13.2s\tremaining: 3.14s\n",
      "808:\tlearn: 48407.9845193\ttotal: 13.2s\tremaining: 3.13s\n",
      "809:\tlearn: 48398.7335351\ttotal: 13.3s\tremaining: 3.11s\n",
      "810:\tlearn: 48360.7776598\ttotal: 13.3s\tremaining: 3.09s\n",
      "811:\tlearn: 48349.9306519\ttotal: 13.3s\tremaining: 3.08s\n",
      "812:\tlearn: 48343.8838723\ttotal: 13.3s\tremaining: 3.06s\n",
      "813:\tlearn: 48310.5094319\ttotal: 13.3s\tremaining: 3.04s\n",
      "814:\tlearn: 48296.1621379\ttotal: 13.3s\tremaining: 3.03s\n",
      "815:\tlearn: 48283.5742424\ttotal: 13.3s\tremaining: 3.01s\n",
      "816:\tlearn: 48272.2628277\ttotal: 13.4s\tremaining: 2.99s\n",
      "817:\tlearn: 48246.5414940\ttotal: 13.4s\tremaining: 2.97s\n",
      "818:\tlearn: 48236.1010277\ttotal: 13.4s\tremaining: 2.96s\n",
      "819:\tlearn: 48234.4959598\ttotal: 13.4s\tremaining: 2.94s\n",
      "820:\tlearn: 48225.0642722\ttotal: 13.4s\tremaining: 2.92s\n",
      "821:\tlearn: 48215.6135065\ttotal: 13.4s\tremaining: 2.9s\n",
      "822:\tlearn: 48193.0866817\ttotal: 13.4s\tremaining: 2.89s\n",
      "823:\tlearn: 48159.8857990\ttotal: 13.5s\tremaining: 2.87s\n",
      "824:\tlearn: 48146.8968078\ttotal: 13.5s\tremaining: 2.86s\n",
      "825:\tlearn: 48138.3058541\ttotal: 13.5s\tremaining: 2.84s\n",
      "826:\tlearn: 48062.4426489\ttotal: 13.5s\tremaining: 2.83s\n",
      "827:\tlearn: 48039.8686241\ttotal: 13.5s\tremaining: 2.81s\n",
      "828:\tlearn: 48014.9542606\ttotal: 13.5s\tremaining: 2.79s\n",
      "829:\tlearn: 48008.5072510\ttotal: 13.6s\tremaining: 2.77s\n",
      "830:\tlearn: 48005.8396563\ttotal: 13.6s\tremaining: 2.76s\n",
      "831:\tlearn: 47981.8014588\ttotal: 13.6s\tremaining: 2.74s\n",
      "832:\tlearn: 47975.7952512\ttotal: 13.6s\tremaining: 2.73s\n",
      "833:\tlearn: 47940.7940886\ttotal: 13.6s\tremaining: 2.71s\n",
      "834:\tlearn: 47936.8235180\ttotal: 13.6s\tremaining: 2.69s\n",
      "835:\tlearn: 47934.3726904\ttotal: 13.6s\tremaining: 2.68s\n",
      "836:\tlearn: 47926.6299159\ttotal: 13.7s\tremaining: 2.66s\n",
      "837:\tlearn: 47923.8415965\ttotal: 13.7s\tremaining: 2.64s\n",
      "838:\tlearn: 47918.1108289\ttotal: 13.8s\tremaining: 2.64s\n",
      "839:\tlearn: 47899.1951369\ttotal: 13.8s\tremaining: 2.63s\n",
      "840:\tlearn: 47893.1574215\ttotal: 13.8s\tremaining: 2.61s\n",
      "841:\tlearn: 47887.9103924\ttotal: 13.8s\tremaining: 2.59s\n",
      "842:\tlearn: 47877.3374087\ttotal: 13.8s\tremaining: 2.57s\n",
      "843:\tlearn: 47840.3579505\ttotal: 13.8s\tremaining: 2.56s\n",
      "844:\tlearn: 47804.6797686\ttotal: 13.9s\tremaining: 2.54s\n",
      "845:\tlearn: 47800.1761273\ttotal: 13.9s\tremaining: 2.52s\n",
      "846:\tlearn: 47790.1067244\ttotal: 13.9s\tremaining: 2.51s\n",
      "847:\tlearn: 47783.3797702\ttotal: 13.9s\tremaining: 2.49s\n",
      "848:\tlearn: 47759.9466222\ttotal: 13.9s\tremaining: 2.48s\n",
      "849:\tlearn: 47757.3935782\ttotal: 13.9s\tremaining: 2.46s\n",
      "850:\tlearn: 47747.0751668\ttotal: 14s\tremaining: 2.44s\n",
      "851:\tlearn: 47712.6092506\ttotal: 14s\tremaining: 2.43s\n",
      "852:\tlearn: 47704.6228911\ttotal: 14s\tremaining: 2.41s\n",
      "853:\tlearn: 47671.3647144\ttotal: 14s\tremaining: 2.39s\n",
      "854:\tlearn: 47658.2523528\ttotal: 14s\tremaining: 2.38s\n",
      "855:\tlearn: 47627.0439582\ttotal: 14s\tremaining: 2.36s\n",
      "856:\tlearn: 47594.6328530\ttotal: 14s\tremaining: 2.34s\n",
      "857:\tlearn: 47592.3112436\ttotal: 14.1s\tremaining: 2.33s\n",
      "858:\tlearn: 47581.7940768\ttotal: 14.1s\tremaining: 2.31s\n",
      "859:\tlearn: 47571.9791612\ttotal: 14.1s\tremaining: 2.29s\n",
      "860:\tlearn: 47500.3182675\ttotal: 14.1s\tremaining: 2.27s\n",
      "861:\tlearn: 47497.4764551\ttotal: 14.1s\tremaining: 2.26s\n",
      "862:\tlearn: 47488.4126789\ttotal: 14.1s\tremaining: 2.24s\n",
      "863:\tlearn: 47486.0761052\ttotal: 14.2s\tremaining: 2.23s\n",
      "864:\tlearn: 47480.9881457\ttotal: 14.2s\tremaining: 2.21s\n",
      "865:\tlearn: 47478.6176206\ttotal: 14.2s\tremaining: 2.19s\n",
      "866:\tlearn: 47456.0140494\ttotal: 14.2s\tremaining: 2.18s\n",
      "867:\tlearn: 47453.0101639\ttotal: 14.2s\tremaining: 2.16s\n",
      "868:\tlearn: 47448.7285819\ttotal: 14.2s\tremaining: 2.14s\n",
      "869:\tlearn: 47442.7335039\ttotal: 14.2s\tremaining: 2.13s\n",
      "870:\tlearn: 47420.9267035\ttotal: 14.2s\tremaining: 2.11s\n",
      "871:\tlearn: 47418.6849354\ttotal: 14.3s\tremaining: 2.09s\n",
      "872:\tlearn: 47399.1889617\ttotal: 14.3s\tremaining: 2.08s\n",
      "873:\tlearn: 47386.8807431\ttotal: 14.3s\tremaining: 2.06s\n",
      "874:\tlearn: 47355.7156020\ttotal: 14.3s\tremaining: 2.04s\n",
      "875:\tlearn: 47334.6532196\ttotal: 14.3s\tremaining: 2.03s\n",
      "876:\tlearn: 47313.8290753\ttotal: 14.3s\tremaining: 2.01s\n",
      "877:\tlearn: 47307.9754390\ttotal: 14.3s\tremaining: 1.99s\n",
      "878:\tlearn: 47301.4939975\ttotal: 14.4s\tremaining: 1.98s\n",
      "879:\tlearn: 47292.6042497\ttotal: 14.4s\tremaining: 1.96s\n",
      "880:\tlearn: 47281.2303374\ttotal: 14.4s\tremaining: 1.95s\n",
      "881:\tlearn: 47265.7831291\ttotal: 14.4s\tremaining: 1.93s\n",
      "882:\tlearn: 47245.4411363\ttotal: 14.4s\tremaining: 1.91s\n",
      "883:\tlearn: 47239.8070964\ttotal: 14.4s\tremaining: 1.9s\n",
      "884:\tlearn: 47208.5538464\ttotal: 14.5s\tremaining: 1.88s\n",
      "885:\tlearn: 47206.3869188\ttotal: 14.5s\tremaining: 1.86s\n",
      "886:\tlearn: 47151.3106806\ttotal: 14.5s\tremaining: 1.84s\n",
      "887:\tlearn: 47139.4782982\ttotal: 14.5s\tremaining: 1.83s\n",
      "888:\tlearn: 47138.2230211\ttotal: 14.5s\tremaining: 1.81s\n",
      "889:\tlearn: 47134.1999413\ttotal: 14.5s\tremaining: 1.79s\n",
      "890:\tlearn: 47114.5204968\ttotal: 14.5s\tremaining: 1.78s\n",
      "891:\tlearn: 47113.3217128\ttotal: 14.5s\tremaining: 1.76s\n",
      "892:\tlearn: 47110.4499348\ttotal: 14.6s\tremaining: 1.75s\n",
      "893:\tlearn: 47108.5177626\ttotal: 14.6s\tremaining: 1.73s\n",
      "894:\tlearn: 47106.6636997\ttotal: 14.6s\tremaining: 1.71s\n",
      "895:\tlearn: 47101.9834654\ttotal: 14.6s\tremaining: 1.7s\n",
      "896:\tlearn: 47084.7740025\ttotal: 14.6s\tremaining: 1.68s\n",
      "897:\tlearn: 47075.2241960\ttotal: 14.6s\tremaining: 1.66s\n",
      "898:\tlearn: 47073.1389915\ttotal: 14.7s\tremaining: 1.65s\n",
      "899:\tlearn: 47040.6535287\ttotal: 14.7s\tremaining: 1.63s\n",
      "900:\tlearn: 47031.0185515\ttotal: 14.7s\tremaining: 1.61s\n",
      "901:\tlearn: 46991.8989714\ttotal: 14.7s\tremaining: 1.59s\n",
      "902:\tlearn: 46985.9042033\ttotal: 14.7s\tremaining: 1.58s\n",
      "903:\tlearn: 46977.8841011\ttotal: 14.7s\tremaining: 1.56s\n",
      "904:\tlearn: 46972.5889749\ttotal: 14.7s\tremaining: 1.54s\n",
      "905:\tlearn: 46971.4327433\ttotal: 14.8s\tremaining: 1.53s\n",
      "906:\tlearn: 46965.6551638\ttotal: 14.8s\tremaining: 1.52s\n",
      "907:\tlearn: 46947.6684896\ttotal: 14.8s\tremaining: 1.5s\n",
      "908:\tlearn: 46936.7455729\ttotal: 14.8s\tremaining: 1.49s\n",
      "909:\tlearn: 46917.6963089\ttotal: 14.8s\tremaining: 1.47s\n",
      "910:\tlearn: 46912.1749265\ttotal: 14.9s\tremaining: 1.45s\n",
      "911:\tlearn: 46893.8034170\ttotal: 14.9s\tremaining: 1.44s\n",
      "912:\tlearn: 46873.3513093\ttotal: 14.9s\tremaining: 1.42s\n",
      "913:\tlearn: 46863.8871013\ttotal: 14.9s\tremaining: 1.4s\n",
      "914:\tlearn: 46844.1233515\ttotal: 14.9s\tremaining: 1.39s\n",
      "915:\tlearn: 46839.2665016\ttotal: 14.9s\tremaining: 1.37s\n",
      "916:\tlearn: 46830.5815235\ttotal: 14.9s\tremaining: 1.35s\n",
      "917:\tlearn: 46821.5184794\ttotal: 14.9s\tremaining: 1.33s\n",
      "918:\tlearn: 46812.2752374\ttotal: 15s\tremaining: 1.32s\n",
      "919:\tlearn: 46802.2677809\ttotal: 15s\tremaining: 1.3s\n",
      "920:\tlearn: 46795.1872683\ttotal: 15s\tremaining: 1.29s\n",
      "921:\tlearn: 46776.7556432\ttotal: 15s\tremaining: 1.27s\n",
      "922:\tlearn: 46761.8960881\ttotal: 15s\tremaining: 1.25s\n",
      "923:\tlearn: 46744.1085031\ttotal: 15.1s\tremaining: 1.24s\n",
      "924:\tlearn: 46739.9596895\ttotal: 15.1s\tremaining: 1.22s\n",
      "925:\tlearn: 46725.7929938\ttotal: 15.1s\tremaining: 1.21s\n",
      "926:\tlearn: 46718.2525045\ttotal: 15.1s\tremaining: 1.19s\n",
      "927:\tlearn: 46713.5907326\ttotal: 15.1s\tremaining: 1.17s\n",
      "928:\tlearn: 46681.2204466\ttotal: 15.1s\tremaining: 1.16s\n",
      "929:\tlearn: 46669.5749342\ttotal: 15.1s\tremaining: 1.14s\n",
      "930:\tlearn: 46666.9503329\ttotal: 15.1s\tremaining: 1.12s\n",
      "931:\tlearn: 46646.8031574\ttotal: 15.2s\tremaining: 1.11s\n",
      "932:\tlearn: 46629.6185645\ttotal: 15.2s\tremaining: 1.09s\n",
      "933:\tlearn: 46592.0124817\ttotal: 15.2s\tremaining: 1.07s\n",
      "934:\tlearn: 46585.1638622\ttotal: 15.2s\tremaining: 1.06s\n",
      "935:\tlearn: 46562.9953010\ttotal: 15.2s\tremaining: 1.04s\n",
      "936:\tlearn: 46531.5081204\ttotal: 15.3s\tremaining: 1.02s\n",
      "937:\tlearn: 46523.3381209\ttotal: 15.3s\tremaining: 1.01s\n",
      "938:\tlearn: 46494.2051670\ttotal: 15.3s\tremaining: 993ms\n",
      "939:\tlearn: 46493.2881919\ttotal: 15.3s\tremaining: 976ms\n",
      "940:\tlearn: 46476.6922088\ttotal: 15.3s\tremaining: 960ms\n",
      "941:\tlearn: 46468.2625743\ttotal: 15.3s\tremaining: 943ms\n",
      "942:\tlearn: 46452.1230166\ttotal: 15.3s\tremaining: 927ms\n",
      "943:\tlearn: 46418.8763015\ttotal: 15.3s\tremaining: 910ms\n",
      "944:\tlearn: 46414.9457317\ttotal: 15.4s\tremaining: 894ms\n",
      "945:\tlearn: 46409.8588143\ttotal: 15.4s\tremaining: 877ms\n",
      "946:\tlearn: 46404.3025961\ttotal: 15.4s\tremaining: 861ms\n",
      "947:\tlearn: 46385.4998312\ttotal: 15.4s\tremaining: 844ms\n",
      "948:\tlearn: 46368.5908523\ttotal: 15.4s\tremaining: 828ms\n",
      "949:\tlearn: 46347.8195972\ttotal: 15.4s\tremaining: 812ms\n",
      "950:\tlearn: 46316.5639850\ttotal: 15.4s\tremaining: 796ms\n",
      "951:\tlearn: 46297.8321762\ttotal: 15.5s\tremaining: 780ms\n",
      "952:\tlearn: 46277.9141165\ttotal: 15.5s\tremaining: 764ms\n",
      "953:\tlearn: 46259.9661884\ttotal: 15.5s\tremaining: 748ms\n",
      "954:\tlearn: 46240.8656824\ttotal: 15.5s\tremaining: 732ms\n",
      "955:\tlearn: 46222.5428263\ttotal: 15.5s\tremaining: 716ms\n",
      "956:\tlearn: 46199.9330961\ttotal: 15.6s\tremaining: 699ms\n",
      "957:\tlearn: 46176.6548263\ttotal: 15.6s\tremaining: 684ms\n",
      "958:\tlearn: 46154.7749792\ttotal: 15.6s\tremaining: 668ms\n",
      "959:\tlearn: 46137.1480935\ttotal: 15.6s\tremaining: 651ms\n",
      "960:\tlearn: 46116.5612334\ttotal: 15.6s\tremaining: 635ms\n",
      "961:\tlearn: 46114.7313369\ttotal: 15.7s\tremaining: 619ms\n",
      "962:\tlearn: 46105.4479342\ttotal: 15.7s\tremaining: 603ms\n",
      "963:\tlearn: 46097.1271513\ttotal: 15.7s\tremaining: 586ms\n",
      "964:\tlearn: 46047.7750269\ttotal: 15.7s\tremaining: 570ms\n",
      "965:\tlearn: 46042.3834419\ttotal: 15.7s\tremaining: 554ms\n",
      "966:\tlearn: 46033.2461418\ttotal: 15.7s\tremaining: 537ms\n",
      "967:\tlearn: 46005.6670840\ttotal: 15.8s\tremaining: 521ms\n",
      "968:\tlearn: 46001.8784090\ttotal: 15.8s\tremaining: 505ms\n",
      "969:\tlearn: 45994.0287128\ttotal: 15.8s\tremaining: 488ms\n",
      "970:\tlearn: 45972.1984330\ttotal: 15.8s\tremaining: 472ms\n",
      "971:\tlearn: 45963.6559329\ttotal: 15.8s\tremaining: 455ms\n",
      "972:\tlearn: 45932.1801112\ttotal: 15.8s\tremaining: 439ms\n",
      "973:\tlearn: 45924.5799397\ttotal: 15.8s\tremaining: 423ms\n",
      "974:\tlearn: 45914.9116282\ttotal: 15.8s\tremaining: 406ms\n",
      "975:\tlearn: 45897.8829710\ttotal: 15.9s\tremaining: 390ms\n",
      "976:\tlearn: 45888.9087872\ttotal: 15.9s\tremaining: 374ms\n",
      "977:\tlearn: 45869.4568529\ttotal: 15.9s\tremaining: 358ms\n",
      "978:\tlearn: 45862.3864648\ttotal: 15.9s\tremaining: 342ms\n",
      "979:\tlearn: 45854.2783180\ttotal: 15.9s\tremaining: 325ms\n",
      "980:\tlearn: 45853.3369954\ttotal: 16s\tremaining: 309ms\n",
      "981:\tlearn: 45845.4420105\ttotal: 16s\tremaining: 293ms\n",
      "982:\tlearn: 45832.5214456\ttotal: 16s\tremaining: 276ms\n",
      "983:\tlearn: 45807.3523131\ttotal: 16s\tremaining: 260ms\n",
      "984:\tlearn: 45803.6498979\ttotal: 16s\tremaining: 244ms\n",
      "985:\tlearn: 45796.3407173\ttotal: 16s\tremaining: 227ms\n",
      "986:\tlearn: 45784.4493611\ttotal: 16s\tremaining: 211ms\n",
      "987:\tlearn: 45756.5639003\ttotal: 16s\tremaining: 195ms\n",
      "988:\tlearn: 45748.9213339\ttotal: 16.1s\tremaining: 179ms\n",
      "989:\tlearn: 45718.6954891\ttotal: 16.1s\tremaining: 162ms\n",
      "990:\tlearn: 45716.1586228\ttotal: 16.1s\tremaining: 146ms\n",
      "991:\tlearn: 45701.5030661\ttotal: 16.1s\tremaining: 130ms\n",
      "992:\tlearn: 45696.7176055\ttotal: 16.1s\tremaining: 114ms\n",
      "993:\tlearn: 45691.9323045\ttotal: 16.1s\tremaining: 97.4ms\n",
      "994:\tlearn: 45631.2555925\ttotal: 16.2s\tremaining: 81.2ms\n",
      "995:\tlearn: 45615.0611029\ttotal: 16.2s\tremaining: 64.9ms\n",
      "996:\tlearn: 45608.2982028\ttotal: 16.2s\tremaining: 48.7ms\n",
      "997:\tlearn: 45599.5796971\ttotal: 16.2s\tremaining: 32.5ms\n",
      "998:\tlearn: 45590.9393914\ttotal: 16.2s\tremaining: 16.2ms\n",
      "999:\tlearn: 45566.8027348\ttotal: 16.2s\tremaining: 0us\n",
      "Learning rate set to 0.071717\n",
      "0:\tlearn: 79211.6642592\ttotal: 14.2ms\tremaining: 14.2s\n",
      "1:\tlearn: 78698.3208086\ttotal: 28.4ms\tremaining: 14.2s\n",
      "2:\tlearn: 78271.1830683\ttotal: 41.7ms\tremaining: 13.9s\n",
      "3:\tlearn: 77944.9512665\ttotal: 52.2ms\tremaining: 13s\n",
      "4:\tlearn: 77599.1120445\ttotal: 74.5ms\tremaining: 14.8s\n",
      "5:\tlearn: 77269.0201389\ttotal: 88.3ms\tremaining: 14.6s\n",
      "6:\tlearn: 76977.1085983\ttotal: 98.7ms\tremaining: 14s\n",
      "7:\tlearn: 76756.0931845\ttotal: 109ms\tremaining: 13.5s\n",
      "8:\tlearn: 76530.6995541\ttotal: 123ms\tremaining: 13.6s\n",
      "9:\tlearn: 76359.1890698\ttotal: 138ms\tremaining: 13.7s\n",
      "10:\tlearn: 76202.8980855\ttotal: 155ms\tremaining: 13.9s\n",
      "11:\tlearn: 76017.4223121\ttotal: 170ms\tremaining: 14s\n",
      "12:\tlearn: 75855.2395378\ttotal: 193ms\tremaining: 14.6s\n",
      "13:\tlearn: 75726.4208534\ttotal: 235ms\tremaining: 16.5s\n",
      "14:\tlearn: 75521.9242449\ttotal: 261ms\tremaining: 17.1s\n",
      "15:\tlearn: 75351.9087350\ttotal: 284ms\tremaining: 17.5s\n",
      "16:\tlearn: 75248.7907160\ttotal: 298ms\tremaining: 17.2s\n",
      "17:\tlearn: 75135.2558247\ttotal: 309ms\tremaining: 16.9s\n",
      "18:\tlearn: 75069.6563951\ttotal: 324ms\tremaining: 16.7s\n",
      "19:\tlearn: 74967.3721301\ttotal: 346ms\tremaining: 17s\n",
      "20:\tlearn: 74895.3533796\ttotal: 360ms\tremaining: 16.8s\n",
      "21:\tlearn: 74795.9793092\ttotal: 378ms\tremaining: 16.8s\n",
      "22:\tlearn: 74697.6242740\ttotal: 394ms\tremaining: 16.8s\n",
      "23:\tlearn: 74613.0850296\ttotal: 413ms\tremaining: 16.8s\n",
      "24:\tlearn: 74483.5047319\ttotal: 439ms\tremaining: 17.1s\n",
      "25:\tlearn: 74426.5085771\ttotal: 466ms\tremaining: 17.5s\n",
      "26:\tlearn: 74375.8071318\ttotal: 481ms\tremaining: 17.3s\n",
      "27:\tlearn: 74245.3224349\ttotal: 499ms\tremaining: 17.3s\n",
      "28:\tlearn: 74197.7025207\ttotal: 517ms\tremaining: 17.3s\n",
      "29:\tlearn: 74147.1239608\ttotal: 533ms\tremaining: 17.2s\n",
      "30:\tlearn: 74081.5352525\ttotal: 551ms\tremaining: 17.2s\n",
      "31:\tlearn: 74047.4055921\ttotal: 565ms\tremaining: 17.1s\n",
      "32:\tlearn: 74014.8118500\ttotal: 581ms\tremaining: 17s\n",
      "33:\tlearn: 73958.8553082\ttotal: 600ms\tremaining: 17s\n",
      "34:\tlearn: 73867.1138601\ttotal: 614ms\tremaining: 16.9s\n",
      "35:\tlearn: 73820.4609368\ttotal: 633ms\tremaining: 17s\n",
      "36:\tlearn: 73786.4736624\ttotal: 648ms\tremaining: 16.9s\n",
      "37:\tlearn: 73569.9279478\ttotal: 676ms\tremaining: 17.1s\n",
      "38:\tlearn: 73540.9050120\ttotal: 694ms\tremaining: 17.1s\n",
      "39:\tlearn: 73505.8060319\ttotal: 709ms\tremaining: 17s\n",
      "40:\tlearn: 73459.3777400\ttotal: 726ms\tremaining: 17s\n",
      "41:\tlearn: 73246.4896692\ttotal: 747ms\tremaining: 17s\n",
      "42:\tlearn: 73219.4298449\ttotal: 784ms\tremaining: 17.4s\n",
      "43:\tlearn: 73192.0726069\ttotal: 836ms\tremaining: 18.2s\n",
      "44:\tlearn: 73174.9916513\ttotal: 855ms\tremaining: 18.1s\n",
      "45:\tlearn: 73144.4687064\ttotal: 882ms\tremaining: 18.3s\n",
      "46:\tlearn: 73121.0080838\ttotal: 900ms\tremaining: 18.3s\n",
      "47:\tlearn: 72934.4982438\ttotal: 916ms\tremaining: 18.2s\n",
      "48:\tlearn: 72910.0528825\ttotal: 933ms\tremaining: 18.1s\n",
      "49:\tlearn: 72889.5337315\ttotal: 948ms\tremaining: 18s\n",
      "50:\tlearn: 72880.0307041\ttotal: 963ms\tremaining: 17.9s\n",
      "51:\tlearn: 72834.1756165\ttotal: 979ms\tremaining: 17.8s\n",
      "52:\tlearn: 72799.1432090\ttotal: 997ms\tremaining: 17.8s\n",
      "53:\tlearn: 72595.6681144\ttotal: 1.01s\tremaining: 17.7s\n",
      "54:\tlearn: 72583.3069071\ttotal: 1.02s\tremaining: 17.5s\n",
      "55:\tlearn: 72421.9291534\ttotal: 1.03s\tremaining: 17.4s\n",
      "56:\tlearn: 72413.0349058\ttotal: 1.05s\tremaining: 17.4s\n",
      "57:\tlearn: 72334.8397908\ttotal: 1.07s\tremaining: 17.3s\n",
      "58:\tlearn: 72293.1256618\ttotal: 1.1s\tremaining: 17.5s\n",
      "59:\tlearn: 72271.5807205\ttotal: 1.11s\tremaining: 17.4s\n",
      "60:\tlearn: 72259.6182421\ttotal: 1.11s\tremaining: 17.2s\n",
      "61:\tlearn: 72244.0363611\ttotal: 1.13s\tremaining: 17.1s\n",
      "62:\tlearn: 72235.7042025\ttotal: 1.13s\tremaining: 16.9s\n",
      "63:\tlearn: 72188.5137937\ttotal: 1.15s\tremaining: 16.8s\n",
      "64:\tlearn: 72171.9237872\ttotal: 1.16s\tremaining: 16.7s\n",
      "65:\tlearn: 71981.4158072\ttotal: 1.17s\tremaining: 16.6s\n",
      "66:\tlearn: 71961.3635676\ttotal: 1.2s\tremaining: 16.7s\n",
      "67:\tlearn: 71943.4973930\ttotal: 1.21s\tremaining: 16.6s\n",
      "68:\tlearn: 71923.0701322\ttotal: 1.22s\tremaining: 16.5s\n",
      "69:\tlearn: 71911.6648155\ttotal: 1.23s\tremaining: 16.4s\n",
      "70:\tlearn: 71760.7874232\ttotal: 1.24s\tremaining: 16.3s\n",
      "71:\tlearn: 71736.2527440\ttotal: 1.26s\tremaining: 16.2s\n",
      "72:\tlearn: 71578.6397966\ttotal: 1.27s\tremaining: 16.2s\n",
      "73:\tlearn: 71562.0812137\ttotal: 1.31s\tremaining: 16.4s\n",
      "74:\tlearn: 71553.4981156\ttotal: 1.32s\tremaining: 16.3s\n",
      "75:\tlearn: 71521.1208078\ttotal: 1.33s\tremaining: 16.2s\n",
      "76:\tlearn: 71507.8105544\ttotal: 1.34s\tremaining: 16.1s\n",
      "77:\tlearn: 71496.1598021\ttotal: 1.36s\tremaining: 16.1s\n",
      "78:\tlearn: 71483.8001160\ttotal: 1.37s\tremaining: 16s\n",
      "79:\tlearn: 71469.8506640\ttotal: 1.38s\tremaining: 15.9s\n",
      "80:\tlearn: 71425.4941590\ttotal: 1.39s\tremaining: 15.8s\n",
      "81:\tlearn: 71307.8779019\ttotal: 1.41s\tremaining: 15.7s\n",
      "82:\tlearn: 71188.9362627\ttotal: 1.42s\tremaining: 15.7s\n",
      "83:\tlearn: 71074.5393271\ttotal: 1.43s\tremaining: 15.6s\n",
      "84:\tlearn: 70970.2856687\ttotal: 1.44s\tremaining: 15.5s\n",
      "85:\tlearn: 70957.9731840\ttotal: 1.46s\tremaining: 15.5s\n",
      "86:\tlearn: 70940.3493139\ttotal: 1.47s\tremaining: 15.4s\n",
      "87:\tlearn: 70899.9917305\ttotal: 1.48s\tremaining: 15.3s\n",
      "88:\tlearn: 70777.5363564\ttotal: 1.5s\tremaining: 15.4s\n",
      "89:\tlearn: 70768.3461623\ttotal: 1.53s\tremaining: 15.5s\n",
      "90:\tlearn: 70675.9744694\ttotal: 1.56s\tremaining: 15.6s\n",
      "91:\tlearn: 70651.5682194\ttotal: 1.57s\tremaining: 15.6s\n",
      "92:\tlearn: 70595.7266592\ttotal: 1.62s\tremaining: 15.8s\n",
      "93:\tlearn: 70583.6318165\ttotal: 1.64s\tremaining: 15.8s\n",
      "94:\tlearn: 70571.5091597\ttotal: 1.67s\tremaining: 15.9s\n",
      "95:\tlearn: 70560.3024870\ttotal: 1.69s\tremaining: 15.9s\n",
      "96:\tlearn: 70531.3224993\ttotal: 1.71s\tremaining: 15.9s\n",
      "97:\tlearn: 70524.0075136\ttotal: 1.73s\tremaining: 15.9s\n",
      "98:\tlearn: 70522.8630709\ttotal: 1.75s\tremaining: 15.9s\n",
      "99:\tlearn: 70423.5779644\ttotal: 1.77s\tremaining: 15.9s\n",
      "100:\tlearn: 70414.6784895\ttotal: 1.78s\tremaining: 15.9s\n",
      "101:\tlearn: 70352.8375538\ttotal: 1.8s\tremaining: 15.9s\n",
      "102:\tlearn: 70278.1590306\ttotal: 1.82s\tremaining: 15.8s\n",
      "103:\tlearn: 70159.6195264\ttotal: 1.83s\tremaining: 15.8s\n",
      "104:\tlearn: 70140.6152400\ttotal: 1.85s\tremaining: 15.8s\n",
      "105:\tlearn: 70126.8843465\ttotal: 1.86s\tremaining: 15.7s\n",
      "106:\tlearn: 70077.0267231\ttotal: 1.87s\tremaining: 15.6s\n",
      "107:\tlearn: 70053.1329271\ttotal: 1.89s\tremaining: 15.6s\n",
      "108:\tlearn: 70046.4449952\ttotal: 1.9s\tremaining: 15.5s\n",
      "109:\tlearn: 70037.8188514\ttotal: 1.91s\tremaining: 15.4s\n",
      "110:\tlearn: 70032.1499483\ttotal: 1.92s\tremaining: 15.4s\n",
      "111:\tlearn: 69972.9599919\ttotal: 1.94s\tremaining: 15.4s\n",
      "112:\tlearn: 69913.8970479\ttotal: 1.97s\tremaining: 15.5s\n",
      "113:\tlearn: 69877.5933944\ttotal: 1.99s\tremaining: 15.5s\n",
      "114:\tlearn: 69825.2114810\ttotal: 2s\tremaining: 15.4s\n",
      "115:\tlearn: 69773.0518539\ttotal: 2.02s\tremaining: 15.4s\n",
      "116:\tlearn: 69767.7107482\ttotal: 2.03s\tremaining: 15.3s\n",
      "117:\tlearn: 69762.7440909\ttotal: 2.05s\tremaining: 15.3s\n",
      "118:\tlearn: 69749.5845075\ttotal: 2.05s\tremaining: 15.2s\n",
      "119:\tlearn: 69719.0896454\ttotal: 2.08s\tremaining: 15.3s\n",
      "120:\tlearn: 69714.2261176\ttotal: 2.09s\tremaining: 15.2s\n",
      "121:\tlearn: 69706.5340845\ttotal: 2.1s\tremaining: 15.1s\n",
      "122:\tlearn: 69591.4404223\ttotal: 2.11s\tremaining: 15.1s\n",
      "123:\tlearn: 69583.5015525\ttotal: 2.13s\tremaining: 15s\n",
      "124:\tlearn: 69482.1116137\ttotal: 2.15s\tremaining: 15s\n",
      "125:\tlearn: 69389.0061989\ttotal: 2.25s\tremaining: 15.6s\n",
      "126:\tlearn: 69316.4790788\ttotal: 2.26s\tremaining: 15.6s\n",
      "127:\tlearn: 69312.0373408\ttotal: 2.27s\tremaining: 15.5s\n",
      "128:\tlearn: 69304.8498104\ttotal: 2.28s\tremaining: 15.4s\n",
      "129:\tlearn: 69288.8679068\ttotal: 2.3s\tremaining: 15.4s\n",
      "130:\tlearn: 69220.1955701\ttotal: 2.31s\tremaining: 15.3s\n",
      "131:\tlearn: 69116.1008685\ttotal: 2.32s\tremaining: 15.2s\n",
      "132:\tlearn: 68983.4172215\ttotal: 2.33s\tremaining: 15.2s\n",
      "133:\tlearn: 68977.0899034\ttotal: 2.35s\tremaining: 15.2s\n",
      "134:\tlearn: 68949.1938825\ttotal: 2.36s\tremaining: 15.1s\n",
      "135:\tlearn: 68848.1055167\ttotal: 2.39s\tremaining: 15.2s\n",
      "136:\tlearn: 68771.0129080\ttotal: 2.41s\tremaining: 15.2s\n",
      "137:\tlearn: 68726.9617777\ttotal: 2.42s\tremaining: 15.1s\n",
      "138:\tlearn: 68720.3976870\ttotal: 2.43s\tremaining: 15.1s\n",
      "139:\tlearn: 68657.9420724\ttotal: 2.45s\tremaining: 15s\n",
      "140:\tlearn: 68603.5940014\ttotal: 2.46s\tremaining: 15s\n",
      "141:\tlearn: 68564.4844047\ttotal: 2.47s\tremaining: 14.9s\n",
      "142:\tlearn: 68560.6924926\ttotal: 2.48s\tremaining: 14.9s\n",
      "143:\tlearn: 68473.9382309\ttotal: 2.49s\tremaining: 14.8s\n",
      "144:\tlearn: 68422.9439518\ttotal: 2.5s\tremaining: 14.8s\n",
      "145:\tlearn: 68374.0374375\ttotal: 2.52s\tremaining: 14.7s\n",
      "146:\tlearn: 68347.4610408\ttotal: 2.53s\tremaining: 14.7s\n",
      "147:\tlearn: 68265.4661797\ttotal: 2.55s\tremaining: 14.7s\n",
      "148:\tlearn: 68259.2483926\ttotal: 2.56s\tremaining: 14.6s\n",
      "149:\tlearn: 68116.0833158\ttotal: 2.57s\tremaining: 14.6s\n",
      "150:\tlearn: 68041.0553725\ttotal: 2.58s\tremaining: 14.5s\n",
      "151:\tlearn: 67916.9832121\ttotal: 2.6s\tremaining: 14.5s\n",
      "152:\tlearn: 67910.7744798\ttotal: 2.62s\tremaining: 14.5s\n",
      "153:\tlearn: 67907.5182003\ttotal: 2.64s\tremaining: 14.5s\n",
      "154:\tlearn: 67867.3557889\ttotal: 2.65s\tremaining: 14.5s\n",
      "155:\tlearn: 67850.6646748\ttotal: 2.67s\tremaining: 14.4s\n",
      "156:\tlearn: 67834.1217677\ttotal: 2.68s\tremaining: 14.4s\n",
      "157:\tlearn: 67804.1045980\ttotal: 2.69s\tremaining: 14.3s\n",
      "158:\tlearn: 67774.4587450\ttotal: 2.7s\tremaining: 14.3s\n",
      "159:\tlearn: 67707.1512744\ttotal: 2.72s\tremaining: 14.3s\n",
      "160:\tlearn: 67672.5452554\ttotal: 2.72s\tremaining: 14.2s\n",
      "161:\tlearn: 67610.9292501\ttotal: 2.75s\tremaining: 14.2s\n",
      "162:\tlearn: 67525.6910868\ttotal: 2.75s\tremaining: 14.1s\n",
      "163:\tlearn: 67480.0885572\ttotal: 2.77s\tremaining: 14.1s\n",
      "164:\tlearn: 67393.2148951\ttotal: 2.78s\tremaining: 14.1s\n",
      "165:\tlearn: 67310.8764389\ttotal: 2.79s\tremaining: 14s\n",
      "166:\tlearn: 67273.6710747\ttotal: 2.81s\tremaining: 14s\n",
      "167:\tlearn: 67191.1742054\ttotal: 2.83s\tremaining: 14s\n",
      "168:\tlearn: 67125.7505204\ttotal: 2.86s\tremaining: 14s\n",
      "169:\tlearn: 67045.9100279\ttotal: 2.88s\tremaining: 14s\n",
      "170:\tlearn: 67042.6338473\ttotal: 2.88s\tremaining: 14s\n",
      "171:\tlearn: 67010.5318933\ttotal: 2.9s\tremaining: 13.9s\n",
      "172:\tlearn: 67006.7396259\ttotal: 2.91s\tremaining: 13.9s\n",
      "173:\tlearn: 66990.9347527\ttotal: 2.92s\tremaining: 13.9s\n",
      "174:\tlearn: 66945.5753448\ttotal: 2.94s\tremaining: 13.8s\n",
      "175:\tlearn: 66866.7275514\ttotal: 2.96s\tremaining: 13.8s\n",
      "176:\tlearn: 66818.8543592\ttotal: 2.97s\tremaining: 13.8s\n",
      "177:\tlearn: 66759.9435248\ttotal: 2.98s\tremaining: 13.8s\n",
      "178:\tlearn: 66731.2668131\ttotal: 3s\tremaining: 13.8s\n",
      "179:\tlearn: 66642.6705239\ttotal: 3.01s\tremaining: 13.7s\n",
      "180:\tlearn: 66607.9280997\ttotal: 3.03s\tremaining: 13.7s\n",
      "181:\tlearn: 66544.6213549\ttotal: 3.05s\tremaining: 13.7s\n",
      "182:\tlearn: 66519.4186744\ttotal: 3.08s\tremaining: 13.7s\n",
      "183:\tlearn: 66478.8497302\ttotal: 3.1s\tremaining: 13.7s\n",
      "184:\tlearn: 66475.3415536\ttotal: 3.11s\tremaining: 13.7s\n",
      "185:\tlearn: 66467.4253288\ttotal: 3.12s\tremaining: 13.7s\n",
      "186:\tlearn: 66443.0557343\ttotal: 3.13s\tremaining: 13.6s\n",
      "187:\tlearn: 66438.7148328\ttotal: 3.15s\tremaining: 13.6s\n",
      "188:\tlearn: 66382.0082504\ttotal: 3.16s\tremaining: 13.6s\n",
      "189:\tlearn: 66378.8447600\ttotal: 3.18s\tremaining: 13.5s\n",
      "190:\tlearn: 66330.0723172\ttotal: 3.19s\tremaining: 13.5s\n",
      "191:\tlearn: 66317.6194140\ttotal: 3.2s\tremaining: 13.5s\n",
      "192:\tlearn: 66285.8070515\ttotal: 3.21s\tremaining: 13.4s\n",
      "193:\tlearn: 66199.1326743\ttotal: 3.23s\tremaining: 13.4s\n",
      "194:\tlearn: 66158.8376053\ttotal: 3.25s\tremaining: 13.4s\n",
      "195:\tlearn: 66111.1660870\ttotal: 3.29s\tremaining: 13.5s\n",
      "196:\tlearn: 66072.4065309\ttotal: 3.3s\tremaining: 13.5s\n",
      "197:\tlearn: 66039.4893206\ttotal: 3.31s\tremaining: 13.4s\n",
      "198:\tlearn: 66030.2375832\ttotal: 3.33s\tremaining: 13.4s\n",
      "199:\tlearn: 65949.0991701\ttotal: 3.34s\tremaining: 13.4s\n",
      "200:\tlearn: 65888.3511292\ttotal: 3.36s\tremaining: 13.4s\n",
      "201:\tlearn: 65796.6950779\ttotal: 3.37s\tremaining: 13.3s\n",
      "202:\tlearn: 65719.7542139\ttotal: 3.39s\tremaining: 13.3s\n",
      "203:\tlearn: 65711.2698909\ttotal: 3.4s\tremaining: 13.2s\n",
      "204:\tlearn: 65679.9622426\ttotal: 3.41s\tremaining: 13.2s\n",
      "205:\tlearn: 65607.5227891\ttotal: 3.42s\tremaining: 13.2s\n",
      "206:\tlearn: 65532.6712511\ttotal: 3.43s\tremaining: 13.2s\n",
      "207:\tlearn: 65521.2300642\ttotal: 3.44s\tremaining: 13.1s\n",
      "208:\tlearn: 65451.2917775\ttotal: 3.45s\tremaining: 13.1s\n",
      "209:\tlearn: 65388.0257614\ttotal: 3.47s\tremaining: 13.1s\n",
      "210:\tlearn: 65355.1739501\ttotal: 3.5s\tremaining: 13.1s\n",
      "211:\tlearn: 65326.1819405\ttotal: 3.52s\tremaining: 13.1s\n",
      "212:\tlearn: 65260.5521802\ttotal: 3.53s\tremaining: 13s\n",
      "213:\tlearn: 65257.4087395\ttotal: 3.54s\tremaining: 13s\n",
      "214:\tlearn: 65229.2266375\ttotal: 3.55s\tremaining: 13s\n",
      "215:\tlearn: 65147.0051836\ttotal: 3.56s\tremaining: 12.9s\n",
      "216:\tlearn: 65052.5983756\ttotal: 3.57s\tremaining: 12.9s\n",
      "217:\tlearn: 65044.8359183\ttotal: 3.59s\tremaining: 12.9s\n",
      "218:\tlearn: 64970.3812934\ttotal: 3.6s\tremaining: 12.8s\n",
      "219:\tlearn: 64957.4565237\ttotal: 3.62s\tremaining: 12.8s\n",
      "220:\tlearn: 64954.5548565\ttotal: 3.63s\tremaining: 12.8s\n",
      "221:\tlearn: 64925.0474051\ttotal: 3.63s\tremaining: 12.7s\n",
      "222:\tlearn: 64892.7109861\ttotal: 3.65s\tremaining: 12.7s\n",
      "223:\tlearn: 64889.8867577\ttotal: 3.67s\tremaining: 12.7s\n",
      "224:\tlearn: 64863.3668132\ttotal: 3.68s\tremaining: 12.7s\n",
      "225:\tlearn: 64860.6671573\ttotal: 3.69s\tremaining: 12.7s\n",
      "226:\tlearn: 64858.0814647\ttotal: 3.71s\tremaining: 12.6s\n",
      "227:\tlearn: 64855.6053234\ttotal: 3.72s\tremaining: 12.6s\n",
      "228:\tlearn: 64792.7207820\ttotal: 3.75s\tremaining: 12.6s\n",
      "229:\tlearn: 64759.1668195\ttotal: 3.77s\tremaining: 12.6s\n",
      "230:\tlearn: 64733.7094479\ttotal: 3.78s\tremaining: 12.6s\n",
      "231:\tlearn: 64682.5916637\ttotal: 3.8s\tremaining: 12.6s\n",
      "232:\tlearn: 64680.2131942\ttotal: 3.81s\tremaining: 12.5s\n",
      "233:\tlearn: 64620.7021879\ttotal: 3.83s\tremaining: 12.5s\n",
      "234:\tlearn: 64565.4150853\ttotal: 3.83s\tremaining: 12.5s\n",
      "235:\tlearn: 64540.7173692\ttotal: 3.85s\tremaining: 12.4s\n",
      "236:\tlearn: 64516.6701201\ttotal: 3.86s\tremaining: 12.4s\n",
      "237:\tlearn: 64447.3480399\ttotal: 3.87s\tremaining: 12.4s\n",
      "238:\tlearn: 64403.1687643\ttotal: 3.88s\tremaining: 12.4s\n",
      "239:\tlearn: 64336.3364612\ttotal: 3.92s\tremaining: 12.4s\n",
      "240:\tlearn: 64331.6306597\ttotal: 3.94s\tremaining: 12.4s\n",
      "241:\tlearn: 64303.3246841\ttotal: 3.95s\tremaining: 12.4s\n",
      "242:\tlearn: 64297.8037518\ttotal: 3.96s\tremaining: 12.3s\n",
      "243:\tlearn: 64290.4478112\ttotal: 3.98s\tremaining: 12.3s\n",
      "244:\tlearn: 64226.0040009\ttotal: 3.99s\tremaining: 12.3s\n",
      "245:\tlearn: 64182.0206834\ttotal: 4s\tremaining: 12.3s\n",
      "246:\tlearn: 64119.9115419\ttotal: 4.02s\tremaining: 12.2s\n",
      "247:\tlearn: 64086.8726715\ttotal: 4.03s\tremaining: 12.2s\n",
      "248:\tlearn: 64058.8431672\ttotal: 4.04s\tremaining: 12.2s\n",
      "249:\tlearn: 64057.1909701\ttotal: 4.05s\tremaining: 12.1s\n",
      "250:\tlearn: 63997.2990408\ttotal: 4.06s\tremaining: 12.1s\n",
      "251:\tlearn: 63990.5936231\ttotal: 4.07s\tremaining: 12.1s\n",
      "252:\tlearn: 63942.0076156\ttotal: 4.08s\tremaining: 12.1s\n",
      "253:\tlearn: 63928.1319910\ttotal: 4.57s\tremaining: 13.4s\n",
      "254:\tlearn: 63882.8875655\ttotal: 4.59s\tremaining: 13.4s\n",
      "255:\tlearn: 63878.4970035\ttotal: 4.6s\tremaining: 13.4s\n",
      "256:\tlearn: 63820.6458528\ttotal: 4.91s\tremaining: 14.2s\n",
      "257:\tlearn: 63764.8884747\ttotal: 4.95s\tremaining: 14.2s\n",
      "258:\tlearn: 63746.2524045\ttotal: 5.05s\tremaining: 14.4s\n",
      "259:\tlearn: 63739.8618189\ttotal: 5.06s\tremaining: 14.4s\n",
      "260:\tlearn: 63714.3722031\ttotal: 5.07s\tremaining: 14.4s\n",
      "261:\tlearn: 63660.5852456\ttotal: 5.09s\tremaining: 14.3s\n",
      "262:\tlearn: 63643.5458443\ttotal: 5.1s\tremaining: 14.3s\n",
      "263:\tlearn: 63591.6815019\ttotal: 5.11s\tremaining: 14.3s\n",
      "264:\tlearn: 63541.6822510\ttotal: 5.24s\tremaining: 14.5s\n",
      "265:\tlearn: 63493.4821984\ttotal: 5.25s\tremaining: 14.5s\n",
      "266:\tlearn: 63467.2764093\ttotal: 5.27s\tremaining: 14.5s\n",
      "267:\tlearn: 63438.1867367\ttotal: 5.28s\tremaining: 14.4s\n",
      "268:\tlearn: 63429.2604781\ttotal: 5.29s\tremaining: 14.4s\n",
      "269:\tlearn: 63412.8055046\ttotal: 5.3s\tremaining: 14.3s\n",
      "270:\tlearn: 63397.3205321\ttotal: 5.32s\tremaining: 14.3s\n",
      "271:\tlearn: 63384.0731402\ttotal: 5.33s\tremaining: 14.3s\n",
      "272:\tlearn: 63333.4476470\ttotal: 5.34s\tremaining: 14.2s\n",
      "273:\tlearn: 63290.3188423\ttotal: 5.35s\tremaining: 14.2s\n",
      "274:\tlearn: 63289.3677680\ttotal: 5.37s\tremaining: 14.1s\n",
      "275:\tlearn: 63285.7866315\ttotal: 5.38s\tremaining: 14.1s\n",
      "276:\tlearn: 63267.9271764\ttotal: 5.4s\tremaining: 14.1s\n",
      "277:\tlearn: 63221.2805936\ttotal: 5.41s\tremaining: 14s\n",
      "278:\tlearn: 63211.2568100\ttotal: 5.42s\tremaining: 14s\n",
      "279:\tlearn: 63166.2734419\ttotal: 5.43s\tremaining: 14s\n",
      "280:\tlearn: 63107.1882492\ttotal: 5.45s\tremaining: 13.9s\n",
      "281:\tlearn: 63052.8073982\ttotal: 5.47s\tremaining: 13.9s\n",
      "282:\tlearn: 63049.5707879\ttotal: 5.5s\tremaining: 13.9s\n",
      "283:\tlearn: 63006.1341172\ttotal: 5.51s\tremaining: 13.9s\n",
      "284:\tlearn: 62989.5277347\ttotal: 5.52s\tremaining: 13.9s\n",
      "285:\tlearn: 62977.2970956\ttotal: 5.53s\tremaining: 13.8s\n",
      "286:\tlearn: 62900.6645471\ttotal: 5.55s\tremaining: 13.8s\n",
      "287:\tlearn: 62793.7080743\ttotal: 5.56s\tremaining: 13.8s\n",
      "288:\tlearn: 62750.2093906\ttotal: 5.58s\tremaining: 13.7s\n",
      "289:\tlearn: 62708.2638792\ttotal: 5.59s\tremaining: 13.7s\n",
      "290:\tlearn: 62648.5216894\ttotal: 5.61s\tremaining: 13.7s\n",
      "291:\tlearn: 62623.8583283\ttotal: 5.61s\tremaining: 13.6s\n",
      "292:\tlearn: 62603.1734255\ttotal: 5.63s\tremaining: 13.6s\n",
      "293:\tlearn: 62587.1850992\ttotal: 5.64s\tremaining: 13.5s\n",
      "294:\tlearn: 62584.0355470\ttotal: 5.64s\tremaining: 13.5s\n",
      "295:\tlearn: 62543.4854615\ttotal: 5.68s\tremaining: 13.5s\n",
      "296:\tlearn: 62504.3823751\ttotal: 5.7s\tremaining: 13.5s\n",
      "297:\tlearn: 62466.6734001\ttotal: 5.71s\tremaining: 13.5s\n",
      "298:\tlearn: 62446.7811246\ttotal: 5.72s\tremaining: 13.4s\n",
      "299:\tlearn: 62428.7697393\ttotal: 5.74s\tremaining: 13.4s\n",
      "300:\tlearn: 62425.7020252\ttotal: 5.75s\tremaining: 13.3s\n",
      "301:\tlearn: 62386.2658058\ttotal: 5.76s\tremaining: 13.3s\n",
      "302:\tlearn: 62348.5021182\ttotal: 5.78s\tremaining: 13.3s\n",
      "303:\tlearn: 62333.0672797\ttotal: 5.79s\tremaining: 13.3s\n",
      "304:\tlearn: 62329.6072059\ttotal: 5.8s\tremaining: 13.2s\n",
      "305:\tlearn: 62309.3532627\ttotal: 5.81s\tremaining: 13.2s\n",
      "306:\tlearn: 62307.6168646\ttotal: 5.83s\tremaining: 13.2s\n",
      "307:\tlearn: 62272.3326786\ttotal: 5.84s\tremaining: 13.1s\n",
      "308:\tlearn: 62205.2225269\ttotal: 5.84s\tremaining: 13.1s\n",
      "309:\tlearn: 62148.0116247\ttotal: 5.86s\tremaining: 13s\n",
      "310:\tlearn: 62110.0838639\ttotal: 5.87s\tremaining: 13s\n",
      "311:\tlearn: 62011.7611447\ttotal: 5.89s\tremaining: 13s\n",
      "312:\tlearn: 61974.8500745\ttotal: 5.91s\tremaining: 13s\n",
      "313:\tlearn: 61956.2274532\ttotal: 5.93s\tremaining: 13s\n",
      "314:\tlearn: 61926.0284700\ttotal: 5.95s\tremaining: 12.9s\n",
      "315:\tlearn: 61911.2264843\ttotal: 5.96s\tremaining: 12.9s\n",
      "316:\tlearn: 61872.4720847\ttotal: 5.98s\tremaining: 12.9s\n",
      "317:\tlearn: 61853.3003603\ttotal: 5.99s\tremaining: 12.9s\n",
      "318:\tlearn: 61841.0478035\ttotal: 6.01s\tremaining: 12.8s\n",
      "319:\tlearn: 61818.7731454\ttotal: 6.02s\tremaining: 12.8s\n",
      "320:\tlearn: 61762.5816073\ttotal: 6.03s\tremaining: 12.8s\n",
      "321:\tlearn: 61748.3114968\ttotal: 6.04s\tremaining: 12.7s\n",
      "322:\tlearn: 61692.5211948\ttotal: 6.05s\tremaining: 12.7s\n",
      "323:\tlearn: 61657.4509175\ttotal: 6.06s\tremaining: 12.7s\n",
      "324:\tlearn: 61636.7443546\ttotal: 6.08s\tremaining: 12.6s\n",
      "325:\tlearn: 61630.3782962\ttotal: 6.1s\tremaining: 12.6s\n",
      "326:\tlearn: 61581.5116410\ttotal: 6.11s\tremaining: 12.6s\n",
      "327:\tlearn: 61548.4326637\ttotal: 6.14s\tremaining: 12.6s\n",
      "328:\tlearn: 61513.6266593\ttotal: 6.16s\tremaining: 12.6s\n",
      "329:\tlearn: 61468.2346489\ttotal: 6.17s\tremaining: 12.5s\n",
      "330:\tlearn: 61433.3690101\ttotal: 6.2s\tremaining: 12.5s\n",
      "331:\tlearn: 61393.8101563\ttotal: 6.21s\tremaining: 12.5s\n",
      "332:\tlearn: 61323.5294399\ttotal: 6.22s\tremaining: 12.5s\n",
      "333:\tlearn: 61302.9285813\ttotal: 6.23s\tremaining: 12.4s\n",
      "334:\tlearn: 61273.1623334\ttotal: 6.24s\tremaining: 12.4s\n",
      "335:\tlearn: 61245.3095464\ttotal: 6.25s\tremaining: 12.4s\n",
      "336:\tlearn: 61239.5189620\ttotal: 6.27s\tremaining: 12.3s\n",
      "337:\tlearn: 61225.6826732\ttotal: 6.28s\tremaining: 12.3s\n",
      "338:\tlearn: 61202.0056838\ttotal: 6.3s\tremaining: 12.3s\n",
      "339:\tlearn: 61177.1195424\ttotal: 6.32s\tremaining: 12.3s\n",
      "340:\tlearn: 61147.0479932\ttotal: 6.33s\tremaining: 12.2s\n",
      "341:\tlearn: 61122.9054011\ttotal: 6.35s\tremaining: 12.2s\n",
      "342:\tlearn: 61091.9225939\ttotal: 6.37s\tremaining: 12.2s\n",
      "343:\tlearn: 61078.5123532\ttotal: 6.38s\tremaining: 12.2s\n",
      "344:\tlearn: 61029.4232409\ttotal: 6.39s\tremaining: 12.1s\n",
      "345:\tlearn: 61008.4789201\ttotal: 6.41s\tremaining: 12.1s\n",
      "346:\tlearn: 60977.2331055\ttotal: 6.42s\tremaining: 12.1s\n",
      "347:\tlearn: 60947.8732107\ttotal: 6.43s\tremaining: 12.1s\n",
      "348:\tlearn: 60928.8362395\ttotal: 6.45s\tremaining: 12s\n",
      "349:\tlearn: 60915.9158580\ttotal: 6.46s\tremaining: 12s\n",
      "350:\tlearn: 60877.9284059\ttotal: 6.47s\tremaining: 12s\n",
      "351:\tlearn: 60864.9074679\ttotal: 6.48s\tremaining: 11.9s\n",
      "352:\tlearn: 60834.9490563\ttotal: 6.49s\tremaining: 11.9s\n",
      "353:\tlearn: 60751.4764955\ttotal: 6.51s\tremaining: 11.9s\n",
      "354:\tlearn: 60710.9816476\ttotal: 6.53s\tremaining: 11.9s\n",
      "355:\tlearn: 60675.2664361\ttotal: 6.55s\tremaining: 11.8s\n",
      "356:\tlearn: 60670.1231620\ttotal: 6.57s\tremaining: 11.8s\n",
      "357:\tlearn: 60641.1505617\ttotal: 6.59s\tremaining: 11.8s\n",
      "358:\tlearn: 60625.6324049\ttotal: 6.61s\tremaining: 11.8s\n",
      "359:\tlearn: 60596.0012979\ttotal: 6.63s\tremaining: 11.8s\n",
      "360:\tlearn: 60569.0411824\ttotal: 6.64s\tremaining: 11.8s\n",
      "361:\tlearn: 60551.1585969\ttotal: 6.65s\tremaining: 11.7s\n",
      "362:\tlearn: 60532.7287903\ttotal: 6.67s\tremaining: 11.7s\n",
      "363:\tlearn: 60520.1283153\ttotal: 6.68s\tremaining: 11.7s\n",
      "364:\tlearn: 60460.5144594\ttotal: 6.69s\tremaining: 11.6s\n",
      "365:\tlearn: 60433.1362939\ttotal: 6.71s\tremaining: 11.6s\n",
      "366:\tlearn: 60405.5773321\ttotal: 6.73s\tremaining: 11.6s\n",
      "367:\tlearn: 60387.8469242\ttotal: 6.76s\tremaining: 11.6s\n",
      "368:\tlearn: 60375.8088183\ttotal: 6.78s\tremaining: 11.6s\n",
      "369:\tlearn: 60350.6646674\ttotal: 6.8s\tremaining: 11.6s\n",
      "370:\tlearn: 60294.3429429\ttotal: 6.81s\tremaining: 11.5s\n",
      "371:\tlearn: 60265.8879245\ttotal: 6.83s\tremaining: 11.5s\n",
      "372:\tlearn: 60241.6011738\ttotal: 6.84s\tremaining: 11.5s\n",
      "373:\tlearn: 60187.2953048\ttotal: 6.86s\tremaining: 11.5s\n",
      "374:\tlearn: 60134.9770231\ttotal: 6.87s\tremaining: 11.5s\n",
      "375:\tlearn: 60113.4800516\ttotal: 6.88s\tremaining: 11.4s\n",
      "376:\tlearn: 60078.8661089\ttotal: 6.89s\tremaining: 11.4s\n",
      "377:\tlearn: 60029.5601518\ttotal: 6.91s\tremaining: 11.4s\n",
      "378:\tlearn: 60023.6563197\ttotal: 6.92s\tremaining: 11.3s\n",
      "379:\tlearn: 59976.2281689\ttotal: 6.93s\tremaining: 11.3s\n",
      "380:\tlearn: 59952.7866350\ttotal: 6.95s\tremaining: 11.3s\n",
      "381:\tlearn: 59896.7411778\ttotal: 6.98s\tremaining: 11.3s\n",
      "382:\tlearn: 59871.2451582\ttotal: 7s\tremaining: 11.3s\n",
      "383:\tlearn: 59858.9863518\ttotal: 7.01s\tremaining: 11.2s\n",
      "384:\tlearn: 59836.7309939\ttotal: 7.03s\tremaining: 11.2s\n",
      "385:\tlearn: 59784.5761414\ttotal: 7.04s\tremaining: 11.2s\n",
      "386:\tlearn: 59775.0323868\ttotal: 7.06s\tremaining: 11.2s\n",
      "387:\tlearn: 59749.6465786\ttotal: 7.07s\tremaining: 11.2s\n",
      "388:\tlearn: 59727.0767801\ttotal: 7.08s\tremaining: 11.1s\n",
      "389:\tlearn: 59699.1007636\ttotal: 7.09s\tremaining: 11.1s\n",
      "390:\tlearn: 59687.2645012\ttotal: 7.11s\tremaining: 11.1s\n",
      "391:\tlearn: 59671.7432063\ttotal: 7.12s\tremaining: 11s\n",
      "392:\tlearn: 59656.5590491\ttotal: 7.14s\tremaining: 11s\n",
      "393:\tlearn: 59642.2320097\ttotal: 7.14s\tremaining: 11s\n",
      "394:\tlearn: 59620.0472929\ttotal: 7.16s\tremaining: 11s\n",
      "395:\tlearn: 59608.6245250\ttotal: 7.18s\tremaining: 10.9s\n",
      "396:\tlearn: 59578.4181021\ttotal: 7.19s\tremaining: 10.9s\n",
      "397:\tlearn: 59556.5923187\ttotal: 7.22s\tremaining: 10.9s\n",
      "398:\tlearn: 59551.0951622\ttotal: 7.24s\tremaining: 10.9s\n",
      "399:\tlearn: 59530.1882136\ttotal: 7.25s\tremaining: 10.9s\n",
      "400:\tlearn: 59521.2777914\ttotal: 7.27s\tremaining: 10.9s\n",
      "401:\tlearn: 59506.2786114\ttotal: 7.28s\tremaining: 10.8s\n",
      "402:\tlearn: 59494.7640296\ttotal: 7.29s\tremaining: 10.8s\n",
      "403:\tlearn: 59479.2751639\ttotal: 7.3s\tremaining: 10.8s\n",
      "404:\tlearn: 59434.2889010\ttotal: 7.31s\tremaining: 10.7s\n",
      "405:\tlearn: 59411.4857654\ttotal: 7.33s\tremaining: 10.7s\n",
      "406:\tlearn: 59406.2515749\ttotal: 7.34s\tremaining: 10.7s\n",
      "407:\tlearn: 59362.8358148\ttotal: 7.35s\tremaining: 10.7s\n",
      "408:\tlearn: 59350.4024061\ttotal: 7.37s\tremaining: 10.6s\n",
      "409:\tlearn: 59328.9622881\ttotal: 7.38s\tremaining: 10.6s\n",
      "410:\tlearn: 59321.6092973\ttotal: 7.39s\tremaining: 10.6s\n",
      "411:\tlearn: 59309.7135669\ttotal: 7.5s\tremaining: 10.7s\n",
      "412:\tlearn: 59299.0970050\ttotal: 7.5s\tremaining: 10.7s\n",
      "413:\tlearn: 59275.2671400\ttotal: 7.52s\tremaining: 10.6s\n",
      "414:\tlearn: 59254.8594480\ttotal: 7.53s\tremaining: 10.6s\n",
      "415:\tlearn: 59200.6656314\ttotal: 7.54s\tremaining: 10.6s\n",
      "416:\tlearn: 59190.6380467\ttotal: 7.55s\tremaining: 10.6s\n",
      "417:\tlearn: 59176.4793361\ttotal: 7.57s\tremaining: 10.5s\n",
      "418:\tlearn: 59156.7744628\ttotal: 7.58s\tremaining: 10.5s\n",
      "419:\tlearn: 59126.7887688\ttotal: 7.59s\tremaining: 10.5s\n",
      "420:\tlearn: 59113.3723355\ttotal: 7.6s\tremaining: 10.5s\n",
      "421:\tlearn: 59097.0953995\ttotal: 7.62s\tremaining: 10.4s\n",
      "422:\tlearn: 59083.4769404\ttotal: 7.65s\tremaining: 10.4s\n",
      "423:\tlearn: 59065.3890193\ttotal: 7.66s\tremaining: 10.4s\n",
      "424:\tlearn: 59046.8202109\ttotal: 7.68s\tremaining: 10.4s\n",
      "425:\tlearn: 59027.7441364\ttotal: 7.69s\tremaining: 10.4s\n",
      "426:\tlearn: 59018.4387785\ttotal: 7.71s\tremaining: 10.3s\n",
      "427:\tlearn: 58949.6398608\ttotal: 7.72s\tremaining: 10.3s\n",
      "428:\tlearn: 58944.7491791\ttotal: 7.73s\tremaining: 10.3s\n",
      "429:\tlearn: 58902.6501780\ttotal: 7.75s\tremaining: 10.3s\n",
      "430:\tlearn: 58897.9779999\ttotal: 7.76s\tremaining: 10.2s\n",
      "431:\tlearn: 58877.1210541\ttotal: 7.77s\tremaining: 10.2s\n",
      "432:\tlearn: 58862.7822546\ttotal: 7.78s\tremaining: 10.2s\n",
      "433:\tlearn: 58850.0231250\ttotal: 7.79s\tremaining: 10.2s\n",
      "434:\tlearn: 58823.2054550\ttotal: 7.8s\tremaining: 10.1s\n",
      "435:\tlearn: 58812.5293220\ttotal: 7.82s\tremaining: 10.1s\n",
      "436:\tlearn: 58804.2190102\ttotal: 7.86s\tremaining: 10.1s\n",
      "437:\tlearn: 58790.8028707\ttotal: 7.87s\tremaining: 10.1s\n",
      "438:\tlearn: 58724.4197844\ttotal: 7.88s\tremaining: 10.1s\n",
      "439:\tlearn: 58716.1133015\ttotal: 7.89s\tremaining: 10s\n",
      "440:\tlearn: 58664.7733728\ttotal: 7.91s\tremaining: 10s\n",
      "441:\tlearn: 58656.0363201\ttotal: 7.93s\tremaining: 10s\n",
      "442:\tlearn: 58642.9903985\ttotal: 7.94s\tremaining: 9.98s\n",
      "443:\tlearn: 58625.4577857\ttotal: 7.95s\tremaining: 9.96s\n",
      "444:\tlearn: 58612.9037499\ttotal: 7.96s\tremaining: 9.93s\n",
      "445:\tlearn: 58567.4660392\ttotal: 7.97s\tremaining: 9.9s\n",
      "446:\tlearn: 58553.4167028\ttotal: 7.99s\tremaining: 9.88s\n",
      "447:\tlearn: 58544.0561657\ttotal: 7.99s\tremaining: 9.85s\n",
      "448:\tlearn: 58520.9872646\ttotal: 8.01s\tremaining: 9.82s\n",
      "449:\tlearn: 58496.5604712\ttotal: 8.02s\tremaining: 9.8s\n",
      "450:\tlearn: 58484.5559377\ttotal: 8.04s\tremaining: 9.79s\n",
      "451:\tlearn: 58428.9376462\ttotal: 8.08s\tremaining: 9.79s\n",
      "452:\tlearn: 58362.1692924\ttotal: 8.09s\tremaining: 9.77s\n",
      "453:\tlearn: 58351.9553954\ttotal: 8.1s\tremaining: 9.74s\n",
      "454:\tlearn: 58344.8115406\ttotal: 8.11s\tremaining: 9.72s\n",
      "455:\tlearn: 58327.5058037\ttotal: 8.13s\tremaining: 9.69s\n",
      "456:\tlearn: 58263.3095474\ttotal: 8.15s\tremaining: 9.69s\n",
      "457:\tlearn: 58238.2465867\ttotal: 8.16s\tremaining: 9.66s\n",
      "458:\tlearn: 58221.3198794\ttotal: 8.17s\tremaining: 9.63s\n",
      "459:\tlearn: 58204.9972776\ttotal: 8.21s\tremaining: 9.64s\n",
      "460:\tlearn: 58195.8512713\ttotal: 8.22s\tremaining: 9.61s\n",
      "461:\tlearn: 58152.2482138\ttotal: 8.24s\tremaining: 9.59s\n",
      "462:\tlearn: 58139.1128104\ttotal: 8.25s\tremaining: 9.57s\n",
      "463:\tlearn: 58120.1529447\ttotal: 8.29s\tremaining: 9.57s\n",
      "464:\tlearn: 58107.5512244\ttotal: 8.31s\tremaining: 9.56s\n",
      "465:\tlearn: 58101.0386277\ttotal: 8.32s\tremaining: 9.53s\n",
      "466:\tlearn: 58090.1057510\ttotal: 8.33s\tremaining: 9.51s\n",
      "467:\tlearn: 58046.3027724\ttotal: 8.35s\tremaining: 9.49s\n",
      "468:\tlearn: 58038.6193835\ttotal: 8.35s\tremaining: 9.46s\n",
      "469:\tlearn: 58028.2188968\ttotal: 8.37s\tremaining: 9.44s\n",
      "470:\tlearn: 57998.7025785\ttotal: 8.38s\tremaining: 9.41s\n",
      "471:\tlearn: 57959.0473178\ttotal: 8.39s\tremaining: 9.38s\n",
      "472:\tlearn: 57905.0820443\ttotal: 8.4s\tremaining: 9.36s\n",
      "473:\tlearn: 57889.2768540\ttotal: 8.41s\tremaining: 9.34s\n",
      "474:\tlearn: 57828.8688813\ttotal: 8.42s\tremaining: 9.31s\n",
      "475:\tlearn: 57819.8802817\ttotal: 8.44s\tremaining: 9.29s\n",
      "476:\tlearn: 57804.2300257\ttotal: 8.45s\tremaining: 9.27s\n",
      "477:\tlearn: 57802.5919100\ttotal: 8.47s\tremaining: 9.25s\n",
      "478:\tlearn: 57791.9529756\ttotal: 8.49s\tremaining: 9.23s\n",
      "479:\tlearn: 57776.6881447\ttotal: 8.51s\tremaining: 9.22s\n",
      "480:\tlearn: 57761.9668759\ttotal: 8.53s\tremaining: 9.21s\n",
      "481:\tlearn: 57748.1434434\ttotal: 8.54s\tremaining: 9.18s\n",
      "482:\tlearn: 57700.3021050\ttotal: 8.56s\tremaining: 9.16s\n",
      "483:\tlearn: 57684.2033011\ttotal: 8.57s\tremaining: 9.14s\n",
      "484:\tlearn: 57631.8465307\ttotal: 8.59s\tremaining: 9.12s\n",
      "485:\tlearn: 57569.4139480\ttotal: 8.6s\tremaining: 9.09s\n",
      "486:\tlearn: 57559.6562756\ttotal: 8.61s\tremaining: 9.07s\n",
      "487:\tlearn: 57545.4050160\ttotal: 8.62s\tremaining: 9.04s\n",
      "488:\tlearn: 57481.4786778\ttotal: 8.63s\tremaining: 9.02s\n",
      "489:\tlearn: 57477.8029777\ttotal: 8.65s\tremaining: 9s\n",
      "490:\tlearn: 57460.2675969\ttotal: 8.66s\tremaining: 8.98s\n",
      "491:\tlearn: 57444.5186233\ttotal: 8.68s\tremaining: 8.96s\n",
      "492:\tlearn: 57432.3930725\ttotal: 8.69s\tremaining: 8.94s\n",
      "493:\tlearn: 57372.4285535\ttotal: 8.71s\tremaining: 8.92s\n",
      "494:\tlearn: 57357.2398302\ttotal: 8.73s\tremaining: 8.91s\n",
      "495:\tlearn: 57352.7353916\ttotal: 8.75s\tremaining: 8.89s\n",
      "496:\tlearn: 57351.2032726\ttotal: 8.78s\tremaining: 8.88s\n",
      "497:\tlearn: 57336.5703855\ttotal: 8.79s\tremaining: 8.86s\n",
      "498:\tlearn: 57299.3920049\ttotal: 8.8s\tremaining: 8.84s\n",
      "499:\tlearn: 57289.9868705\ttotal: 8.81s\tremaining: 8.81s\n",
      "500:\tlearn: 57282.7279303\ttotal: 8.83s\tremaining: 8.79s\n",
      "501:\tlearn: 57243.1174246\ttotal: 8.84s\tremaining: 8.77s\n",
      "502:\tlearn: 57204.0406456\ttotal: 8.85s\tremaining: 8.74s\n",
      "503:\tlearn: 57167.1844071\ttotal: 8.86s\tremaining: 8.72s\n",
      "504:\tlearn: 57153.0450012\ttotal: 8.88s\tremaining: 8.7s\n",
      "505:\tlearn: 57120.1987218\ttotal: 8.89s\tremaining: 8.68s\n",
      "506:\tlearn: 57099.8589422\ttotal: 8.91s\tremaining: 8.66s\n",
      "507:\tlearn: 57090.3205679\ttotal: 8.93s\tremaining: 8.65s\n",
      "508:\tlearn: 57055.8710382\ttotal: 8.95s\tremaining: 8.64s\n",
      "509:\tlearn: 57022.6513037\ttotal: 8.97s\tremaining: 8.62s\n",
      "510:\tlearn: 57013.8683874\ttotal: 8.98s\tremaining: 8.59s\n",
      "511:\tlearn: 56989.5671008\ttotal: 8.99s\tremaining: 8.57s\n",
      "512:\tlearn: 56957.5321588\ttotal: 9.01s\tremaining: 8.55s\n",
      "513:\tlearn: 56907.9000598\ttotal: 9.02s\tremaining: 8.53s\n",
      "514:\tlearn: 56868.9248773\ttotal: 9.03s\tremaining: 8.51s\n",
      "515:\tlearn: 56859.4769961\ttotal: 9.04s\tremaining: 8.48s\n",
      "516:\tlearn: 56840.4289816\ttotal: 9.06s\tremaining: 8.46s\n",
      "517:\tlearn: 56813.6825857\ttotal: 9.07s\tremaining: 8.44s\n",
      "518:\tlearn: 56792.0606584\ttotal: 9.09s\tremaining: 8.42s\n",
      "519:\tlearn: 56780.3899820\ttotal: 9.1s\tremaining: 8.4s\n",
      "520:\tlearn: 56710.6643264\ttotal: 9.12s\tremaining: 8.38s\n",
      "521:\tlearn: 56685.9765614\ttotal: 9.15s\tremaining: 8.38s\n",
      "522:\tlearn: 56663.2813181\ttotal: 9.17s\tremaining: 8.36s\n",
      "523:\tlearn: 56641.5003413\ttotal: 9.18s\tremaining: 8.34s\n",
      "524:\tlearn: 56632.6784895\ttotal: 9.21s\tremaining: 8.33s\n",
      "525:\tlearn: 56609.5642597\ttotal: 9.22s\tremaining: 8.31s\n",
      "526:\tlearn: 56601.4184476\ttotal: 9.23s\tremaining: 8.29s\n",
      "527:\tlearn: 56592.9263077\ttotal: 9.24s\tremaining: 8.26s\n",
      "528:\tlearn: 56525.2753041\ttotal: 9.25s\tremaining: 8.24s\n",
      "529:\tlearn: 56512.7702761\ttotal: 9.27s\tremaining: 8.22s\n",
      "530:\tlearn: 56504.5900442\ttotal: 9.28s\tremaining: 8.2s\n",
      "531:\tlearn: 56496.7257181\ttotal: 9.29s\tremaining: 8.18s\n",
      "532:\tlearn: 56467.5967942\ttotal: 9.3s\tremaining: 8.15s\n",
      "533:\tlearn: 56453.8423679\ttotal: 9.32s\tremaining: 8.13s\n",
      "534:\tlearn: 56440.5883084\ttotal: 9.41s\tremaining: 8.18s\n",
      "535:\tlearn: 56427.4205367\ttotal: 9.43s\tremaining: 8.16s\n",
      "536:\tlearn: 56367.7087599\ttotal: 9.44s\tremaining: 8.14s\n",
      "537:\tlearn: 56348.7229350\ttotal: 9.45s\tremaining: 8.12s\n",
      "538:\tlearn: 56340.7685047\ttotal: 9.46s\tremaining: 8.09s\n",
      "539:\tlearn: 56335.9204574\ttotal: 9.47s\tremaining: 8.07s\n",
      "540:\tlearn: 56328.4567888\ttotal: 9.48s\tremaining: 8.04s\n",
      "541:\tlearn: 56308.8341834\ttotal: 9.5s\tremaining: 8.03s\n",
      "542:\tlearn: 56277.6439050\ttotal: 9.51s\tremaining: 8.01s\n",
      "543:\tlearn: 56256.3324841\ttotal: 9.53s\tremaining: 7.99s\n",
      "544:\tlearn: 56250.1933429\ttotal: 9.53s\tremaining: 7.96s\n",
      "545:\tlearn: 56196.8202993\ttotal: 9.55s\tremaining: 7.94s\n",
      "546:\tlearn: 56189.6124566\ttotal: 9.56s\tremaining: 7.92s\n",
      "547:\tlearn: 56149.9021293\ttotal: 9.59s\tremaining: 7.91s\n",
      "548:\tlearn: 56133.5725695\ttotal: 9.62s\tremaining: 7.9s\n",
      "549:\tlearn: 56120.7307767\ttotal: 9.63s\tremaining: 7.88s\n",
      "550:\tlearn: 56108.3538471\ttotal: 9.64s\tremaining: 7.85s\n",
      "551:\tlearn: 56078.1790249\ttotal: 9.65s\tremaining: 7.83s\n",
      "552:\tlearn: 56073.3671225\ttotal: 9.66s\tremaining: 7.81s\n",
      "553:\tlearn: 56053.6070537\ttotal: 9.68s\tremaining: 7.79s\n",
      "554:\tlearn: 56041.6589570\ttotal: 9.7s\tremaining: 7.78s\n",
      "555:\tlearn: 56026.9378219\ttotal: 9.71s\tremaining: 7.76s\n",
      "556:\tlearn: 55972.2840312\ttotal: 9.72s\tremaining: 7.73s\n",
      "557:\tlearn: 55925.7518546\ttotal: 9.73s\tremaining: 7.71s\n",
      "558:\tlearn: 55886.4562368\ttotal: 9.75s\tremaining: 7.69s\n",
      "559:\tlearn: 55868.7395529\ttotal: 9.76s\tremaining: 7.67s\n",
      "560:\tlearn: 55827.6226695\ttotal: 9.81s\tremaining: 7.68s\n",
      "561:\tlearn: 55815.2108715\ttotal: 9.82s\tremaining: 7.66s\n",
      "562:\tlearn: 55757.1978664\ttotal: 9.83s\tremaining: 7.63s\n",
      "563:\tlearn: 55746.2612577\ttotal: 9.86s\tremaining: 7.62s\n",
      "564:\tlearn: 55725.2454400\ttotal: 9.88s\tremaining: 7.6s\n",
      "565:\tlearn: 55714.0552811\ttotal: 9.88s\tremaining: 7.58s\n",
      "566:\tlearn: 55696.7211392\ttotal: 9.9s\tremaining: 7.56s\n",
      "567:\tlearn: 55680.8532643\ttotal: 9.91s\tremaining: 7.54s\n",
      "568:\tlearn: 55669.2565231\ttotal: 9.93s\tremaining: 7.52s\n",
      "569:\tlearn: 55655.4432145\ttotal: 9.94s\tremaining: 7.5s\n",
      "570:\tlearn: 55637.3346036\ttotal: 9.95s\tremaining: 7.48s\n",
      "571:\tlearn: 55631.0512696\ttotal: 9.96s\tremaining: 7.45s\n",
      "572:\tlearn: 55601.3185556\ttotal: 9.97s\tremaining: 7.43s\n",
      "573:\tlearn: 55586.1855768\ttotal: 10s\tremaining: 7.43s\n",
      "574:\tlearn: 55574.8274290\ttotal: 10s\tremaining: 7.42s\n",
      "575:\tlearn: 55561.8129112\ttotal: 10s\tremaining: 7.39s\n",
      "576:\tlearn: 55544.0256948\ttotal: 10.1s\tremaining: 7.37s\n",
      "577:\tlearn: 55529.9967341\ttotal: 10.1s\tremaining: 7.35s\n",
      "578:\tlearn: 55523.9633857\ttotal: 10.1s\tremaining: 7.33s\n",
      "579:\tlearn: 55506.1861614\ttotal: 10.1s\tremaining: 7.31s\n",
      "580:\tlearn: 55486.7060461\ttotal: 10.1s\tremaining: 7.29s\n",
      "581:\tlearn: 55352.6167915\ttotal: 10.1s\tremaining: 7.27s\n",
      "582:\tlearn: 55335.4479572\ttotal: 10.1s\tremaining: 7.25s\n",
      "583:\tlearn: 55326.6306741\ttotal: 10.2s\tremaining: 7.23s\n",
      "584:\tlearn: 55320.6550830\ttotal: 10.2s\tremaining: 7.21s\n",
      "585:\tlearn: 55291.6900767\ttotal: 10.2s\tremaining: 7.19s\n",
      "586:\tlearn: 55277.7707564\ttotal: 10.2s\tremaining: 7.17s\n",
      "587:\tlearn: 55248.4329942\ttotal: 10.2s\tremaining: 7.15s\n",
      "588:\tlearn: 55231.7315255\ttotal: 10.2s\tremaining: 7.13s\n",
      "589:\tlearn: 55220.3694214\ttotal: 10.2s\tremaining: 7.12s\n",
      "590:\tlearn: 55192.6177416\ttotal: 10.3s\tremaining: 7.1s\n",
      "591:\tlearn: 55181.6796239\ttotal: 10.3s\tremaining: 7.08s\n",
      "592:\tlearn: 55175.7657055\ttotal: 10.3s\tremaining: 7.06s\n",
      "593:\tlearn: 55165.3854378\ttotal: 10.3s\tremaining: 7.04s\n",
      "594:\tlearn: 55119.9761788\ttotal: 10.3s\tremaining: 7.03s\n",
      "595:\tlearn: 55062.2998750\ttotal: 10.3s\tremaining: 7s\n",
      "596:\tlearn: 55004.3882868\ttotal: 10.4s\tremaining: 6.99s\n",
      "597:\tlearn: 54949.9907967\ttotal: 10.4s\tremaining: 6.97s\n",
      "598:\tlearn: 54923.0986267\ttotal: 10.4s\tremaining: 6.94s\n",
      "599:\tlearn: 54904.5111544\ttotal: 10.4s\tremaining: 6.92s\n",
      "600:\tlearn: 54894.1221030\ttotal: 10.4s\tremaining: 6.91s\n",
      "601:\tlearn: 54877.4017052\ttotal: 10.4s\tremaining: 6.89s\n",
      "602:\tlearn: 54867.1049772\ttotal: 10.4s\tremaining: 6.87s\n",
      "603:\tlearn: 54861.6042234\ttotal: 10.5s\tremaining: 6.86s\n",
      "604:\tlearn: 54848.8771505\ttotal: 10.5s\tremaining: 6.84s\n",
      "605:\tlearn: 54838.5911986\ttotal: 10.5s\tremaining: 6.82s\n",
      "606:\tlearn: 54829.3938825\ttotal: 10.5s\tremaining: 6.8s\n",
      "607:\tlearn: 54813.4848640\ttotal: 10.5s\tremaining: 6.79s\n",
      "608:\tlearn: 54802.8062278\ttotal: 10.5s\tremaining: 6.77s\n",
      "609:\tlearn: 54676.0671684\ttotal: 10.6s\tremaining: 6.75s\n",
      "610:\tlearn: 54621.2773193\ttotal: 10.6s\tremaining: 6.73s\n",
      "611:\tlearn: 54603.0464211\ttotal: 10.6s\tremaining: 6.71s\n",
      "612:\tlearn: 54571.9198574\ttotal: 10.6s\tremaining: 6.69s\n",
      "613:\tlearn: 54561.9461945\ttotal: 10.6s\tremaining: 6.67s\n",
      "614:\tlearn: 54550.6254123\ttotal: 10.6s\tremaining: 6.65s\n",
      "615:\tlearn: 54535.7356840\ttotal: 10.6s\tremaining: 6.63s\n",
      "616:\tlearn: 54529.3367829\ttotal: 10.6s\tremaining: 6.61s\n",
      "617:\tlearn: 54526.9276383\ttotal: 10.7s\tremaining: 6.6s\n",
      "618:\tlearn: 54519.5090283\ttotal: 10.7s\tremaining: 6.58s\n",
      "619:\tlearn: 54514.5839526\ttotal: 10.7s\tremaining: 6.56s\n",
      "620:\tlearn: 54514.2350236\ttotal: 10.7s\tremaining: 6.54s\n",
      "621:\tlearn: 54505.9604489\ttotal: 10.7s\tremaining: 6.53s\n",
      "622:\tlearn: 54505.1294415\ttotal: 10.8s\tremaining: 6.51s\n",
      "623:\tlearn: 54502.0511982\ttotal: 10.8s\tremaining: 6.49s\n",
      "624:\tlearn: 54448.8988786\ttotal: 10.8s\tremaining: 6.47s\n",
      "625:\tlearn: 54362.6833313\ttotal: 10.8s\tremaining: 6.45s\n",
      "626:\tlearn: 54315.5761382\ttotal: 10.8s\tremaining: 6.43s\n",
      "627:\tlearn: 54305.4920494\ttotal: 10.8s\tremaining: 6.41s\n",
      "628:\tlearn: 54292.0808515\ttotal: 10.8s\tremaining: 6.39s\n",
      "629:\tlearn: 54247.7286060\ttotal: 10.8s\tremaining: 6.37s\n",
      "630:\tlearn: 54230.9886818\ttotal: 10.9s\tremaining: 6.35s\n",
      "631:\tlearn: 54223.3990663\ttotal: 10.9s\tremaining: 6.34s\n",
      "632:\tlearn: 54211.2127404\ttotal: 10.9s\tremaining: 6.32s\n",
      "633:\tlearn: 54197.7475703\ttotal: 10.9s\tremaining: 6.3s\n",
      "634:\tlearn: 54181.4952361\ttotal: 10.9s\tremaining: 6.29s\n",
      "635:\tlearn: 54165.4122348\ttotal: 11s\tremaining: 6.27s\n",
      "636:\tlearn: 54162.2459692\ttotal: 11s\tremaining: 6.25s\n",
      "637:\tlearn: 54159.8574103\ttotal: 11s\tremaining: 6.24s\n",
      "638:\tlearn: 54155.7671552\ttotal: 11s\tremaining: 6.22s\n",
      "639:\tlearn: 54134.6020852\ttotal: 11s\tremaining: 6.2s\n",
      "640:\tlearn: 54131.6442943\ttotal: 11s\tremaining: 6.18s\n",
      "641:\tlearn: 54128.4164648\ttotal: 11.1s\tremaining: 6.17s\n",
      "642:\tlearn: 54124.7791978\ttotal: 11.1s\tremaining: 6.15s\n",
      "643:\tlearn: 54122.1539511\ttotal: 11.1s\tremaining: 6.14s\n",
      "644:\tlearn: 54119.8252167\ttotal: 11.1s\tremaining: 6.12s\n",
      "645:\tlearn: 54116.7384525\ttotal: 11.1s\tremaining: 6.1s\n",
      "646:\tlearn: 54114.1303133\ttotal: 11.2s\tremaining: 6.08s\n",
      "647:\tlearn: 54105.9446759\ttotal: 11.2s\tremaining: 6.07s\n",
      "648:\tlearn: 54103.8984644\ttotal: 11.2s\tremaining: 6.05s\n",
      "649:\tlearn: 54102.3700169\ttotal: 11.2s\tremaining: 6.02s\n",
      "650:\tlearn: 54099.8575261\ttotal: 11.2s\tremaining: 6s\n",
      "651:\tlearn: 54098.4527819\ttotal: 11.2s\tremaining: 5.98s\n",
      "652:\tlearn: 54096.6961793\ttotal: 11.2s\tremaining: 5.96s\n",
      "653:\tlearn: 54075.1187748\ttotal: 11.2s\tremaining: 5.94s\n",
      "654:\tlearn: 54064.2160944\ttotal: 11.3s\tremaining: 5.93s\n",
      "655:\tlearn: 54062.9199442\ttotal: 11.3s\tremaining: 5.91s\n",
      "656:\tlearn: 54053.3768095\ttotal: 11.3s\tremaining: 5.89s\n",
      "657:\tlearn: 54052.1557769\ttotal: 11.3s\tremaining: 5.87s\n",
      "658:\tlearn: 54050.3985463\ttotal: 11.3s\tremaining: 5.86s\n",
      "659:\tlearn: 54041.1978668\ttotal: 11.3s\tremaining: 5.84s\n",
      "660:\tlearn: 54021.7505784\ttotal: 11.4s\tremaining: 5.85s\n",
      "661:\tlearn: 54011.5762179\ttotal: 11.4s\tremaining: 5.83s\n",
      "662:\tlearn: 53986.2157542\ttotal: 11.4s\tremaining: 5.82s\n",
      "663:\tlearn: 53970.4957309\ttotal: 11.5s\tremaining: 5.8s\n",
      "664:\tlearn: 53963.7553862\ttotal: 11.5s\tremaining: 5.78s\n",
      "665:\tlearn: 53961.8203687\ttotal: 11.5s\tremaining: 5.76s\n",
      "666:\tlearn: 53959.0230567\ttotal: 11.5s\tremaining: 5.74s\n",
      "667:\tlearn: 53957.0618615\ttotal: 11.5s\tremaining: 5.73s\n",
      "668:\tlearn: 53942.1152985\ttotal: 11.6s\tremaining: 5.71s\n",
      "669:\tlearn: 53923.4323880\ttotal: 11.6s\tremaining: 5.7s\n",
      "670:\tlearn: 53908.8687137\ttotal: 11.6s\tremaining: 5.68s\n",
      "671:\tlearn: 53903.2162486\ttotal: 11.6s\tremaining: 5.66s\n",
      "672:\tlearn: 53831.6983262\ttotal: 11.6s\tremaining: 5.64s\n",
      "673:\tlearn: 53779.9362682\ttotal: 11.6s\tremaining: 5.62s\n",
      "674:\tlearn: 53767.8926215\ttotal: 11.6s\tremaining: 5.6s\n",
      "675:\tlearn: 53762.3886072\ttotal: 11.6s\tremaining: 5.58s\n",
      "676:\tlearn: 53748.2140315\ttotal: 11.7s\tremaining: 5.56s\n",
      "677:\tlearn: 53734.3640228\ttotal: 11.7s\tremaining: 5.54s\n",
      "678:\tlearn: 53695.1153058\ttotal: 11.7s\tremaining: 5.52s\n",
      "679:\tlearn: 53686.8889698\ttotal: 11.7s\tremaining: 5.5s\n",
      "680:\tlearn: 53673.5148648\ttotal: 11.7s\tremaining: 5.48s\n",
      "681:\tlearn: 53664.7977626\ttotal: 11.7s\tremaining: 5.46s\n",
      "682:\tlearn: 53627.1646092\ttotal: 11.7s\tremaining: 5.44s\n",
      "683:\tlearn: 53617.2356308\ttotal: 11.7s\tremaining: 5.43s\n",
      "684:\tlearn: 53590.2070648\ttotal: 11.8s\tremaining: 5.41s\n",
      "685:\tlearn: 53513.2110117\ttotal: 11.8s\tremaining: 5.4s\n",
      "686:\tlearn: 53460.3145049\ttotal: 11.8s\tremaining: 5.39s\n",
      "687:\tlearn: 53435.8075191\ttotal: 11.8s\tremaining: 5.37s\n",
      "688:\tlearn: 53422.8485721\ttotal: 11.9s\tremaining: 5.36s\n",
      "689:\tlearn: 53413.9774247\ttotal: 11.9s\tremaining: 5.34s\n",
      "690:\tlearn: 53399.1250000\ttotal: 11.9s\tremaining: 5.32s\n",
      "691:\tlearn: 53348.1712264\ttotal: 11.9s\tremaining: 5.3s\n",
      "692:\tlearn: 53335.6769016\ttotal: 11.9s\tremaining: 5.28s\n",
      "693:\tlearn: 53286.5907282\ttotal: 11.9s\tremaining: 5.26s\n",
      "694:\tlearn: 53260.9912873\ttotal: 11.9s\tremaining: 5.24s\n",
      "695:\tlearn: 53247.0478588\ttotal: 12s\tremaining: 5.22s\n",
      "696:\tlearn: 53226.3351177\ttotal: 12s\tremaining: 5.22s\n",
      "697:\tlearn: 53217.3827330\ttotal: 12s\tremaining: 5.2s\n",
      "698:\tlearn: 53203.6612851\ttotal: 12s\tremaining: 5.18s\n",
      "699:\tlearn: 53186.4834172\ttotal: 12s\tremaining: 5.16s\n",
      "700:\tlearn: 53170.6761909\ttotal: 12s\tremaining: 5.14s\n",
      "701:\tlearn: 53155.2033465\ttotal: 12.1s\tremaining: 5.12s\n",
      "702:\tlearn: 53141.5977986\ttotal: 12.1s\tremaining: 5.1s\n",
      "703:\tlearn: 53138.8123984\ttotal: 12.1s\tremaining: 5.09s\n",
      "704:\tlearn: 53127.7092901\ttotal: 12.1s\tremaining: 5.07s\n",
      "705:\tlearn: 53102.8011232\ttotal: 12.1s\tremaining: 5.05s\n",
      "706:\tlearn: 53094.1904107\ttotal: 12.1s\tremaining: 5.03s\n",
      "707:\tlearn: 53085.6881822\ttotal: 12.1s\tremaining: 5.01s\n",
      "708:\tlearn: 53068.8598803\ttotal: 12.2s\tremaining: 4.99s\n",
      "709:\tlearn: 53028.5474286\ttotal: 12.2s\tremaining: 4.97s\n",
      "710:\tlearn: 53025.6384962\ttotal: 12.2s\tremaining: 4.96s\n",
      "711:\tlearn: 53001.0385010\ttotal: 12.2s\tremaining: 4.95s\n",
      "712:\tlearn: 52990.9182687\ttotal: 12.2s\tremaining: 4.93s\n",
      "713:\tlearn: 52985.8013661\ttotal: 12.3s\tremaining: 4.91s\n",
      "714:\tlearn: 52979.3300878\ttotal: 12.3s\tremaining: 4.89s\n",
      "715:\tlearn: 52955.3011909\ttotal: 12.3s\tremaining: 4.87s\n",
      "716:\tlearn: 52939.6646461\ttotal: 12.3s\tremaining: 4.85s\n",
      "717:\tlearn: 52934.0851998\ttotal: 12.3s\tremaining: 4.83s\n",
      "718:\tlearn: 52923.7251896\ttotal: 12.3s\tremaining: 4.81s\n",
      "719:\tlearn: 52916.1601148\ttotal: 12.3s\tremaining: 4.8s\n",
      "720:\tlearn: 52911.0146248\ttotal: 12.3s\tremaining: 4.78s\n",
      "721:\tlearn: 52908.5096957\ttotal: 12.4s\tremaining: 4.76s\n",
      "722:\tlearn: 52890.7688909\ttotal: 12.4s\tremaining: 4.74s\n",
      "723:\tlearn: 52887.2078939\ttotal: 12.4s\tremaining: 4.72s\n",
      "724:\tlearn: 52879.1302861\ttotal: 12.4s\tremaining: 4.71s\n",
      "725:\tlearn: 52850.0673048\ttotal: 12.4s\tremaining: 4.69s\n",
      "726:\tlearn: 52835.4093222\ttotal: 12.5s\tremaining: 4.68s\n",
      "727:\tlearn: 52824.6351022\ttotal: 12.5s\tremaining: 4.66s\n",
      "728:\tlearn: 52815.3296425\ttotal: 12.5s\tremaining: 4.64s\n",
      "729:\tlearn: 52749.3001331\ttotal: 12.5s\tremaining: 4.62s\n",
      "730:\tlearn: 52736.4090234\ttotal: 12.5s\tremaining: 4.6s\n",
      "731:\tlearn: 52722.3368854\ttotal: 12.5s\tremaining: 4.58s\n",
      "732:\tlearn: 52719.7211151\ttotal: 12.5s\tremaining: 4.56s\n",
      "733:\tlearn: 52707.3866729\ttotal: 12.5s\tremaining: 4.55s\n",
      "734:\tlearn: 52698.4525799\ttotal: 12.6s\tremaining: 4.53s\n",
      "735:\tlearn: 52687.3128932\ttotal: 12.6s\tremaining: 4.51s\n",
      "736:\tlearn: 52639.8976458\ttotal: 12.6s\tremaining: 4.49s\n",
      "737:\tlearn: 52632.9687283\ttotal: 12.6s\tremaining: 4.47s\n",
      "738:\tlearn: 52629.7749771\ttotal: 12.6s\tremaining: 4.45s\n",
      "739:\tlearn: 52623.4350989\ttotal: 12.6s\tremaining: 4.43s\n",
      "740:\tlearn: 52608.3757679\ttotal: 12.6s\tremaining: 4.42s\n",
      "741:\tlearn: 52590.7221685\ttotal: 12.7s\tremaining: 4.41s\n",
      "742:\tlearn: 52586.0157832\ttotal: 12.7s\tremaining: 4.39s\n",
      "743:\tlearn: 52551.1060479\ttotal: 12.7s\tremaining: 4.37s\n",
      "744:\tlearn: 52507.1964302\ttotal: 12.7s\tremaining: 4.35s\n",
      "745:\tlearn: 52502.0263145\ttotal: 12.7s\tremaining: 4.33s\n",
      "746:\tlearn: 52491.1374895\ttotal: 12.7s\tremaining: 4.31s\n",
      "747:\tlearn: 52420.4687859\ttotal: 12.7s\tremaining: 4.29s\n",
      "748:\tlearn: 52403.9630406\ttotal: 12.8s\tremaining: 4.28s\n",
      "749:\tlearn: 52335.7797846\ttotal: 12.8s\tremaining: 4.26s\n",
      "750:\tlearn: 52269.9993655\ttotal: 12.8s\tremaining: 4.24s\n",
      "751:\tlearn: 52206.5343195\ttotal: 12.8s\tremaining: 4.22s\n",
      "752:\tlearn: 52159.9972797\ttotal: 12.8s\tremaining: 4.2s\n",
      "753:\tlearn: 52098.7090607\ttotal: 12.8s\tremaining: 4.19s\n",
      "754:\tlearn: 52053.8227813\ttotal: 12.9s\tremaining: 4.17s\n",
      "755:\tlearn: 52045.9268656\ttotal: 12.9s\tremaining: 4.16s\n",
      "756:\tlearn: 51986.7318029\ttotal: 12.9s\tremaining: 4.14s\n",
      "757:\tlearn: 51982.6383032\ttotal: 12.9s\tremaining: 4.12s\n",
      "758:\tlearn: 51975.0217486\ttotal: 12.9s\tremaining: 4.1s\n",
      "759:\tlearn: 51962.1673071\ttotal: 12.9s\tremaining: 4.08s\n",
      "760:\tlearn: 51938.6973378\ttotal: 12.9s\tremaining: 4.07s\n",
      "761:\tlearn: 51926.7075536\ttotal: 13s\tremaining: 4.05s\n",
      "762:\tlearn: 51922.0483563\ttotal: 13s\tremaining: 4.03s\n",
      "763:\tlearn: 51864.8684389\ttotal: 13s\tremaining: 4.01s\n",
      "764:\tlearn: 51841.3549171\ttotal: 13s\tremaining: 3.99s\n",
      "765:\tlearn: 51787.7359667\ttotal: 13s\tremaining: 3.98s\n",
      "766:\tlearn: 51771.8643572\ttotal: 13s\tremaining: 3.96s\n",
      "767:\tlearn: 51758.0997468\ttotal: 13s\tremaining: 3.94s\n",
      "768:\tlearn: 51702.8124956\ttotal: 13.1s\tremaining: 3.93s\n",
      "769:\tlearn: 51695.4461941\ttotal: 13.1s\tremaining: 3.91s\n",
      "770:\tlearn: 51690.6325600\ttotal: 13.1s\tremaining: 3.89s\n",
      "771:\tlearn: 51676.9166623\ttotal: 13.1s\tremaining: 3.88s\n",
      "772:\tlearn: 51623.5338344\ttotal: 13.1s\tremaining: 3.86s\n",
      "773:\tlearn: 51605.0712055\ttotal: 13.2s\tremaining: 3.84s\n",
      "774:\tlearn: 51593.6529613\ttotal: 13.2s\tremaining: 3.82s\n",
      "775:\tlearn: 51586.2511430\ttotal: 13.2s\tremaining: 3.81s\n",
      "776:\tlearn: 51563.6321924\ttotal: 13.2s\tremaining: 3.79s\n",
      "777:\tlearn: 51556.4949443\ttotal: 13.2s\tremaining: 3.77s\n",
      "778:\tlearn: 51535.0123863\ttotal: 13.2s\tremaining: 3.75s\n",
      "779:\tlearn: 51522.9685779\ttotal: 13.2s\tremaining: 3.73s\n",
      "780:\tlearn: 51499.2193505\ttotal: 13.2s\tremaining: 3.71s\n",
      "781:\tlearn: 51473.6280631\ttotal: 13.3s\tremaining: 3.7s\n",
      "782:\tlearn: 51465.9636368\ttotal: 13.3s\tremaining: 3.68s\n",
      "783:\tlearn: 51461.9999636\ttotal: 13.3s\tremaining: 3.66s\n",
      "784:\tlearn: 51459.2462217\ttotal: 13.3s\tremaining: 3.64s\n",
      "785:\tlearn: 51449.8702946\ttotal: 13.3s\tremaining: 3.63s\n",
      "786:\tlearn: 51445.9144039\ttotal: 13.4s\tremaining: 3.63s\n",
      "787:\tlearn: 51439.9289997\ttotal: 13.4s\tremaining: 3.61s\n",
      "788:\tlearn: 51399.7679862\ttotal: 13.4s\tremaining: 3.6s\n",
      "789:\tlearn: 51375.1079741\ttotal: 13.5s\tremaining: 3.58s\n",
      "790:\tlearn: 51331.3090896\ttotal: 13.5s\tremaining: 3.56s\n",
      "791:\tlearn: 51317.4328316\ttotal: 13.5s\tremaining: 3.54s\n",
      "792:\tlearn: 51314.0867736\ttotal: 13.5s\tremaining: 3.52s\n",
      "793:\tlearn: 51305.1015630\ttotal: 13.5s\tremaining: 3.5s\n",
      "794:\tlearn: 51298.2030860\ttotal: 13.5s\tremaining: 3.49s\n",
      "795:\tlearn: 51291.5715361\ttotal: 13.6s\tremaining: 3.48s\n",
      "796:\tlearn: 51279.9355046\ttotal: 13.6s\tremaining: 3.46s\n",
      "797:\tlearn: 51259.5569619\ttotal: 13.6s\tremaining: 3.44s\n",
      "798:\tlearn: 51250.7426432\ttotal: 13.6s\tremaining: 3.42s\n",
      "799:\tlearn: 51239.8266918\ttotal: 13.6s\tremaining: 3.4s\n",
      "800:\tlearn: 51229.3161324\ttotal: 13.6s\tremaining: 3.39s\n",
      "801:\tlearn: 51213.7132123\ttotal: 13.7s\tremaining: 3.37s\n",
      "802:\tlearn: 51203.8322153\ttotal: 13.7s\tremaining: 3.35s\n",
      "803:\tlearn: 51193.4458132\ttotal: 13.7s\tremaining: 3.33s\n",
      "804:\tlearn: 51182.2996528\ttotal: 13.7s\tremaining: 3.31s\n",
      "805:\tlearn: 51170.1526550\ttotal: 13.7s\tremaining: 3.3s\n",
      "806:\tlearn: 51127.8423316\ttotal: 13.7s\tremaining: 3.28s\n",
      "807:\tlearn: 51112.5150286\ttotal: 13.7s\tremaining: 3.26s\n",
      "808:\tlearn: 51110.2143642\ttotal: 13.8s\tremaining: 3.25s\n",
      "809:\tlearn: 51100.6661150\ttotal: 13.8s\tremaining: 3.23s\n",
      "810:\tlearn: 51092.4884501\ttotal: 13.8s\tremaining: 3.21s\n",
      "811:\tlearn: 51070.4685508\ttotal: 13.8s\tremaining: 3.19s\n",
      "812:\tlearn: 51063.9338848\ttotal: 13.8s\tremaining: 3.18s\n",
      "813:\tlearn: 51062.0078317\ttotal: 13.8s\tremaining: 3.16s\n",
      "814:\tlearn: 51039.3881576\ttotal: 13.8s\tremaining: 3.14s\n",
      "815:\tlearn: 51019.8261545\ttotal: 13.9s\tremaining: 3.12s\n",
      "816:\tlearn: 51014.2577154\ttotal: 13.9s\tremaining: 3.1s\n",
      "817:\tlearn: 50962.1509954\ttotal: 13.9s\tremaining: 3.09s\n",
      "818:\tlearn: 50960.9894760\ttotal: 13.9s\tremaining: 3.07s\n",
      "819:\tlearn: 50949.5486682\ttotal: 13.9s\tremaining: 3.05s\n",
      "820:\tlearn: 50849.5927596\ttotal: 13.9s\tremaining: 3.03s\n",
      "821:\tlearn: 50830.3137167\ttotal: 13.9s\tremaining: 3.02s\n",
      "822:\tlearn: 50821.6966950\ttotal: 13.9s\tremaining: 3s\n",
      "823:\tlearn: 50772.4300437\ttotal: 14s\tremaining: 2.98s\n",
      "824:\tlearn: 50754.1566051\ttotal: 14s\tremaining: 2.97s\n",
      "825:\tlearn: 50724.2641748\ttotal: 14s\tremaining: 2.95s\n",
      "826:\tlearn: 50717.5555744\ttotal: 14s\tremaining: 2.93s\n",
      "827:\tlearn: 50706.3878962\ttotal: 14s\tremaining: 2.92s\n",
      "828:\tlearn: 50673.2319325\ttotal: 14s\tremaining: 2.9s\n",
      "829:\tlearn: 50664.2168780\ttotal: 14.1s\tremaining: 2.88s\n",
      "830:\tlearn: 50646.2499370\ttotal: 14.1s\tremaining: 2.86s\n",
      "831:\tlearn: 50624.3033334\ttotal: 14.1s\tremaining: 2.84s\n",
      "832:\tlearn: 50530.0732291\ttotal: 14.1s\tremaining: 2.83s\n",
      "833:\tlearn: 50499.4037826\ttotal: 14.1s\tremaining: 2.81s\n",
      "834:\tlearn: 50491.7750146\ttotal: 14.1s\tremaining: 2.79s\n",
      "835:\tlearn: 50483.3908769\ttotal: 14.1s\tremaining: 2.77s\n",
      "836:\tlearn: 50457.0583917\ttotal: 14.1s\tremaining: 2.75s\n",
      "837:\tlearn: 50447.0531178\ttotal: 14.2s\tremaining: 2.74s\n",
      "838:\tlearn: 50444.2203406\ttotal: 14.2s\tremaining: 2.72s\n",
      "839:\tlearn: 50427.1058902\ttotal: 14.2s\tremaining: 2.71s\n",
      "840:\tlearn: 50397.9411225\ttotal: 14.2s\tremaining: 2.69s\n",
      "841:\tlearn: 50380.3074182\ttotal: 14.2s\tremaining: 2.67s\n",
      "842:\tlearn: 50358.0593026\ttotal: 14.3s\tremaining: 2.65s\n",
      "843:\tlearn: 50351.5119663\ttotal: 14.3s\tremaining: 2.64s\n",
      "844:\tlearn: 50340.2783578\ttotal: 14.3s\tremaining: 2.62s\n",
      "845:\tlearn: 50323.3488305\ttotal: 14.3s\tremaining: 2.6s\n",
      "846:\tlearn: 50314.7070017\ttotal: 14.3s\tremaining: 2.58s\n",
      "847:\tlearn: 50311.4667965\ttotal: 14.3s\tremaining: 2.57s\n",
      "848:\tlearn: 50307.9212187\ttotal: 14.3s\tremaining: 2.55s\n",
      "849:\tlearn: 50297.9961658\ttotal: 14.3s\tremaining: 2.53s\n",
      "850:\tlearn: 50254.3497161\ttotal: 14.4s\tremaining: 2.51s\n",
      "851:\tlearn: 50245.5951048\ttotal: 14.4s\tremaining: 2.5s\n",
      "852:\tlearn: 50195.9324747\ttotal: 14.4s\tremaining: 2.48s\n",
      "853:\tlearn: 50188.4922366\ttotal: 14.4s\tremaining: 2.46s\n",
      "854:\tlearn: 50147.9410481\ttotal: 14.4s\tremaining: 2.45s\n",
      "855:\tlearn: 50124.9477892\ttotal: 14.4s\tremaining: 2.43s\n",
      "856:\tlearn: 50115.6418663\ttotal: 14.5s\tremaining: 2.41s\n",
      "857:\tlearn: 50103.0538780\ttotal: 14.5s\tremaining: 2.39s\n",
      "858:\tlearn: 50095.0048385\ttotal: 14.5s\tremaining: 2.38s\n",
      "859:\tlearn: 50006.1940568\ttotal: 14.5s\tremaining: 2.36s\n",
      "860:\tlearn: 49984.3558247\ttotal: 14.5s\tremaining: 2.34s\n",
      "861:\tlearn: 49968.9446975\ttotal: 14.5s\tremaining: 2.32s\n",
      "862:\tlearn: 49965.3856990\ttotal: 14.5s\tremaining: 2.31s\n",
      "863:\tlearn: 49935.0827662\ttotal: 14.5s\tremaining: 2.29s\n",
      "864:\tlearn: 49928.6950364\ttotal: 14.6s\tremaining: 2.27s\n",
      "865:\tlearn: 49860.4790606\ttotal: 14.6s\tremaining: 2.25s\n",
      "866:\tlearn: 49822.2770965\ttotal: 14.6s\tremaining: 2.24s\n",
      "867:\tlearn: 49813.6457176\ttotal: 14.6s\tremaining: 2.22s\n",
      "868:\tlearn: 49810.3769577\ttotal: 14.6s\tremaining: 2.21s\n",
      "869:\tlearn: 49804.1766988\ttotal: 14.6s\tremaining: 2.19s\n",
      "870:\tlearn: 49798.2033959\ttotal: 14.7s\tremaining: 2.17s\n",
      "871:\tlearn: 49759.0167474\ttotal: 14.7s\tremaining: 2.15s\n",
      "872:\tlearn: 49753.6681357\ttotal: 14.7s\tremaining: 2.14s\n",
      "873:\tlearn: 49670.2433186\ttotal: 14.7s\tremaining: 2.12s\n",
      "874:\tlearn: 49663.2540059\ttotal: 14.7s\tremaining: 2.1s\n",
      "875:\tlearn: 49659.9280147\ttotal: 14.7s\tremaining: 2.08s\n",
      "876:\tlearn: 49620.5474353\ttotal: 14.7s\tremaining: 2.07s\n",
      "877:\tlearn: 49616.8786173\ttotal: 14.7s\tremaining: 2.05s\n",
      "878:\tlearn: 49605.9968358\ttotal: 14.8s\tremaining: 2.03s\n",
      "879:\tlearn: 49567.7593832\ttotal: 14.8s\tremaining: 2.02s\n",
      "880:\tlearn: 49556.1412914\ttotal: 14.8s\tremaining: 2s\n",
      "881:\tlearn: 49539.3514957\ttotal: 14.8s\tremaining: 1.98s\n",
      "882:\tlearn: 49523.1672718\ttotal: 14.8s\tremaining: 1.96s\n",
      "883:\tlearn: 49517.9961798\ttotal: 14.8s\tremaining: 1.95s\n",
      "884:\tlearn: 49507.8974533\ttotal: 14.9s\tremaining: 1.93s\n",
      "885:\tlearn: 49502.1048392\ttotal: 14.9s\tremaining: 1.91s\n",
      "886:\tlearn: 49437.5558957\ttotal: 14.9s\tremaining: 1.9s\n",
      "887:\tlearn: 49387.3604385\ttotal: 14.9s\tremaining: 1.88s\n",
      "888:\tlearn: 49373.3992437\ttotal: 14.9s\tremaining: 1.86s\n",
      "889:\tlearn: 49344.9555522\ttotal: 14.9s\tremaining: 1.84s\n",
      "890:\tlearn: 49296.4693212\ttotal: 14.9s\tremaining: 1.83s\n",
      "891:\tlearn: 49249.6780432\ttotal: 15s\tremaining: 1.81s\n",
      "892:\tlearn: 49244.0606910\ttotal: 15s\tremaining: 1.79s\n",
      "893:\tlearn: 49232.6372509\ttotal: 15s\tremaining: 1.78s\n",
      "894:\tlearn: 49187.4625436\ttotal: 15s\tremaining: 1.76s\n",
      "895:\tlearn: 49109.9879597\ttotal: 15s\tremaining: 1.74s\n",
      "896:\tlearn: 49066.3260903\ttotal: 15.1s\tremaining: 1.74s\n",
      "897:\tlearn: 49015.6629767\ttotal: 15.1s\tremaining: 1.72s\n",
      "898:\tlearn: 48978.3077444\ttotal: 15.1s\tremaining: 1.7s\n",
      "899:\tlearn: 48965.2822592\ttotal: 15.2s\tremaining: 1.68s\n",
      "900:\tlearn: 48962.1048476\ttotal: 15.2s\tremaining: 1.67s\n",
      "901:\tlearn: 48919.8708486\ttotal: 15.2s\tremaining: 1.65s\n",
      "902:\tlearn: 48914.8243984\ttotal: 15.2s\tremaining: 1.63s\n",
      "903:\tlearn: 48886.2011136\ttotal: 15.2s\tremaining: 1.61s\n",
      "904:\tlearn: 48875.0376594\ttotal: 15.2s\tremaining: 1.6s\n",
      "905:\tlearn: 48864.2145165\ttotal: 15.2s\tremaining: 1.58s\n",
      "906:\tlearn: 48826.4456760\ttotal: 15.3s\tremaining: 1.56s\n",
      "907:\tlearn: 48823.3250532\ttotal: 15.3s\tremaining: 1.55s\n",
      "908:\tlearn: 48819.5421395\ttotal: 15.3s\tremaining: 1.53s\n",
      "909:\tlearn: 48809.1340397\ttotal: 15.3s\tremaining: 1.51s\n",
      "910:\tlearn: 48745.5949848\ttotal: 15.3s\tremaining: 1.5s\n",
      "911:\tlearn: 48731.9912019\ttotal: 15.3s\tremaining: 1.48s\n",
      "912:\tlearn: 48712.6719640\ttotal: 15.3s\tremaining: 1.46s\n",
      "913:\tlearn: 48702.6890099\ttotal: 15.4s\tremaining: 1.44s\n",
      "914:\tlearn: 48663.6222190\ttotal: 15.4s\tremaining: 1.43s\n",
      "915:\tlearn: 48642.5060379\ttotal: 15.4s\tremaining: 1.41s\n",
      "916:\tlearn: 48639.4104396\ttotal: 15.4s\tremaining: 1.39s\n",
      "917:\tlearn: 48628.9298724\ttotal: 15.4s\tremaining: 1.38s\n",
      "918:\tlearn: 48616.1271524\ttotal: 15.4s\tremaining: 1.36s\n",
      "919:\tlearn: 48590.6139089\ttotal: 15.4s\tremaining: 1.34s\n",
      "920:\tlearn: 48579.7121254\ttotal: 15.4s\tremaining: 1.32s\n",
      "921:\tlearn: 48576.3869799\ttotal: 15.5s\tremaining: 1.31s\n",
      "922:\tlearn: 48567.9864129\ttotal: 15.5s\tremaining: 1.29s\n",
      "923:\tlearn: 48526.9606034\ttotal: 15.5s\tremaining: 1.27s\n",
      "924:\tlearn: 48517.1512634\ttotal: 15.5s\tremaining: 1.26s\n",
      "925:\tlearn: 48512.3736814\ttotal: 15.5s\tremaining: 1.24s\n",
      "926:\tlearn: 48472.7709145\ttotal: 15.5s\tremaining: 1.22s\n",
      "927:\tlearn: 48434.5537286\ttotal: 15.6s\tremaining: 1.21s\n",
      "928:\tlearn: 48429.0314111\ttotal: 15.6s\tremaining: 1.19s\n",
      "929:\tlearn: 48393.0909411\ttotal: 15.6s\tremaining: 1.17s\n",
      "930:\tlearn: 48388.1505207\ttotal: 15.6s\tremaining: 1.16s\n",
      "931:\tlearn: 48371.3215854\ttotal: 15.6s\tremaining: 1.14s\n",
      "932:\tlearn: 48334.3853649\ttotal: 15.6s\tremaining: 1.12s\n",
      "933:\tlearn: 48260.3809325\ttotal: 15.6s\tremaining: 1.1s\n",
      "934:\tlearn: 48255.0356560\ttotal: 15.7s\tremaining: 1.09s\n",
      "935:\tlearn: 48219.9066636\ttotal: 15.7s\tremaining: 1.07s\n",
      "936:\tlearn: 48180.1090455\ttotal: 15.7s\tremaining: 1.05s\n",
      "937:\tlearn: 48145.4993232\ttotal: 15.7s\tremaining: 1.04s\n",
      "938:\tlearn: 48112.1431859\ttotal: 15.7s\tremaining: 1.02s\n",
      "939:\tlearn: 48093.9752685\ttotal: 15.7s\tremaining: 1s\n",
      "940:\tlearn: 48083.5984802\ttotal: 15.8s\tremaining: 988ms\n",
      "941:\tlearn: 48078.4215856\ttotal: 15.8s\tremaining: 971ms\n",
      "942:\tlearn: 48075.6796334\ttotal: 15.8s\tremaining: 954ms\n",
      "943:\tlearn: 48034.6499524\ttotal: 15.8s\tremaining: 937ms\n",
      "944:\tlearn: 48002.4039112\ttotal: 15.8s\tremaining: 920ms\n",
      "945:\tlearn: 47994.2058646\ttotal: 15.8s\tremaining: 903ms\n",
      "946:\tlearn: 47990.5049817\ttotal: 15.8s\tremaining: 886ms\n",
      "947:\tlearn: 47985.7036832\ttotal: 15.8s\tremaining: 869ms\n",
      "948:\tlearn: 47982.9184797\ttotal: 15.8s\tremaining: 852ms\n",
      "949:\tlearn: 47913.0308945\ttotal: 15.9s\tremaining: 835ms\n",
      "950:\tlearn: 47881.8551616\ttotal: 15.9s\tremaining: 818ms\n",
      "951:\tlearn: 47866.4312022\ttotal: 15.9s\tremaining: 802ms\n",
      "952:\tlearn: 47836.3378253\ttotal: 15.9s\tremaining: 785ms\n",
      "953:\tlearn: 47827.0240890\ttotal: 15.9s\tremaining: 768ms\n",
      "954:\tlearn: 47817.7878146\ttotal: 16s\tremaining: 752ms\n",
      "955:\tlearn: 47778.2214908\ttotal: 16s\tremaining: 735ms\n",
      "956:\tlearn: 47768.5213380\ttotal: 16s\tremaining: 718ms\n",
      "957:\tlearn: 47759.6177923\ttotal: 16s\tremaining: 701ms\n",
      "958:\tlearn: 47736.1062866\ttotal: 16s\tremaining: 685ms\n",
      "959:\tlearn: 47724.5853430\ttotal: 16s\tremaining: 668ms\n",
      "960:\tlearn: 47721.8340458\ttotal: 16s\tremaining: 651ms\n",
      "961:\tlearn: 47714.9126955\ttotal: 16.1s\tremaining: 634ms\n",
      "962:\tlearn: 47698.3357472\ttotal: 16.1s\tremaining: 617ms\n",
      "963:\tlearn: 47690.0330778\ttotal: 16.1s\tremaining: 601ms\n",
      "964:\tlearn: 47685.1769207\ttotal: 16.1s\tremaining: 585ms\n",
      "965:\tlearn: 47619.2839333\ttotal: 16.1s\tremaining: 568ms\n",
      "966:\tlearn: 47613.8360434\ttotal: 16.1s\tremaining: 551ms\n",
      "967:\tlearn: 47605.3126167\ttotal: 16.2s\tremaining: 534ms\n",
      "968:\tlearn: 47543.2049343\ttotal: 16.2s\tremaining: 517ms\n",
      "969:\tlearn: 47535.0624623\ttotal: 16.2s\tremaining: 500ms\n",
      "970:\tlearn: 47526.8444739\ttotal: 16.2s\tremaining: 484ms\n",
      "971:\tlearn: 47518.9319938\ttotal: 16.2s\tremaining: 467ms\n",
      "972:\tlearn: 47489.6902974\ttotal: 16.2s\tremaining: 450ms\n",
      "973:\tlearn: 47487.4227774\ttotal: 16.2s\tremaining: 433ms\n",
      "974:\tlearn: 47480.6098268\ttotal: 16.2s\tremaining: 417ms\n",
      "975:\tlearn: 47473.2482104\ttotal: 16.3s\tremaining: 400ms\n",
      "976:\tlearn: 47445.0218148\ttotal: 16.3s\tremaining: 383ms\n",
      "977:\tlearn: 47439.8623955\ttotal: 16.3s\tremaining: 366ms\n",
      "978:\tlearn: 47433.5129050\ttotal: 16.3s\tremaining: 350ms\n",
      "979:\tlearn: 47417.5185136\ttotal: 16.3s\tremaining: 333ms\n",
      "980:\tlearn: 47415.3870840\ttotal: 16.4s\tremaining: 317ms\n",
      "981:\tlearn: 47388.1311470\ttotal: 16.4s\tremaining: 300ms\n",
      "982:\tlearn: 47383.6256120\ttotal: 16.4s\tremaining: 284ms\n",
      "983:\tlearn: 47379.5026576\ttotal: 16.4s\tremaining: 267ms\n",
      "984:\tlearn: 47353.2166352\ttotal: 16.4s\tremaining: 250ms\n",
      "985:\tlearn: 47348.6654435\ttotal: 16.4s\tremaining: 233ms\n",
      "986:\tlearn: 47338.1108212\ttotal: 16.5s\tremaining: 217ms\n",
      "987:\tlearn: 47330.4466486\ttotal: 16.5s\tremaining: 200ms\n",
      "988:\tlearn: 47321.6904416\ttotal: 16.5s\tremaining: 183ms\n",
      "989:\tlearn: 47314.1644347\ttotal: 16.5s\tremaining: 167ms\n",
      "990:\tlearn: 47298.7859527\ttotal: 16.5s\tremaining: 150ms\n",
      "991:\tlearn: 47236.2070345\ttotal: 16.5s\tremaining: 133ms\n",
      "992:\tlearn: 47210.7784880\ttotal: 16.6s\tremaining: 117ms\n",
      "993:\tlearn: 47200.7483767\ttotal: 16.6s\tremaining: 100ms\n",
      "994:\tlearn: 47176.2107551\ttotal: 16.6s\tremaining: 83.3ms\n",
      "995:\tlearn: 47137.7568327\ttotal: 16.6s\tremaining: 66.7ms\n",
      "996:\tlearn: 47114.0619604\ttotal: 16.6s\tremaining: 50ms\n",
      "997:\tlearn: 47107.2493374\ttotal: 16.6s\tremaining: 33.3ms\n",
      "998:\tlearn: 47102.8518285\ttotal: 16.6s\tremaining: 16.7ms\n",
      "999:\tlearn: 47093.9321924\ttotal: 16.6s\tremaining: 0us\n",
      "Learning rate set to 0.071717\n",
      "0:\tlearn: 76368.3973135\ttotal: 50.6ms\tremaining: 50.5s\n",
      "1:\tlearn: 75951.9707858\ttotal: 71.6ms\tremaining: 35.7s\n",
      "2:\tlearn: 75538.9711276\ttotal: 98.6ms\tremaining: 32.8s\n",
      "3:\tlearn: 75185.2394089\ttotal: 117ms\tremaining: 29.3s\n",
      "4:\tlearn: 74806.6407322\ttotal: 137ms\tremaining: 27.3s\n",
      "5:\tlearn: 74462.1699759\ttotal: 164ms\tremaining: 27.2s\n",
      "6:\tlearn: 74208.2768204\ttotal: 185ms\tremaining: 26.2s\n",
      "7:\tlearn: 73928.5014175\ttotal: 220ms\tremaining: 27.3s\n",
      "8:\tlearn: 73716.3399790\ttotal: 245ms\tremaining: 27s\n",
      "9:\tlearn: 73535.7902707\ttotal: 262ms\tremaining: 25.9s\n",
      "10:\tlearn: 73382.4373587\ttotal: 281ms\tremaining: 25.3s\n",
      "11:\tlearn: 73122.2301553\ttotal: 299ms\tremaining: 24.6s\n",
      "12:\tlearn: 72972.2807684\ttotal: 319ms\tremaining: 24.2s\n",
      "13:\tlearn: 72841.2646408\ttotal: 334ms\tremaining: 23.5s\n",
      "14:\tlearn: 72720.5379380\ttotal: 348ms\tremaining: 22.8s\n",
      "15:\tlearn: 72545.2008527\ttotal: 362ms\tremaining: 22.3s\n",
      "16:\tlearn: 72433.0986458\ttotal: 399ms\tremaining: 23.1s\n",
      "17:\tlearn: 72290.6654419\ttotal: 417ms\tremaining: 22.8s\n",
      "18:\tlearn: 72173.9037954\ttotal: 453ms\tremaining: 23.4s\n",
      "19:\tlearn: 72090.4433703\ttotal: 476ms\tremaining: 23.3s\n",
      "20:\tlearn: 72012.7024210\ttotal: 517ms\tremaining: 24.1s\n",
      "21:\tlearn: 71896.1186407\ttotal: 546ms\tremaining: 24.3s\n",
      "22:\tlearn: 71749.6582108\ttotal: 567ms\tremaining: 24.1s\n",
      "23:\tlearn: 71664.2481162\ttotal: 596ms\tremaining: 24.2s\n",
      "24:\tlearn: 71561.6277142\ttotal: 614ms\tremaining: 24s\n",
      "25:\tlearn: 71300.3290489\ttotal: 630ms\tremaining: 23.6s\n",
      "26:\tlearn: 71230.9553175\ttotal: 645ms\tremaining: 23.3s\n",
      "27:\tlearn: 71162.3724346\ttotal: 658ms\tremaining: 22.8s\n",
      "28:\tlearn: 71098.0127027\ttotal: 676ms\tremaining: 22.6s\n",
      "29:\tlearn: 71023.1977469\ttotal: 684ms\tremaining: 22.1s\n",
      "30:\tlearn: 70965.2179986\ttotal: 746ms\tremaining: 23.3s\n",
      "31:\tlearn: 70930.1879519\ttotal: 779ms\tremaining: 23.6s\n",
      "32:\tlearn: 70890.1601025\ttotal: 804ms\tremaining: 23.6s\n",
      "33:\tlearn: 70829.3157892\ttotal: 817ms\tremaining: 23.2s\n",
      "34:\tlearn: 70796.9348956\ttotal: 833ms\tremaining: 23s\n",
      "35:\tlearn: 70754.5954774\ttotal: 847ms\tremaining: 22.7s\n",
      "36:\tlearn: 70722.6703832\ttotal: 861ms\tremaining: 22.4s\n",
      "37:\tlearn: 70684.0928617\ttotal: 871ms\tremaining: 22s\n",
      "38:\tlearn: 70640.9446824\ttotal: 895ms\tremaining: 22s\n",
      "39:\tlearn: 70605.5905500\ttotal: 926ms\tremaining: 22.2s\n",
      "40:\tlearn: 70562.6850367\ttotal: 946ms\tremaining: 22.1s\n",
      "41:\tlearn: 70439.0734054\ttotal: 960ms\tremaining: 21.9s\n",
      "42:\tlearn: 70412.4595993\ttotal: 973ms\tremaining: 21.6s\n",
      "43:\tlearn: 70363.2613292\ttotal: 981ms\tremaining: 21.3s\n",
      "44:\tlearn: 70325.6494107\ttotal: 994ms\tremaining: 21.1s\n",
      "45:\tlearn: 70291.8520823\ttotal: 1.01s\tremaining: 20.9s\n",
      "46:\tlearn: 70267.8461680\ttotal: 1.04s\tremaining: 21.1s\n",
      "47:\tlearn: 70242.0595613\ttotal: 1.05s\tremaining: 20.8s\n",
      "48:\tlearn: 70224.9841161\ttotal: 1.06s\tremaining: 20.6s\n",
      "49:\tlearn: 70195.2119472\ttotal: 1.08s\tremaining: 20.5s\n",
      "50:\tlearn: 70171.4282620\ttotal: 1.09s\tremaining: 20.4s\n",
      "51:\tlearn: 70150.0527744\ttotal: 1.11s\tremaining: 20.3s\n",
      "52:\tlearn: 70092.7244597\ttotal: 1.17s\tremaining: 20.9s\n",
      "53:\tlearn: 70064.8835076\ttotal: 1.18s\tremaining: 20.7s\n",
      "54:\tlearn: 70042.3422930\ttotal: 1.2s\tremaining: 20.6s\n",
      "55:\tlearn: 70019.0062760\ttotal: 1.21s\tremaining: 20.4s\n",
      "56:\tlearn: 69995.2380057\ttotal: 1.22s\tremaining: 20.2s\n",
      "57:\tlearn: 69966.2774411\ttotal: 1.55s\tremaining: 25.3s\n",
      "58:\tlearn: 69949.9490543\ttotal: 1.6s\tremaining: 25.6s\n",
      "59:\tlearn: 69925.9469891\ttotal: 1.64s\tremaining: 25.6s\n",
      "60:\tlearn: 69899.4134689\ttotal: 1.83s\tremaining: 28.1s\n",
      "61:\tlearn: 69882.8902126\ttotal: 1.86s\tremaining: 28.1s\n",
      "62:\tlearn: 69841.5294287\ttotal: 1.89s\tremaining: 28.1s\n",
      "63:\tlearn: 69669.4053757\ttotal: 1.91s\tremaining: 27.9s\n",
      "64:\tlearn: 69493.7018410\ttotal: 1.94s\tremaining: 27.9s\n",
      "65:\tlearn: 69477.1872531\ttotal: 1.97s\tremaining: 27.9s\n",
      "66:\tlearn: 69459.8559447\ttotal: 2s\tremaining: 27.8s\n",
      "67:\tlearn: 69404.3785782\ttotal: 2.01s\tremaining: 27.6s\n",
      "68:\tlearn: 69382.2092580\ttotal: 2.03s\tremaining: 27.4s\n",
      "69:\tlearn: 69304.0845592\ttotal: 2.05s\tremaining: 27.2s\n",
      "70:\tlearn: 69238.3226242\ttotal: 2.08s\tremaining: 27.2s\n",
      "71:\tlearn: 69218.7277580\ttotal: 2.11s\tremaining: 27.2s\n",
      "72:\tlearn: 69206.0401372\ttotal: 2.21s\tremaining: 28.1s\n",
      "73:\tlearn: 69196.1889246\ttotal: 2.23s\tremaining: 27.9s\n",
      "74:\tlearn: 69183.9259971\ttotal: 2.25s\tremaining: 27.7s\n",
      "75:\tlearn: 69176.3326197\ttotal: 2.26s\tremaining: 27.5s\n",
      "76:\tlearn: 69169.7767421\ttotal: 2.28s\tremaining: 27.3s\n",
      "77:\tlearn: 69162.8279312\ttotal: 2.29s\tremaining: 27s\n",
      "78:\tlearn: 69156.7996673\ttotal: 2.29s\tremaining: 26.8s\n",
      "79:\tlearn: 68973.7239945\ttotal: 2.31s\tremaining: 26.5s\n",
      "80:\tlearn: 68928.1891766\ttotal: 2.32s\tremaining: 26.3s\n",
      "81:\tlearn: 68785.7021148\ttotal: 2.35s\tremaining: 26.3s\n",
      "82:\tlearn: 68779.2030454\ttotal: 2.37s\tremaining: 26.1s\n",
      "83:\tlearn: 68743.9079651\ttotal: 2.38s\tremaining: 25.9s\n",
      "84:\tlearn: 68555.1547439\ttotal: 2.39s\tremaining: 25.8s\n",
      "85:\tlearn: 68541.8063428\ttotal: 2.4s\tremaining: 25.6s\n",
      "86:\tlearn: 68536.6749026\ttotal: 2.41s\tremaining: 25.3s\n",
      "87:\tlearn: 68430.0732368\ttotal: 2.43s\tremaining: 25.2s\n",
      "88:\tlearn: 68423.4513640\ttotal: 2.44s\tremaining: 25s\n",
      "89:\tlearn: 68282.8735565\ttotal: 2.46s\tremaining: 24.9s\n",
      "90:\tlearn: 68272.3800216\ttotal: 2.47s\tremaining: 24.7s\n",
      "91:\tlearn: 68261.0718222\ttotal: 2.49s\tremaining: 24.6s\n",
      "92:\tlearn: 68255.5624900\ttotal: 2.5s\tremaining: 24.4s\n",
      "93:\tlearn: 68251.0133216\ttotal: 2.51s\tremaining: 24.2s\n",
      "94:\tlearn: 68052.5546693\ttotal: 2.53s\tremaining: 24.1s\n",
      "95:\tlearn: 68029.7669041\ttotal: 2.53s\tremaining: 23.9s\n",
      "96:\tlearn: 67968.5888464\ttotal: 2.55s\tremaining: 23.7s\n",
      "97:\tlearn: 67842.6873892\ttotal: 2.56s\tremaining: 23.6s\n",
      "98:\tlearn: 67800.1985298\ttotal: 2.58s\tremaining: 23.4s\n",
      "99:\tlearn: 67786.4172934\ttotal: 2.61s\tremaining: 23.5s\n",
      "100:\tlearn: 67780.9907377\ttotal: 2.63s\tremaining: 23.4s\n",
      "101:\tlearn: 67728.6031675\ttotal: 2.64s\tremaining: 23.2s\n",
      "102:\tlearn: 67499.1136920\ttotal: 2.66s\tremaining: 23.2s\n",
      "103:\tlearn: 67467.3753563\ttotal: 2.67s\tremaining: 23s\n",
      "104:\tlearn: 67461.8184098\ttotal: 2.68s\tremaining: 22.9s\n",
      "105:\tlearn: 67437.7217667\ttotal: 2.7s\tremaining: 22.8s\n",
      "106:\tlearn: 67379.3054784\ttotal: 2.73s\tremaining: 22.8s\n",
      "107:\tlearn: 67327.1641219\ttotal: 2.75s\tremaining: 22.7s\n",
      "108:\tlearn: 67308.1008535\ttotal: 2.77s\tremaining: 22.6s\n",
      "109:\tlearn: 67304.1112133\ttotal: 2.78s\tremaining: 22.5s\n",
      "110:\tlearn: 67152.4236325\ttotal: 2.8s\tremaining: 22.4s\n",
      "111:\tlearn: 67139.3759945\ttotal: 2.83s\tremaining: 22.4s\n",
      "112:\tlearn: 67114.9133000\ttotal: 2.84s\tremaining: 22.3s\n",
      "113:\tlearn: 67000.4457495\ttotal: 2.85s\tremaining: 22.2s\n",
      "114:\tlearn: 66956.3073941\ttotal: 2.86s\tremaining: 22s\n",
      "115:\tlearn: 66802.1777573\ttotal: 2.88s\tremaining: 21.9s\n",
      "116:\tlearn: 66756.4050511\ttotal: 2.89s\tremaining: 21.8s\n",
      "117:\tlearn: 66600.0204143\ttotal: 2.91s\tremaining: 21.7s\n",
      "118:\tlearn: 66577.0738619\ttotal: 2.92s\tremaining: 21.6s\n",
      "119:\tlearn: 66464.6882114\ttotal: 2.93s\tremaining: 21.5s\n",
      "120:\tlearn: 66440.5495741\ttotal: 2.95s\tremaining: 21.4s\n",
      "121:\tlearn: 66321.4137458\ttotal: 2.96s\tremaining: 21.3s\n",
      "122:\tlearn: 66290.2818248\ttotal: 2.98s\tremaining: 21.2s\n",
      "123:\tlearn: 66285.7021447\ttotal: 3s\tremaining: 21.2s\n",
      "124:\tlearn: 66264.9906421\ttotal: 3.02s\tremaining: 21.2s\n",
      "125:\tlearn: 66261.3812990\ttotal: 3.04s\tremaining: 21.1s\n",
      "126:\tlearn: 66241.6091799\ttotal: 3.06s\tremaining: 21s\n",
      "127:\tlearn: 66237.8979985\ttotal: 3.06s\tremaining: 20.9s\n",
      "128:\tlearn: 66231.0044876\ttotal: 3.08s\tremaining: 20.8s\n",
      "129:\tlearn: 66210.9259626\ttotal: 3.1s\tremaining: 20.7s\n",
      "130:\tlearn: 66115.7904748\ttotal: 3.11s\tremaining: 20.6s\n",
      "131:\tlearn: 65968.1161157\ttotal: 3.13s\tremaining: 20.6s\n",
      "132:\tlearn: 65945.0254442\ttotal: 3.14s\tremaining: 20.5s\n",
      "133:\tlearn: 65938.2553782\ttotal: 3.16s\tremaining: 20.4s\n",
      "134:\tlearn: 65802.7139667\ttotal: 3.17s\tremaining: 20.3s\n",
      "135:\tlearn: 65795.3823778\ttotal: 3.19s\tremaining: 20.2s\n",
      "136:\tlearn: 65660.4016937\ttotal: 3.22s\tremaining: 20.3s\n",
      "137:\tlearn: 65589.3147546\ttotal: 3.24s\tremaining: 20.2s\n",
      "138:\tlearn: 65578.3424367\ttotal: 3.27s\tremaining: 20.2s\n",
      "139:\tlearn: 65562.7625406\ttotal: 3.29s\tremaining: 20.2s\n",
      "140:\tlearn: 65444.1348122\ttotal: 3.3s\tremaining: 20.1s\n",
      "141:\tlearn: 65435.5380386\ttotal: 3.31s\tremaining: 20s\n",
      "142:\tlearn: 65415.6410617\ttotal: 3.33s\tremaining: 19.9s\n",
      "143:\tlearn: 65296.1493028\ttotal: 3.34s\tremaining: 19.9s\n",
      "144:\tlearn: 65242.6070877\ttotal: 3.35s\tremaining: 19.8s\n",
      "145:\tlearn: 65134.5465478\ttotal: 3.37s\tremaining: 19.7s\n",
      "146:\tlearn: 65083.5501549\ttotal: 3.39s\tremaining: 19.7s\n",
      "147:\tlearn: 65006.1374427\ttotal: 3.39s\tremaining: 19.5s\n",
      "148:\tlearn: 64957.4908945\ttotal: 3.41s\tremaining: 19.5s\n",
      "149:\tlearn: 64854.0198199\ttotal: 3.42s\tremaining: 19.4s\n",
      "150:\tlearn: 64736.9219985\ttotal: 3.44s\tremaining: 19.3s\n",
      "151:\tlearn: 64654.0669502\ttotal: 3.45s\tremaining: 19.3s\n",
      "152:\tlearn: 64561.9982222\ttotal: 3.48s\tremaining: 19.3s\n",
      "153:\tlearn: 64559.2685168\ttotal: 3.5s\tremaining: 19.2s\n",
      "154:\tlearn: 64513.7613316\ttotal: 3.51s\tremaining: 19.1s\n",
      "155:\tlearn: 64426.2336873\ttotal: 3.53s\tremaining: 19.1s\n",
      "156:\tlearn: 64344.1899384\ttotal: 3.54s\tremaining: 19s\n",
      "157:\tlearn: 64325.6696165\ttotal: 3.56s\tremaining: 19s\n",
      "158:\tlearn: 64265.4656578\ttotal: 3.57s\tremaining: 18.9s\n",
      "159:\tlearn: 64194.3242560\ttotal: 3.58s\tremaining: 18.8s\n",
      "160:\tlearn: 64117.6539214\ttotal: 3.59s\tremaining: 18.7s\n",
      "161:\tlearn: 64084.2252210\ttotal: 3.6s\tremaining: 18.6s\n",
      "162:\tlearn: 64011.5521089\ttotal: 3.61s\tremaining: 18.6s\n",
      "163:\tlearn: 63966.1703725\ttotal: 3.63s\tremaining: 18.5s\n",
      "164:\tlearn: 63902.7792967\ttotal: 3.64s\tremaining: 18.4s\n",
      "165:\tlearn: 63852.3928279\ttotal: 3.66s\tremaining: 18.4s\n",
      "166:\tlearn: 63812.8998902\ttotal: 3.69s\tremaining: 18.4s\n",
      "167:\tlearn: 63790.1691680\ttotal: 3.71s\tremaining: 18.4s\n",
      "168:\tlearn: 63740.7456777\ttotal: 3.72s\tremaining: 18.3s\n",
      "169:\tlearn: 63694.7710005\ttotal: 3.73s\tremaining: 18.2s\n",
      "170:\tlearn: 63682.4841257\ttotal: 3.75s\tremaining: 18.2s\n",
      "171:\tlearn: 63614.0945742\ttotal: 3.76s\tremaining: 18.1s\n",
      "172:\tlearn: 63539.9994838\ttotal: 3.78s\tremaining: 18.1s\n",
      "173:\tlearn: 63518.1495823\ttotal: 3.79s\tremaining: 18s\n",
      "174:\tlearn: 63474.0934025\ttotal: 3.8s\tremaining: 17.9s\n",
      "175:\tlearn: 63462.0205870\ttotal: 3.81s\tremaining: 17.8s\n",
      "176:\tlearn: 63407.5335093\ttotal: 3.82s\tremaining: 17.8s\n",
      "177:\tlearn: 63345.0945854\ttotal: 3.83s\tremaining: 17.7s\n",
      "178:\tlearn: 63322.3080409\ttotal: 3.84s\tremaining: 17.6s\n",
      "179:\tlearn: 63301.0630330\ttotal: 3.86s\tremaining: 17.6s\n",
      "180:\tlearn: 63235.8304047\ttotal: 3.97s\tremaining: 18s\n",
      "181:\tlearn: 63176.8960444\ttotal: 3.99s\tremaining: 17.9s\n",
      "182:\tlearn: 63132.1636703\ttotal: 4s\tremaining: 17.8s\n",
      "183:\tlearn: 63097.5430318\ttotal: 4.01s\tremaining: 17.8s\n",
      "184:\tlearn: 63043.6211717\ttotal: 4.03s\tremaining: 17.7s\n",
      "185:\tlearn: 62999.9155769\ttotal: 4.04s\tremaining: 17.7s\n",
      "186:\tlearn: 62956.8902491\ttotal: 4.05s\tremaining: 17.6s\n",
      "187:\tlearn: 62884.7806321\ttotal: 4.06s\tremaining: 17.5s\n",
      "188:\tlearn: 62853.2391975\ttotal: 4.08s\tremaining: 17.5s\n",
      "189:\tlearn: 62801.9513612\ttotal: 4.11s\tremaining: 17.5s\n",
      "190:\tlearn: 62732.5118069\ttotal: 4.14s\tremaining: 17.5s\n",
      "191:\tlearn: 62690.4206430\ttotal: 4.15s\tremaining: 17.5s\n",
      "192:\tlearn: 62641.9388213\ttotal: 4.16s\tremaining: 17.4s\n",
      "193:\tlearn: 62596.0560604\ttotal: 4.18s\tremaining: 17.4s\n",
      "194:\tlearn: 62567.0153091\ttotal: 4.19s\tremaining: 17.3s\n",
      "195:\tlearn: 62526.5626851\ttotal: 4.2s\tremaining: 17.2s\n",
      "196:\tlearn: 62467.1876580\ttotal: 4.21s\tremaining: 17.2s\n",
      "197:\tlearn: 62417.7293746\ttotal: 4.22s\tremaining: 17.1s\n",
      "198:\tlearn: 62394.9542753\ttotal: 4.24s\tremaining: 17.1s\n",
      "199:\tlearn: 62347.7366854\ttotal: 4.25s\tremaining: 17s\n",
      "200:\tlearn: 62281.9362305\ttotal: 4.26s\tremaining: 16.9s\n",
      "201:\tlearn: 62211.9323030\ttotal: 4.27s\tremaining: 16.9s\n",
      "202:\tlearn: 62179.5285243\ttotal: 4.29s\tremaining: 16.8s\n",
      "203:\tlearn: 62168.0522588\ttotal: 4.3s\tremaining: 16.8s\n",
      "204:\tlearn: 62148.4181458\ttotal: 4.31s\tremaining: 16.7s\n",
      "205:\tlearn: 62131.4012198\ttotal: 4.32s\tremaining: 16.6s\n",
      "206:\tlearn: 62113.8591960\ttotal: 4.35s\tremaining: 16.7s\n",
      "207:\tlearn: 62082.5801286\ttotal: 4.37s\tremaining: 16.6s\n",
      "208:\tlearn: 62078.0782364\ttotal: 4.38s\tremaining: 16.6s\n",
      "209:\tlearn: 62060.4419053\ttotal: 4.4s\tremaining: 16.6s\n",
      "210:\tlearn: 61979.1127849\ttotal: 4.42s\tremaining: 16.5s\n",
      "211:\tlearn: 61906.2799346\ttotal: 4.43s\tremaining: 16.5s\n",
      "212:\tlearn: 61894.9477132\ttotal: 4.44s\tremaining: 16.4s\n",
      "213:\tlearn: 61817.2320720\ttotal: 4.45s\tremaining: 16.4s\n",
      "214:\tlearn: 61788.4454975\ttotal: 4.47s\tremaining: 16.3s\n",
      "215:\tlearn: 61732.2616991\ttotal: 4.48s\tremaining: 16.3s\n",
      "216:\tlearn: 61716.6607457\ttotal: 4.49s\tremaining: 16.2s\n",
      "217:\tlearn: 61642.6262153\ttotal: 4.51s\tremaining: 16.2s\n",
      "218:\tlearn: 61632.6101570\ttotal: 4.53s\tremaining: 16.1s\n",
      "219:\tlearn: 61608.5118259\ttotal: 4.54s\tremaining: 16.1s\n",
      "220:\tlearn: 61572.8794683\ttotal: 4.55s\tremaining: 16.1s\n",
      "221:\tlearn: 61502.4261800\ttotal: 4.56s\tremaining: 16s\n",
      "222:\tlearn: 61468.4321968\ttotal: 4.58s\tremaining: 15.9s\n",
      "223:\tlearn: 61458.3222225\ttotal: 4.59s\tremaining: 15.9s\n",
      "224:\tlearn: 61393.8935840\ttotal: 4.61s\tremaining: 15.9s\n",
      "225:\tlearn: 61326.4818877\ttotal: 4.62s\tremaining: 15.8s\n",
      "226:\tlearn: 61303.5428214\ttotal: 4.64s\tremaining: 15.8s\n",
      "227:\tlearn: 61238.7575725\ttotal: 4.64s\tremaining: 15.7s\n",
      "228:\tlearn: 61232.7479734\ttotal: 4.66s\tremaining: 15.7s\n",
      "229:\tlearn: 61170.4833079\ttotal: 4.67s\tremaining: 15.6s\n",
      "230:\tlearn: 61110.6266371\ttotal: 4.68s\tremaining: 15.6s\n",
      "231:\tlearn: 61068.4264543\ttotal: 4.69s\tremaining: 15.5s\n",
      "232:\tlearn: 61010.8042001\ttotal: 4.71s\tremaining: 15.5s\n",
      "233:\tlearn: 60992.9554133\ttotal: 4.74s\tremaining: 15.5s\n",
      "234:\tlearn: 60937.5102798\ttotal: 4.76s\tremaining: 15.5s\n",
      "235:\tlearn: 60918.5892984\ttotal: 4.78s\tremaining: 15.5s\n",
      "236:\tlearn: 60865.2282030\ttotal: 4.8s\tremaining: 15.4s\n",
      "237:\tlearn: 60843.0090920\ttotal: 4.81s\tremaining: 15.4s\n",
      "238:\tlearn: 60813.6706070\ttotal: 4.82s\tremaining: 15.3s\n",
      "239:\tlearn: 60756.2700358\ttotal: 4.83s\tremaining: 15.3s\n",
      "240:\tlearn: 60734.8418360\ttotal: 4.85s\tremaining: 15.3s\n",
      "241:\tlearn: 60683.1469036\ttotal: 4.86s\tremaining: 15.2s\n",
      "242:\tlearn: 60655.0199582\ttotal: 4.87s\tremaining: 15.2s\n",
      "243:\tlearn: 60605.6978268\ttotal: 4.89s\tremaining: 15.1s\n",
      "244:\tlearn: 60582.1666819\ttotal: 4.9s\tremaining: 15.1s\n",
      "245:\tlearn: 60534.4707704\ttotal: 4.91s\tremaining: 15.1s\n",
      "246:\tlearn: 60488.5554534\ttotal: 4.93s\tremaining: 15s\n",
      "247:\tlearn: 60417.0911174\ttotal: 4.94s\tremaining: 15s\n",
      "248:\tlearn: 60372.8305118\ttotal: 4.96s\tremaining: 15s\n",
      "249:\tlearn: 60330.3502335\ttotal: 4.99s\tremaining: 15s\n",
      "250:\tlearn: 60289.4204002\ttotal: 5.01s\tremaining: 14.9s\n",
      "251:\tlearn: 60253.1419925\ttotal: 5.02s\tremaining: 14.9s\n",
      "252:\tlearn: 60224.7336710\ttotal: 5.03s\tremaining: 14.9s\n",
      "253:\tlearn: 60185.2393616\ttotal: 5.04s\tremaining: 14.8s\n",
      "254:\tlearn: 60158.8644061\ttotal: 5.05s\tremaining: 14.8s\n",
      "255:\tlearn: 60120.7852527\ttotal: 5.06s\tremaining: 14.7s\n",
      "256:\tlearn: 60084.0852962\ttotal: 5.08s\tremaining: 14.7s\n",
      "257:\tlearn: 60051.3129080\ttotal: 5.09s\tremaining: 14.6s\n",
      "258:\tlearn: 60018.7417948\ttotal: 5.11s\tremaining: 14.6s\n",
      "259:\tlearn: 59983.3317857\ttotal: 5.11s\tremaining: 14.6s\n",
      "260:\tlearn: 59971.7527215\ttotal: 5.13s\tremaining: 14.5s\n",
      "261:\tlearn: 59937.6102609\ttotal: 5.15s\tremaining: 14.5s\n",
      "262:\tlearn: 59928.1718513\ttotal: 5.18s\tremaining: 14.5s\n",
      "263:\tlearn: 59911.8697634\ttotal: 5.19s\tremaining: 14.5s\n",
      "264:\tlearn: 59896.9124157\ttotal: 5.22s\tremaining: 14.5s\n",
      "265:\tlearn: 59827.5920722\ttotal: 5.23s\tremaining: 14.4s\n",
      "266:\tlearn: 59794.2744098\ttotal: 5.24s\tremaining: 14.4s\n",
      "267:\tlearn: 59762.4664238\ttotal: 5.26s\tremaining: 14.4s\n",
      "268:\tlearn: 59735.9371391\ttotal: 5.27s\tremaining: 14.3s\n",
      "269:\tlearn: 59705.2571131\ttotal: 5.28s\tremaining: 14.3s\n",
      "270:\tlearn: 59675.6779085\ttotal: 5.3s\tremaining: 14.3s\n",
      "271:\tlearn: 59647.1586350\ttotal: 5.32s\tremaining: 14.2s\n",
      "272:\tlearn: 59630.4497929\ttotal: 5.33s\tremaining: 14.2s\n",
      "273:\tlearn: 59609.6978590\ttotal: 5.34s\tremaining: 14.2s\n",
      "274:\tlearn: 59591.2108543\ttotal: 5.36s\tremaining: 14.1s\n",
      "275:\tlearn: 59567.2416247\ttotal: 5.38s\tremaining: 14.1s\n",
      "276:\tlearn: 59500.1092385\ttotal: 5.4s\tremaining: 14.1s\n",
      "277:\tlearn: 59472.6726618\ttotal: 5.41s\tremaining: 14.1s\n",
      "278:\tlearn: 59446.2165422\ttotal: 5.42s\tremaining: 14s\n",
      "279:\tlearn: 59431.1369970\ttotal: 5.44s\tremaining: 14s\n",
      "280:\tlearn: 59426.0375983\ttotal: 5.45s\tremaining: 13.9s\n",
      "281:\tlearn: 59400.5179497\ttotal: 5.46s\tremaining: 13.9s\n",
      "282:\tlearn: 59375.5418185\ttotal: 5.47s\tremaining: 13.9s\n",
      "283:\tlearn: 59352.1101875\ttotal: 5.49s\tremaining: 13.8s\n",
      "284:\tlearn: 59327.9033666\ttotal: 5.5s\tremaining: 13.8s\n",
      "285:\tlearn: 59321.2420503\ttotal: 5.52s\tremaining: 13.8s\n",
      "286:\tlearn: 59275.6244666\ttotal: 5.53s\tremaining: 13.7s\n",
      "287:\tlearn: 59208.1598846\ttotal: 5.54s\tremaining: 13.7s\n",
      "288:\tlearn: 59143.1707858\ttotal: 5.56s\tremaining: 13.7s\n",
      "289:\tlearn: 59127.0974181\ttotal: 5.58s\tremaining: 13.7s\n",
      "290:\tlearn: 59104.8235454\ttotal: 5.65s\tremaining: 13.8s\n",
      "291:\tlearn: 59044.4066569\ttotal: 5.7s\tremaining: 13.8s\n",
      "292:\tlearn: 59028.9261880\ttotal: 5.71s\tremaining: 13.8s\n",
      "293:\tlearn: 58960.8204515\ttotal: 5.73s\tremaining: 13.8s\n",
      "294:\tlearn: 58935.3295814\ttotal: 5.75s\tremaining: 13.7s\n",
      "295:\tlearn: 58870.3276130\ttotal: 5.77s\tremaining: 13.7s\n",
      "296:\tlearn: 58849.0426534\ttotal: 5.78s\tremaining: 13.7s\n",
      "297:\tlearn: 58831.4911715\ttotal: 5.83s\tremaining: 13.7s\n",
      "298:\tlearn: 58817.2158966\ttotal: 5.84s\tremaining: 13.7s\n",
      "299:\tlearn: 58811.8204193\ttotal: 5.85s\tremaining: 13.6s\n",
      "300:\tlearn: 58788.9858656\ttotal: 5.86s\tremaining: 13.6s\n",
      "301:\tlearn: 58766.9636983\ttotal: 5.87s\tremaining: 13.6s\n",
      "302:\tlearn: 58745.2468836\ttotal: 5.88s\tremaining: 13.5s\n",
      "303:\tlearn: 58730.3586303\ttotal: 5.9s\tremaining: 13.5s\n",
      "304:\tlearn: 58689.5436883\ttotal: 5.91s\tremaining: 13.5s\n",
      "305:\tlearn: 58662.6398415\ttotal: 5.93s\tremaining: 13.4s\n",
      "306:\tlearn: 58599.5717728\ttotal: 5.95s\tremaining: 13.4s\n",
      "307:\tlearn: 58568.5796912\ttotal: 5.96s\tremaining: 13.4s\n",
      "308:\tlearn: 58548.0071676\ttotal: 5.97s\tremaining: 13.4s\n",
      "309:\tlearn: 58528.4824256\ttotal: 5.98s\tremaining: 13.3s\n",
      "310:\tlearn: 58489.7733877\ttotal: 6s\tremaining: 13.3s\n",
      "311:\tlearn: 58467.3105146\ttotal: 6.03s\tremaining: 13.3s\n",
      "312:\tlearn: 58443.0208141\ttotal: 6.06s\tremaining: 13.3s\n",
      "313:\tlearn: 58401.4086788\ttotal: 6.08s\tremaining: 13.3s\n",
      "314:\tlearn: 58394.2960835\ttotal: 6.1s\tremaining: 13.3s\n",
      "315:\tlearn: 58381.6176572\ttotal: 6.11s\tremaining: 13.2s\n",
      "316:\tlearn: 58373.9682067\ttotal: 6.12s\tremaining: 13.2s\n",
      "317:\tlearn: 58353.1296013\ttotal: 6.14s\tremaining: 13.2s\n",
      "318:\tlearn: 58293.3723004\ttotal: 6.15s\tremaining: 13.1s\n",
      "319:\tlearn: 58270.0887018\ttotal: 6.16s\tremaining: 13.1s\n",
      "320:\tlearn: 58251.8640748\ttotal: 6.17s\tremaining: 13.1s\n",
      "321:\tlearn: 58225.3223747\ttotal: 6.18s\tremaining: 13s\n",
      "322:\tlearn: 58188.5227860\ttotal: 6.19s\tremaining: 13s\n",
      "323:\tlearn: 58173.7790049\ttotal: 6.21s\tremaining: 13s\n",
      "324:\tlearn: 58153.5117143\ttotal: 6.22s\tremaining: 12.9s\n",
      "325:\tlearn: 58104.4440705\ttotal: 6.25s\tremaining: 12.9s\n",
      "326:\tlearn: 58097.5434568\ttotal: 6.27s\tremaining: 12.9s\n",
      "327:\tlearn: 58030.5547684\ttotal: 6.28s\tremaining: 12.9s\n",
      "328:\tlearn: 58011.2838289\ttotal: 6.29s\tremaining: 12.8s\n",
      "329:\tlearn: 57977.3614864\ttotal: 6.31s\tremaining: 12.8s\n",
      "330:\tlearn: 57956.1768658\ttotal: 6.32s\tremaining: 12.8s\n",
      "331:\tlearn: 57949.6416013\ttotal: 6.33s\tremaining: 12.7s\n",
      "332:\tlearn: 57937.8020469\ttotal: 6.34s\tremaining: 12.7s\n",
      "333:\tlearn: 57876.4460500\ttotal: 6.36s\tremaining: 12.7s\n",
      "334:\tlearn: 57857.8469975\ttotal: 6.37s\tremaining: 12.7s\n",
      "335:\tlearn: 57822.0160029\ttotal: 6.38s\tremaining: 12.6s\n",
      "336:\tlearn: 57757.8691144\ttotal: 6.39s\tremaining: 12.6s\n",
      "337:\tlearn: 57739.5073834\ttotal: 6.41s\tremaining: 12.5s\n",
      "338:\tlearn: 57722.1517407\ttotal: 6.42s\tremaining: 12.5s\n",
      "339:\tlearn: 57708.9815550\ttotal: 6.42s\tremaining: 12.5s\n",
      "340:\tlearn: 57666.5443136\ttotal: 6.45s\tremaining: 12.5s\n",
      "341:\tlearn: 57661.9167797\ttotal: 6.47s\tremaining: 12.5s\n",
      "342:\tlearn: 57621.9802056\ttotal: 6.49s\tremaining: 12.4s\n",
      "343:\tlearn: 57612.5430078\ttotal: 6.5s\tremaining: 12.4s\n",
      "344:\tlearn: 57606.3705046\ttotal: 6.51s\tremaining: 12.4s\n",
      "345:\tlearn: 57597.2149217\ttotal: 6.52s\tremaining: 12.3s\n",
      "346:\tlearn: 57537.8480886\ttotal: 6.54s\tremaining: 12.3s\n",
      "347:\tlearn: 57529.4204119\ttotal: 6.55s\tremaining: 12.3s\n",
      "348:\tlearn: 57493.7677624\ttotal: 6.57s\tremaining: 12.2s\n",
      "349:\tlearn: 57489.5395476\ttotal: 6.58s\tremaining: 12.2s\n",
      "350:\tlearn: 57475.0425029\ttotal: 6.59s\tremaining: 12.2s\n",
      "351:\tlearn: 57451.3245310\ttotal: 6.61s\tremaining: 12.2s\n",
      "352:\tlearn: 57447.6666726\ttotal: 6.62s\tremaining: 12.1s\n",
      "353:\tlearn: 57439.9323073\ttotal: 6.64s\tremaining: 12.1s\n",
      "354:\tlearn: 57427.3096040\ttotal: 6.66s\tremaining: 12.1s\n",
      "355:\tlearn: 57413.4659626\ttotal: 6.67s\tremaining: 12.1s\n",
      "356:\tlearn: 57388.6725655\ttotal: 6.7s\tremaining: 12.1s\n",
      "357:\tlearn: 57355.6195472\ttotal: 6.71s\tremaining: 12s\n",
      "358:\tlearn: 57298.2046024\ttotal: 6.72s\tremaining: 12s\n",
      "359:\tlearn: 57282.5469582\ttotal: 6.74s\tremaining: 12s\n",
      "360:\tlearn: 57277.0289778\ttotal: 6.75s\tremaining: 12s\n",
      "361:\tlearn: 57239.2061610\ttotal: 6.77s\tremaining: 11.9s\n",
      "362:\tlearn: 57232.1301302\ttotal: 6.78s\tremaining: 11.9s\n",
      "363:\tlearn: 57224.1781221\ttotal: 6.79s\tremaining: 11.9s\n",
      "364:\tlearn: 57212.7930814\ttotal: 6.8s\tremaining: 11.8s\n",
      "365:\tlearn: 57189.4410426\ttotal: 6.82s\tremaining: 11.8s\n",
      "366:\tlearn: 57177.4613615\ttotal: 6.83s\tremaining: 11.8s\n",
      "367:\tlearn: 57115.2514074\ttotal: 6.84s\tremaining: 11.8s\n",
      "368:\tlearn: 57109.7546171\ttotal: 6.86s\tremaining: 11.7s\n",
      "369:\tlearn: 57071.8412766\ttotal: 6.87s\tremaining: 11.7s\n",
      "370:\tlearn: 57056.4629233\ttotal: 6.89s\tremaining: 11.7s\n",
      "371:\tlearn: 57049.9996050\ttotal: 6.94s\tremaining: 11.7s\n",
      "372:\tlearn: 57043.5071737\ttotal: 6.96s\tremaining: 11.7s\n",
      "373:\tlearn: 57034.7744963\ttotal: 6.97s\tremaining: 11.7s\n",
      "374:\tlearn: 57020.0712181\ttotal: 6.98s\tremaining: 11.6s\n",
      "375:\tlearn: 56966.1162005\ttotal: 7s\tremaining: 11.6s\n",
      "376:\tlearn: 56960.8803865\ttotal: 7.01s\tremaining: 11.6s\n",
      "377:\tlearn: 56955.8966540\ttotal: 7.02s\tremaining: 11.6s\n",
      "378:\tlearn: 56937.8718201\ttotal: 7.03s\tremaining: 11.5s\n",
      "379:\tlearn: 56923.2171345\ttotal: 7.05s\tremaining: 11.5s\n",
      "380:\tlearn: 56910.3834938\ttotal: 7.07s\tremaining: 11.5s\n",
      "381:\tlearn: 56905.6751711\ttotal: 7.08s\tremaining: 11.5s\n",
      "382:\tlearn: 56901.1847661\ttotal: 7.18s\tremaining: 11.6s\n",
      "383:\tlearn: 56895.8603657\ttotal: 7.2s\tremaining: 11.5s\n",
      "384:\tlearn: 56882.7132331\ttotal: 7.21s\tremaining: 11.5s\n",
      "385:\tlearn: 56856.4997483\ttotal: 7.22s\tremaining: 11.5s\n",
      "386:\tlearn: 56848.4435990\ttotal: 7.23s\tremaining: 11.5s\n",
      "387:\tlearn: 56825.1970511\ttotal: 7.24s\tremaining: 11.4s\n",
      "388:\tlearn: 56769.5157910\ttotal: 7.25s\tremaining: 11.4s\n",
      "389:\tlearn: 56758.5273809\ttotal: 7.26s\tremaining: 11.4s\n",
      "390:\tlearn: 56744.3965978\ttotal: 7.28s\tremaining: 11.3s\n",
      "391:\tlearn: 56730.1605703\ttotal: 7.3s\tremaining: 11.3s\n",
      "392:\tlearn: 56701.6248960\ttotal: 7.33s\tremaining: 11.3s\n",
      "393:\tlearn: 56687.1926523\ttotal: 7.35s\tremaining: 11.3s\n",
      "394:\tlearn: 56663.3190978\ttotal: 7.36s\tremaining: 11.3s\n",
      "395:\tlearn: 56650.1485455\ttotal: 7.38s\tremaining: 11.3s\n",
      "396:\tlearn: 56571.7356955\ttotal: 7.4s\tremaining: 11.2s\n",
      "397:\tlearn: 56559.0209488\ttotal: 7.41s\tremaining: 11.2s\n",
      "398:\tlearn: 56546.3089384\ttotal: 7.42s\tremaining: 11.2s\n",
      "399:\tlearn: 56536.8598714\ttotal: 7.43s\tremaining: 11.2s\n",
      "400:\tlearn: 56526.7493822\ttotal: 7.45s\tremaining: 11.1s\n",
      "401:\tlearn: 56466.1379641\ttotal: 7.46s\tremaining: 11.1s\n",
      "402:\tlearn: 56432.8725255\ttotal: 7.48s\tremaining: 11.1s\n",
      "403:\tlearn: 56420.4463764\ttotal: 7.49s\tremaining: 11.1s\n",
      "404:\tlearn: 56399.9263770\ttotal: 7.51s\tremaining: 11s\n",
      "405:\tlearn: 56377.7541911\ttotal: 7.55s\tremaining: 11s\n",
      "406:\tlearn: 56367.5873728\ttotal: 7.57s\tremaining: 11s\n",
      "407:\tlearn: 56343.1190189\ttotal: 7.58s\tremaining: 11s\n",
      "408:\tlearn: 56325.4466399\ttotal: 7.6s\tremaining: 11s\n",
      "409:\tlearn: 56287.0752992\ttotal: 7.61s\tremaining: 11s\n",
      "410:\tlearn: 56262.8839837\ttotal: 7.63s\tremaining: 10.9s\n",
      "411:\tlearn: 56212.2698206\ttotal: 7.64s\tremaining: 10.9s\n",
      "412:\tlearn: 56204.9128608\ttotal: 7.66s\tremaining: 10.9s\n",
      "413:\tlearn: 56150.7779488\ttotal: 7.67s\tremaining: 10.9s\n",
      "414:\tlearn: 56075.0166823\ttotal: 7.69s\tremaining: 10.8s\n",
      "415:\tlearn: 56066.3715496\ttotal: 7.71s\tremaining: 10.8s\n",
      "416:\tlearn: 56058.0394600\ttotal: 7.73s\tremaining: 10.8s\n",
      "417:\tlearn: 56053.7597318\ttotal: 7.75s\tremaining: 10.8s\n",
      "418:\tlearn: 56027.0920154\ttotal: 7.78s\tremaining: 10.8s\n",
      "419:\tlearn: 56006.7845227\ttotal: 7.81s\tremaining: 10.8s\n",
      "420:\tlearn: 55954.4315931\ttotal: 7.83s\tremaining: 10.8s\n",
      "421:\tlearn: 55945.5273709\ttotal: 7.85s\tremaining: 10.7s\n",
      "422:\tlearn: 55924.4064380\ttotal: 7.87s\tremaining: 10.7s\n",
      "423:\tlearn: 55912.2389922\ttotal: 7.89s\tremaining: 10.7s\n",
      "424:\tlearn: 55889.5534761\ttotal: 7.91s\tremaining: 10.7s\n",
      "425:\tlearn: 55864.4670054\ttotal: 7.92s\tremaining: 10.7s\n",
      "426:\tlearn: 55792.3673087\ttotal: 7.94s\tremaining: 10.7s\n",
      "427:\tlearn: 55781.1077075\ttotal: 7.96s\tremaining: 10.6s\n",
      "428:\tlearn: 55752.9202970\ttotal: 7.98s\tremaining: 10.6s\n",
      "429:\tlearn: 55737.2690977\ttotal: 8s\tremaining: 10.6s\n",
      "430:\tlearn: 55706.3104646\ttotal: 8.03s\tremaining: 10.6s\n",
      "431:\tlearn: 55702.2513703\ttotal: 8.05s\tremaining: 10.6s\n",
      "432:\tlearn: 55681.5387800\ttotal: 8.07s\tremaining: 10.6s\n",
      "433:\tlearn: 55669.3096243\ttotal: 8.08s\tremaining: 10.5s\n",
      "434:\tlearn: 55621.4163378\ttotal: 8.11s\tremaining: 10.5s\n",
      "435:\tlearn: 55555.4816207\ttotal: 8.13s\tremaining: 10.5s\n",
      "436:\tlearn: 55547.6853032\ttotal: 8.14s\tremaining: 10.5s\n",
      "437:\tlearn: 55533.1118627\ttotal: 8.16s\tremaining: 10.5s\n",
      "438:\tlearn: 55520.8535484\ttotal: 8.18s\tremaining: 10.5s\n",
      "439:\tlearn: 55508.5561839\ttotal: 8.19s\tremaining: 10.4s\n",
      "440:\tlearn: 55481.0935327\ttotal: 8.23s\tremaining: 10.4s\n",
      "441:\tlearn: 55471.8530910\ttotal: 8.25s\tremaining: 10.4s\n",
      "442:\tlearn: 55466.0417181\ttotal: 8.27s\tremaining: 10.4s\n",
      "443:\tlearn: 55445.7024802\ttotal: 8.28s\tremaining: 10.4s\n",
      "444:\tlearn: 55403.8924402\ttotal: 8.3s\tremaining: 10.3s\n",
      "445:\tlearn: 55340.5336861\ttotal: 8.31s\tremaining: 10.3s\n",
      "446:\tlearn: 55333.1437310\ttotal: 8.33s\tremaining: 10.3s\n",
      "447:\tlearn: 55288.5004037\ttotal: 8.35s\tremaining: 10.3s\n",
      "448:\tlearn: 55281.3690021\ttotal: 8.36s\tremaining: 10.3s\n",
      "449:\tlearn: 55273.0847932\ttotal: 8.38s\tremaining: 10.2s\n",
      "450:\tlearn: 55268.6424230\ttotal: 8.4s\tremaining: 10.2s\n",
      "451:\tlearn: 55261.9520706\ttotal: 8.41s\tremaining: 10.2s\n",
      "452:\tlearn: 55227.7211662\ttotal: 8.43s\tremaining: 10.2s\n",
      "453:\tlearn: 55224.3928614\ttotal: 8.47s\tremaining: 10.2s\n",
      "454:\tlearn: 55218.3545783\ttotal: 8.48s\tremaining: 10.2s\n",
      "455:\tlearn: 55207.4936485\ttotal: 8.5s\tremaining: 10.1s\n",
      "456:\tlearn: 55188.0077801\ttotal: 8.52s\tremaining: 10.1s\n",
      "457:\tlearn: 55181.2442301\ttotal: 8.53s\tremaining: 10.1s\n",
      "458:\tlearn: 55153.0207663\ttotal: 8.54s\tremaining: 10.1s\n",
      "459:\tlearn: 55129.3824469\ttotal: 8.56s\tremaining: 10s\n",
      "460:\tlearn: 55069.4802770\ttotal: 8.57s\tremaining: 10s\n",
      "461:\tlearn: 55018.2981939\ttotal: 8.58s\tremaining: 9.99s\n",
      "462:\tlearn: 54973.5031585\ttotal: 8.59s\tremaining: 9.97s\n",
      "463:\tlearn: 54962.8954023\ttotal: 8.62s\tremaining: 9.95s\n",
      "464:\tlearn: 54888.3722631\ttotal: 8.63s\tremaining: 9.93s\n",
      "465:\tlearn: 54872.5443804\ttotal: 8.64s\tremaining: 9.9s\n",
      "466:\tlearn: 54861.3185703\ttotal: 8.65s\tremaining: 9.88s\n",
      "467:\tlearn: 54850.7359402\ttotal: 8.66s\tremaining: 9.84s\n",
      "468:\tlearn: 54844.6371128\ttotal: 8.67s\tremaining: 9.82s\n",
      "469:\tlearn: 54777.6288369\ttotal: 8.69s\tremaining: 9.8s\n",
      "470:\tlearn: 54767.6132630\ttotal: 8.79s\tremaining: 9.88s\n",
      "471:\tlearn: 54761.7329445\ttotal: 8.81s\tremaining: 9.85s\n",
      "472:\tlearn: 54703.6963450\ttotal: 8.82s\tremaining: 9.83s\n",
      "473:\tlearn: 54697.7690612\ttotal: 8.84s\tremaining: 9.81s\n",
      "474:\tlearn: 54662.7625035\ttotal: 8.85s\tremaining: 9.79s\n",
      "475:\tlearn: 54636.2076190\ttotal: 8.87s\tremaining: 9.76s\n",
      "476:\tlearn: 54630.0461764\ttotal: 8.88s\tremaining: 9.73s\n",
      "477:\tlearn: 54619.7878465\ttotal: 8.89s\tremaining: 9.71s\n",
      "478:\tlearn: 54596.5311350\ttotal: 8.91s\tremaining: 9.69s\n",
      "479:\tlearn: 54591.2368763\ttotal: 8.92s\tremaining: 9.67s\n",
      "480:\tlearn: 54585.7728158\ttotal: 8.96s\tremaining: 9.67s\n",
      "481:\tlearn: 54575.8778349\ttotal: 8.97s\tremaining: 9.64s\n",
      "482:\tlearn: 54557.9488056\ttotal: 8.99s\tremaining: 9.62s\n",
      "483:\tlearn: 54496.0145233\ttotal: 9s\tremaining: 9.6s\n",
      "484:\tlearn: 54475.5760127\ttotal: 9.02s\tremaining: 9.58s\n",
      "485:\tlearn: 54417.2922552\ttotal: 9.04s\tremaining: 9.56s\n",
      "486:\tlearn: 54394.5567645\ttotal: 9.06s\tremaining: 9.55s\n",
      "487:\tlearn: 54326.0973272\ttotal: 9.07s\tremaining: 9.52s\n",
      "488:\tlearn: 54285.5550798\ttotal: 9.09s\tremaining: 9.49s\n",
      "489:\tlearn: 54275.5244329\ttotal: 9.1s\tremaining: 9.47s\n",
      "490:\tlearn: 54253.9636034\ttotal: 9.12s\tremaining: 9.45s\n",
      "491:\tlearn: 54248.2315673\ttotal: 9.15s\tremaining: 9.45s\n",
      "492:\tlearn: 54242.9090116\ttotal: 9.16s\tremaining: 9.43s\n",
      "493:\tlearn: 54223.6341096\ttotal: 9.18s\tremaining: 9.4s\n",
      "494:\tlearn: 54214.1202463\ttotal: 9.19s\tremaining: 9.37s\n",
      "495:\tlearn: 54203.8817777\ttotal: 9.2s\tremaining: 9.35s\n",
      "496:\tlearn: 54153.6496837\ttotal: 9.22s\tremaining: 9.33s\n",
      "497:\tlearn: 54121.1093661\ttotal: 9.25s\tremaining: 9.32s\n",
      "498:\tlearn: 54116.1912007\ttotal: 9.26s\tremaining: 9.3s\n",
      "499:\tlearn: 54104.7093641\ttotal: 9.27s\tremaining: 9.27s\n",
      "500:\tlearn: 54095.9719775\ttotal: 9.28s\tremaining: 9.24s\n",
      "501:\tlearn: 54091.0309998\ttotal: 9.29s\tremaining: 9.22s\n",
      "502:\tlearn: 54075.5281447\ttotal: 9.31s\tremaining: 9.2s\n",
      "503:\tlearn: 54048.4991302\ttotal: 9.32s\tremaining: 9.17s\n",
      "504:\tlearn: 54044.7091297\ttotal: 9.33s\tremaining: 9.15s\n",
      "505:\tlearn: 54041.0854025\ttotal: 9.36s\tremaining: 9.13s\n",
      "506:\tlearn: 54037.6179259\ttotal: 9.37s\tremaining: 9.11s\n",
      "507:\tlearn: 54025.6485595\ttotal: 9.4s\tremaining: 9.1s\n",
      "508:\tlearn: 54020.9933140\ttotal: 9.41s\tremaining: 9.08s\n",
      "509:\tlearn: 54009.4596527\ttotal: 9.42s\tremaining: 9.05s\n",
      "510:\tlearn: 53990.4431601\ttotal: 9.43s\tremaining: 9.03s\n",
      "511:\tlearn: 53982.3781355\ttotal: 9.45s\tremaining: 9s\n",
      "512:\tlearn: 53972.7500925\ttotal: 9.46s\tremaining: 8.98s\n",
      "513:\tlearn: 53968.1393770\ttotal: 9.47s\tremaining: 8.96s\n",
      "514:\tlearn: 53957.0136923\ttotal: 9.49s\tremaining: 8.94s\n",
      "515:\tlearn: 53952.2048914\ttotal: 9.5s\tremaining: 8.91s\n",
      "516:\tlearn: 53947.7934746\ttotal: 9.51s\tremaining: 8.89s\n",
      "517:\tlearn: 53876.0607263\ttotal: 9.53s\tremaining: 8.87s\n",
      "518:\tlearn: 53871.8053745\ttotal: 9.54s\tremaining: 8.85s\n",
      "519:\tlearn: 53807.9932969\ttotal: 9.56s\tremaining: 8.83s\n",
      "520:\tlearn: 53798.6201945\ttotal: 9.58s\tremaining: 8.81s\n",
      "521:\tlearn: 53794.3284022\ttotal: 9.61s\tremaining: 8.79s\n",
      "522:\tlearn: 53790.3903945\ttotal: 9.63s\tremaining: 8.78s\n",
      "523:\tlearn: 53741.6534474\ttotal: 9.64s\tremaining: 8.76s\n",
      "524:\tlearn: 53730.5660370\ttotal: 9.65s\tremaining: 8.73s\n",
      "525:\tlearn: 53709.3837623\ttotal: 9.67s\tremaining: 8.72s\n",
      "526:\tlearn: 53649.0250544\ttotal: 9.69s\tremaining: 8.69s\n",
      "527:\tlearn: 53639.9878736\ttotal: 9.7s\tremaining: 8.67s\n",
      "528:\tlearn: 53580.3161655\ttotal: 9.71s\tremaining: 8.65s\n",
      "529:\tlearn: 53574.7504288\ttotal: 9.72s\tremaining: 8.62s\n",
      "530:\tlearn: 53562.9338591\ttotal: 9.73s\tremaining: 8.6s\n",
      "531:\tlearn: 53535.1685496\ttotal: 9.75s\tremaining: 8.57s\n",
      "532:\tlearn: 53531.5224779\ttotal: 9.76s\tremaining: 8.55s\n",
      "533:\tlearn: 53522.8181298\ttotal: 9.78s\tremaining: 8.54s\n",
      "534:\tlearn: 53518.1798625\ttotal: 9.79s\tremaining: 8.51s\n",
      "535:\tlearn: 53487.3224238\ttotal: 9.83s\tremaining: 8.51s\n",
      "536:\tlearn: 53478.9290954\ttotal: 9.84s\tremaining: 8.48s\n",
      "537:\tlearn: 53475.3781495\ttotal: 9.85s\tremaining: 8.46s\n",
      "538:\tlearn: 53455.9064873\ttotal: 9.87s\tremaining: 8.44s\n",
      "539:\tlearn: 53433.0316346\ttotal: 9.88s\tremaining: 8.42s\n",
      "540:\tlearn: 53375.8952294\ttotal: 9.91s\tremaining: 8.41s\n",
      "541:\tlearn: 53341.4433800\ttotal: 9.92s\tremaining: 8.39s\n",
      "542:\tlearn: 53333.2512950\ttotal: 9.94s\tremaining: 8.37s\n",
      "543:\tlearn: 53309.5487611\ttotal: 9.95s\tremaining: 8.34s\n",
      "544:\tlearn: 53276.0617843\ttotal: 9.97s\tremaining: 8.33s\n",
      "545:\tlearn: 53247.1090604\ttotal: 9.99s\tremaining: 8.31s\n",
      "546:\tlearn: 53185.4601297\ttotal: 10s\tremaining: 8.29s\n",
      "547:\tlearn: 53175.8376407\ttotal: 10s\tremaining: 8.28s\n",
      "548:\tlearn: 53138.6337129\ttotal: 10.1s\tremaining: 8.26s\n",
      "549:\tlearn: 53128.4065533\ttotal: 10.1s\tremaining: 8.24s\n",
      "550:\tlearn: 53120.5900085\ttotal: 10.1s\tremaining: 8.21s\n",
      "551:\tlearn: 53116.4462471\ttotal: 10.1s\tremaining: 8.2s\n",
      "552:\tlearn: 53057.0051635\ttotal: 10.1s\tremaining: 8.17s\n",
      "553:\tlearn: 53053.6090469\ttotal: 10.1s\tremaining: 8.15s\n",
      "554:\tlearn: 53050.3657148\ttotal: 10.1s\tremaining: 8.13s\n",
      "555:\tlearn: 53039.5651769\ttotal: 10.1s\tremaining: 8.1s\n",
      "556:\tlearn: 53029.1568315\ttotal: 10.2s\tremaining: 8.08s\n",
      "557:\tlearn: 52981.6153192\ttotal: 10.2s\tremaining: 8.05s\n",
      "558:\tlearn: 52968.3376507\ttotal: 10.2s\tremaining: 8.03s\n",
      "559:\tlearn: 52951.2411018\ttotal: 10.2s\tremaining: 8.01s\n",
      "560:\tlearn: 52930.9787760\ttotal: 10.2s\tremaining: 7.99s\n",
      "561:\tlearn: 52896.2554166\ttotal: 10.2s\tremaining: 7.97s\n",
      "562:\tlearn: 52863.3749590\ttotal: 10.4s\tremaining: 8.04s\n",
      "563:\tlearn: 52856.1213724\ttotal: 10.4s\tremaining: 8.02s\n",
      "564:\tlearn: 52849.4636808\ttotal: 10.4s\tremaining: 8s\n",
      "565:\tlearn: 52815.1474269\ttotal: 10.4s\tremaining: 7.97s\n",
      "566:\tlearn: 52812.0850978\ttotal: 10.4s\tremaining: 7.95s\n",
      "567:\tlearn: 52753.9765334\ttotal: 10.4s\tremaining: 7.94s\n",
      "568:\tlearn: 52751.0080932\ttotal: 10.5s\tremaining: 7.93s\n",
      "569:\tlearn: 52739.3369712\ttotal: 10.5s\tremaining: 7.91s\n",
      "570:\tlearn: 52718.9579365\ttotal: 10.5s\tremaining: 7.88s\n",
      "571:\tlearn: 52709.2080709\ttotal: 10.5s\tremaining: 7.87s\n",
      "572:\tlearn: 52701.7129634\ttotal: 10.5s\tremaining: 7.84s\n",
      "573:\tlearn: 52698.7847795\ttotal: 10.5s\tremaining: 7.82s\n",
      "574:\tlearn: 52689.9179256\ttotal: 10.5s\tremaining: 7.8s\n",
      "575:\tlearn: 52677.0961697\ttotal: 10.6s\tremaining: 7.79s\n",
      "576:\tlearn: 52621.1879649\ttotal: 10.6s\tremaining: 7.76s\n",
      "577:\tlearn: 52617.0932966\ttotal: 10.6s\tremaining: 7.74s\n",
      "578:\tlearn: 52597.7861503\ttotal: 10.6s\tremaining: 7.72s\n",
      "579:\tlearn: 52595.0877803\ttotal: 10.6s\tremaining: 7.7s\n",
      "580:\tlearn: 52582.6968971\ttotal: 10.6s\tremaining: 7.68s\n",
      "581:\tlearn: 52578.9990833\ttotal: 10.7s\tremaining: 7.69s\n",
      "582:\tlearn: 52576.5133517\ttotal: 10.7s\tremaining: 7.67s\n",
      "583:\tlearn: 52573.1697695\ttotal: 10.7s\tremaining: 7.64s\n",
      "584:\tlearn: 52555.6759460\ttotal: 10.7s\tremaining: 7.62s\n",
      "585:\tlearn: 52504.2217033\ttotal: 10.8s\tremaining: 7.6s\n",
      "586:\tlearn: 52446.3197049\ttotal: 10.8s\tremaining: 7.59s\n",
      "587:\tlearn: 52443.2688009\ttotal: 10.8s\tremaining: 7.57s\n",
      "588:\tlearn: 52441.0844803\ttotal: 10.8s\tremaining: 7.55s\n",
      "589:\tlearn: 52438.9871608\ttotal: 10.8s\tremaining: 7.53s\n",
      "590:\tlearn: 52417.6199195\ttotal: 10.8s\tremaining: 7.51s\n",
      "591:\tlearn: 52413.0640289\ttotal: 10.9s\tremaining: 7.49s\n",
      "592:\tlearn: 52358.9385189\ttotal: 10.9s\tremaining: 7.47s\n",
      "593:\tlearn: 52308.5709147\ttotal: 10.9s\tremaining: 7.46s\n",
      "594:\tlearn: 52290.8411881\ttotal: 10.9s\tremaining: 7.44s\n",
      "595:\tlearn: 52271.5347663\ttotal: 10.9s\tremaining: 7.42s\n",
      "596:\tlearn: 52219.2368496\ttotal: 11s\tremaining: 7.39s\n",
      "597:\tlearn: 52160.5166853\ttotal: 11s\tremaining: 7.37s\n",
      "598:\tlearn: 52143.9001877\ttotal: 11s\tremaining: 7.35s\n",
      "599:\tlearn: 52141.9329396\ttotal: 11s\tremaining: 7.33s\n",
      "600:\tlearn: 52123.4464454\ttotal: 11s\tremaining: 7.31s\n",
      "601:\tlearn: 52065.4792071\ttotal: 11s\tremaining: 7.29s\n",
      "602:\tlearn: 52015.0496284\ttotal: 11s\tremaining: 7.27s\n",
      "603:\tlearn: 52012.3522934\ttotal: 11s\tremaining: 7.24s\n",
      "604:\tlearn: 52008.1035302\ttotal: 11.1s\tremaining: 7.22s\n",
      "605:\tlearn: 51974.1495327\ttotal: 11.1s\tremaining: 7.2s\n",
      "606:\tlearn: 51956.6627209\ttotal: 11.1s\tremaining: 7.18s\n",
      "607:\tlearn: 51941.6737851\ttotal: 11.1s\tremaining: 7.17s\n",
      "608:\tlearn: 51924.7609258\ttotal: 11.1s\tremaining: 7.15s\n",
      "609:\tlearn: 51907.9089892\ttotal: 11.2s\tremaining: 7.13s\n",
      "610:\tlearn: 51882.9438376\ttotal: 11.2s\tremaining: 7.11s\n",
      "611:\tlearn: 51834.7985323\ttotal: 11.2s\tremaining: 7.09s\n",
      "612:\tlearn: 51818.5358966\ttotal: 11.2s\tremaining: 7.07s\n",
      "613:\tlearn: 51805.6057272\ttotal: 11.2s\tremaining: 7.05s\n",
      "614:\tlearn: 51795.5063457\ttotal: 11.2s\tremaining: 7.03s\n",
      "615:\tlearn: 51784.0782994\ttotal: 11.2s\tremaining: 7s\n",
      "616:\tlearn: 51762.3113481\ttotal: 11.3s\tremaining: 6.99s\n",
      "617:\tlearn: 51754.2163458\ttotal: 11.3s\tremaining: 6.96s\n",
      "618:\tlearn: 51743.2756837\ttotal: 11.3s\tremaining: 6.94s\n",
      "619:\tlearn: 51732.7656544\ttotal: 11.3s\tremaining: 6.92s\n",
      "620:\tlearn: 51722.6659171\ttotal: 11.3s\tremaining: 6.9s\n",
      "621:\tlearn: 51699.1091509\ttotal: 11.3s\tremaining: 6.88s\n",
      "622:\tlearn: 51680.1693095\ttotal: 11.4s\tremaining: 6.87s\n",
      "623:\tlearn: 51672.0758801\ttotal: 11.4s\tremaining: 6.85s\n",
      "624:\tlearn: 51614.0195392\ttotal: 11.4s\tremaining: 6.83s\n",
      "625:\tlearn: 51604.7890210\ttotal: 11.4s\tremaining: 6.81s\n",
      "626:\tlearn: 51584.8223674\ttotal: 11.4s\tremaining: 6.79s\n",
      "627:\tlearn: 51582.9757752\ttotal: 11.4s\tremaining: 6.77s\n",
      "628:\tlearn: 51572.5402844\ttotal: 11.4s\tremaining: 6.75s\n",
      "629:\tlearn: 51566.1589216\ttotal: 11.5s\tremaining: 6.73s\n",
      "630:\tlearn: 51558.7682237\ttotal: 11.5s\tremaining: 6.7s\n",
      "631:\tlearn: 51557.0173174\ttotal: 11.5s\tremaining: 6.68s\n",
      "632:\tlearn: 51539.2621427\ttotal: 11.5s\tremaining: 6.66s\n",
      "633:\tlearn: 51535.3306824\ttotal: 11.5s\tremaining: 6.64s\n",
      "634:\tlearn: 51530.7352257\ttotal: 11.5s\tremaining: 6.62s\n",
      "635:\tlearn: 51524.8164005\ttotal: 11.6s\tremaining: 6.61s\n",
      "636:\tlearn: 51515.1391176\ttotal: 11.6s\tremaining: 6.59s\n",
      "637:\tlearn: 51493.2230976\ttotal: 11.6s\tremaining: 6.57s\n",
      "638:\tlearn: 51488.3204759\ttotal: 11.6s\tremaining: 6.55s\n",
      "639:\tlearn: 51468.0127187\ttotal: 11.6s\tremaining: 6.53s\n",
      "640:\tlearn: 51446.5577056\ttotal: 11.6s\tremaining: 6.51s\n",
      "641:\tlearn: 51434.1625518\ttotal: 11.6s\tremaining: 6.49s\n",
      "642:\tlearn: 51405.8321269\ttotal: 11.7s\tremaining: 6.47s\n",
      "643:\tlearn: 51381.3862866\ttotal: 11.7s\tremaining: 6.45s\n",
      "644:\tlearn: 51325.2300998\ttotal: 11.7s\tremaining: 6.43s\n",
      "645:\tlearn: 51306.7127442\ttotal: 11.7s\tremaining: 6.41s\n",
      "646:\tlearn: 51298.8079392\ttotal: 11.7s\tremaining: 6.39s\n",
      "647:\tlearn: 51273.3171119\ttotal: 11.7s\tremaining: 6.37s\n",
      "648:\tlearn: 51256.3487300\ttotal: 11.8s\tremaining: 6.4s\n",
      "649:\tlearn: 51231.9142068\ttotal: 11.9s\tremaining: 6.4s\n",
      "650:\tlearn: 51223.5086823\ttotal: 11.9s\tremaining: 6.37s\n",
      "651:\tlearn: 51215.0503324\ttotal: 11.9s\tremaining: 6.35s\n",
      "652:\tlearn: 51190.3201912\ttotal: 11.9s\tremaining: 6.33s\n",
      "653:\tlearn: 51160.3236358\ttotal: 11.9s\tremaining: 6.31s\n",
      "654:\tlearn: 51151.2054495\ttotal: 11.9s\tremaining: 6.29s\n",
      "655:\tlearn: 51099.7137300\ttotal: 12s\tremaining: 6.27s\n",
      "656:\tlearn: 51053.9339629\ttotal: 12s\tremaining: 6.25s\n",
      "657:\tlearn: 51018.6765498\ttotal: 12s\tremaining: 6.23s\n",
      "658:\tlearn: 51011.0107703\ttotal: 12s\tremaining: 6.21s\n",
      "659:\tlearn: 50979.4716015\ttotal: 12s\tremaining: 6.19s\n",
      "660:\tlearn: 50975.4199143\ttotal: 12s\tremaining: 6.17s\n",
      "661:\tlearn: 50963.5559471\ttotal: 12s\tremaining: 6.14s\n",
      "662:\tlearn: 50948.1656930\ttotal: 12.1s\tremaining: 6.13s\n",
      "663:\tlearn: 50939.2884839\ttotal: 12.1s\tremaining: 6.12s\n",
      "664:\tlearn: 50884.0664454\ttotal: 12.1s\tremaining: 6.1s\n",
      "665:\tlearn: 50868.5528146\ttotal: 12.1s\tremaining: 6.08s\n",
      "666:\tlearn: 50849.9787180\ttotal: 12.1s\tremaining: 6.06s\n",
      "667:\tlearn: 50827.9805410\ttotal: 12.2s\tremaining: 6.04s\n",
      "668:\tlearn: 50820.3296670\ttotal: 12.2s\tremaining: 6.02s\n",
      "669:\tlearn: 50791.1977450\ttotal: 12.2s\tremaining: 6s\n",
      "670:\tlearn: 50785.7454820\ttotal: 12.2s\tremaining: 5.98s\n",
      "671:\tlearn: 50768.1563149\ttotal: 12.2s\tremaining: 5.96s\n",
      "672:\tlearn: 50764.7282216\ttotal: 12.2s\tremaining: 5.94s\n",
      "673:\tlearn: 50741.6382209\ttotal: 12.2s\tremaining: 5.92s\n",
      "674:\tlearn: 50727.9471167\ttotal: 12.2s\tremaining: 5.89s\n",
      "675:\tlearn: 50706.6959610\ttotal: 12.3s\tremaining: 5.88s\n",
      "676:\tlearn: 50693.9248763\ttotal: 12.3s\tremaining: 5.87s\n",
      "677:\tlearn: 50692.1651608\ttotal: 12.3s\tremaining: 5.84s\n",
      "678:\tlearn: 50680.7838118\ttotal: 12.3s\tremaining: 5.83s\n",
      "679:\tlearn: 50630.5836226\ttotal: 12.3s\tremaining: 5.81s\n",
      "680:\tlearn: 50616.8336453\ttotal: 12.4s\tremaining: 5.79s\n",
      "681:\tlearn: 50598.8061990\ttotal: 12.4s\tremaining: 5.77s\n",
      "682:\tlearn: 50550.0559989\ttotal: 12.4s\tremaining: 5.75s\n",
      "683:\tlearn: 50542.2397144\ttotal: 12.4s\tremaining: 5.73s\n",
      "684:\tlearn: 50532.7396541\ttotal: 12.4s\tremaining: 5.71s\n",
      "685:\tlearn: 50527.3757900\ttotal: 12.4s\tremaining: 5.69s\n",
      "686:\tlearn: 50473.7504264\ttotal: 12.4s\tremaining: 5.67s\n",
      "687:\tlearn: 50466.1633157\ttotal: 12.5s\tremaining: 5.65s\n",
      "688:\tlearn: 50441.2703070\ttotal: 12.5s\tremaining: 5.63s\n",
      "689:\tlearn: 50433.0459293\ttotal: 12.5s\tremaining: 5.61s\n",
      "690:\tlearn: 50418.4496491\ttotal: 12.5s\tremaining: 5.6s\n",
      "691:\tlearn: 50401.3859051\ttotal: 12.5s\tremaining: 5.58s\n",
      "692:\tlearn: 50367.4741889\ttotal: 12.5s\tremaining: 5.55s\n",
      "693:\tlearn: 50361.1308786\ttotal: 12.6s\tremaining: 5.54s\n",
      "694:\tlearn: 50344.7012393\ttotal: 12.6s\tremaining: 5.52s\n",
      "695:\tlearn: 50289.8501821\ttotal: 12.6s\tremaining: 5.5s\n",
      "696:\tlearn: 50268.1826320\ttotal: 12.6s\tremaining: 5.48s\n",
      "697:\tlearn: 50254.2290695\ttotal: 12.6s\tremaining: 5.46s\n",
      "698:\tlearn: 50221.3873196\ttotal: 12.6s\tremaining: 5.44s\n",
      "699:\tlearn: 50192.5205224\ttotal: 12.6s\tremaining: 5.42s\n",
      "700:\tlearn: 50171.8799890\ttotal: 12.7s\tremaining: 5.4s\n",
      "701:\tlearn: 50127.4041587\ttotal: 12.7s\tremaining: 5.38s\n",
      "702:\tlearn: 50113.4756665\ttotal: 12.7s\tremaining: 5.36s\n",
      "703:\tlearn: 50104.5950831\ttotal: 12.7s\tremaining: 5.35s\n",
      "704:\tlearn: 50076.2233977\ttotal: 12.7s\tremaining: 5.33s\n",
      "705:\tlearn: 50064.3302835\ttotal: 12.8s\tremaining: 5.31s\n",
      "706:\tlearn: 50050.9792535\ttotal: 12.8s\tremaining: 5.29s\n",
      "707:\tlearn: 50039.2310370\ttotal: 12.8s\tremaining: 5.27s\n",
      "708:\tlearn: 50033.3909181\ttotal: 12.8s\tremaining: 5.25s\n",
      "709:\tlearn: 50017.7769827\ttotal: 12.8s\tremaining: 5.23s\n",
      "710:\tlearn: 50010.7888707\ttotal: 12.8s\tremaining: 5.21s\n",
      "711:\tlearn: 50002.5253464\ttotal: 12.8s\tremaining: 5.19s\n",
      "712:\tlearn: 49989.6859997\ttotal: 12.8s\tremaining: 5.17s\n",
      "713:\tlearn: 49983.9558594\ttotal: 12.9s\tremaining: 5.15s\n",
      "714:\tlearn: 49976.0058197\ttotal: 12.9s\tremaining: 5.13s\n",
      "715:\tlearn: 49949.9054551\ttotal: 12.9s\tremaining: 5.11s\n",
      "716:\tlearn: 49942.1390300\ttotal: 12.9s\tremaining: 5.09s\n",
      "717:\tlearn: 49927.7922725\ttotal: 12.9s\tremaining: 5.07s\n",
      "718:\tlearn: 49886.4476038\ttotal: 12.9s\tremaining: 5.06s\n",
      "719:\tlearn: 49846.6675937\ttotal: 13s\tremaining: 5.04s\n",
      "720:\tlearn: 49808.0134452\ttotal: 13s\tremaining: 5.02s\n",
      "721:\tlearn: 49770.0539624\ttotal: 13s\tremaining: 5s\n",
      "722:\tlearn: 49747.5763493\ttotal: 13s\tremaining: 4.98s\n",
      "723:\tlearn: 49723.8136873\ttotal: 13s\tremaining: 4.97s\n",
      "724:\tlearn: 49715.6056011\ttotal: 13s\tremaining: 4.95s\n",
      "725:\tlearn: 49708.6329204\ttotal: 13.1s\tremaining: 4.93s\n",
      "726:\tlearn: 49694.3265241\ttotal: 13.1s\tremaining: 4.91s\n",
      "727:\tlearn: 49676.2381873\ttotal: 13.1s\tremaining: 4.89s\n",
      "728:\tlearn: 49671.0246272\ttotal: 13.1s\tremaining: 4.87s\n",
      "729:\tlearn: 49648.6040876\ttotal: 13.1s\tremaining: 4.85s\n",
      "730:\tlearn: 49621.2059530\ttotal: 13.1s\tremaining: 4.83s\n",
      "731:\tlearn: 49617.9034649\ttotal: 13.1s\tremaining: 4.81s\n",
      "732:\tlearn: 49602.4545358\ttotal: 13.2s\tremaining: 4.79s\n",
      "733:\tlearn: 49595.7237442\ttotal: 13.2s\tremaining: 4.78s\n",
      "734:\tlearn: 49591.6472221\ttotal: 13.2s\tremaining: 4.76s\n",
      "735:\tlearn: 49584.7490909\ttotal: 13.2s\tremaining: 4.74s\n",
      "736:\tlearn: 49558.2165862\ttotal: 13.2s\tremaining: 4.72s\n",
      "737:\tlearn: 49527.7616690\ttotal: 13.2s\tremaining: 4.7s\n",
      "738:\tlearn: 49511.0639114\ttotal: 13.3s\tremaining: 4.68s\n",
      "739:\tlearn: 49466.3673946\ttotal: 13.3s\tremaining: 4.66s\n",
      "740:\tlearn: 49444.7982025\ttotal: 13.3s\tremaining: 4.64s\n",
      "741:\tlearn: 49391.2040669\ttotal: 13.3s\tremaining: 4.62s\n",
      "742:\tlearn: 49377.9271459\ttotal: 13.3s\tremaining: 4.6s\n",
      "743:\tlearn: 49368.3358109\ttotal: 13.3s\tremaining: 4.58s\n",
      "744:\tlearn: 49365.1907580\ttotal: 13.3s\tremaining: 4.57s\n",
      "745:\tlearn: 49360.2082561\ttotal: 13.4s\tremaining: 4.55s\n",
      "746:\tlearn: 49342.6201793\ttotal: 13.5s\tremaining: 4.56s\n",
      "747:\tlearn: 49339.1865376\ttotal: 13.5s\tremaining: 4.54s\n",
      "748:\tlearn: 49295.9597517\ttotal: 13.5s\tremaining: 4.52s\n",
      "749:\tlearn: 49274.3410685\ttotal: 13.5s\tremaining: 4.5s\n",
      "750:\tlearn: 49270.8731483\ttotal: 13.5s\tremaining: 4.48s\n",
      "751:\tlearn: 49268.0243109\ttotal: 13.5s\tremaining: 4.46s\n",
      "752:\tlearn: 49252.8435067\ttotal: 13.5s\tremaining: 4.44s\n",
      "753:\tlearn: 49226.8593939\ttotal: 13.6s\tremaining: 4.42s\n",
      "754:\tlearn: 49202.7635976\ttotal: 13.6s\tremaining: 4.41s\n",
      "755:\tlearn: 49177.9447879\ttotal: 13.6s\tremaining: 4.39s\n",
      "756:\tlearn: 49163.3821484\ttotal: 13.6s\tremaining: 4.37s\n",
      "757:\tlearn: 49141.4045561\ttotal: 13.6s\tremaining: 4.35s\n",
      "758:\tlearn: 49138.6922505\ttotal: 13.7s\tremaining: 4.33s\n",
      "759:\tlearn: 49125.3760712\ttotal: 13.7s\tremaining: 4.32s\n",
      "760:\tlearn: 49119.9505045\ttotal: 13.7s\tremaining: 4.3s\n",
      "761:\tlearn: 49096.9116646\ttotal: 13.7s\tremaining: 4.28s\n",
      "762:\tlearn: 49084.8226146\ttotal: 13.7s\tremaining: 4.26s\n",
      "763:\tlearn: 49079.7316676\ttotal: 13.7s\tremaining: 4.24s\n",
      "764:\tlearn: 49074.5145075\ttotal: 13.7s\tremaining: 4.22s\n",
      "765:\tlearn: 49066.6622900\ttotal: 13.7s\tremaining: 4.2s\n",
      "766:\tlearn: 49059.1388590\ttotal: 13.8s\tremaining: 4.18s\n",
      "767:\tlearn: 49051.9261891\ttotal: 13.8s\tremaining: 4.16s\n",
      "768:\tlearn: 49014.3477331\ttotal: 13.8s\tremaining: 4.14s\n",
      "769:\tlearn: 49011.7646605\ttotal: 13.8s\tremaining: 4.13s\n",
      "770:\tlearn: 48989.6589523\ttotal: 13.8s\tremaining: 4.11s\n",
      "771:\tlearn: 48985.9361977\ttotal: 13.8s\tremaining: 4.09s\n",
      "772:\tlearn: 48981.5364340\ttotal: 13.8s\tremaining: 4.07s\n",
      "773:\tlearn: 48975.2315897\ttotal: 13.9s\tremaining: 4.05s\n",
      "774:\tlearn: 48972.6487552\ttotal: 13.9s\tremaining: 4.03s\n",
      "775:\tlearn: 48966.0301327\ttotal: 13.9s\tremaining: 4.01s\n",
      "776:\tlearn: 48960.3362465\ttotal: 13.9s\tremaining: 3.99s\n",
      "777:\tlearn: 48941.2830175\ttotal: 13.9s\tremaining: 3.97s\n",
      "778:\tlearn: 48924.8013600\ttotal: 13.9s\tremaining: 3.95s\n",
      "779:\tlearn: 48876.2793057\ttotal: 14s\tremaining: 3.94s\n",
      "780:\tlearn: 48865.1427313\ttotal: 14s\tremaining: 3.92s\n",
      "781:\tlearn: 48858.2479140\ttotal: 14s\tremaining: 3.9s\n",
      "782:\tlearn: 48851.6312333\ttotal: 14s\tremaining: 3.89s\n",
      "783:\tlearn: 48838.9046742\ttotal: 14s\tremaining: 3.87s\n",
      "784:\tlearn: 48819.1359461\ttotal: 14.1s\tremaining: 3.85s\n",
      "785:\tlearn: 48811.9235249\ttotal: 14.1s\tremaining: 3.83s\n",
      "786:\tlearn: 48806.9131966\ttotal: 14.1s\tremaining: 3.81s\n",
      "787:\tlearn: 48802.7677967\ttotal: 14.1s\tremaining: 3.79s\n",
      "788:\tlearn: 48797.2810437\ttotal: 14.1s\tremaining: 3.77s\n",
      "789:\tlearn: 48776.5194434\ttotal: 14.1s\tremaining: 3.75s\n",
      "790:\tlearn: 48770.3327654\ttotal: 14.1s\tremaining: 3.73s\n",
      "791:\tlearn: 48760.8768510\ttotal: 14.1s\tremaining: 3.71s\n",
      "792:\tlearn: 48722.4618508\ttotal: 14.2s\tremaining: 3.69s\n",
      "793:\tlearn: 48717.9117096\ttotal: 14.2s\tremaining: 3.68s\n",
      "794:\tlearn: 48715.4192180\ttotal: 14.2s\tremaining: 3.66s\n",
      "795:\tlearn: 48709.0267223\ttotal: 14.3s\tremaining: 3.67s\n",
      "796:\tlearn: 48693.6676317\ttotal: 14.4s\tremaining: 3.66s\n",
      "797:\tlearn: 48637.9881679\ttotal: 14.7s\tremaining: 3.71s\n",
      "798:\tlearn: 48625.4012416\ttotal: 14.7s\tremaining: 3.7s\n",
      "799:\tlearn: 48593.9369070\ttotal: 14.7s\tremaining: 3.68s\n",
      "800:\tlearn: 48576.9675945\ttotal: 15.1s\tremaining: 3.74s\n",
      "801:\tlearn: 48556.5262347\ttotal: 15.1s\tremaining: 3.73s\n",
      "802:\tlearn: 48532.8875693\ttotal: 15.1s\tremaining: 3.72s\n",
      "803:\tlearn: 48511.8200406\ttotal: 15.2s\tremaining: 3.7s\n",
      "804:\tlearn: 48469.6230124\ttotal: 15.2s\tremaining: 3.68s\n",
      "805:\tlearn: 48465.8464545\ttotal: 15.2s\tremaining: 3.66s\n",
      "806:\tlearn: 48462.7598879\ttotal: 15.2s\tremaining: 3.64s\n",
      "807:\tlearn: 48436.3190864\ttotal: 15.2s\tremaining: 3.62s\n",
      "808:\tlearn: 48416.7857517\ttotal: 15.2s\tremaining: 3.6s\n",
      "809:\tlearn: 48393.5914807\ttotal: 15.4s\tremaining: 3.6s\n",
      "810:\tlearn: 48378.3852983\ttotal: 15.4s\tremaining: 3.58s\n",
      "811:\tlearn: 48374.5530640\ttotal: 15.4s\tremaining: 3.56s\n",
      "812:\tlearn: 48357.8207085\ttotal: 15.4s\tremaining: 3.54s\n",
      "813:\tlearn: 48310.4488483\ttotal: 15.4s\tremaining: 3.52s\n",
      "814:\tlearn: 48305.5294824\ttotal: 15.4s\tremaining: 3.5s\n",
      "815:\tlearn: 48251.8574413\ttotal: 15.4s\tremaining: 3.48s\n",
      "816:\tlearn: 48228.5866897\ttotal: 15.5s\tremaining: 3.46s\n",
      "817:\tlearn: 48214.2075511\ttotal: 15.5s\tremaining: 3.44s\n",
      "818:\tlearn: 48208.2062328\ttotal: 15.5s\tremaining: 3.42s\n",
      "819:\tlearn: 48189.1778065\ttotal: 15.5s\tremaining: 3.4s\n",
      "820:\tlearn: 48168.0851165\ttotal: 15.5s\tremaining: 3.38s\n",
      "821:\tlearn: 48149.8195040\ttotal: 15.5s\tremaining: 3.36s\n",
      "822:\tlearn: 48143.5364320\ttotal: 15.5s\tremaining: 3.34s\n",
      "823:\tlearn: 48125.3942554\ttotal: 15.6s\tremaining: 3.32s\n",
      "824:\tlearn: 48108.3025804\ttotal: 15.6s\tremaining: 3.31s\n",
      "825:\tlearn: 48104.7176441\ttotal: 15.6s\tremaining: 3.29s\n",
      "826:\tlearn: 48093.8237656\ttotal: 15.6s\tremaining: 3.27s\n",
      "827:\tlearn: 48057.5300095\ttotal: 15.7s\tremaining: 3.25s\n",
      "828:\tlearn: 48044.8378215\ttotal: 15.7s\tremaining: 3.23s\n",
      "829:\tlearn: 48029.6612657\ttotal: 15.7s\tremaining: 3.21s\n",
      "830:\tlearn: 48022.6535813\ttotal: 15.7s\tremaining: 3.19s\n",
      "831:\tlearn: 48005.7271066\ttotal: 15.7s\tremaining: 3.17s\n",
      "832:\tlearn: 47998.9856309\ttotal: 15.7s\tremaining: 3.15s\n",
      "833:\tlearn: 47979.3740777\ttotal: 15.7s\tremaining: 3.13s\n",
      "834:\tlearn: 47962.9231524\ttotal: 15.7s\tremaining: 3.11s\n",
      "835:\tlearn: 47947.0317853\ttotal: 15.8s\tremaining: 3.09s\n",
      "836:\tlearn: 47943.6344012\ttotal: 15.8s\tremaining: 3.07s\n",
      "837:\tlearn: 47923.6715122\ttotal: 15.8s\tremaining: 3.05s\n",
      "838:\tlearn: 47906.3311174\ttotal: 15.8s\tremaining: 3.04s\n",
      "839:\tlearn: 47894.7043925\ttotal: 15.8s\tremaining: 3.02s\n",
      "840:\tlearn: 47849.5804842\ttotal: 15.9s\tremaining: 3s\n",
      "841:\tlearn: 47832.3867823\ttotal: 15.9s\tremaining: 2.98s\n",
      "842:\tlearn: 47804.4530333\ttotal: 15.9s\tremaining: 2.96s\n",
      "843:\tlearn: 47789.7561410\ttotal: 15.9s\tremaining: 2.94s\n",
      "844:\tlearn: 47775.6406532\ttotal: 15.9s\tremaining: 2.92s\n",
      "845:\tlearn: 47740.3644112\ttotal: 15.9s\tremaining: 2.9s\n",
      "846:\tlearn: 47730.9027356\ttotal: 16s\tremaining: 2.88s\n",
      "847:\tlearn: 47720.1118523\ttotal: 16s\tremaining: 2.86s\n",
      "848:\tlearn: 47704.7156971\ttotal: 16s\tremaining: 2.84s\n",
      "849:\tlearn: 47702.5126543\ttotal: 16s\tremaining: 2.82s\n",
      "850:\tlearn: 47696.8332346\ttotal: 16s\tremaining: 2.81s\n",
      "851:\tlearn: 47683.2824022\ttotal: 16s\tremaining: 2.79s\n",
      "852:\tlearn: 47674.3136214\ttotal: 16.1s\tremaining: 2.77s\n",
      "853:\tlearn: 47669.5670132\ttotal: 16.1s\tremaining: 2.75s\n",
      "854:\tlearn: 47649.9675486\ttotal: 16.1s\tremaining: 2.73s\n",
      "855:\tlearn: 47643.9596338\ttotal: 16.1s\tremaining: 2.71s\n",
      "856:\tlearn: 47641.3642732\ttotal: 16.1s\tremaining: 2.69s\n",
      "857:\tlearn: 47637.0813487\ttotal: 16.2s\tremaining: 2.67s\n",
      "858:\tlearn: 47634.6784832\ttotal: 16.2s\tremaining: 2.66s\n",
      "859:\tlearn: 47631.4212306\ttotal: 16.2s\tremaining: 2.64s\n",
      "860:\tlearn: 47625.1523129\ttotal: 16.3s\tremaining: 2.63s\n",
      "861:\tlearn: 47620.9934168\ttotal: 16.3s\tremaining: 2.61s\n",
      "862:\tlearn: 47612.4733920\ttotal: 16.3s\tremaining: 2.59s\n",
      "863:\tlearn: 47607.0251340\ttotal: 16.3s\tremaining: 2.57s\n",
      "864:\tlearn: 47601.7878345\ttotal: 16.3s\tremaining: 2.55s\n",
      "865:\tlearn: 47598.6121734\ttotal: 16.3s\tremaining: 2.53s\n",
      "866:\tlearn: 47596.3147073\ttotal: 16.4s\tremaining: 2.51s\n",
      "867:\tlearn: 47585.6623081\ttotal: 16.4s\tremaining: 2.49s\n",
      "868:\tlearn: 47575.2615243\ttotal: 16.4s\tremaining: 2.47s\n",
      "869:\tlearn: 47570.2243866\ttotal: 16.4s\tremaining: 2.45s\n",
      "870:\tlearn: 47529.3972052\ttotal: 16.4s\tremaining: 2.43s\n",
      "871:\tlearn: 47515.2699109\ttotal: 16.4s\tremaining: 2.41s\n",
      "872:\tlearn: 47508.0182550\ttotal: 16.4s\tremaining: 2.39s\n",
      "873:\tlearn: 47503.1670906\ttotal: 16.5s\tremaining: 2.37s\n",
      "874:\tlearn: 47489.8865671\ttotal: 16.5s\tremaining: 2.35s\n",
      "875:\tlearn: 47487.9058030\ttotal: 16.5s\tremaining: 2.33s\n",
      "876:\tlearn: 47483.4580892\ttotal: 16.5s\tremaining: 2.31s\n",
      "877:\tlearn: 47477.4871249\ttotal: 16.5s\tremaining: 2.29s\n",
      "878:\tlearn: 47469.3708271\ttotal: 16.5s\tremaining: 2.28s\n",
      "879:\tlearn: 47454.0594675\ttotal: 16.5s\tremaining: 2.26s\n",
      "880:\tlearn: 47448.6329030\ttotal: 16.6s\tremaining: 2.24s\n",
      "881:\tlearn: 47433.8658242\ttotal: 16.6s\tremaining: 2.22s\n",
      "882:\tlearn: 47419.9651191\ttotal: 16.6s\tremaining: 2.2s\n",
      "883:\tlearn: 47380.8788111\ttotal: 16.6s\tremaining: 2.18s\n",
      "884:\tlearn: 47367.3885020\ttotal: 16.6s\tremaining: 2.16s\n",
      "885:\tlearn: 47354.1016679\ttotal: 16.6s\tremaining: 2.14s\n",
      "886:\tlearn: 47345.8893305\ttotal: 16.6s\tremaining: 2.12s\n",
      "887:\tlearn: 47336.7808454\ttotal: 16.7s\tremaining: 2.1s\n",
      "888:\tlearn: 47326.1349536\ttotal: 16.7s\tremaining: 2.08s\n",
      "889:\tlearn: 47320.8894191\ttotal: 16.7s\tremaining: 2.06s\n",
      "890:\tlearn: 47307.8211074\ttotal: 16.7s\tremaining: 2.04s\n",
      "891:\tlearn: 47303.4533041\ttotal: 16.7s\tremaining: 2.02s\n",
      "892:\tlearn: 47287.8797348\ttotal: 16.7s\tremaining: 2.01s\n",
      "893:\tlearn: 47275.1550938\ttotal: 16.8s\tremaining: 1.99s\n",
      "894:\tlearn: 47261.0369812\ttotal: 16.8s\tremaining: 1.97s\n",
      "895:\tlearn: 47244.2105101\ttotal: 16.8s\tremaining: 1.95s\n",
      "896:\tlearn: 47218.8747484\ttotal: 16.8s\tremaining: 1.93s\n",
      "897:\tlearn: 47204.0822775\ttotal: 16.8s\tremaining: 1.91s\n",
      "898:\tlearn: 47190.3710096\ttotal: 16.8s\tremaining: 1.89s\n",
      "899:\tlearn: 47177.1947469\ttotal: 16.8s\tremaining: 1.87s\n",
      "900:\tlearn: 47156.9046577\ttotal: 16.9s\tremaining: 1.85s\n",
      "901:\tlearn: 47155.1485095\ttotal: 17s\tremaining: 1.84s\n",
      "902:\tlearn: 47143.0669280\ttotal: 17s\tremaining: 1.83s\n",
      "903:\tlearn: 47130.7100257\ttotal: 17.1s\tremaining: 1.81s\n",
      "904:\tlearn: 47123.1355428\ttotal: 17.1s\tremaining: 1.79s\n",
      "905:\tlearn: 47115.8501026\ttotal: 17.1s\tremaining: 1.78s\n",
      "906:\tlearn: 47110.0726394\ttotal: 17.1s\tremaining: 1.76s\n",
      "907:\tlearn: 47087.9309271\ttotal: 17.1s\tremaining: 1.74s\n",
      "908:\tlearn: 47081.5802235\ttotal: 17.2s\tremaining: 1.72s\n",
      "909:\tlearn: 47064.1360013\ttotal: 17.2s\tremaining: 1.7s\n",
      "910:\tlearn: 47061.9060284\ttotal: 17.2s\tremaining: 1.68s\n",
      "911:\tlearn: 47060.3258777\ttotal: 17.2s\tremaining: 1.66s\n",
      "912:\tlearn: 47056.1484550\ttotal: 17.2s\tremaining: 1.64s\n",
      "913:\tlearn: 47052.4436217\ttotal: 17.2s\tremaining: 1.62s\n",
      "914:\tlearn: 47050.3874886\ttotal: 17.2s\tremaining: 1.6s\n",
      "915:\tlearn: 47045.0282472\ttotal: 17.3s\tremaining: 1.58s\n",
      "916:\tlearn: 47033.7548540\ttotal: 17.3s\tremaining: 1.56s\n",
      "917:\tlearn: 47032.3814332\ttotal: 17.3s\tremaining: 1.54s\n",
      "918:\tlearn: 47026.4669912\ttotal: 17.3s\tremaining: 1.52s\n",
      "919:\tlearn: 47022.5652435\ttotal: 17.3s\tremaining: 1.51s\n",
      "920:\tlearn: 47021.3535300\ttotal: 17.3s\tremaining: 1.49s\n",
      "921:\tlearn: 47009.7888496\ttotal: 17.3s\tremaining: 1.47s\n",
      "922:\tlearn: 46997.0439352\ttotal: 17.4s\tremaining: 1.45s\n",
      "923:\tlearn: 46993.2839013\ttotal: 17.4s\tremaining: 1.43s\n",
      "924:\tlearn: 46986.4259148\ttotal: 17.4s\tremaining: 1.41s\n",
      "925:\tlearn: 46981.1215946\ttotal: 17.4s\tremaining: 1.39s\n",
      "926:\tlearn: 46976.5619701\ttotal: 17.4s\tremaining: 1.37s\n",
      "927:\tlearn: 46973.7388406\ttotal: 17.4s\tremaining: 1.35s\n",
      "928:\tlearn: 46923.9564255\ttotal: 17.4s\tremaining: 1.33s\n",
      "929:\tlearn: 46920.6366447\ttotal: 17.5s\tremaining: 1.31s\n",
      "930:\tlearn: 46908.9572219\ttotal: 17.5s\tremaining: 1.29s\n",
      "931:\tlearn: 46897.1492815\ttotal: 17.5s\tremaining: 1.27s\n",
      "932:\tlearn: 46881.6242237\ttotal: 17.5s\tremaining: 1.26s\n",
      "933:\tlearn: 46857.2235345\ttotal: 17.5s\tremaining: 1.24s\n",
      "934:\tlearn: 46849.5613875\ttotal: 17.5s\tremaining: 1.22s\n",
      "935:\tlearn: 46837.1397020\ttotal: 17.6s\tremaining: 1.2s\n",
      "936:\tlearn: 46831.9561125\ttotal: 17.6s\tremaining: 1.18s\n",
      "937:\tlearn: 46828.5472360\ttotal: 17.6s\tremaining: 1.16s\n",
      "938:\tlearn: 46825.2754930\ttotal: 17.6s\tremaining: 1.14s\n",
      "939:\tlearn: 46818.8984752\ttotal: 17.6s\tremaining: 1.12s\n",
      "940:\tlearn: 46812.7606658\ttotal: 17.6s\tremaining: 1.1s\n",
      "941:\tlearn: 46800.8206165\ttotal: 17.6s\tremaining: 1.09s\n",
      "942:\tlearn: 46794.9107506\ttotal: 17.7s\tremaining: 1.07s\n",
      "943:\tlearn: 46773.2037779\ttotal: 17.7s\tremaining: 1.05s\n",
      "944:\tlearn: 46734.5749860\ttotal: 17.7s\tremaining: 1.03s\n",
      "945:\tlearn: 46730.7310707\ttotal: 17.7s\tremaining: 1.01s\n",
      "946:\tlearn: 46724.8082457\ttotal: 17.7s\tremaining: 991ms\n",
      "947:\tlearn: 46720.6614864\ttotal: 17.7s\tremaining: 972ms\n",
      "948:\tlearn: 46707.3315215\ttotal: 17.7s\tremaining: 953ms\n",
      "949:\tlearn: 46701.6855769\ttotal: 17.8s\tremaining: 935ms\n",
      "950:\tlearn: 46695.1582943\ttotal: 17.8s\tremaining: 916ms\n",
      "951:\tlearn: 46688.0451726\ttotal: 17.8s\tremaining: 898ms\n",
      "952:\tlearn: 46682.6708151\ttotal: 17.8s\tremaining: 878ms\n",
      "953:\tlearn: 46679.3301995\ttotal: 17.8s\tremaining: 859ms\n",
      "954:\tlearn: 46672.9068554\ttotal: 17.8s\tremaining: 840ms\n",
      "955:\tlearn: 46669.7589078\ttotal: 17.9s\tremaining: 822ms\n",
      "956:\tlearn: 46664.5171734\ttotal: 17.9s\tremaining: 803ms\n",
      "957:\tlearn: 46655.8243969\ttotal: 17.9s\tremaining: 784ms\n",
      "958:\tlearn: 46653.9316553\ttotal: 17.9s\tremaining: 766ms\n",
      "959:\tlearn: 46650.5077980\ttotal: 17.9s\tremaining: 747ms\n",
      "960:\tlearn: 46615.4182127\ttotal: 17.9s\tremaining: 728ms\n",
      "961:\tlearn: 46584.5249017\ttotal: 18s\tremaining: 709ms\n",
      "962:\tlearn: 46581.0149424\ttotal: 18s\tremaining: 691ms\n",
      "963:\tlearn: 46575.9567757\ttotal: 18s\tremaining: 672ms\n",
      "964:\tlearn: 46568.4479226\ttotal: 18s\tremaining: 654ms\n",
      "965:\tlearn: 46550.7142165\ttotal: 18s\tremaining: 635ms\n",
      "966:\tlearn: 46534.6135637\ttotal: 18s\tremaining: 616ms\n",
      "967:\tlearn: 46520.9261276\ttotal: 18.1s\tremaining: 597ms\n",
      "968:\tlearn: 46516.0473221\ttotal: 18.1s\tremaining: 578ms\n",
      "969:\tlearn: 46506.9363921\ttotal: 18.1s\tremaining: 559ms\n",
      "970:\tlearn: 46496.4813379\ttotal: 18.1s\tremaining: 541ms\n",
      "971:\tlearn: 46484.6827205\ttotal: 18.1s\tremaining: 522ms\n",
      "972:\tlearn: 46481.8921216\ttotal: 18.1s\tremaining: 503ms\n",
      "973:\tlearn: 46464.2374162\ttotal: 18.1s\tremaining: 484ms\n",
      "974:\tlearn: 46447.8612397\ttotal: 18.2s\tremaining: 466ms\n",
      "975:\tlearn: 46436.9130672\ttotal: 18.2s\tremaining: 447ms\n",
      "976:\tlearn: 46426.5573448\ttotal: 18.2s\tremaining: 429ms\n",
      "977:\tlearn: 46391.8093428\ttotal: 18.2s\tremaining: 410ms\n",
      "978:\tlearn: 46390.4108762\ttotal: 18.2s\tremaining: 391ms\n",
      "979:\tlearn: 46380.0801262\ttotal: 18.2s\tremaining: 372ms\n",
      "980:\tlearn: 46375.0236193\ttotal: 18.3s\tremaining: 354ms\n",
      "981:\tlearn: 46367.6180722\ttotal: 18.3s\tremaining: 335ms\n",
      "982:\tlearn: 46360.5053182\ttotal: 18.3s\tremaining: 316ms\n",
      "983:\tlearn: 46357.8711599\ttotal: 18.3s\tremaining: 298ms\n",
      "984:\tlearn: 46355.7834497\ttotal: 18.3s\tremaining: 279ms\n",
      "985:\tlearn: 46351.1880552\ttotal: 18.3s\tremaining: 260ms\n",
      "986:\tlearn: 46347.9981207\ttotal: 18.3s\tremaining: 242ms\n",
      "987:\tlearn: 46344.2722893\ttotal: 18.4s\tremaining: 223ms\n",
      "988:\tlearn: 46341.3317678\ttotal: 18.4s\tremaining: 204ms\n",
      "989:\tlearn: 46335.0170397\ttotal: 18.4s\tremaining: 186ms\n",
      "990:\tlearn: 46326.3484910\ttotal: 18.4s\tremaining: 167ms\n",
      "991:\tlearn: 46318.8471482\ttotal: 18.5s\tremaining: 149ms\n",
      "992:\tlearn: 46313.2432409\ttotal: 18.5s\tremaining: 131ms\n",
      "993:\tlearn: 46306.8283981\ttotal: 18.5s\tremaining: 112ms\n",
      "994:\tlearn: 46296.2133682\ttotal: 18.6s\tremaining: 93.3ms\n",
      "995:\tlearn: 46268.0960384\ttotal: 18.6s\tremaining: 74.6ms\n",
      "996:\tlearn: 46263.3804008\ttotal: 18.6s\tremaining: 55.9ms\n",
      "997:\tlearn: 46258.5810848\ttotal: 18.6s\tremaining: 37.3ms\n",
      "998:\tlearn: 46241.9051614\ttotal: 18.6s\tremaining: 18.6ms\n",
      "999:\tlearn: 46234.4716846\ttotal: 18.6s\tremaining: 0us\n",
      "Learning rate set to 0.071716\n",
      "0:\tlearn: 76006.9653711\ttotal: 38ms\tremaining: 37.9s\n",
      "1:\tlearn: 75585.1930581\ttotal: 70.4ms\tremaining: 35.1s\n",
      "2:\tlearn: 75121.6230612\ttotal: 87.3ms\tremaining: 29s\n",
      "3:\tlearn: 74775.4916917\ttotal: 107ms\tremaining: 26.7s\n",
      "4:\tlearn: 74410.2354600\ttotal: 126ms\tremaining: 25s\n",
      "5:\tlearn: 74063.4505324\ttotal: 151ms\tremaining: 25.1s\n",
      "6:\tlearn: 73817.1225008\ttotal: 165ms\tremaining: 23.5s\n",
      "7:\tlearn: 73580.9465091\ttotal: 192ms\tremaining: 23.8s\n",
      "8:\tlearn: 73375.1723792\ttotal: 210ms\tremaining: 23.1s\n",
      "9:\tlearn: 73200.8421276\ttotal: 253ms\tremaining: 25.1s\n",
      "10:\tlearn: 73047.0690984\ttotal: 343ms\tremaining: 30.8s\n",
      "11:\tlearn: 72874.1423997\ttotal: 370ms\tremaining: 30.5s\n",
      "12:\tlearn: 72689.8937699\ttotal: 391ms\tremaining: 29.7s\n",
      "13:\tlearn: 72558.6253804\ttotal: 406ms\tremaining: 28.6s\n",
      "14:\tlearn: 72447.8751717\ttotal: 418ms\tremaining: 27.4s\n",
      "15:\tlearn: 72304.4633172\ttotal: 434ms\tremaining: 26.7s\n",
      "16:\tlearn: 72201.0485682\ttotal: 461ms\tremaining: 26.6s\n",
      "17:\tlearn: 72088.4791413\ttotal: 494ms\tremaining: 27s\n",
      "18:\tlearn: 71848.3841419\ttotal: 520ms\tremaining: 26.9s\n",
      "19:\tlearn: 71762.9214642\ttotal: 531ms\tremaining: 26s\n",
      "20:\tlearn: 71689.5411359\ttotal: 543ms\tremaining: 25.3s\n",
      "21:\tlearn: 71631.8763756\ttotal: 557ms\tremaining: 24.8s\n",
      "22:\tlearn: 71479.9076988\ttotal: 572ms\tremaining: 24.3s\n",
      "23:\tlearn: 71350.7434551\ttotal: 584ms\tremaining: 23.7s\n",
      "24:\tlearn: 71233.7949217\ttotal: 597ms\tremaining: 23.3s\n",
      "25:\tlearn: 71159.2384236\ttotal: 616ms\tremaining: 23.1s\n",
      "26:\tlearn: 71111.5072205\ttotal: 625ms\tremaining: 22.5s\n",
      "27:\tlearn: 71046.4302622\ttotal: 638ms\tremaining: 22.1s\n",
      "28:\tlearn: 71005.1775565\ttotal: 650ms\tremaining: 21.8s\n",
      "29:\tlearn: 70969.1762616\ttotal: 662ms\tremaining: 21.4s\n",
      "30:\tlearn: 70951.3294424\ttotal: 683ms\tremaining: 21.3s\n",
      "31:\tlearn: 70873.5109127\ttotal: 712ms\tremaining: 21.5s\n",
      "32:\tlearn: 70810.5128918\ttotal: 732ms\tremaining: 21.4s\n",
      "33:\tlearn: 70747.2303820\ttotal: 744ms\tremaining: 21.1s\n",
      "34:\tlearn: 70705.8466397\ttotal: 754ms\tremaining: 20.8s\n",
      "35:\tlearn: 70683.9082164\ttotal: 768ms\tremaining: 20.6s\n",
      "36:\tlearn: 70634.2159670\ttotal: 781ms\tremaining: 20.3s\n",
      "37:\tlearn: 70563.6713895\ttotal: 790ms\tremaining: 20s\n",
      "38:\tlearn: 70541.2487753\ttotal: 835ms\tremaining: 20.6s\n",
      "39:\tlearn: 70509.6999314\ttotal: 870ms\tremaining: 20.9s\n",
      "40:\tlearn: 70491.1067901\ttotal: 916ms\tremaining: 21.4s\n",
      "41:\tlearn: 70438.2691963\ttotal: 932ms\tremaining: 21.3s\n",
      "42:\tlearn: 70425.9356966\ttotal: 963ms\tremaining: 21.4s\n",
      "43:\tlearn: 70378.8792822\ttotal: 977ms\tremaining: 21.2s\n",
      "44:\tlearn: 70294.5515698\ttotal: 993ms\tremaining: 21.1s\n",
      "45:\tlearn: 70273.9828382\ttotal: 1s\tremaining: 20.8s\n",
      "46:\tlearn: 70239.7153967\ttotal: 1.02s\tremaining: 20.8s\n",
      "47:\tlearn: 70228.9093357\ttotal: 1.03s\tremaining: 20.5s\n",
      "48:\tlearn: 70182.7083570\ttotal: 1.05s\tremaining: 20.3s\n",
      "49:\tlearn: 70172.4910516\ttotal: 1.06s\tremaining: 20.1s\n",
      "50:\tlearn: 70121.0565512\ttotal: 1.07s\tremaining: 20s\n",
      "51:\tlearn: 70098.1074916\ttotal: 1.09s\tremaining: 19.8s\n",
      "52:\tlearn: 70088.5541915\ttotal: 1.1s\tremaining: 19.6s\n",
      "53:\tlearn: 70064.8768038\ttotal: 1.11s\tremaining: 19.5s\n",
      "54:\tlearn: 70043.0714750\ttotal: 1.12s\tremaining: 19.3s\n",
      "55:\tlearn: 69988.2886582\ttotal: 1.26s\tremaining: 21.2s\n",
      "56:\tlearn: 69977.5841725\ttotal: 1.27s\tremaining: 21.1s\n",
      "57:\tlearn: 69949.4497705\ttotal: 1.28s\tremaining: 20.9s\n",
      "58:\tlearn: 69917.9074731\ttotal: 1.3s\tremaining: 20.7s\n",
      "59:\tlearn: 69823.9035599\ttotal: 1.31s\tremaining: 20.6s\n",
      "60:\tlearn: 69762.3327907\ttotal: 1.33s\tremaining: 20.5s\n",
      "61:\tlearn: 69726.5826389\ttotal: 1.35s\tremaining: 20.4s\n",
      "62:\tlearn: 69682.0589593\ttotal: 1.36s\tremaining: 20.2s\n",
      "63:\tlearn: 69653.2295649\ttotal: 1.37s\tremaining: 20.1s\n",
      "64:\tlearn: 69550.7559541\ttotal: 1.38s\tremaining: 19.9s\n",
      "65:\tlearn: 69540.1008562\ttotal: 1.4s\tremaining: 19.8s\n",
      "66:\tlearn: 69529.4261706\ttotal: 1.41s\tremaining: 19.6s\n",
      "67:\tlearn: 69517.1951460\ttotal: 1.42s\tremaining: 19.5s\n",
      "68:\tlearn: 69491.2091881\ttotal: 1.43s\tremaining: 19.3s\n",
      "69:\tlearn: 69410.3274332\ttotal: 1.45s\tremaining: 19.2s\n",
      "70:\tlearn: 69328.5192843\ttotal: 1.46s\tremaining: 19.1s\n",
      "71:\tlearn: 69309.7297437\ttotal: 1.48s\tremaining: 19.1s\n",
      "72:\tlearn: 69253.6887573\ttotal: 1.5s\tremaining: 19.1s\n",
      "73:\tlearn: 69246.8081637\ttotal: 1.51s\tremaining: 19s\n",
      "74:\tlearn: 69238.5747176\ttotal: 1.53s\tremaining: 18.8s\n",
      "75:\tlearn: 69230.9164870\ttotal: 1.54s\tremaining: 18.8s\n",
      "76:\tlearn: 69213.6675014\ttotal: 1.56s\tremaining: 18.7s\n",
      "77:\tlearn: 69205.8173150\ttotal: 1.56s\tremaining: 18.5s\n",
      "78:\tlearn: 69195.6976152\ttotal: 1.58s\tremaining: 18.4s\n",
      "79:\tlearn: 69131.4213753\ttotal: 1.59s\tremaining: 18.3s\n",
      "80:\tlearn: 69079.0513095\ttotal: 1.61s\tremaining: 18.2s\n",
      "81:\tlearn: 69069.1113143\ttotal: 1.62s\tremaining: 18.1s\n",
      "82:\tlearn: 69050.5349781\ttotal: 1.64s\tremaining: 18.1s\n",
      "83:\tlearn: 69000.6926504\ttotal: 1.65s\tremaining: 18s\n",
      "84:\tlearn: 68912.1515682\ttotal: 1.66s\tremaining: 17.9s\n",
      "85:\tlearn: 68898.7403094\ttotal: 1.68s\tremaining: 17.8s\n",
      "86:\tlearn: 68892.6873643\ttotal: 1.74s\tremaining: 18.3s\n",
      "87:\tlearn: 68886.5177502\ttotal: 1.76s\tremaining: 18.2s\n",
      "88:\tlearn: 68801.6676622\ttotal: 1.78s\tremaining: 18.2s\n",
      "89:\tlearn: 68752.5444484\ttotal: 1.79s\tremaining: 18.1s\n",
      "90:\tlearn: 68746.4140082\ttotal: 1.8s\tremaining: 18s\n",
      "91:\tlearn: 68727.5910935\ttotal: 1.81s\tremaining: 17.9s\n",
      "92:\tlearn: 68681.9790938\ttotal: 1.83s\tremaining: 17.8s\n",
      "93:\tlearn: 68676.1198715\ttotal: 1.84s\tremaining: 17.8s\n",
      "94:\tlearn: 68664.1365147\ttotal: 1.86s\tremaining: 17.7s\n",
      "95:\tlearn: 68651.9137862\ttotal: 1.87s\tremaining: 17.6s\n",
      "96:\tlearn: 68606.7028396\ttotal: 1.88s\tremaining: 17.5s\n",
      "97:\tlearn: 68564.6424144\ttotal: 1.9s\tremaining: 17.5s\n",
      "98:\tlearn: 68559.3211929\ttotal: 1.92s\tremaining: 17.5s\n",
      "99:\tlearn: 68497.0634457\ttotal: 1.94s\tremaining: 17.5s\n",
      "100:\tlearn: 68492.5854612\ttotal: 1.95s\tremaining: 17.4s\n",
      "101:\tlearn: 68405.8242745\ttotal: 1.97s\tremaining: 17.3s\n",
      "102:\tlearn: 68336.8824419\ttotal: 1.98s\tremaining: 17.2s\n",
      "103:\tlearn: 68331.2366696\ttotal: 1.99s\tremaining: 17.2s\n",
      "104:\tlearn: 68291.7822681\ttotal: 2.01s\tremaining: 17.1s\n",
      "105:\tlearn: 68188.2582570\ttotal: 2.02s\tremaining: 17.1s\n",
      "106:\tlearn: 68109.3675917\ttotal: 2.04s\tremaining: 17s\n",
      "107:\tlearn: 68088.8825217\ttotal: 2.05s\tremaining: 17s\n",
      "108:\tlearn: 68069.0200663\ttotal: 2.06s\tremaining: 16.9s\n",
      "109:\tlearn: 68039.2215758\ttotal: 2.08s\tremaining: 16.8s\n",
      "110:\tlearn: 67977.8299009\ttotal: 2.09s\tremaining: 16.7s\n",
      "111:\tlearn: 67856.5170825\ttotal: 2.1s\tremaining: 16.7s\n",
      "112:\tlearn: 67793.8933892\ttotal: 2.15s\tremaining: 16.9s\n",
      "113:\tlearn: 67789.6068624\ttotal: 2.16s\tremaining: 16.8s\n",
      "114:\tlearn: 67744.5897128\ttotal: 2.17s\tremaining: 16.7s\n",
      "115:\tlearn: 67722.5424855\ttotal: 2.19s\tremaining: 16.7s\n",
      "116:\tlearn: 67707.6455500\ttotal: 2.2s\tremaining: 16.6s\n",
      "117:\tlearn: 67688.7650696\ttotal: 2.21s\tremaining: 16.5s\n",
      "118:\tlearn: 67619.5353067\ttotal: 2.23s\tremaining: 16.5s\n",
      "119:\tlearn: 67587.3226058\ttotal: 2.24s\tremaining: 16.4s\n",
      "120:\tlearn: 67580.5573079\ttotal: 2.26s\tremaining: 16.4s\n",
      "121:\tlearn: 67562.7304401\ttotal: 2.27s\tremaining: 16.4s\n",
      "122:\tlearn: 67524.5992524\ttotal: 2.29s\tremaining: 16.3s\n",
      "123:\tlearn: 67425.9801236\ttotal: 2.3s\tremaining: 16.3s\n",
      "124:\tlearn: 67390.3370916\ttotal: 2.32s\tremaining: 16.2s\n",
      "125:\tlearn: 67386.1657931\ttotal: 2.35s\tremaining: 16.3s\n",
      "126:\tlearn: 67380.5438359\ttotal: 2.37s\tremaining: 16.3s\n",
      "127:\tlearn: 67351.4989930\ttotal: 2.38s\tremaining: 16.2s\n",
      "128:\tlearn: 67316.4757083\ttotal: 2.4s\tremaining: 16.2s\n",
      "129:\tlearn: 67292.3491611\ttotal: 2.41s\tremaining: 16.1s\n",
      "130:\tlearn: 67284.4803257\ttotal: 2.42s\tremaining: 16.1s\n",
      "131:\tlearn: 67258.5315667\ttotal: 2.44s\tremaining: 16s\n",
      "132:\tlearn: 67236.0623887\ttotal: 2.45s\tremaining: 16s\n",
      "133:\tlearn: 67215.0564858\ttotal: 2.46s\tremaining: 15.9s\n",
      "134:\tlearn: 67155.2112725\ttotal: 2.47s\tremaining: 15.8s\n",
      "135:\tlearn: 67151.7667010\ttotal: 2.48s\tremaining: 15.8s\n",
      "136:\tlearn: 67129.2198845\ttotal: 2.5s\tremaining: 15.7s\n",
      "137:\tlearn: 67093.0384215\ttotal: 2.51s\tremaining: 15.7s\n",
      "138:\tlearn: 67083.3047772\ttotal: 2.53s\tremaining: 15.7s\n",
      "139:\tlearn: 67057.8026021\ttotal: 2.63s\tremaining: 16.2s\n",
      "140:\tlearn: 66976.7461721\ttotal: 2.66s\tremaining: 16.2s\n",
      "141:\tlearn: 66973.0111321\ttotal: 2.67s\tremaining: 16.1s\n",
      "142:\tlearn: 66958.0989405\ttotal: 2.69s\tremaining: 16.1s\n",
      "143:\tlearn: 66935.6104564\ttotal: 2.7s\tremaining: 16s\n",
      "144:\tlearn: 66858.1635932\ttotal: 2.71s\tremaining: 16s\n",
      "145:\tlearn: 66843.1487782\ttotal: 2.73s\tremaining: 15.9s\n",
      "146:\tlearn: 66842.6247147\ttotal: 2.73s\tremaining: 15.9s\n",
      "147:\tlearn: 66833.9974354\ttotal: 2.76s\tremaining: 15.9s\n",
      "148:\tlearn: 66767.0713340\ttotal: 2.79s\tremaining: 15.9s\n",
      "149:\tlearn: 66734.6141659\ttotal: 2.8s\tremaining: 15.9s\n",
      "150:\tlearn: 66716.1193317\ttotal: 2.81s\tremaining: 15.8s\n",
      "151:\tlearn: 66703.2382263\ttotal: 2.83s\tremaining: 15.8s\n",
      "152:\tlearn: 66686.8835493\ttotal: 2.84s\tremaining: 15.7s\n",
      "153:\tlearn: 66661.0360852\ttotal: 2.86s\tremaining: 15.7s\n",
      "154:\tlearn: 66616.3988323\ttotal: 2.87s\tremaining: 15.7s\n",
      "155:\tlearn: 66610.8037914\ttotal: 2.88s\tremaining: 15.6s\n",
      "156:\tlearn: 66606.2746536\ttotal: 2.89s\tremaining: 15.5s\n",
      "157:\tlearn: 66602.5590487\ttotal: 2.91s\tremaining: 15.5s\n",
      "158:\tlearn: 66599.1155112\ttotal: 2.92s\tremaining: 15.4s\n",
      "159:\tlearn: 66518.7444412\ttotal: 2.93s\tremaining: 15.4s\n",
      "160:\tlearn: 66489.1419945\ttotal: 2.94s\tremaining: 15.3s\n",
      "161:\tlearn: 66459.9780082\ttotal: 2.96s\tremaining: 15.3s\n",
      "162:\tlearn: 66457.1682890\ttotal: 2.98s\tremaining: 15.3s\n",
      "163:\tlearn: 66446.3606833\ttotal: 2.99s\tremaining: 15.2s\n",
      "164:\tlearn: 66435.6514244\ttotal: 3.02s\tremaining: 15.3s\n",
      "165:\tlearn: 66407.5850104\ttotal: 3.04s\tremaining: 15.3s\n",
      "166:\tlearn: 66361.7023734\ttotal: 3.05s\tremaining: 15.2s\n",
      "167:\tlearn: 66343.2937321\ttotal: 3.07s\tremaining: 15.2s\n",
      "168:\tlearn: 66283.2911902\ttotal: 3.08s\tremaining: 15.2s\n",
      "169:\tlearn: 66230.9767151\ttotal: 3.09s\tremaining: 15.1s\n",
      "170:\tlearn: 66228.7764460\ttotal: 3.1s\tremaining: 15.1s\n",
      "171:\tlearn: 66226.2964226\ttotal: 3.12s\tremaining: 15s\n",
      "172:\tlearn: 66198.0279723\ttotal: 3.13s\tremaining: 15s\n",
      "173:\tlearn: 66171.3980102\ttotal: 3.14s\tremaining: 14.9s\n",
      "174:\tlearn: 66145.3442516\ttotal: 3.16s\tremaining: 14.9s\n",
      "175:\tlearn: 66081.9247501\ttotal: 3.17s\tremaining: 14.8s\n",
      "176:\tlearn: 66056.8207538\ttotal: 3.19s\tremaining: 14.9s\n",
      "177:\tlearn: 66032.6625158\ttotal: 3.22s\tremaining: 14.9s\n",
      "178:\tlearn: 65979.2640420\ttotal: 3.23s\tremaining: 14.8s\n",
      "179:\tlearn: 65934.7720986\ttotal: 3.25s\tremaining: 14.8s\n",
      "180:\tlearn: 65911.7196910\ttotal: 3.26s\tremaining: 14.8s\n",
      "181:\tlearn: 65844.6938979\ttotal: 3.28s\tremaining: 14.7s\n",
      "182:\tlearn: 65842.7456367\ttotal: 3.29s\tremaining: 14.7s\n",
      "183:\tlearn: 65822.6903864\ttotal: 3.3s\tremaining: 14.6s\n",
      "184:\tlearn: 65757.7975924\ttotal: 3.31s\tremaining: 14.6s\n",
      "185:\tlearn: 65738.2644061\ttotal: 3.32s\tremaining: 14.5s\n",
      "186:\tlearn: 65732.6651122\ttotal: 3.34s\tremaining: 14.5s\n",
      "187:\tlearn: 65710.4735156\ttotal: 3.36s\tremaining: 14.5s\n",
      "188:\tlearn: 65667.2940269\ttotal: 3.37s\tremaining: 14.5s\n",
      "189:\tlearn: 65613.6137113\ttotal: 3.38s\tremaining: 14.4s\n",
      "190:\tlearn: 65592.2357115\ttotal: 3.4s\tremaining: 14.4s\n",
      "191:\tlearn: 65573.5235970\ttotal: 3.42s\tremaining: 14.4s\n",
      "192:\tlearn: 65552.7857264\ttotal: 3.45s\tremaining: 14.4s\n",
      "193:\tlearn: 65484.8473197\ttotal: 3.47s\tremaining: 14.4s\n",
      "194:\tlearn: 65464.8107748\ttotal: 3.49s\tremaining: 14.4s\n",
      "195:\tlearn: 65446.8863493\ttotal: 3.5s\tremaining: 14.4s\n",
      "196:\tlearn: 65430.3852948\ttotal: 3.51s\tremaining: 14.3s\n",
      "197:\tlearn: 65413.1118201\ttotal: 3.52s\tremaining: 14.3s\n",
      "198:\tlearn: 65393.9863837\ttotal: 3.54s\tremaining: 14.2s\n",
      "199:\tlearn: 65344.0057784\ttotal: 3.57s\tremaining: 14.3s\n",
      "200:\tlearn: 65327.3783348\ttotal: 3.58s\tremaining: 14.3s\n",
      "201:\tlearn: 65311.4534868\ttotal: 3.6s\tremaining: 14.2s\n",
      "202:\tlearn: 65296.1406491\ttotal: 3.6s\tremaining: 14.2s\n",
      "203:\tlearn: 65280.8071114\ttotal: 3.62s\tremaining: 14.1s\n",
      "204:\tlearn: 65264.3153995\ttotal: 3.65s\tremaining: 14.2s\n",
      "205:\tlearn: 65245.6706310\ttotal: 3.67s\tremaining: 14.1s\n",
      "206:\tlearn: 65155.6649590\ttotal: 3.69s\tremaining: 14.1s\n",
      "207:\tlearn: 65137.8635970\ttotal: 3.7s\tremaining: 14.1s\n",
      "208:\tlearn: 65069.0319214\ttotal: 3.71s\tremaining: 14.1s\n",
      "209:\tlearn: 65054.2691399\ttotal: 3.73s\tremaining: 14s\n",
      "210:\tlearn: 65040.0874718\ttotal: 3.74s\tremaining: 14s\n",
      "211:\tlearn: 65022.8006112\ttotal: 3.75s\tremaining: 13.9s\n",
      "212:\tlearn: 64955.3249279\ttotal: 3.77s\tremaining: 13.9s\n",
      "213:\tlearn: 64938.6237483\ttotal: 3.78s\tremaining: 13.9s\n",
      "214:\tlearn: 64924.9721851\ttotal: 3.79s\tremaining: 13.8s\n",
      "215:\tlearn: 64859.3078994\ttotal: 3.8s\tremaining: 13.8s\n",
      "216:\tlearn: 64794.0854773\ttotal: 3.82s\tremaining: 13.8s\n",
      "217:\tlearn: 64778.0976336\ttotal: 3.83s\tremaining: 13.8s\n",
      "218:\tlearn: 64765.1228721\ttotal: 3.85s\tremaining: 13.7s\n",
      "219:\tlearn: 64751.9785839\ttotal: 3.87s\tremaining: 13.7s\n",
      "220:\tlearn: 64653.1996076\ttotal: 3.97s\tremaining: 14s\n",
      "221:\tlearn: 64572.3572104\ttotal: 3.98s\tremaining: 14s\n",
      "222:\tlearn: 64520.4988895\ttotal: 4s\tremaining: 13.9s\n",
      "223:\tlearn: 64503.8043319\ttotal: 4.01s\tremaining: 13.9s\n",
      "224:\tlearn: 64488.2520049\ttotal: 4.02s\tremaining: 13.9s\n",
      "225:\tlearn: 64425.3290591\ttotal: 4.03s\tremaining: 13.8s\n",
      "226:\tlearn: 64412.6157314\ttotal: 4.05s\tremaining: 13.8s\n",
      "227:\tlearn: 64400.3901976\ttotal: 4.06s\tremaining: 13.8s\n",
      "228:\tlearn: 64386.7810902\ttotal: 4.1s\tremaining: 13.8s\n",
      "229:\tlearn: 64344.0255218\ttotal: 4.11s\tremaining: 13.8s\n",
      "230:\tlearn: 64272.9285291\ttotal: 4.13s\tremaining: 13.7s\n",
      "231:\tlearn: 64253.3677907\ttotal: 4.14s\tremaining: 13.7s\n",
      "232:\tlearn: 64151.8774592\ttotal: 4.15s\tremaining: 13.7s\n",
      "233:\tlearn: 64136.8098446\ttotal: 4.17s\tremaining: 13.6s\n",
      "234:\tlearn: 64125.0320688\ttotal: 4.18s\tremaining: 13.6s\n",
      "235:\tlearn: 64109.8877550\ttotal: 4.19s\tremaining: 13.6s\n",
      "236:\tlearn: 64095.3599494\ttotal: 4.21s\tremaining: 13.5s\n",
      "237:\tlearn: 64037.7338896\ttotal: 4.22s\tremaining: 13.5s\n",
      "238:\tlearn: 63974.4330137\ttotal: 4.23s\tremaining: 13.5s\n",
      "239:\tlearn: 63872.1911823\ttotal: 4.24s\tremaining: 13.4s\n",
      "240:\tlearn: 63858.1291882\ttotal: 4.25s\tremaining: 13.4s\n",
      "241:\tlearn: 63846.7513989\ttotal: 4.27s\tremaining: 13.4s\n",
      "242:\tlearn: 63806.9648106\ttotal: 4.28s\tremaining: 13.3s\n",
      "243:\tlearn: 63768.2728316\ttotal: 4.32s\tremaining: 13.4s\n",
      "244:\tlearn: 63758.0601541\ttotal: 4.34s\tremaining: 13.4s\n",
      "245:\tlearn: 63694.7656631\ttotal: 4.35s\tremaining: 13.3s\n",
      "246:\tlearn: 63684.2161358\ttotal: 4.37s\tremaining: 13.3s\n",
      "247:\tlearn: 63670.7478155\ttotal: 4.38s\tremaining: 13.3s\n",
      "248:\tlearn: 63655.9907720\ttotal: 4.4s\tremaining: 13.3s\n",
      "249:\tlearn: 63634.0411816\ttotal: 4.41s\tremaining: 13.2s\n",
      "250:\tlearn: 63574.2047612\ttotal: 4.42s\tremaining: 13.2s\n",
      "251:\tlearn: 63541.2111077\ttotal: 4.43s\tremaining: 13.2s\n",
      "252:\tlearn: 63444.5934185\ttotal: 4.45s\tremaining: 13.1s\n",
      "253:\tlearn: 63432.7593008\ttotal: 4.46s\tremaining: 13.1s\n",
      "254:\tlearn: 63386.6646394\ttotal: 4.48s\tremaining: 13.1s\n",
      "255:\tlearn: 63332.1303660\ttotal: 4.5s\tremaining: 13.1s\n",
      "256:\tlearn: 63318.9884026\ttotal: 4.53s\tremaining: 13.1s\n",
      "257:\tlearn: 63257.8598960\ttotal: 4.54s\tremaining: 13.1s\n",
      "258:\tlearn: 63245.1811844\ttotal: 4.56s\tremaining: 13s\n",
      "259:\tlearn: 63141.8288438\ttotal: 4.57s\tremaining: 13s\n",
      "260:\tlearn: 63118.9797547\ttotal: 4.58s\tremaining: 13s\n",
      "261:\tlearn: 63109.6358095\ttotal: 4.6s\tremaining: 12.9s\n",
      "262:\tlearn: 63058.0926690\ttotal: 4.61s\tremaining: 12.9s\n",
      "263:\tlearn: 63026.4460508\ttotal: 4.63s\tremaining: 12.9s\n",
      "264:\tlearn: 63006.4696012\ttotal: 4.64s\tremaining: 12.9s\n",
      "265:\tlearn: 62997.4329900\ttotal: 4.65s\tremaining: 12.8s\n",
      "266:\tlearn: 62982.3561639\ttotal: 4.66s\tremaining: 12.8s\n",
      "267:\tlearn: 62975.9016526\ttotal: 4.68s\tremaining: 12.8s\n",
      "268:\tlearn: 62942.3507103\ttotal: 4.69s\tremaining: 12.8s\n",
      "269:\tlearn: 62874.0828418\ttotal: 4.71s\tremaining: 12.7s\n",
      "270:\tlearn: 62863.6939357\ttotal: 4.73s\tremaining: 12.7s\n",
      "271:\tlearn: 62815.9685132\ttotal: 4.76s\tremaining: 12.8s\n",
      "272:\tlearn: 62791.5414347\ttotal: 4.78s\tremaining: 12.7s\n",
      "273:\tlearn: 62783.1686390\ttotal: 4.79s\tremaining: 12.7s\n",
      "274:\tlearn: 62674.3786217\ttotal: 4.81s\tremaining: 12.7s\n",
      "275:\tlearn: 62620.5599634\ttotal: 4.82s\tremaining: 12.6s\n",
      "276:\tlearn: 62553.3147204\ttotal: 4.83s\tremaining: 12.6s\n",
      "277:\tlearn: 62451.5258573\ttotal: 4.84s\tremaining: 12.6s\n",
      "278:\tlearn: 62443.3547058\ttotal: 4.85s\tremaining: 12.5s\n",
      "279:\tlearn: 62347.7368807\ttotal: 4.87s\tremaining: 12.5s\n",
      "280:\tlearn: 62324.1375445\ttotal: 4.88s\tremaining: 12.5s\n",
      "281:\tlearn: 62260.4672392\ttotal: 4.89s\tremaining: 12.5s\n",
      "282:\tlearn: 62196.5948279\ttotal: 4.91s\tremaining: 12.4s\n",
      "283:\tlearn: 62153.9077563\ttotal: 4.93s\tremaining: 12.4s\n",
      "284:\tlearn: 62060.3108470\ttotal: 4.96s\tremaining: 12.4s\n",
      "285:\tlearn: 62011.0009684\ttotal: 4.97s\tremaining: 12.4s\n",
      "286:\tlearn: 61959.5408125\ttotal: 5s\tremaining: 12.4s\n",
      "287:\tlearn: 61900.2994012\ttotal: 5.01s\tremaining: 12.4s\n",
      "288:\tlearn: 61884.9474035\ttotal: 5.03s\tremaining: 12.4s\n",
      "289:\tlearn: 61874.1059386\ttotal: 5.04s\tremaining: 12.3s\n",
      "290:\tlearn: 61843.5956551\ttotal: 5.05s\tremaining: 12.3s\n",
      "291:\tlearn: 61783.9591503\ttotal: 5.07s\tremaining: 12.3s\n",
      "292:\tlearn: 61773.8818963\ttotal: 5.08s\tremaining: 12.3s\n",
      "293:\tlearn: 61712.5429582\ttotal: 5.09s\tremaining: 12.2s\n",
      "294:\tlearn: 61653.6657712\ttotal: 5.1s\tremaining: 12.2s\n",
      "295:\tlearn: 61592.3855181\ttotal: 5.12s\tremaining: 12.2s\n",
      "296:\tlearn: 61533.6738254\ttotal: 5.25s\tremaining: 12.4s\n",
      "297:\tlearn: 61480.9060424\ttotal: 5.26s\tremaining: 12.4s\n",
      "298:\tlearn: 61430.2300432\ttotal: 5.28s\tremaining: 12.4s\n",
      "299:\tlearn: 61377.4469016\ttotal: 5.29s\tremaining: 12.3s\n",
      "300:\tlearn: 61330.4158682\ttotal: 5.3s\tremaining: 12.3s\n",
      "301:\tlearn: 61281.4066639\ttotal: 5.31s\tremaining: 12.3s\n",
      "302:\tlearn: 61234.4141819\ttotal: 5.33s\tremaining: 12.3s\n",
      "303:\tlearn: 61201.1772445\ttotal: 5.34s\tremaining: 12.2s\n",
      "304:\tlearn: 61160.9085378\ttotal: 5.36s\tremaining: 12.2s\n",
      "305:\tlearn: 61120.1099169\ttotal: 5.37s\tremaining: 12.2s\n",
      "306:\tlearn: 61111.4674230\ttotal: 5.38s\tremaining: 12.2s\n",
      "307:\tlearn: 61072.2632874\ttotal: 5.4s\tremaining: 12.1s\n",
      "308:\tlearn: 61031.2202721\ttotal: 5.41s\tremaining: 12.1s\n",
      "309:\tlearn: 61019.1757841\ttotal: 5.42s\tremaining: 12.1s\n",
      "310:\tlearn: 60963.2627546\ttotal: 5.44s\tremaining: 12s\n",
      "311:\tlearn: 60913.5078195\ttotal: 5.45s\tremaining: 12s\n",
      "312:\tlearn: 60903.5853592\ttotal: 5.47s\tremaining: 12s\n",
      "313:\tlearn: 60864.1164844\ttotal: 5.51s\tremaining: 12s\n",
      "314:\tlearn: 60852.0175776\ttotal: 5.51s\tremaining: 12s\n",
      "315:\tlearn: 60786.6181182\ttotal: 5.53s\tremaining: 12s\n",
      "316:\tlearn: 60751.3011865\ttotal: 5.55s\tremaining: 12s\n",
      "317:\tlearn: 60717.3590273\ttotal: 5.56s\tremaining: 11.9s\n",
      "318:\tlearn: 60684.7326341\ttotal: 5.58s\tremaining: 11.9s\n",
      "319:\tlearn: 60673.7799012\ttotal: 5.59s\tremaining: 11.9s\n",
      "320:\tlearn: 60611.7897333\ttotal: 5.61s\tremaining: 11.9s\n",
      "321:\tlearn: 60586.3425849\ttotal: 5.62s\tremaining: 11.8s\n",
      "322:\tlearn: 60532.4978382\ttotal: 5.63s\tremaining: 11.8s\n",
      "323:\tlearn: 60505.3792128\ttotal: 5.65s\tremaining: 11.8s\n",
      "324:\tlearn: 60497.4496899\ttotal: 5.67s\tremaining: 11.8s\n",
      "325:\tlearn: 60475.9895011\ttotal: 5.68s\tremaining: 11.8s\n",
      "326:\tlearn: 60412.6229697\ttotal: 5.71s\tremaining: 11.8s\n",
      "327:\tlearn: 60411.0738901\ttotal: 5.73s\tremaining: 11.7s\n",
      "328:\tlearn: 60383.2159440\ttotal: 5.74s\tremaining: 11.7s\n",
      "329:\tlearn: 60351.6644464\ttotal: 5.76s\tremaining: 11.7s\n",
      "330:\tlearn: 60321.3272760\ttotal: 5.78s\tremaining: 11.7s\n",
      "331:\tlearn: 60319.8505587\ttotal: 5.79s\tremaining: 11.6s\n",
      "332:\tlearn: 60293.0840287\ttotal: 5.8s\tremaining: 11.6s\n",
      "333:\tlearn: 60267.4506499\ttotal: 5.81s\tremaining: 11.6s\n",
      "334:\tlearn: 60226.8691403\ttotal: 5.82s\tremaining: 11.6s\n",
      "335:\tlearn: 60209.8888912\ttotal: 5.84s\tremaining: 11.5s\n",
      "336:\tlearn: 60205.2084910\ttotal: 5.85s\tremaining: 11.5s\n",
      "337:\tlearn: 60175.9588798\ttotal: 5.87s\tremaining: 11.5s\n",
      "338:\tlearn: 60116.2820786\ttotal: 5.88s\tremaining: 11.5s\n",
      "339:\tlearn: 60084.2686228\ttotal: 5.89s\tremaining: 11.4s\n",
      "340:\tlearn: 60052.6518236\ttotal: 5.91s\tremaining: 11.4s\n",
      "341:\tlearn: 60045.5954930\ttotal: 5.92s\tremaining: 11.4s\n",
      "342:\tlearn: 60041.1257472\ttotal: 5.95s\tremaining: 11.4s\n",
      "343:\tlearn: 60021.5151449\ttotal: 5.97s\tremaining: 11.4s\n",
      "344:\tlearn: 60008.0261011\ttotal: 5.98s\tremaining: 11.4s\n",
      "345:\tlearn: 59969.7223433\ttotal: 6s\tremaining: 11.3s\n",
      "346:\tlearn: 59933.3699008\ttotal: 6.02s\tremaining: 11.3s\n",
      "347:\tlearn: 59924.0506903\ttotal: 6.03s\tremaining: 11.3s\n",
      "348:\tlearn: 59893.6528794\ttotal: 6.04s\tremaining: 11.3s\n",
      "349:\tlearn: 59867.2932733\ttotal: 6.05s\tremaining: 11.2s\n",
      "350:\tlearn: 59812.6115828\ttotal: 6.07s\tremaining: 11.2s\n",
      "351:\tlearn: 59793.7473207\ttotal: 6.09s\tremaining: 11.2s\n",
      "352:\tlearn: 59768.3686521\ttotal: 6.1s\tremaining: 11.2s\n",
      "353:\tlearn: 59763.3985393\ttotal: 6.12s\tremaining: 11.2s\n",
      "354:\tlearn: 59735.1360288\ttotal: 6.13s\tremaining: 11.1s\n",
      "355:\tlearn: 59676.3838851\ttotal: 6.16s\tremaining: 11.1s\n",
      "356:\tlearn: 59667.1724727\ttotal: 6.18s\tremaining: 11.1s\n",
      "357:\tlearn: 59610.7962974\ttotal: 6.19s\tremaining: 11.1s\n",
      "358:\tlearn: 59586.3166313\ttotal: 6.2s\tremaining: 11.1s\n",
      "359:\tlearn: 59571.8837964\ttotal: 6.22s\tremaining: 11.1s\n",
      "360:\tlearn: 59531.0433800\ttotal: 6.23s\tremaining: 11s\n",
      "361:\tlearn: 59507.4695436\ttotal: 6.24s\tremaining: 11s\n",
      "362:\tlearn: 59494.0611726\ttotal: 6.25s\tremaining: 11s\n",
      "363:\tlearn: 59489.5105395\ttotal: 6.27s\tremaining: 10.9s\n",
      "364:\tlearn: 59466.8218398\ttotal: 6.28s\tremaining: 10.9s\n",
      "365:\tlearn: 59462.4714109\ttotal: 6.3s\tremaining: 10.9s\n",
      "366:\tlearn: 59437.3576757\ttotal: 6.31s\tremaining: 10.9s\n",
      "367:\tlearn: 59397.2106062\ttotal: 6.32s\tremaining: 10.9s\n",
      "368:\tlearn: 59340.3732101\ttotal: 6.33s\tremaining: 10.8s\n",
      "369:\tlearn: 59333.1365746\ttotal: 6.37s\tremaining: 10.8s\n",
      "370:\tlearn: 59315.1064987\ttotal: 6.38s\tremaining: 10.8s\n",
      "371:\tlearn: 59291.0737404\ttotal: 6.39s\tremaining: 10.8s\n",
      "372:\tlearn: 59234.0560741\ttotal: 6.41s\tremaining: 10.8s\n",
      "373:\tlearn: 59198.8278159\ttotal: 6.43s\tremaining: 10.8s\n",
      "374:\tlearn: 59174.0803110\ttotal: 6.44s\tremaining: 10.7s\n",
      "375:\tlearn: 59120.0433446\ttotal: 6.46s\tremaining: 10.7s\n",
      "376:\tlearn: 59115.7647961\ttotal: 6.47s\tremaining: 10.7s\n",
      "377:\tlearn: 59078.7702418\ttotal: 6.48s\tremaining: 10.7s\n",
      "378:\tlearn: 59057.7360267\ttotal: 6.5s\tremaining: 10.6s\n",
      "379:\tlearn: 59051.9933928\ttotal: 6.51s\tremaining: 10.6s\n",
      "380:\tlearn: 59012.7852427\ttotal: 6.52s\tremaining: 10.6s\n",
      "381:\tlearn: 58993.3684398\ttotal: 6.54s\tremaining: 10.6s\n",
      "382:\tlearn: 58953.3128746\ttotal: 6.55s\tremaining: 10.6s\n",
      "383:\tlearn: 58943.2466843\ttotal: 6.57s\tremaining: 10.5s\n",
      "384:\tlearn: 58867.7568511\ttotal: 6.67s\tremaining: 10.7s\n",
      "385:\tlearn: 58851.7680318\ttotal: 6.7s\tremaining: 10.7s\n",
      "386:\tlearn: 58847.7512487\ttotal: 6.71s\tremaining: 10.6s\n",
      "387:\tlearn: 58842.0220480\ttotal: 6.72s\tremaining: 10.6s\n",
      "388:\tlearn: 58833.3206719\ttotal: 6.74s\tremaining: 10.6s\n",
      "389:\tlearn: 58781.0957733\ttotal: 6.75s\tremaining: 10.6s\n",
      "390:\tlearn: 58758.6718733\ttotal: 6.76s\tremaining: 10.5s\n",
      "391:\tlearn: 58751.1739810\ttotal: 6.79s\tremaining: 10.5s\n",
      "392:\tlearn: 58729.6782975\ttotal: 6.82s\tremaining: 10.5s\n",
      "393:\tlearn: 58710.4400739\ttotal: 6.83s\tremaining: 10.5s\n",
      "394:\tlearn: 58688.2199604\ttotal: 6.84s\tremaining: 10.5s\n",
      "395:\tlearn: 58669.0989549\ttotal: 6.86s\tremaining: 10.5s\n",
      "396:\tlearn: 58665.1254357\ttotal: 6.87s\tremaining: 10.4s\n",
      "397:\tlearn: 58646.9888070\ttotal: 6.88s\tremaining: 10.4s\n",
      "398:\tlearn: 58639.3962827\ttotal: 6.92s\tremaining: 10.4s\n",
      "399:\tlearn: 58576.1374003\ttotal: 6.93s\tremaining: 10.4s\n",
      "400:\tlearn: 58565.8304802\ttotal: 6.96s\tremaining: 10.4s\n",
      "401:\tlearn: 58535.2949056\ttotal: 6.97s\tremaining: 10.4s\n",
      "402:\tlearn: 58522.8614114\ttotal: 6.99s\tremaining: 10.4s\n",
      "403:\tlearn: 58469.9657578\ttotal: 7s\tremaining: 10.3s\n",
      "404:\tlearn: 58414.4912240\ttotal: 7.02s\tremaining: 10.3s\n",
      "405:\tlearn: 58373.6851824\ttotal: 7.03s\tremaining: 10.3s\n",
      "406:\tlearn: 58356.3571344\ttotal: 7.06s\tremaining: 10.3s\n",
      "407:\tlearn: 58335.6094932\ttotal: 7.08s\tremaining: 10.3s\n",
      "408:\tlearn: 58316.1284640\ttotal: 7.09s\tremaining: 10.3s\n",
      "409:\tlearn: 58296.6317876\ttotal: 7.11s\tremaining: 10.2s\n",
      "410:\tlearn: 58245.9486440\ttotal: 7.13s\tremaining: 10.2s\n",
      "411:\tlearn: 58192.3855089\ttotal: 7.14s\tremaining: 10.2s\n",
      "412:\tlearn: 58171.4543609\ttotal: 7.15s\tremaining: 10.2s\n",
      "413:\tlearn: 58122.5509994\ttotal: 7.16s\tremaining: 10.1s\n",
      "414:\tlearn: 58092.9204312\ttotal: 7.18s\tremaining: 10.1s\n",
      "415:\tlearn: 58086.5371259\ttotal: 7.19s\tremaining: 10.1s\n",
      "416:\tlearn: 58079.8415948\ttotal: 7.21s\tremaining: 10.1s\n",
      "417:\tlearn: 58063.4521147\ttotal: 7.22s\tremaining: 10.1s\n",
      "418:\tlearn: 58024.6177166\ttotal: 7.23s\tremaining: 10s\n",
      "419:\tlearn: 57997.3557633\ttotal: 7.24s\tremaining: 10s\n",
      "420:\tlearn: 57985.4215504\ttotal: 7.27s\tremaining: 10s\n",
      "421:\tlearn: 57962.9640161\ttotal: 7.29s\tremaining: 9.99s\n",
      "422:\tlearn: 57949.8715827\ttotal: 7.3s\tremaining: 9.96s\n",
      "423:\tlearn: 57885.2046338\ttotal: 7.32s\tremaining: 9.94s\n",
      "424:\tlearn: 57877.1650333\ttotal: 7.33s\tremaining: 9.92s\n",
      "425:\tlearn: 57860.5562468\ttotal: 7.34s\tremaining: 9.89s\n",
      "426:\tlearn: 57849.0618843\ttotal: 7.35s\tremaining: 9.86s\n",
      "427:\tlearn: 57838.0016022\ttotal: 7.36s\tremaining: 9.84s\n",
      "428:\tlearn: 57800.6965610\ttotal: 7.38s\tremaining: 9.82s\n",
      "429:\tlearn: 57784.8816462\ttotal: 7.39s\tremaining: 9.8s\n",
      "430:\tlearn: 57771.7957388\ttotal: 7.41s\tremaining: 9.78s\n",
      "431:\tlearn: 57767.0981525\ttotal: 7.42s\tremaining: 9.75s\n",
      "432:\tlearn: 57715.1969636\ttotal: 7.43s\tremaining: 9.73s\n",
      "433:\tlearn: 57704.5668201\ttotal: 7.44s\tremaining: 9.71s\n",
      "434:\tlearn: 57690.8025696\ttotal: 7.49s\tremaining: 9.73s\n",
      "435:\tlearn: 57684.9679333\ttotal: 7.5s\tremaining: 9.71s\n",
      "436:\tlearn: 57680.1447888\ttotal: 7.52s\tremaining: 9.69s\n",
      "437:\tlearn: 57620.4141995\ttotal: 7.53s\tremaining: 9.66s\n",
      "438:\tlearn: 57601.7445945\ttotal: 7.55s\tremaining: 9.64s\n",
      "439:\tlearn: 57571.2546773\ttotal: 7.56s\tremaining: 9.63s\n",
      "440:\tlearn: 57553.2669383\ttotal: 7.57s\tremaining: 9.6s\n",
      "441:\tlearn: 57516.1795949\ttotal: 7.59s\tremaining: 9.58s\n",
      "442:\tlearn: 57469.8211155\ttotal: 7.6s\tremaining: 9.56s\n",
      "443:\tlearn: 57463.3944869\ttotal: 7.61s\tremaining: 9.54s\n",
      "444:\tlearn: 57452.2526209\ttotal: 7.63s\tremaining: 9.51s\n",
      "445:\tlearn: 57442.2785752\ttotal: 7.63s\tremaining: 9.48s\n",
      "446:\tlearn: 57426.3523774\ttotal: 7.65s\tremaining: 9.46s\n",
      "447:\tlearn: 57405.2642475\ttotal: 7.67s\tremaining: 9.44s\n",
      "448:\tlearn: 57395.0347621\ttotal: 7.68s\tremaining: 9.43s\n",
      "449:\tlearn: 57344.5719602\ttotal: 7.71s\tremaining: 9.43s\n",
      "450:\tlearn: 57330.3173420\ttotal: 7.73s\tremaining: 9.41s\n",
      "451:\tlearn: 57285.8938133\ttotal: 7.74s\tremaining: 9.39s\n",
      "452:\tlearn: 57275.5468124\ttotal: 7.76s\tremaining: 9.37s\n",
      "453:\tlearn: 57265.9547115\ttotal: 7.78s\tremaining: 9.35s\n",
      "454:\tlearn: 57256.5101346\ttotal: 7.78s\tremaining: 9.32s\n",
      "455:\tlearn: 57211.6485332\ttotal: 7.8s\tremaining: 9.3s\n",
      "456:\tlearn: 57202.4147514\ttotal: 7.81s\tremaining: 9.28s\n",
      "457:\tlearn: 57193.5219154\ttotal: 7.82s\tremaining: 9.26s\n",
      "458:\tlearn: 57150.2563628\ttotal: 7.83s\tremaining: 9.23s\n",
      "459:\tlearn: 57141.6830625\ttotal: 7.84s\tremaining: 9.21s\n",
      "460:\tlearn: 57137.6850308\ttotal: 7.86s\tremaining: 9.19s\n",
      "461:\tlearn: 57121.7663136\ttotal: 7.88s\tremaining: 9.17s\n",
      "462:\tlearn: 57072.9783238\ttotal: 7.99s\tremaining: 9.26s\n",
      "463:\tlearn: 57031.2078316\ttotal: 8s\tremaining: 9.24s\n",
      "464:\tlearn: 57024.8519511\ttotal: 8.02s\tremaining: 9.22s\n",
      "465:\tlearn: 57018.4163606\ttotal: 8.03s\tremaining: 9.2s\n",
      "466:\tlearn: 56992.6215013\ttotal: 8.05s\tremaining: 9.19s\n",
      "467:\tlearn: 56977.9611511\ttotal: 8.06s\tremaining: 9.16s\n",
      "468:\tlearn: 56952.5802336\ttotal: 8.07s\tremaining: 9.14s\n",
      "469:\tlearn: 56944.0259584\ttotal: 8.09s\tremaining: 9.13s\n",
      "470:\tlearn: 56924.1184513\ttotal: 8.13s\tremaining: 9.13s\n",
      "471:\tlearn: 56883.7566518\ttotal: 8.14s\tremaining: 9.11s\n",
      "472:\tlearn: 56867.5095470\ttotal: 8.16s\tremaining: 9.09s\n",
      "473:\tlearn: 56828.8544421\ttotal: 8.17s\tremaining: 9.06s\n",
      "474:\tlearn: 56821.1707801\ttotal: 8.18s\tremaining: 9.04s\n",
      "475:\tlearn: 56748.1249839\ttotal: 8.2s\tremaining: 9.02s\n",
      "476:\tlearn: 56714.9157792\ttotal: 8.22s\tremaining: 9.01s\n",
      "477:\tlearn: 56707.9706684\ttotal: 8.22s\tremaining: 8.98s\n",
      "478:\tlearn: 56694.4308811\ttotal: 8.24s\tremaining: 8.96s\n",
      "479:\tlearn: 56636.5908244\ttotal: 8.25s\tremaining: 8.94s\n",
      "480:\tlearn: 56617.6236758\ttotal: 8.26s\tremaining: 8.91s\n",
      "481:\tlearn: 56575.9177212\ttotal: 8.29s\tremaining: 8.91s\n",
      "482:\tlearn: 56560.3860042\ttotal: 8.32s\tremaining: 8.91s\n",
      "483:\tlearn: 56555.3768785\ttotal: 8.34s\tremaining: 8.89s\n",
      "484:\tlearn: 56547.1249178\ttotal: 8.35s\tremaining: 8.87s\n",
      "485:\tlearn: 56535.1883550\ttotal: 8.36s\tremaining: 8.84s\n",
      "486:\tlearn: 56518.4361599\ttotal: 8.37s\tremaining: 8.82s\n",
      "487:\tlearn: 56480.6689290\ttotal: 8.39s\tremaining: 8.8s\n",
      "488:\tlearn: 56472.7080286\ttotal: 8.4s\tremaining: 8.78s\n",
      "489:\tlearn: 56465.3937085\ttotal: 8.42s\tremaining: 8.76s\n",
      "490:\tlearn: 56409.7272549\ttotal: 8.43s\tremaining: 8.74s\n",
      "491:\tlearn: 56386.3347027\ttotal: 8.44s\tremaining: 8.72s\n",
      "492:\tlearn: 56382.3910030\ttotal: 8.46s\tremaining: 8.7s\n",
      "493:\tlearn: 56368.7942786\ttotal: 8.47s\tremaining: 8.68s\n",
      "494:\tlearn: 56366.0306791\ttotal: 8.48s\tremaining: 8.66s\n",
      "495:\tlearn: 56362.3226421\ttotal: 8.49s\tremaining: 8.63s\n",
      "496:\tlearn: 56354.6339779\ttotal: 8.54s\tremaining: 8.64s\n",
      "497:\tlearn: 56337.6106324\ttotal: 8.55s\tremaining: 8.62s\n",
      "498:\tlearn: 56330.1981389\ttotal: 8.56s\tremaining: 8.6s\n",
      "499:\tlearn: 56322.0768411\ttotal: 8.57s\tremaining: 8.57s\n",
      "500:\tlearn: 56314.9403086\ttotal: 8.59s\tremaining: 8.55s\n",
      "501:\tlearn: 56308.0618476\ttotal: 8.6s\tremaining: 8.53s\n",
      "502:\tlearn: 56301.4316485\ttotal: 8.61s\tremaining: 8.51s\n",
      "503:\tlearn: 56295.0403380\ttotal: 8.62s\tremaining: 8.49s\n",
      "504:\tlearn: 56291.2604639\ttotal: 8.64s\tremaining: 8.47s\n",
      "505:\tlearn: 56260.5998174\ttotal: 8.66s\tremaining: 8.45s\n",
      "506:\tlearn: 56212.8606183\ttotal: 8.67s\tremaining: 8.43s\n",
      "507:\tlearn: 56177.4124059\ttotal: 8.68s\tremaining: 8.41s\n",
      "508:\tlearn: 56174.9668714\ttotal: 8.7s\tremaining: 8.39s\n",
      "509:\tlearn: 56168.6618674\ttotal: 8.71s\tremaining: 8.37s\n",
      "510:\tlearn: 56117.7271548\ttotal: 8.72s\tremaining: 8.35s\n",
      "511:\tlearn: 56111.0100143\ttotal: 8.74s\tremaining: 8.33s\n",
      "512:\tlearn: 56071.4801142\ttotal: 8.75s\tremaining: 8.3s\n",
      "513:\tlearn: 56053.8440569\ttotal: 8.88s\tremaining: 8.4s\n",
      "514:\tlearn: 55981.9428153\ttotal: 8.92s\tremaining: 8.4s\n",
      "515:\tlearn: 55978.1967646\ttotal: 9.24s\tremaining: 8.67s\n",
      "516:\tlearn: 55953.1896394\ttotal: 9.27s\tremaining: 8.66s\n",
      "517:\tlearn: 55947.0115948\ttotal: 9.42s\tremaining: 8.77s\n",
      "518:\tlearn: 55898.2325000\ttotal: 9.62s\tremaining: 8.92s\n",
      "519:\tlearn: 55892.2706404\ttotal: 9.69s\tremaining: 8.94s\n",
      "520:\tlearn: 55888.6188501\ttotal: 9.7s\tremaining: 8.92s\n",
      "521:\tlearn: 55882.8709888\ttotal: 9.72s\tremaining: 8.9s\n",
      "522:\tlearn: 55837.9855459\ttotal: 9.74s\tremaining: 8.88s\n",
      "523:\tlearn: 55830.1955821\ttotal: 9.75s\tremaining: 8.85s\n",
      "524:\tlearn: 55790.8732504\ttotal: 9.76s\tremaining: 8.83s\n",
      "525:\tlearn: 55785.3164806\ttotal: 9.77s\tremaining: 8.81s\n",
      "526:\tlearn: 55783.1069203\ttotal: 9.79s\tremaining: 8.79s\n",
      "527:\tlearn: 55777.6191259\ttotal: 9.8s\tremaining: 8.76s\n",
      "528:\tlearn: 55774.8034038\ttotal: 9.81s\tremaining: 8.74s\n",
      "529:\tlearn: 55768.8315715\ttotal: 9.84s\tremaining: 8.72s\n",
      "530:\tlearn: 55748.3303582\ttotal: 9.86s\tremaining: 8.71s\n",
      "531:\tlearn: 55721.4507341\ttotal: 9.88s\tremaining: 8.69s\n",
      "532:\tlearn: 55718.7717350\ttotal: 9.89s\tremaining: 8.66s\n",
      "533:\tlearn: 55699.5144782\ttotal: 9.9s\tremaining: 8.64s\n",
      "534:\tlearn: 55664.5792667\ttotal: 9.92s\tremaining: 8.62s\n",
      "535:\tlearn: 55645.2660905\ttotal: 9.94s\tremaining: 8.61s\n",
      "536:\tlearn: 55577.0247936\ttotal: 9.95s\tremaining: 8.58s\n",
      "537:\tlearn: 55556.1862078\ttotal: 9.97s\tremaining: 8.56s\n",
      "538:\tlearn: 55547.1635182\ttotal: 9.98s\tremaining: 8.54s\n",
      "539:\tlearn: 55478.2184211\ttotal: 10s\tremaining: 8.52s\n",
      "540:\tlearn: 55455.5988668\ttotal: 10s\tremaining: 8.49s\n",
      "541:\tlearn: 55449.9591516\ttotal: 10s\tremaining: 8.48s\n",
      "542:\tlearn: 55435.5137282\ttotal: 10.1s\tremaining: 8.46s\n",
      "543:\tlearn: 55421.4871210\ttotal: 10.1s\tremaining: 8.45s\n",
      "544:\tlearn: 55374.8309088\ttotal: 10.1s\tremaining: 8.44s\n",
      "545:\tlearn: 55368.3020320\ttotal: 10.1s\tremaining: 8.41s\n",
      "546:\tlearn: 55355.0840878\ttotal: 10.1s\tremaining: 8.39s\n",
      "547:\tlearn: 55351.1828204\ttotal: 10.1s\tremaining: 8.37s\n",
      "548:\tlearn: 55342.6111315\ttotal: 10.2s\tremaining: 8.35s\n",
      "549:\tlearn: 55297.4731988\ttotal: 10.2s\tremaining: 8.32s\n",
      "550:\tlearn: 55264.2996344\ttotal: 10.2s\tremaining: 8.3s\n",
      "551:\tlearn: 55258.9341455\ttotal: 10.2s\tremaining: 8.28s\n",
      "552:\tlearn: 55246.3314787\ttotal: 10.2s\tremaining: 8.26s\n",
      "553:\tlearn: 55227.6425427\ttotal: 10.2s\tremaining: 8.23s\n",
      "554:\tlearn: 55165.8353098\ttotal: 10.2s\tremaining: 8.22s\n",
      "555:\tlearn: 55160.8816942\ttotal: 10.3s\tremaining: 8.21s\n",
      "556:\tlearn: 55147.5463763\ttotal: 10.3s\tremaining: 8.19s\n",
      "557:\tlearn: 55117.3592795\ttotal: 10.3s\tremaining: 8.17s\n",
      "558:\tlearn: 55094.6977738\ttotal: 10.3s\tremaining: 8.14s\n",
      "559:\tlearn: 55055.3324406\ttotal: 10.3s\tremaining: 8.12s\n",
      "560:\tlearn: 55052.7945477\ttotal: 10.4s\tremaining: 8.1s\n",
      "561:\tlearn: 55049.5018437\ttotal: 10.4s\tremaining: 8.08s\n",
      "562:\tlearn: 55046.6227834\ttotal: 10.4s\tremaining: 8.05s\n",
      "563:\tlearn: 55025.9758698\ttotal: 10.4s\tremaining: 8.03s\n",
      "564:\tlearn: 55009.3172642\ttotal: 10.4s\tremaining: 8.01s\n",
      "565:\tlearn: 54990.8011277\ttotal: 10.4s\tremaining: 7.99s\n",
      "566:\tlearn: 54945.4962182\ttotal: 10.4s\tremaining: 7.96s\n",
      "567:\tlearn: 54942.1914748\ttotal: 10.4s\tremaining: 7.94s\n",
      "568:\tlearn: 54930.3316783\ttotal: 10.5s\tremaining: 7.93s\n",
      "569:\tlearn: 54901.9900515\ttotal: 10.5s\tremaining: 7.92s\n",
      "570:\tlearn: 54875.1232501\ttotal: 10.5s\tremaining: 7.9s\n",
      "571:\tlearn: 54858.3513623\ttotal: 10.5s\tremaining: 7.88s\n",
      "572:\tlearn: 54854.9753039\ttotal: 10.5s\tremaining: 7.86s\n",
      "573:\tlearn: 54847.9259987\ttotal: 10.6s\tremaining: 7.83s\n",
      "574:\tlearn: 54841.0754185\ttotal: 10.6s\tremaining: 7.81s\n",
      "575:\tlearn: 54823.2080631\ttotal: 10.6s\tremaining: 7.79s\n",
      "576:\tlearn: 54806.0215791\ttotal: 10.6s\tremaining: 7.77s\n",
      "577:\tlearn: 54756.5957982\ttotal: 10.6s\tremaining: 7.75s\n",
      "578:\tlearn: 54743.7428176\ttotal: 10.6s\tremaining: 7.73s\n",
      "579:\tlearn: 54726.5205656\ttotal: 10.6s\tremaining: 7.71s\n",
      "580:\tlearn: 54713.5415878\ttotal: 10.7s\tremaining: 7.69s\n",
      "581:\tlearn: 54669.5403689\ttotal: 10.7s\tremaining: 7.67s\n",
      "582:\tlearn: 54657.9503476\ttotal: 10.7s\tremaining: 7.65s\n",
      "583:\tlearn: 54644.3840257\ttotal: 10.7s\tremaining: 7.63s\n",
      "584:\tlearn: 54641.1219889\ttotal: 10.7s\tremaining: 7.62s\n",
      "585:\tlearn: 54605.4107199\ttotal: 10.8s\tremaining: 7.6s\n",
      "586:\tlearn: 54598.4126017\ttotal: 10.8s\tremaining: 7.58s\n",
      "587:\tlearn: 54591.3033952\ttotal: 10.8s\tremaining: 7.55s\n",
      "588:\tlearn: 54575.2100891\ttotal: 10.8s\tremaining: 7.53s\n",
      "589:\tlearn: 54549.1586238\ttotal: 10.8s\tremaining: 7.51s\n",
      "590:\tlearn: 54481.0147857\ttotal: 10.8s\tremaining: 7.49s\n",
      "591:\tlearn: 54445.7894464\ttotal: 10.8s\tremaining: 7.47s\n",
      "592:\tlearn: 54440.8026983\ttotal: 10.9s\tremaining: 7.45s\n",
      "593:\tlearn: 54414.9681174\ttotal: 10.9s\tremaining: 7.43s\n",
      "594:\tlearn: 54372.4281322\ttotal: 10.9s\tremaining: 7.41s\n",
      "595:\tlearn: 54352.3228139\ttotal: 10.9s\tremaining: 7.39s\n",
      "596:\tlearn: 54297.6962053\ttotal: 11s\tremaining: 7.43s\n",
      "597:\tlearn: 54264.3920159\ttotal: 11s\tremaining: 7.41s\n",
      "598:\tlearn: 54258.3224386\ttotal: 11s\tremaining: 7.39s\n",
      "599:\tlearn: 54255.3936470\ttotal: 11.1s\tremaining: 7.37s\n",
      "600:\tlearn: 54249.1611714\ttotal: 11.1s\tremaining: 7.34s\n",
      "601:\tlearn: 54244.5899023\ttotal: 11.1s\tremaining: 7.33s\n",
      "602:\tlearn: 54233.5927575\ttotal: 11.1s\tremaining: 7.31s\n",
      "603:\tlearn: 54201.0232107\ttotal: 11.1s\tremaining: 7.29s\n",
      "604:\tlearn: 54198.3653873\ttotal: 11.2s\tremaining: 7.28s\n",
      "605:\tlearn: 54183.7384375\ttotal: 11.2s\tremaining: 7.27s\n",
      "606:\tlearn: 54177.7979056\ttotal: 11.2s\tremaining: 7.24s\n",
      "607:\tlearn: 54136.5018101\ttotal: 11.2s\tremaining: 7.22s\n",
      "608:\tlearn: 54130.3338581\ttotal: 11.2s\tremaining: 7.2s\n",
      "609:\tlearn: 54126.1878358\ttotal: 11.2s\tremaining: 7.18s\n",
      "610:\tlearn: 54100.7681530\ttotal: 11.2s\tremaining: 7.16s\n",
      "611:\tlearn: 54088.7727475\ttotal: 11.3s\tremaining: 7.13s\n",
      "612:\tlearn: 54013.1093567\ttotal: 11.3s\tremaining: 7.14s\n",
      "613:\tlearn: 53998.0852432\ttotal: 11.3s\tremaining: 7.12s\n",
      "614:\tlearn: 53936.3272246\ttotal: 11.3s\tremaining: 7.09s\n",
      "615:\tlearn: 53931.5157019\ttotal: 11.3s\tremaining: 7.08s\n",
      "616:\tlearn: 53908.6327594\ttotal: 11.4s\tremaining: 7.07s\n",
      "617:\tlearn: 53850.3298449\ttotal: 11.4s\tremaining: 7.05s\n",
      "618:\tlearn: 53846.9833261\ttotal: 11.4s\tremaining: 7.03s\n",
      "619:\tlearn: 53844.5220771\ttotal: 11.4s\tremaining: 7.01s\n",
      "620:\tlearn: 53837.7568835\ttotal: 11.5s\tremaining: 6.99s\n",
      "621:\tlearn: 53826.3041802\ttotal: 11.5s\tremaining: 6.97s\n",
      "622:\tlearn: 53810.5784414\ttotal: 11.5s\tremaining: 6.95s\n",
      "623:\tlearn: 53795.5010035\ttotal: 11.5s\tremaining: 6.93s\n",
      "624:\tlearn: 53788.2353120\ttotal: 11.5s\tremaining: 6.91s\n",
      "625:\tlearn: 53779.3177390\ttotal: 11.5s\tremaining: 6.89s\n",
      "626:\tlearn: 53776.9212364\ttotal: 11.5s\tremaining: 6.87s\n",
      "627:\tlearn: 53725.2415104\ttotal: 11.6s\tremaining: 6.86s\n",
      "628:\tlearn: 53720.9596187\ttotal: 11.6s\tremaining: 6.85s\n",
      "629:\tlearn: 53680.8331422\ttotal: 11.6s\tremaining: 6.83s\n",
      "630:\tlearn: 53658.1537444\ttotal: 11.6s\tremaining: 6.81s\n",
      "631:\tlearn: 53646.1681983\ttotal: 11.7s\tremaining: 6.78s\n",
      "632:\tlearn: 53634.7013225\ttotal: 11.7s\tremaining: 6.76s\n",
      "633:\tlearn: 53595.2301303\ttotal: 11.7s\tremaining: 6.74s\n",
      "634:\tlearn: 53570.0041896\ttotal: 11.7s\tremaining: 6.72s\n",
      "635:\tlearn: 53557.5686456\ttotal: 11.7s\tremaining: 6.7s\n",
      "636:\tlearn: 53535.4185647\ttotal: 11.7s\tremaining: 6.68s\n",
      "637:\tlearn: 53479.8955634\ttotal: 11.7s\tremaining: 6.66s\n",
      "638:\tlearn: 53460.7490679\ttotal: 11.8s\tremaining: 6.64s\n",
      "639:\tlearn: 53439.3285127\ttotal: 11.8s\tremaining: 6.64s\n",
      "640:\tlearn: 53389.2066742\ttotal: 11.8s\tremaining: 6.62s\n",
      "641:\tlearn: 53346.3655052\ttotal: 11.8s\tremaining: 6.59s\n",
      "642:\tlearn: 53325.4567604\ttotal: 11.8s\tremaining: 6.57s\n",
      "643:\tlearn: 53315.1585441\ttotal: 11.9s\tremaining: 6.55s\n",
      "644:\tlearn: 53309.3786807\ttotal: 11.9s\tremaining: 6.53s\n",
      "645:\tlearn: 53307.4892452\ttotal: 11.9s\tremaining: 6.51s\n",
      "646:\tlearn: 53304.5865235\ttotal: 11.9s\tremaining: 6.49s\n",
      "647:\tlearn: 53300.5499736\ttotal: 11.9s\tremaining: 6.47s\n",
      "648:\tlearn: 53280.7958346\ttotal: 11.9s\tremaining: 6.45s\n",
      "649:\tlearn: 53245.0302459\ttotal: 11.9s\tremaining: 6.43s\n",
      "650:\tlearn: 53235.2063691\ttotal: 12s\tremaining: 6.41s\n",
      "651:\tlearn: 53218.1501352\ttotal: 12s\tremaining: 6.39s\n",
      "652:\tlearn: 53209.9284975\ttotal: 12s\tremaining: 6.38s\n",
      "653:\tlearn: 53176.7466980\ttotal: 12s\tremaining: 6.36s\n",
      "654:\tlearn: 53174.3210781\ttotal: 12s\tremaining: 6.33s\n",
      "655:\tlearn: 53160.9019934\ttotal: 12s\tremaining: 6.31s\n",
      "656:\tlearn: 53148.0915302\ttotal: 12.1s\tremaining: 6.29s\n",
      "657:\tlearn: 53146.1018359\ttotal: 12.1s\tremaining: 6.27s\n",
      "658:\tlearn: 53141.6570693\ttotal: 12.1s\tremaining: 6.25s\n",
      "659:\tlearn: 53107.1344396\ttotal: 12.1s\tremaining: 6.23s\n",
      "660:\tlearn: 53096.6510721\ttotal: 12.1s\tremaining: 6.21s\n",
      "661:\tlearn: 53089.8867605\ttotal: 12.1s\tremaining: 6.19s\n",
      "662:\tlearn: 53040.8457206\ttotal: 12.1s\tremaining: 6.17s\n",
      "663:\tlearn: 53021.3830272\ttotal: 12.1s\tremaining: 6.15s\n",
      "664:\tlearn: 53006.0036565\ttotal: 12.2s\tremaining: 6.13s\n",
      "665:\tlearn: 52998.3068850\ttotal: 12.3s\tremaining: 6.16s\n",
      "666:\tlearn: 52966.4017802\ttotal: 12.3s\tremaining: 6.15s\n",
      "667:\tlearn: 52955.4150309\ttotal: 12.3s\tremaining: 6.13s\n",
      "668:\tlearn: 52881.2058774\ttotal: 12.3s\tremaining: 6.11s\n",
      "669:\tlearn: 52875.0660219\ttotal: 12.4s\tremaining: 6.08s\n",
      "670:\tlearn: 52873.2380852\ttotal: 12.4s\tremaining: 6.06s\n",
      "671:\tlearn: 52866.1261519\ttotal: 12.4s\tremaining: 6.04s\n",
      "672:\tlearn: 52823.8758544\ttotal: 12.4s\tremaining: 6.02s\n",
      "673:\tlearn: 52804.5353201\ttotal: 12.4s\tremaining: 6s\n",
      "674:\tlearn: 52769.1067195\ttotal: 12.4s\tremaining: 5.98s\n",
      "675:\tlearn: 52753.7392127\ttotal: 12.4s\tremaining: 5.96s\n",
      "676:\tlearn: 52745.9841972\ttotal: 12.5s\tremaining: 5.94s\n",
      "677:\tlearn: 52727.2437684\ttotal: 12.5s\tremaining: 5.92s\n",
      "678:\tlearn: 52685.9858820\ttotal: 12.5s\tremaining: 5.91s\n",
      "679:\tlearn: 52638.5429835\ttotal: 12.5s\tremaining: 5.9s\n",
      "680:\tlearn: 52592.9078411\ttotal: 12.5s\tremaining: 5.88s\n",
      "681:\tlearn: 52578.2277901\ttotal: 12.6s\tremaining: 5.87s\n",
      "682:\tlearn: 52570.5101533\ttotal: 12.6s\tremaining: 5.85s\n",
      "683:\tlearn: 52526.4519443\ttotal: 12.6s\tremaining: 5.83s\n",
      "684:\tlearn: 52486.7517281\ttotal: 12.6s\tremaining: 5.81s\n",
      "685:\tlearn: 52468.7744544\ttotal: 12.6s\tremaining: 5.79s\n",
      "686:\tlearn: 52426.2001150\ttotal: 12.7s\tremaining: 5.77s\n",
      "687:\tlearn: 52415.1495268\ttotal: 12.7s\tremaining: 5.75s\n",
      "688:\tlearn: 52403.0083933\ttotal: 12.7s\tremaining: 5.72s\n",
      "689:\tlearn: 52398.0445343\ttotal: 12.7s\tremaining: 5.7s\n",
      "690:\tlearn: 52365.0026160\ttotal: 12.7s\tremaining: 5.69s\n",
      "691:\tlearn: 52323.8782791\ttotal: 12.8s\tremaining: 5.68s\n",
      "692:\tlearn: 52315.8653758\ttotal: 12.8s\tremaining: 5.66s\n",
      "693:\tlearn: 52276.1739800\ttotal: 12.8s\tremaining: 5.63s\n",
      "694:\tlearn: 52243.1734625\ttotal: 12.8s\tremaining: 5.61s\n",
      "695:\tlearn: 52205.1393050\ttotal: 12.8s\tremaining: 5.59s\n",
      "696:\tlearn: 52189.8832079\ttotal: 12.8s\tremaining: 5.58s\n",
      "697:\tlearn: 52151.5119974\ttotal: 12.8s\tremaining: 5.55s\n",
      "698:\tlearn: 52113.1172119\ttotal: 12.8s\tremaining: 5.53s\n",
      "699:\tlearn: 52071.4054231\ttotal: 12.9s\tremaining: 5.51s\n",
      "700:\tlearn: 52034.3195586\ttotal: 12.9s\tremaining: 5.49s\n",
      "701:\tlearn: 52030.6655480\ttotal: 12.9s\tremaining: 5.47s\n",
      "702:\tlearn: 51975.8126197\ttotal: 12.9s\tremaining: 5.45s\n",
      "703:\tlearn: 51966.1896748\ttotal: 12.9s\tremaining: 5.43s\n",
      "704:\tlearn: 51919.1608195\ttotal: 12.9s\tremaining: 5.41s\n",
      "705:\tlearn: 51882.4718357\ttotal: 12.9s\tremaining: 5.39s\n",
      "706:\tlearn: 51842.0207624\ttotal: 13s\tremaining: 5.37s\n",
      "707:\tlearn: 51834.5783078\ttotal: 13s\tremaining: 5.35s\n",
      "708:\tlearn: 51803.9049316\ttotal: 13s\tremaining: 5.34s\n",
      "709:\tlearn: 51769.2259934\ttotal: 13s\tremaining: 5.32s\n",
      "710:\tlearn: 51751.9890461\ttotal: 13s\tremaining: 5.3s\n",
      "711:\tlearn: 51748.1674132\ttotal: 13.1s\tremaining: 5.28s\n",
      "712:\tlearn: 51742.2623670\ttotal: 13.1s\tremaining: 5.26s\n",
      "713:\tlearn: 51738.5764932\ttotal: 13.1s\tremaining: 5.24s\n",
      "714:\tlearn: 51721.0698273\ttotal: 13.1s\tremaining: 5.22s\n",
      "715:\tlearn: 51716.5518916\ttotal: 13.1s\tremaining: 5.2s\n",
      "716:\tlearn: 51703.7658911\ttotal: 13.1s\tremaining: 5.18s\n",
      "717:\tlearn: 51700.5858973\ttotal: 13.1s\tremaining: 5.16s\n",
      "718:\tlearn: 51684.1384263\ttotal: 13.1s\tremaining: 5.14s\n",
      "719:\tlearn: 51679.5116586\ttotal: 13.2s\tremaining: 5.12s\n",
      "720:\tlearn: 51672.9005873\ttotal: 13.2s\tremaining: 5.1s\n",
      "721:\tlearn: 51668.4436707\ttotal: 13.2s\tremaining: 5.08s\n",
      "722:\tlearn: 51651.5654245\ttotal: 13.2s\tremaining: 5.07s\n",
      "723:\tlearn: 51594.4846661\ttotal: 13.3s\tremaining: 5.05s\n",
      "724:\tlearn: 51520.3105110\ttotal: 13.3s\tremaining: 5.03s\n",
      "725:\tlearn: 51518.6769225\ttotal: 13.3s\tremaining: 5.01s\n",
      "726:\tlearn: 51484.7947462\ttotal: 13.3s\tremaining: 4.99s\n",
      "727:\tlearn: 51480.5535772\ttotal: 13.3s\tremaining: 4.97s\n",
      "728:\tlearn: 51470.2772956\ttotal: 13.3s\tremaining: 4.95s\n",
      "729:\tlearn: 51461.4926746\ttotal: 13.3s\tremaining: 4.93s\n",
      "730:\tlearn: 51459.8877140\ttotal: 13.3s\tremaining: 4.91s\n",
      "731:\tlearn: 51455.9913260\ttotal: 13.4s\tremaining: 4.89s\n",
      "732:\tlearn: 51423.5023283\ttotal: 13.4s\tremaining: 4.87s\n",
      "733:\tlearn: 51419.2523337\ttotal: 13.4s\tremaining: 4.85s\n",
      "734:\tlearn: 51381.7218681\ttotal: 13.4s\tremaining: 4.83s\n",
      "735:\tlearn: 51377.9747302\ttotal: 13.4s\tremaining: 4.82s\n",
      "736:\tlearn: 51369.7393683\ttotal: 13.5s\tremaining: 4.8s\n",
      "737:\tlearn: 51338.3600273\ttotal: 13.5s\tremaining: 4.78s\n",
      "738:\tlearn: 51331.8093497\ttotal: 13.5s\tremaining: 4.76s\n",
      "739:\tlearn: 51310.8551004\ttotal: 13.5s\tremaining: 4.74s\n",
      "740:\tlearn: 51278.9701796\ttotal: 13.5s\tremaining: 4.72s\n",
      "741:\tlearn: 51242.6988507\ttotal: 13.5s\tremaining: 4.7s\n",
      "742:\tlearn: 51211.3824039\ttotal: 13.5s\tremaining: 4.68s\n",
      "743:\tlearn: 51195.0334387\ttotal: 13.6s\tremaining: 4.66s\n",
      "744:\tlearn: 51178.2477826\ttotal: 13.6s\tremaining: 4.64s\n",
      "745:\tlearn: 51162.3553594\ttotal: 13.6s\tremaining: 4.62s\n",
      "746:\tlearn: 51158.5968645\ttotal: 13.6s\tremaining: 4.6s\n",
      "747:\tlearn: 51120.5907969\ttotal: 13.6s\tremaining: 4.59s\n",
      "748:\tlearn: 51105.7952362\ttotal: 13.6s\tremaining: 4.57s\n",
      "749:\tlearn: 51100.3969988\ttotal: 13.7s\tremaining: 4.55s\n",
      "750:\tlearn: 51075.9645850\ttotal: 13.8s\tremaining: 4.56s\n",
      "751:\tlearn: 51061.9534472\ttotal: 13.8s\tremaining: 4.54s\n",
      "752:\tlearn: 51010.8928536\ttotal: 13.8s\tremaining: 4.52s\n",
      "753:\tlearn: 50974.5201861\ttotal: 13.8s\tremaining: 4.51s\n",
      "754:\tlearn: 50957.9090762\ttotal: 13.8s\tremaining: 4.49s\n",
      "755:\tlearn: 50952.8440490\ttotal: 13.9s\tremaining: 4.48s\n",
      "756:\tlearn: 50933.8621640\ttotal: 13.9s\tremaining: 4.46s\n",
      "757:\tlearn: 50930.3938327\ttotal: 13.9s\tremaining: 4.44s\n",
      "758:\tlearn: 50926.8148405\ttotal: 13.9s\tremaining: 4.42s\n",
      "759:\tlearn: 50894.6283261\ttotal: 13.9s\tremaining: 4.4s\n",
      "760:\tlearn: 50883.1371762\ttotal: 14s\tremaining: 4.38s\n",
      "761:\tlearn: 50879.0980264\ttotal: 14s\tremaining: 4.37s\n",
      "762:\tlearn: 50873.0270947\ttotal: 14.1s\tremaining: 4.38s\n",
      "763:\tlearn: 50856.7652104\ttotal: 14.1s\tremaining: 4.37s\n",
      "764:\tlearn: 50853.6445561\ttotal: 14.2s\tremaining: 4.35s\n",
      "765:\tlearn: 50843.4614201\ttotal: 14.2s\tremaining: 4.33s\n",
      "766:\tlearn: 50837.9127382\ttotal: 14.2s\tremaining: 4.32s\n",
      "767:\tlearn: 50833.5972230\ttotal: 14.2s\tremaining: 4.3s\n",
      "768:\tlearn: 50816.6929172\ttotal: 14.2s\tremaining: 4.28s\n",
      "769:\tlearn: 50780.4684914\ttotal: 14.2s\tremaining: 4.26s\n",
      "770:\tlearn: 50770.0243454\ttotal: 14.3s\tremaining: 4.24s\n",
      "771:\tlearn: 50767.0250741\ttotal: 14.3s\tremaining: 4.22s\n",
      "772:\tlearn: 50719.4090612\ttotal: 14.3s\tremaining: 4.2s\n",
      "773:\tlearn: 50715.3220345\ttotal: 14.3s\tremaining: 4.18s\n",
      "774:\tlearn: 50708.2192453\ttotal: 14.3s\tremaining: 4.17s\n",
      "775:\tlearn: 50702.5529551\ttotal: 14.4s\tremaining: 4.15s\n",
      "776:\tlearn: 50687.2909195\ttotal: 14.4s\tremaining: 4.13s\n",
      "777:\tlearn: 50672.5981497\ttotal: 14.4s\tremaining: 4.11s\n",
      "778:\tlearn: 50630.4361525\ttotal: 14.4s\tremaining: 4.09s\n",
      "779:\tlearn: 50627.4828105\ttotal: 14.4s\tremaining: 4.07s\n",
      "780:\tlearn: 50597.8396506\ttotal: 14.4s\tremaining: 4.05s\n",
      "781:\tlearn: 50587.4101986\ttotal: 14.5s\tremaining: 4.03s\n",
      "782:\tlearn: 50583.8424951\ttotal: 14.5s\tremaining: 4.01s\n",
      "783:\tlearn: 50571.0105327\ttotal: 14.5s\tremaining: 3.99s\n",
      "784:\tlearn: 50500.7879443\ttotal: 14.5s\tremaining: 3.97s\n",
      "785:\tlearn: 50490.3842914\ttotal: 14.5s\tremaining: 3.95s\n",
      "786:\tlearn: 50474.9301803\ttotal: 14.5s\tremaining: 3.93s\n",
      "787:\tlearn: 50461.0209095\ttotal: 14.5s\tremaining: 3.91s\n",
      "788:\tlearn: 50458.2700486\ttotal: 14.5s\tremaining: 3.89s\n",
      "789:\tlearn: 50454.2974645\ttotal: 14.6s\tremaining: 3.87s\n",
      "790:\tlearn: 50440.4528121\ttotal: 14.6s\tremaining: 3.85s\n",
      "791:\tlearn: 50408.7574187\ttotal: 14.6s\tremaining: 3.84s\n",
      "792:\tlearn: 50399.2307703\ttotal: 14.6s\tremaining: 3.82s\n",
      "793:\tlearn: 50395.1664815\ttotal: 14.6s\tremaining: 3.8s\n",
      "794:\tlearn: 50367.2254793\ttotal: 14.6s\tremaining: 3.78s\n",
      "795:\tlearn: 50336.3169648\ttotal: 14.7s\tremaining: 3.76s\n",
      "796:\tlearn: 50332.4970455\ttotal: 14.7s\tremaining: 3.74s\n",
      "797:\tlearn: 50330.0259571\ttotal: 14.7s\tremaining: 3.72s\n",
      "798:\tlearn: 50313.8793397\ttotal: 14.7s\tremaining: 3.7s\n",
      "799:\tlearn: 50284.7290703\ttotal: 14.7s\tremaining: 3.68s\n",
      "800:\tlearn: 50266.4464248\ttotal: 14.7s\tremaining: 3.66s\n",
      "801:\tlearn: 50258.8583965\ttotal: 14.8s\tremaining: 3.64s\n",
      "802:\tlearn: 50229.6941469\ttotal: 14.8s\tremaining: 3.62s\n",
      "803:\tlearn: 50226.9176844\ttotal: 14.8s\tremaining: 3.6s\n",
      "804:\tlearn: 50213.6598712\ttotal: 14.8s\tremaining: 3.59s\n",
      "805:\tlearn: 50198.6307652\ttotal: 14.8s\tremaining: 3.57s\n",
      "806:\tlearn: 50153.9993764\ttotal: 14.8s\tremaining: 3.55s\n",
      "807:\tlearn: 50149.4962451\ttotal: 14.9s\tremaining: 3.53s\n",
      "808:\tlearn: 50136.7369666\ttotal: 14.9s\tremaining: 3.51s\n",
      "809:\tlearn: 50133.0374787\ttotal: 14.9s\tremaining: 3.49s\n",
      "810:\tlearn: 50107.4862461\ttotal: 14.9s\tremaining: 3.48s\n",
      "811:\tlearn: 50099.6205127\ttotal: 14.9s\tremaining: 3.46s\n",
      "812:\tlearn: 50062.4846355\ttotal: 14.9s\tremaining: 3.44s\n",
      "813:\tlearn: 50057.9375230\ttotal: 15s\tremaining: 3.42s\n",
      "814:\tlearn: 50050.2064840\ttotal: 15s\tremaining: 3.4s\n",
      "815:\tlearn: 50046.4143138\ttotal: 15s\tremaining: 3.38s\n",
      "816:\tlearn: 50041.3361278\ttotal: 15s\tremaining: 3.36s\n",
      "817:\tlearn: 50027.3802340\ttotal: 15s\tremaining: 3.34s\n",
      "818:\tlearn: 50014.2001894\ttotal: 15s\tremaining: 3.32s\n",
      "819:\tlearn: 50000.8905403\ttotal: 15.2s\tremaining: 3.33s\n",
      "820:\tlearn: 49998.4847565\ttotal: 15.2s\tremaining: 3.31s\n",
      "821:\tlearn: 49994.4458600\ttotal: 15.3s\tremaining: 3.31s\n",
      "822:\tlearn: 49967.4851035\ttotal: 15.3s\tremaining: 3.29s\n",
      "823:\tlearn: 49963.7577732\ttotal: 15.3s\tremaining: 3.27s\n",
      "824:\tlearn: 49943.2440436\ttotal: 15.3s\tremaining: 3.25s\n",
      "825:\tlearn: 49917.1687445\ttotal: 15.3s\tremaining: 3.23s\n",
      "826:\tlearn: 49908.4189510\ttotal: 15.4s\tremaining: 3.21s\n",
      "827:\tlearn: 49903.4476012\ttotal: 15.4s\tremaining: 3.19s\n",
      "828:\tlearn: 49893.9314495\ttotal: 15.4s\tremaining: 3.17s\n",
      "829:\tlearn: 49864.4437438\ttotal: 15.4s\tremaining: 3.16s\n",
      "830:\tlearn: 49838.7368218\ttotal: 15.4s\tremaining: 3.14s\n",
      "831:\tlearn: 49833.8216340\ttotal: 15.4s\tremaining: 3.12s\n",
      "832:\tlearn: 49827.7866724\ttotal: 15.5s\tremaining: 3.1s\n",
      "833:\tlearn: 49788.8788207\ttotal: 15.5s\tremaining: 3.08s\n",
      "834:\tlearn: 49784.2426831\ttotal: 15.5s\tremaining: 3.06s\n",
      "835:\tlearn: 49748.1377604\ttotal: 15.5s\tremaining: 3.04s\n",
      "836:\tlearn: 49731.3581316\ttotal: 15.5s\tremaining: 3.03s\n",
      "837:\tlearn: 49723.7839491\ttotal: 15.5s\tremaining: 3s\n",
      "838:\tlearn: 49720.3598940\ttotal: 15.6s\tremaining: 2.99s\n",
      "839:\tlearn: 49695.1501584\ttotal: 15.6s\tremaining: 2.97s\n",
      "840:\tlearn: 49669.0651242\ttotal: 15.6s\tremaining: 2.95s\n",
      "841:\tlearn: 49660.0991445\ttotal: 15.6s\tremaining: 2.93s\n",
      "842:\tlearn: 49635.3684616\ttotal: 15.6s\tremaining: 2.91s\n",
      "843:\tlearn: 49616.6966242\ttotal: 15.6s\tremaining: 2.89s\n",
      "844:\tlearn: 49604.4782302\ttotal: 15.6s\tremaining: 2.87s\n",
      "845:\tlearn: 49601.6743408\ttotal: 15.7s\tremaining: 2.85s\n",
      "846:\tlearn: 49577.2310392\ttotal: 15.7s\tremaining: 2.83s\n",
      "847:\tlearn: 49573.6163278\ttotal: 15.7s\tremaining: 2.81s\n",
      "848:\tlearn: 49563.6373761\ttotal: 15.7s\tremaining: 2.8s\n",
      "849:\tlearn: 49558.1972694\ttotal: 15.7s\tremaining: 2.78s\n",
      "850:\tlearn: 49554.6100806\ttotal: 15.8s\tremaining: 2.76s\n",
      "851:\tlearn: 49518.8185472\ttotal: 15.8s\tremaining: 2.74s\n",
      "852:\tlearn: 49512.0914342\ttotal: 15.8s\tremaining: 2.72s\n",
      "853:\tlearn: 49498.9180377\ttotal: 15.8s\tremaining: 2.7s\n",
      "854:\tlearn: 49493.8337638\ttotal: 15.8s\tremaining: 2.68s\n",
      "855:\tlearn: 49490.7126326\ttotal: 15.8s\tremaining: 2.66s\n",
      "856:\tlearn: 49485.8654745\ttotal: 15.8s\tremaining: 2.64s\n",
      "857:\tlearn: 49481.0313660\ttotal: 15.8s\tremaining: 2.62s\n",
      "858:\tlearn: 49478.2595197\ttotal: 15.9s\tremaining: 2.6s\n",
      "859:\tlearn: 49459.0738961\ttotal: 15.9s\tremaining: 2.58s\n",
      "860:\tlearn: 49446.9487439\ttotal: 15.9s\tremaining: 2.56s\n",
      "861:\tlearn: 49435.4758223\ttotal: 15.9s\tremaining: 2.54s\n",
      "862:\tlearn: 49425.0641113\ttotal: 15.9s\tremaining: 2.52s\n",
      "863:\tlearn: 49420.1319956\ttotal: 15.9s\tremaining: 2.51s\n",
      "864:\tlearn: 49402.6931016\ttotal: 16s\tremaining: 2.49s\n",
      "865:\tlearn: 49386.7360323\ttotal: 16s\tremaining: 2.47s\n",
      "866:\tlearn: 49380.6634343\ttotal: 16s\tremaining: 2.45s\n",
      "867:\tlearn: 49378.8890230\ttotal: 16s\tremaining: 2.43s\n",
      "868:\tlearn: 49372.9627188\ttotal: 16s\tremaining: 2.41s\n",
      "869:\tlearn: 49362.2850620\ttotal: 16s\tremaining: 2.39s\n",
      "870:\tlearn: 49346.7886504\ttotal: 16s\tremaining: 2.38s\n",
      "871:\tlearn: 49340.0023585\ttotal: 16.1s\tremaining: 2.36s\n",
      "872:\tlearn: 49329.9064702\ttotal: 16.1s\tremaining: 2.34s\n",
      "873:\tlearn: 49318.8939544\ttotal: 16.1s\tremaining: 2.32s\n",
      "874:\tlearn: 49315.5730262\ttotal: 16.1s\tremaining: 2.3s\n",
      "875:\tlearn: 49299.0050827\ttotal: 16.1s\tremaining: 2.28s\n",
      "876:\tlearn: 49296.0228396\ttotal: 16.1s\tremaining: 2.26s\n",
      "877:\tlearn: 49291.9790272\ttotal: 16.2s\tremaining: 2.25s\n",
      "878:\tlearn: 49286.7923806\ttotal: 16.2s\tremaining: 2.23s\n",
      "879:\tlearn: 49283.2499789\ttotal: 16.2s\tremaining: 2.21s\n",
      "880:\tlearn: 49279.1529222\ttotal: 16.2s\tremaining: 2.19s\n",
      "881:\tlearn: 49248.3047179\ttotal: 16.2s\tremaining: 2.17s\n",
      "882:\tlearn: 49238.9124167\ttotal: 16.2s\tremaining: 2.15s\n",
      "883:\tlearn: 49236.2360656\ttotal: 16.2s\tremaining: 2.13s\n",
      "884:\tlearn: 49229.7835404\ttotal: 16.3s\tremaining: 2.11s\n",
      "885:\tlearn: 49226.2574574\ttotal: 16.3s\tremaining: 2.09s\n",
      "886:\tlearn: 49216.9991399\ttotal: 16.3s\tremaining: 2.08s\n",
      "887:\tlearn: 49214.8119234\ttotal: 16.3s\tremaining: 2.06s\n",
      "888:\tlearn: 49202.7413978\ttotal: 16.3s\tremaining: 2.04s\n",
      "889:\tlearn: 49191.6445794\ttotal: 16.3s\tremaining: 2.02s\n",
      "890:\tlearn: 49167.7667649\ttotal: 16.3s\tremaining: 2s\n",
      "891:\tlearn: 49098.2893202\ttotal: 16.5s\tremaining: 1.99s\n",
      "892:\tlearn: 49097.1637164\ttotal: 16.5s\tremaining: 1.97s\n",
      "893:\tlearn: 49090.5628285\ttotal: 16.5s\tremaining: 1.95s\n",
      "894:\tlearn: 49068.4121020\ttotal: 16.5s\tremaining: 1.94s\n",
      "895:\tlearn: 49061.0161144\ttotal: 16.5s\tremaining: 1.92s\n",
      "896:\tlearn: 49059.9756241\ttotal: 16.5s\tremaining: 1.9s\n",
      "897:\tlearn: 49056.2147966\ttotal: 16.5s\tremaining: 1.88s\n",
      "898:\tlearn: 49052.5781699\ttotal: 16.6s\tremaining: 1.86s\n",
      "899:\tlearn: 49050.4146886\ttotal: 16.6s\tremaining: 1.84s\n",
      "900:\tlearn: 49041.0329862\ttotal: 16.6s\tremaining: 1.82s\n",
      "901:\tlearn: 49035.2628361\ttotal: 16.6s\tremaining: 1.81s\n",
      "902:\tlearn: 49028.4193772\ttotal: 16.6s\tremaining: 1.79s\n",
      "903:\tlearn: 49018.0484368\ttotal: 16.6s\tremaining: 1.77s\n",
      "904:\tlearn: 48977.5501016\ttotal: 16.7s\tremaining: 1.75s\n",
      "905:\tlearn: 48948.3018902\ttotal: 16.7s\tremaining: 1.73s\n",
      "906:\tlearn: 48933.1960874\ttotal: 16.7s\tremaining: 1.71s\n",
      "907:\tlearn: 48928.3621506\ttotal: 16.7s\tremaining: 1.69s\n",
      "908:\tlearn: 48919.4237805\ttotal: 16.7s\tremaining: 1.68s\n",
      "909:\tlearn: 48910.8363439\ttotal: 16.7s\tremaining: 1.66s\n",
      "910:\tlearn: 48907.6712616\ttotal: 16.8s\tremaining: 1.64s\n",
      "911:\tlearn: 48902.3712104\ttotal: 16.8s\tremaining: 1.62s\n",
      "912:\tlearn: 48833.6267809\ttotal: 16.8s\tremaining: 1.6s\n",
      "913:\tlearn: 48831.0861842\ttotal: 16.8s\tremaining: 1.58s\n",
      "914:\tlearn: 48823.2184105\ttotal: 16.8s\tremaining: 1.56s\n",
      "915:\tlearn: 48819.3918960\ttotal: 16.9s\tremaining: 1.55s\n",
      "916:\tlearn: 48812.0452511\ttotal: 16.9s\tremaining: 1.53s\n",
      "917:\tlearn: 48807.7106316\ttotal: 16.9s\tremaining: 1.51s\n",
      "918:\tlearn: 48795.4470580\ttotal: 16.9s\tremaining: 1.49s\n",
      "919:\tlearn: 48788.3083015\ttotal: 16.9s\tremaining: 1.47s\n",
      "920:\tlearn: 48721.9569384\ttotal: 16.9s\tremaining: 1.45s\n",
      "921:\tlearn: 48717.2088254\ttotal: 16.9s\tremaining: 1.43s\n",
      "922:\tlearn: 48695.7398065\ttotal: 17s\tremaining: 1.42s\n",
      "923:\tlearn: 48689.5917294\ttotal: 17s\tremaining: 1.4s\n",
      "924:\tlearn: 48675.0372321\ttotal: 17s\tremaining: 1.38s\n",
      "925:\tlearn: 48612.0500810\ttotal: 17s\tremaining: 1.36s\n",
      "926:\tlearn: 48550.1677674\ttotal: 17s\tremaining: 1.34s\n",
      "927:\tlearn: 48544.2337281\ttotal: 17.1s\tremaining: 1.32s\n",
      "928:\tlearn: 48540.4415427\ttotal: 17.1s\tremaining: 1.3s\n",
      "929:\tlearn: 48481.9720458\ttotal: 17.1s\tremaining: 1.29s\n",
      "930:\tlearn: 48474.7325059\ttotal: 17.1s\tremaining: 1.27s\n",
      "931:\tlearn: 48460.4039281\ttotal: 17.1s\tremaining: 1.25s\n",
      "932:\tlearn: 48403.7932858\ttotal: 17.1s\tremaining: 1.23s\n",
      "933:\tlearn: 48347.9994491\ttotal: 17.1s\tremaining: 1.21s\n",
      "934:\tlearn: 48295.2648673\ttotal: 17.2s\tremaining: 1.19s\n",
      "935:\tlearn: 48294.2771552\ttotal: 17.2s\tremaining: 1.17s\n",
      "936:\tlearn: 48282.0371508\ttotal: 17.2s\tremaining: 1.16s\n",
      "937:\tlearn: 48231.3273891\ttotal: 17.2s\tremaining: 1.14s\n",
      "938:\tlearn: 48182.2605841\ttotal: 17.2s\tremaining: 1.12s\n",
      "939:\tlearn: 48134.9415317\ttotal: 17.2s\tremaining: 1.1s\n",
      "940:\tlearn: 48123.1136652\ttotal: 17.2s\tremaining: 1.08s\n",
      "941:\tlearn: 48111.7222866\ttotal: 17.3s\tremaining: 1.06s\n",
      "942:\tlearn: 48066.0610185\ttotal: 17.3s\tremaining: 1.04s\n",
      "943:\tlearn: 48047.7881275\ttotal: 17.3s\tremaining: 1.03s\n",
      "944:\tlearn: 48046.5380885\ttotal: 17.3s\tremaining: 1.01s\n",
      "945:\tlearn: 48038.6158179\ttotal: 17.3s\tremaining: 989ms\n",
      "946:\tlearn: 48027.7606736\ttotal: 17.3s\tremaining: 970ms\n",
      "947:\tlearn: 48013.3054304\ttotal: 17.3s\tremaining: 952ms\n",
      "948:\tlearn: 47969.2114011\ttotal: 17.4s\tremaining: 933ms\n",
      "949:\tlearn: 47962.5130996\ttotal: 17.4s\tremaining: 915ms\n",
      "950:\tlearn: 47941.4730293\ttotal: 17.4s\tremaining: 897ms\n",
      "951:\tlearn: 47938.4148204\ttotal: 17.4s\tremaining: 878ms\n",
      "952:\tlearn: 47934.7408011\ttotal: 17.4s\tremaining: 859ms\n",
      "953:\tlearn: 47931.1970934\ttotal: 17.4s\tremaining: 841ms\n",
      "954:\tlearn: 47888.6260013\ttotal: 17.5s\tremaining: 824ms\n",
      "955:\tlearn: 47882.2011794\ttotal: 17.5s\tremaining: 805ms\n",
      "956:\tlearn: 47879.5386347\ttotal: 17.5s\tremaining: 787ms\n",
      "957:\tlearn: 47836.9717519\ttotal: 17.5s\tremaining: 768ms\n",
      "958:\tlearn: 47826.8985112\ttotal: 17.5s\tremaining: 750ms\n",
      "959:\tlearn: 47787.2267727\ttotal: 17.6s\tremaining: 731ms\n",
      "960:\tlearn: 47776.1834348\ttotal: 17.6s\tremaining: 713ms\n",
      "961:\tlearn: 47768.1195899\ttotal: 17.6s\tremaining: 694ms\n",
      "962:\tlearn: 47767.1141005\ttotal: 17.6s\tremaining: 676ms\n",
      "963:\tlearn: 47763.7791581\ttotal: 17.6s\tremaining: 658ms\n",
      "964:\tlearn: 47739.3953902\ttotal: 17.6s\tremaining: 639ms\n",
      "965:\tlearn: 47734.3635923\ttotal: 17.6s\tremaining: 621ms\n",
      "966:\tlearn: 47696.1041886\ttotal: 17.6s\tremaining: 602ms\n",
      "967:\tlearn: 47690.1371085\ttotal: 17.7s\tremaining: 584ms\n",
      "968:\tlearn: 47657.2342503\ttotal: 17.7s\tremaining: 565ms\n",
      "969:\tlearn: 47647.4657280\ttotal: 17.8s\tremaining: 549ms\n",
      "970:\tlearn: 47610.4584744\ttotal: 17.8s\tremaining: 531ms\n",
      "971:\tlearn: 47592.4760490\ttotal: 17.8s\tremaining: 513ms\n",
      "972:\tlearn: 47591.3320580\ttotal: 17.8s\tremaining: 494ms\n",
      "973:\tlearn: 47555.6735124\ttotal: 17.8s\tremaining: 476ms\n",
      "974:\tlearn: 47521.2186017\ttotal: 17.8s\tremaining: 458ms\n",
      "975:\tlearn: 47488.0277998\ttotal: 17.9s\tremaining: 439ms\n",
      "976:\tlearn: 47486.4042383\ttotal: 17.9s\tremaining: 421ms\n",
      "977:\tlearn: 47477.8134177\ttotal: 17.9s\tremaining: 402ms\n",
      "978:\tlearn: 47453.1192213\ttotal: 17.9s\tremaining: 384ms\n",
      "979:\tlearn: 47440.2811866\ttotal: 17.9s\tremaining: 366ms\n",
      "980:\tlearn: 47434.7479906\ttotal: 18s\tremaining: 348ms\n",
      "981:\tlearn: 47426.6438816\ttotal: 18s\tremaining: 329ms\n",
      "982:\tlearn: 47395.1831231\ttotal: 18s\tremaining: 311ms\n",
      "983:\tlearn: 47379.9276976\ttotal: 18s\tremaining: 293ms\n",
      "984:\tlearn: 47371.5692497\ttotal: 18s\tremaining: 274ms\n",
      "985:\tlearn: 47369.9569241\ttotal: 18s\tremaining: 256ms\n",
      "986:\tlearn: 47364.5915997\ttotal: 18s\tremaining: 238ms\n",
      "987:\tlearn: 47360.8660911\ttotal: 18.1s\tremaining: 219ms\n",
      "988:\tlearn: 47337.0534947\ttotal: 18.1s\tremaining: 201ms\n",
      "989:\tlearn: 47307.2484557\ttotal: 18.1s\tremaining: 183ms\n",
      "990:\tlearn: 47302.0013069\ttotal: 18.1s\tremaining: 164ms\n",
      "991:\tlearn: 47278.3589013\ttotal: 18.1s\tremaining: 146ms\n",
      "992:\tlearn: 47276.8582717\ttotal: 18.1s\tremaining: 128ms\n",
      "993:\tlearn: 47240.1907890\ttotal: 18.2s\tremaining: 110ms\n",
      "994:\tlearn: 47231.6802157\ttotal: 18.2s\tremaining: 91.3ms\n",
      "995:\tlearn: 47195.5047015\ttotal: 18.2s\tremaining: 73ms\n",
      "996:\tlearn: 47161.3626086\ttotal: 18.2s\tremaining: 54.7ms\n",
      "997:\tlearn: 47160.3190764\ttotal: 18.2s\tremaining: 36.5ms\n",
      "998:\tlearn: 47128.0671970\ttotal: 18.2s\tremaining: 18.3ms\n",
      "999:\tlearn: 47123.5523681\ttotal: 18.3s\tremaining: 0us\n",
      "Learning rate set to 0.071716\n",
      "0:\tlearn: 72684.9974535\ttotal: 19.6ms\tremaining: 19.5s\n",
      "1:\tlearn: 72240.6215101\ttotal: 50.8ms\tremaining: 25.3s\n",
      "2:\tlearn: 71852.8442612\ttotal: 67.9ms\tremaining: 22.6s\n",
      "3:\tlearn: 71481.3734187\ttotal: 81.7ms\tremaining: 20.3s\n",
      "4:\tlearn: 71154.0343161\ttotal: 98.3ms\tremaining: 19.6s\n",
      "5:\tlearn: 70796.3380153\ttotal: 115ms\tremaining: 19.1s\n",
      "6:\tlearn: 70511.8357371\ttotal: 130ms\tremaining: 18.4s\n",
      "7:\tlearn: 70298.6125396\ttotal: 143ms\tremaining: 17.8s\n",
      "8:\tlearn: 70079.8647658\ttotal: 156ms\tremaining: 17.2s\n",
      "9:\tlearn: 69850.2415197\ttotal: 173ms\tremaining: 17.1s\n",
      "10:\tlearn: 69693.8722178\ttotal: 183ms\tremaining: 16.5s\n",
      "11:\tlearn: 69497.0093173\ttotal: 205ms\tremaining: 16.9s\n",
      "12:\tlearn: 69366.8596044\ttotal: 239ms\tremaining: 18.1s\n",
      "13:\tlearn: 69203.4454898\ttotal: 249ms\tremaining: 17.5s\n",
      "14:\tlearn: 69084.7849569\ttotal: 267ms\tremaining: 17.5s\n",
      "15:\tlearn: 68969.2470278\ttotal: 282ms\tremaining: 17.4s\n",
      "16:\tlearn: 68883.7111105\ttotal: 298ms\tremaining: 17.3s\n",
      "17:\tlearn: 68800.4082710\ttotal: 313ms\tremaining: 17.1s\n",
      "18:\tlearn: 68712.5203676\ttotal: 328ms\tremaining: 16.9s\n",
      "19:\tlearn: 68633.2979765\ttotal: 344ms\tremaining: 16.8s\n",
      "20:\tlearn: 68568.5917638\ttotal: 358ms\tremaining: 16.7s\n",
      "21:\tlearn: 68472.8602992\ttotal: 374ms\tremaining: 16.6s\n",
      "22:\tlearn: 68403.4789848\ttotal: 385ms\tremaining: 16.4s\n",
      "23:\tlearn: 68334.5325746\ttotal: 396ms\tremaining: 16.1s\n",
      "24:\tlearn: 68269.2477650\ttotal: 411ms\tremaining: 16s\n",
      "25:\tlearn: 68179.5019632\ttotal: 428ms\tremaining: 16s\n",
      "26:\tlearn: 68136.7644393\ttotal: 448ms\tremaining: 16.1s\n",
      "27:\tlearn: 68085.4957680\ttotal: 471ms\tremaining: 16.4s\n",
      "28:\tlearn: 68046.1255315\ttotal: 489ms\tremaining: 16.4s\n",
      "29:\tlearn: 68004.9082604\ttotal: 508ms\tremaining: 16.4s\n",
      "30:\tlearn: 67957.7940082\ttotal: 519ms\tremaining: 16.2s\n",
      "31:\tlearn: 67929.3533207\ttotal: 534ms\tremaining: 16.2s\n",
      "32:\tlearn: 67887.9442609\ttotal: 545ms\tremaining: 16s\n",
      "33:\tlearn: 67855.3286280\ttotal: 559ms\tremaining: 15.9s\n",
      "34:\tlearn: 67809.5032679\ttotal: 574ms\tremaining: 15.8s\n",
      "35:\tlearn: 67783.3474149\ttotal: 592ms\tremaining: 15.8s\n",
      "36:\tlearn: 67771.5136156\ttotal: 600ms\tremaining: 15.6s\n",
      "37:\tlearn: 67738.0386862\ttotal: 611ms\tremaining: 15.5s\n",
      "38:\tlearn: 67670.5902136\ttotal: 625ms\tremaining: 15.4s\n",
      "39:\tlearn: 67643.7951680\ttotal: 637ms\tremaining: 15.3s\n",
      "40:\tlearn: 67633.2682199\ttotal: 660ms\tremaining: 15.4s\n",
      "41:\tlearn: 67555.0533373\ttotal: 756ms\tremaining: 17.3s\n",
      "42:\tlearn: 67536.7492418\ttotal: 776ms\tremaining: 17.3s\n",
      "43:\tlearn: 67461.8347619\ttotal: 823ms\tremaining: 17.9s\n",
      "44:\tlearn: 67438.7713870\ttotal: 909ms\tremaining: 19.3s\n",
      "45:\tlearn: 67412.1676907\ttotal: 924ms\tremaining: 19.2s\n",
      "46:\tlearn: 67384.0778434\ttotal: 938ms\tremaining: 19s\n",
      "47:\tlearn: 67359.9237222\ttotal: 948ms\tremaining: 18.8s\n",
      "48:\tlearn: 67352.4908072\ttotal: 956ms\tremaining: 18.6s\n",
      "49:\tlearn: 67329.0126292\ttotal: 968ms\tremaining: 18.4s\n",
      "50:\tlearn: 67298.5874290\ttotal: 987ms\tremaining: 18.4s\n",
      "51:\tlearn: 67284.4636947\ttotal: 1s\tremaining: 18.2s\n",
      "52:\tlearn: 67269.8249134\ttotal: 1.01s\tremaining: 18s\n",
      "53:\tlearn: 67227.8563090\ttotal: 1.02s\tremaining: 17.9s\n",
      "54:\tlearn: 67209.8244492\ttotal: 1.03s\tremaining: 17.8s\n",
      "55:\tlearn: 67197.0149048\ttotal: 1.05s\tremaining: 17.7s\n",
      "56:\tlearn: 67179.6284491\ttotal: 1.06s\tremaining: 17.6s\n",
      "57:\tlearn: 67164.9609062\ttotal: 1.07s\tremaining: 17.4s\n",
      "58:\tlearn: 67098.6108931\ttotal: 1.09s\tremaining: 17.3s\n",
      "59:\tlearn: 67036.1682129\ttotal: 1.1s\tremaining: 17.3s\n",
      "60:\tlearn: 67016.8515024\ttotal: 1.12s\tremaining: 17.2s\n",
      "61:\tlearn: 66957.7727249\ttotal: 1.14s\tremaining: 17.2s\n",
      "62:\tlearn: 66929.9003083\ttotal: 1.15s\tremaining: 17.1s\n",
      "63:\tlearn: 66906.2444611\ttotal: 1.18s\tremaining: 17.2s\n",
      "64:\tlearn: 66790.8738409\ttotal: 1.2s\tremaining: 17.3s\n",
      "65:\tlearn: 66769.2781113\ttotal: 1.21s\tremaining: 17.2s\n",
      "66:\tlearn: 66762.2441450\ttotal: 1.22s\tremaining: 17s\n",
      "67:\tlearn: 66635.9147245\ttotal: 1.24s\tremaining: 17s\n",
      "68:\tlearn: 66629.3449860\ttotal: 1.25s\tremaining: 16.9s\n",
      "69:\tlearn: 66566.7457465\ttotal: 1.26s\tremaining: 16.8s\n",
      "70:\tlearn: 66485.9542990\ttotal: 1.28s\tremaining: 16.7s\n",
      "71:\tlearn: 66474.8191086\ttotal: 1.29s\tremaining: 16.6s\n",
      "72:\tlearn: 66402.5804125\ttotal: 1.3s\tremaining: 16.5s\n",
      "73:\tlearn: 66342.2879162\ttotal: 1.32s\tremaining: 16.5s\n",
      "74:\tlearn: 66263.9522926\ttotal: 1.33s\tremaining: 16.4s\n",
      "75:\tlearn: 66250.7971562\ttotal: 1.35s\tremaining: 16.4s\n",
      "76:\tlearn: 66126.0956212\ttotal: 1.37s\tremaining: 16.5s\n",
      "77:\tlearn: 65931.5392392\ttotal: 1.39s\tremaining: 16.5s\n",
      "78:\tlearn: 65854.8183110\ttotal: 1.46s\tremaining: 17s\n",
      "79:\tlearn: 65843.4154703\ttotal: 1.47s\tremaining: 16.9s\n",
      "80:\tlearn: 65803.8895131\ttotal: 1.48s\tremaining: 16.8s\n",
      "81:\tlearn: 65714.3954459\ttotal: 1.5s\tremaining: 16.8s\n",
      "82:\tlearn: 65709.8996900\ttotal: 1.51s\tremaining: 16.7s\n",
      "83:\tlearn: 65684.7940574\ttotal: 1.52s\tremaining: 16.6s\n",
      "84:\tlearn: 65673.6372734\ttotal: 1.54s\tremaining: 16.6s\n",
      "85:\tlearn: 65618.9579945\ttotal: 1.55s\tremaining: 16.5s\n",
      "86:\tlearn: 65602.4478388\ttotal: 1.57s\tremaining: 16.5s\n",
      "87:\tlearn: 65584.9012231\ttotal: 1.59s\tremaining: 16.5s\n",
      "88:\tlearn: 65578.9084723\ttotal: 1.62s\tremaining: 16.6s\n",
      "89:\tlearn: 65533.1528812\ttotal: 1.63s\tremaining: 16.5s\n",
      "90:\tlearn: 65511.3927203\ttotal: 1.65s\tremaining: 16.4s\n",
      "91:\tlearn: 65497.8021013\ttotal: 1.66s\tremaining: 16.4s\n",
      "92:\tlearn: 65387.3894196\ttotal: 1.68s\tremaining: 16.3s\n",
      "93:\tlearn: 65313.8246368\ttotal: 1.69s\tremaining: 16.3s\n",
      "94:\tlearn: 65282.3531742\ttotal: 1.7s\tremaining: 16.2s\n",
      "95:\tlearn: 65236.5597723\ttotal: 1.71s\tremaining: 16.1s\n",
      "96:\tlearn: 65209.7064000\ttotal: 1.73s\tremaining: 16.1s\n",
      "97:\tlearn: 65209.2971734\ttotal: 1.74s\tremaining: 16s\n",
      "98:\tlearn: 65156.7828603\ttotal: 1.74s\tremaining: 15.9s\n",
      "99:\tlearn: 65101.6133398\ttotal: 1.76s\tremaining: 15.8s\n",
      "100:\tlearn: 65089.6504301\ttotal: 1.78s\tremaining: 15.8s\n",
      "101:\tlearn: 65084.3370988\ttotal: 1.81s\tremaining: 15.9s\n",
      "102:\tlearn: 65034.6767618\ttotal: 1.82s\tremaining: 15.9s\n",
      "103:\tlearn: 64975.5883559\ttotal: 1.84s\tremaining: 15.9s\n",
      "104:\tlearn: 64920.9780094\ttotal: 1.85s\tremaining: 15.8s\n",
      "105:\tlearn: 64919.5851299\ttotal: 1.86s\tremaining: 15.7s\n",
      "106:\tlearn: 64916.4116731\ttotal: 1.88s\tremaining: 15.7s\n",
      "107:\tlearn: 64862.6490115\ttotal: 1.89s\tremaining: 15.6s\n",
      "108:\tlearn: 64787.2981848\ttotal: 1.91s\tremaining: 15.6s\n",
      "109:\tlearn: 64777.0464578\ttotal: 1.92s\tremaining: 15.5s\n",
      "110:\tlearn: 64651.0527331\ttotal: 1.94s\tremaining: 15.5s\n",
      "111:\tlearn: 64632.7351320\ttotal: 1.95s\tremaining: 15.5s\n",
      "112:\tlearn: 64474.5179089\ttotal: 1.96s\tremaining: 15.4s\n",
      "113:\tlearn: 64425.0289872\ttotal: 1.98s\tremaining: 15.4s\n",
      "114:\tlearn: 64397.9916359\ttotal: 1.99s\tremaining: 15.3s\n",
      "115:\tlearn: 64371.9341281\ttotal: 2.01s\tremaining: 15.3s\n",
      "116:\tlearn: 64341.5042498\ttotal: 2.02s\tremaining: 15.3s\n",
      "117:\tlearn: 64335.7347628\ttotal: 2.05s\tremaining: 15.3s\n",
      "118:\tlearn: 64318.6023978\ttotal: 2.15s\tremaining: 15.9s\n",
      "119:\tlearn: 64290.5080233\ttotal: 2.16s\tremaining: 15.9s\n",
      "120:\tlearn: 64181.3073281\ttotal: 2.17s\tremaining: 15.8s\n",
      "121:\tlearn: 64131.9108013\ttotal: 2.19s\tremaining: 15.8s\n",
      "122:\tlearn: 64122.8296741\ttotal: 2.21s\tremaining: 15.7s\n",
      "123:\tlearn: 63992.8202389\ttotal: 2.22s\tremaining: 15.7s\n",
      "124:\tlearn: 63870.4183608\ttotal: 2.25s\tremaining: 15.8s\n",
      "125:\tlearn: 63828.6969176\ttotal: 2.27s\tremaining: 15.7s\n",
      "126:\tlearn: 63680.0279237\ttotal: 2.27s\tremaining: 15.6s\n",
      "127:\tlearn: 63629.0040752\ttotal: 2.28s\tremaining: 15.6s\n",
      "128:\tlearn: 63554.4982843\ttotal: 2.31s\tremaining: 15.6s\n",
      "129:\tlearn: 63536.5885782\ttotal: 2.32s\tremaining: 15.5s\n",
      "130:\tlearn: 63495.5464321\ttotal: 2.33s\tremaining: 15.5s\n",
      "131:\tlearn: 63451.9580446\ttotal: 2.35s\tremaining: 15.4s\n",
      "132:\tlearn: 63399.4984482\ttotal: 2.36s\tremaining: 15.4s\n",
      "133:\tlearn: 63391.0337812\ttotal: 2.37s\tremaining: 15.3s\n",
      "134:\tlearn: 63326.9164157\ttotal: 2.38s\tremaining: 15.3s\n",
      "135:\tlearn: 63283.1874132\ttotal: 2.4s\tremaining: 15.2s\n",
      "136:\tlearn: 63271.9567266\ttotal: 2.41s\tremaining: 15.2s\n",
      "137:\tlearn: 63228.4023554\ttotal: 2.43s\tremaining: 15.2s\n",
      "138:\tlearn: 63160.3644736\ttotal: 2.47s\tremaining: 15.3s\n",
      "139:\tlearn: 63137.0361390\ttotal: 2.48s\tremaining: 15.3s\n",
      "140:\tlearn: 63134.6248262\ttotal: 2.5s\tremaining: 15.2s\n",
      "141:\tlearn: 63118.6759945\ttotal: 2.51s\tremaining: 15.2s\n",
      "142:\tlearn: 63116.3334752\ttotal: 2.52s\tremaining: 15.1s\n",
      "143:\tlearn: 63111.7403570\ttotal: 2.53s\tremaining: 15s\n",
      "144:\tlearn: 63068.2869933\ttotal: 2.55s\tremaining: 15s\n",
      "145:\tlearn: 63026.8561428\ttotal: 2.56s\tremaining: 15s\n",
      "146:\tlearn: 62986.5257019\ttotal: 2.58s\tremaining: 15s\n",
      "147:\tlearn: 62928.6599527\ttotal: 2.59s\tremaining: 14.9s\n",
      "148:\tlearn: 62818.5818664\ttotal: 2.6s\tremaining: 14.8s\n",
      "149:\tlearn: 62765.2754235\ttotal: 2.61s\tremaining: 14.8s\n",
      "150:\tlearn: 62714.6641667\ttotal: 2.62s\tremaining: 14.8s\n",
      "151:\tlearn: 62686.2743137\ttotal: 2.64s\tremaining: 14.7s\n",
      "152:\tlearn: 62648.9273309\ttotal: 2.68s\tremaining: 14.9s\n",
      "153:\tlearn: 62636.7471113\ttotal: 2.7s\tremaining: 14.8s\n",
      "154:\tlearn: 62596.2051008\ttotal: 2.71s\tremaining: 14.8s\n",
      "155:\tlearn: 62563.5262310\ttotal: 2.72s\tremaining: 14.7s\n",
      "156:\tlearn: 62542.4966292\ttotal: 2.74s\tremaining: 14.7s\n",
      "157:\tlearn: 62538.4420080\ttotal: 2.76s\tremaining: 14.7s\n",
      "158:\tlearn: 62408.1468174\ttotal: 2.77s\tremaining: 14.7s\n",
      "159:\tlearn: 62402.0540003\ttotal: 2.78s\tremaining: 14.6s\n",
      "160:\tlearn: 62370.3515081\ttotal: 2.79s\tremaining: 14.6s\n",
      "161:\tlearn: 62366.3930461\ttotal: 2.8s\tremaining: 14.5s\n",
      "162:\tlearn: 62314.0240818\ttotal: 2.82s\tremaining: 14.5s\n",
      "163:\tlearn: 62308.1247324\ttotal: 2.83s\tremaining: 14.4s\n",
      "164:\tlearn: 62306.9367058\ttotal: 2.84s\tremaining: 14.4s\n",
      "165:\tlearn: 62275.6513278\ttotal: 2.87s\tremaining: 14.4s\n",
      "166:\tlearn: 62269.9765328\ttotal: 2.89s\tremaining: 14.4s\n",
      "167:\tlearn: 62252.6505880\ttotal: 2.9s\tremaining: 14.4s\n",
      "168:\tlearn: 62243.6128067\ttotal: 2.92s\tremaining: 14.3s\n",
      "169:\tlearn: 62169.5402592\ttotal: 2.93s\tremaining: 14.3s\n",
      "170:\tlearn: 62139.3797642\ttotal: 2.94s\tremaining: 14.3s\n",
      "171:\tlearn: 62110.4721307\ttotal: 2.95s\tremaining: 14.2s\n",
      "172:\tlearn: 62082.9005191\ttotal: 2.97s\tremaining: 14.2s\n",
      "173:\tlearn: 62055.2525849\ttotal: 2.99s\tremaining: 14.2s\n",
      "174:\tlearn: 62020.8638404\ttotal: 3s\tremaining: 14.1s\n",
      "175:\tlearn: 62001.0836824\ttotal: 3.01s\tremaining: 14.1s\n",
      "176:\tlearn: 61968.0672344\ttotal: 3.02s\tremaining: 14.1s\n",
      "177:\tlearn: 61942.3697862\ttotal: 3.04s\tremaining: 14s\n",
      "178:\tlearn: 61924.8905034\ttotal: 3.05s\tremaining: 14s\n",
      "179:\tlearn: 61881.8348345\ttotal: 3.07s\tremaining: 14s\n",
      "180:\tlearn: 61760.3875396\ttotal: 3.09s\tremaining: 14s\n",
      "181:\tlearn: 61735.6432857\ttotal: 3.1s\tremaining: 13.9s\n",
      "182:\tlearn: 61696.6582716\ttotal: 3.14s\tremaining: 14s\n",
      "183:\tlearn: 61591.9940089\ttotal: 3.15s\tremaining: 14s\n",
      "184:\tlearn: 61493.2759620\ttotal: 3.17s\tremaining: 14s\n",
      "185:\tlearn: 61480.7580704\ttotal: 3.18s\tremaining: 13.9s\n",
      "186:\tlearn: 61458.8184680\ttotal: 3.2s\tremaining: 13.9s\n",
      "187:\tlearn: 61450.8923588\ttotal: 3.21s\tremaining: 13.9s\n",
      "188:\tlearn: 61394.9272062\ttotal: 3.22s\tremaining: 13.8s\n",
      "189:\tlearn: 61374.9037043\ttotal: 3.23s\tremaining: 13.8s\n",
      "190:\tlearn: 61359.2907879\ttotal: 3.25s\tremaining: 13.7s\n",
      "191:\tlearn: 61328.0358078\ttotal: 3.26s\tremaining: 13.7s\n",
      "192:\tlearn: 61315.0455399\ttotal: 3.28s\tremaining: 13.7s\n",
      "193:\tlearn: 61304.4440668\ttotal: 3.29s\tremaining: 13.7s\n",
      "194:\tlearn: 61189.8013111\ttotal: 3.3s\tremaining: 13.6s\n",
      "195:\tlearn: 61149.2735775\ttotal: 3.31s\tremaining: 13.6s\n",
      "196:\tlearn: 61079.1311773\ttotal: 3.41s\tremaining: 13.9s\n",
      "197:\tlearn: 61065.4401826\ttotal: 3.43s\tremaining: 13.9s\n",
      "198:\tlearn: 61062.6947881\ttotal: 3.44s\tremaining: 13.8s\n",
      "199:\tlearn: 61053.4021655\ttotal: 3.45s\tremaining: 13.8s\n",
      "200:\tlearn: 61035.9218016\ttotal: 3.46s\tremaining: 13.8s\n",
      "201:\tlearn: 60948.2887891\ttotal: 3.48s\tremaining: 13.7s\n",
      "202:\tlearn: 60931.0432314\ttotal: 3.49s\tremaining: 13.7s\n",
      "203:\tlearn: 60864.2336968\ttotal: 3.51s\tremaining: 13.7s\n",
      "204:\tlearn: 60846.8082482\ttotal: 3.55s\tremaining: 13.8s\n",
      "205:\tlearn: 60815.6570595\ttotal: 3.56s\tremaining: 13.7s\n",
      "206:\tlearn: 60802.2946695\ttotal: 3.58s\tremaining: 13.7s\n",
      "207:\tlearn: 60773.1038202\ttotal: 3.6s\tremaining: 13.7s\n",
      "208:\tlearn: 60757.3941831\ttotal: 3.61s\tremaining: 13.7s\n",
      "209:\tlearn: 60736.5621864\ttotal: 3.62s\tremaining: 13.6s\n",
      "210:\tlearn: 60714.2951083\ttotal: 3.64s\tremaining: 13.6s\n",
      "211:\tlearn: 60637.5781827\ttotal: 3.64s\tremaining: 13.5s\n",
      "212:\tlearn: 60575.3418180\ttotal: 3.66s\tremaining: 13.5s\n",
      "213:\tlearn: 60559.8296663\ttotal: 3.67s\tremaining: 13.5s\n",
      "214:\tlearn: 60489.9989310\ttotal: 3.69s\tremaining: 13.5s\n",
      "215:\tlearn: 60427.1366132\ttotal: 3.7s\tremaining: 13.4s\n",
      "216:\tlearn: 60399.4225952\ttotal: 3.71s\tremaining: 13.4s\n",
      "217:\tlearn: 60383.7161931\ttotal: 3.72s\tremaining: 13.4s\n",
      "218:\tlearn: 60377.9849485\ttotal: 3.74s\tremaining: 13.3s\n",
      "219:\tlearn: 60366.3895488\ttotal: 3.76s\tremaining: 13.3s\n",
      "220:\tlearn: 60308.2002477\ttotal: 3.77s\tremaining: 13.3s\n",
      "221:\tlearn: 60296.0282267\ttotal: 3.79s\tremaining: 13.3s\n",
      "222:\tlearn: 60231.5084275\ttotal: 3.81s\tremaining: 13.3s\n",
      "223:\tlearn: 60218.2829857\ttotal: 3.81s\tremaining: 13.2s\n",
      "224:\tlearn: 60158.3215285\ttotal: 3.83s\tremaining: 13.2s\n",
      "225:\tlearn: 60104.1269751\ttotal: 3.84s\tremaining: 13.2s\n",
      "226:\tlearn: 60051.9992456\ttotal: 3.86s\tremaining: 13.1s\n",
      "227:\tlearn: 60012.8585393\ttotal: 3.88s\tremaining: 13.1s\n",
      "228:\tlearn: 59980.0627545\ttotal: 3.89s\tremaining: 13.1s\n",
      "229:\tlearn: 59968.1881591\ttotal: 3.9s\tremaining: 13.1s\n",
      "230:\tlearn: 59966.6473818\ttotal: 3.91s\tremaining: 13s\n",
      "231:\tlearn: 59916.9979069\ttotal: 3.93s\tremaining: 13s\n",
      "232:\tlearn: 59888.2235007\ttotal: 3.94s\tremaining: 13s\n",
      "233:\tlearn: 59872.7148293\ttotal: 4.09s\tremaining: 13.4s\n",
      "234:\tlearn: 59861.3750992\ttotal: 4.17s\tremaining: 13.6s\n",
      "235:\tlearn: 59859.9420701\ttotal: 4.51s\tremaining: 14.6s\n",
      "236:\tlearn: 59845.0695992\ttotal: 4.64s\tremaining: 15s\n",
      "237:\tlearn: 59824.1868428\ttotal: 4.68s\tremaining: 15s\n",
      "238:\tlearn: 59809.9627992\ttotal: 4.91s\tremaining: 15.6s\n",
      "239:\tlearn: 59799.0401436\ttotal: 4.93s\tremaining: 15.6s\n",
      "240:\tlearn: 59773.1523311\ttotal: 4.94s\tremaining: 15.6s\n",
      "241:\tlearn: 59730.9485843\ttotal: 4.96s\tremaining: 15.5s\n",
      "242:\tlearn: 59716.6098415\ttotal: 4.97s\tremaining: 15.5s\n",
      "243:\tlearn: 59700.1950422\ttotal: 4.98s\tremaining: 15.4s\n",
      "244:\tlearn: 59650.0728681\ttotal: 4.99s\tremaining: 15.4s\n",
      "245:\tlearn: 59633.7720558\ttotal: 5.01s\tremaining: 15.4s\n",
      "246:\tlearn: 59624.4317253\ttotal: 5.02s\tremaining: 15.3s\n",
      "247:\tlearn: 59605.8394913\ttotal: 5.04s\tremaining: 15.3s\n",
      "248:\tlearn: 59588.9287776\ttotal: 5.05s\tremaining: 15.2s\n",
      "249:\tlearn: 59548.0900769\ttotal: 5.06s\tremaining: 15.2s\n",
      "250:\tlearn: 59527.0923318\ttotal: 5.07s\tremaining: 15.1s\n",
      "251:\tlearn: 59517.4908550\ttotal: 5.09s\tremaining: 15.1s\n",
      "252:\tlearn: 59507.1483441\ttotal: 5.1s\tremaining: 15.1s\n",
      "253:\tlearn: 59481.4076147\ttotal: 5.12s\tremaining: 15s\n",
      "254:\tlearn: 59471.4271112\ttotal: 5.14s\tremaining: 15s\n",
      "255:\tlearn: 59416.6854847\ttotal: 5.15s\tremaining: 15s\n",
      "256:\tlearn: 59390.3973811\ttotal: 5.19s\tremaining: 15s\n",
      "257:\tlearn: 59378.6496494\ttotal: 5.21s\tremaining: 15s\n",
      "258:\tlearn: 59356.9638990\ttotal: 5.22s\tremaining: 14.9s\n",
      "259:\tlearn: 59298.2629704\ttotal: 5.24s\tremaining: 14.9s\n",
      "260:\tlearn: 59288.5542975\ttotal: 5.25s\tremaining: 14.9s\n",
      "261:\tlearn: 59278.7359894\ttotal: 5.26s\tremaining: 14.8s\n",
      "262:\tlearn: 59174.3858328\ttotal: 5.27s\tremaining: 14.8s\n",
      "263:\tlearn: 59163.2001020\ttotal: 5.29s\tremaining: 14.7s\n",
      "264:\tlearn: 59158.7324806\ttotal: 5.3s\tremaining: 14.7s\n",
      "265:\tlearn: 59140.5180199\ttotal: 5.32s\tremaining: 14.7s\n",
      "266:\tlearn: 59066.0188755\ttotal: 5.33s\tremaining: 14.6s\n",
      "267:\tlearn: 59057.0937083\ttotal: 5.35s\tremaining: 14.6s\n",
      "268:\tlearn: 59030.5382548\ttotal: 5.36s\tremaining: 14.6s\n",
      "269:\tlearn: 59025.1067718\ttotal: 5.39s\tremaining: 14.6s\n",
      "270:\tlearn: 58997.8421612\ttotal: 5.42s\tremaining: 14.6s\n",
      "271:\tlearn: 58994.5554521\ttotal: 5.43s\tremaining: 14.5s\n",
      "272:\tlearn: 58896.7185852\ttotal: 5.45s\tremaining: 14.5s\n",
      "273:\tlearn: 58878.0704508\ttotal: 5.46s\tremaining: 14.5s\n",
      "274:\tlearn: 58840.1986358\ttotal: 5.47s\tremaining: 14.4s\n",
      "275:\tlearn: 58815.6932513\ttotal: 5.48s\tremaining: 14.4s\n",
      "276:\tlearn: 58812.5257364\ttotal: 5.5s\tremaining: 14.3s\n",
      "277:\tlearn: 58803.2912659\ttotal: 5.51s\tremaining: 14.3s\n",
      "278:\tlearn: 58760.2663369\ttotal: 5.52s\tremaining: 14.3s\n",
      "279:\tlearn: 58718.8090107\ttotal: 5.54s\tremaining: 14.2s\n",
      "280:\tlearn: 58716.8240986\ttotal: 5.56s\tremaining: 14.2s\n",
      "281:\tlearn: 58673.6643841\ttotal: 5.57s\tremaining: 14.2s\n",
      "282:\tlearn: 58634.6234260\ttotal: 5.59s\tremaining: 14.2s\n",
      "283:\tlearn: 58608.0951001\ttotal: 5.63s\tremaining: 14.2s\n",
      "284:\tlearn: 58582.6783638\ttotal: 5.64s\tremaining: 14.2s\n",
      "285:\tlearn: 58569.0370480\ttotal: 5.66s\tremaining: 14.1s\n",
      "286:\tlearn: 58527.1029298\ttotal: 5.69s\tremaining: 14.1s\n",
      "287:\tlearn: 58520.5697406\ttotal: 5.71s\tremaining: 14.1s\n",
      "288:\tlearn: 58491.9879370\ttotal: 5.72s\tremaining: 14.1s\n",
      "289:\tlearn: 58485.4377972\ttotal: 5.74s\tremaining: 14s\n",
      "290:\tlearn: 58412.9081587\ttotal: 5.75s\tremaining: 14s\n",
      "291:\tlearn: 58404.6069427\ttotal: 5.76s\tremaining: 14s\n",
      "292:\tlearn: 58347.6904587\ttotal: 5.78s\tremaining: 13.9s\n",
      "293:\tlearn: 58307.2377220\ttotal: 5.8s\tremaining: 13.9s\n",
      "294:\tlearn: 58293.9418786\ttotal: 5.83s\tremaining: 13.9s\n",
      "295:\tlearn: 58260.7050494\ttotal: 5.84s\tremaining: 13.9s\n",
      "296:\tlearn: 58244.3637950\ttotal: 5.86s\tremaining: 13.9s\n",
      "297:\tlearn: 58223.5377962\ttotal: 5.87s\tremaining: 13.8s\n",
      "298:\tlearn: 58186.9508777\ttotal: 5.89s\tremaining: 13.8s\n",
      "299:\tlearn: 58169.6835545\ttotal: 5.91s\tremaining: 13.8s\n",
      "300:\tlearn: 58134.4132113\ttotal: 5.92s\tremaining: 13.8s\n",
      "301:\tlearn: 58088.3516640\ttotal: 5.93s\tremaining: 13.7s\n",
      "302:\tlearn: 58013.1790350\ttotal: 5.96s\tremaining: 13.7s\n",
      "303:\tlearn: 57968.8913891\ttotal: 5.97s\tremaining: 13.7s\n",
      "304:\tlearn: 57964.6780317\ttotal: 6s\tremaining: 13.7s\n",
      "305:\tlearn: 57930.5974693\ttotal: 6.11s\tremaining: 13.8s\n",
      "306:\tlearn: 57929.5343206\ttotal: 6.14s\tremaining: 13.9s\n",
      "307:\tlearn: 57928.5110051\ttotal: 6.17s\tremaining: 13.9s\n",
      "308:\tlearn: 57927.7299958\ttotal: 6.19s\tremaining: 13.8s\n",
      "309:\tlearn: 57894.8725931\ttotal: 6.22s\tremaining: 13.8s\n",
      "310:\tlearn: 57872.3042813\ttotal: 6.27s\tremaining: 13.9s\n",
      "311:\tlearn: 57865.3036291\ttotal: 6.29s\tremaining: 13.9s\n",
      "312:\tlearn: 57840.7479636\ttotal: 6.3s\tremaining: 13.8s\n",
      "313:\tlearn: 57832.2930962\ttotal: 6.32s\tremaining: 13.8s\n",
      "314:\tlearn: 57790.2165036\ttotal: 6.33s\tremaining: 13.8s\n",
      "315:\tlearn: 57776.8334093\ttotal: 6.34s\tremaining: 13.7s\n",
      "316:\tlearn: 57764.5642523\ttotal: 6.35s\tremaining: 13.7s\n",
      "317:\tlearn: 57720.6171174\ttotal: 6.38s\tremaining: 13.7s\n",
      "318:\tlearn: 57720.0125595\ttotal: 6.39s\tremaining: 13.6s\n",
      "319:\tlearn: 57708.9644186\ttotal: 6.4s\tremaining: 13.6s\n",
      "320:\tlearn: 57697.2927353\ttotal: 6.41s\tremaining: 13.6s\n",
      "321:\tlearn: 57684.4396213\ttotal: 6.42s\tremaining: 13.5s\n",
      "322:\tlearn: 57683.5547169\ttotal: 6.44s\tremaining: 13.5s\n",
      "323:\tlearn: 57682.7026864\ttotal: 6.45s\tremaining: 13.5s\n",
      "324:\tlearn: 57662.5799449\ttotal: 6.49s\tremaining: 13.5s\n",
      "325:\tlearn: 57655.1170872\ttotal: 6.5s\tremaining: 13.4s\n",
      "326:\tlearn: 57654.2964791\ttotal: 6.51s\tremaining: 13.4s\n",
      "327:\tlearn: 57645.3457109\ttotal: 6.53s\tremaining: 13.4s\n",
      "328:\tlearn: 57615.0327178\ttotal: 6.54s\tremaining: 13.3s\n",
      "329:\tlearn: 57575.1132786\ttotal: 6.55s\tremaining: 13.3s\n",
      "330:\tlearn: 57567.0722226\ttotal: 6.57s\tremaining: 13.3s\n",
      "331:\tlearn: 57529.6525149\ttotal: 6.58s\tremaining: 13.2s\n",
      "332:\tlearn: 57517.4004621\ttotal: 6.59s\tremaining: 13.2s\n",
      "333:\tlearn: 57505.6063563\ttotal: 6.6s\tremaining: 13.2s\n",
      "334:\tlearn: 57491.0037678\ttotal: 6.62s\tremaining: 13.1s\n",
      "335:\tlearn: 57473.3809156\ttotal: 6.63s\tremaining: 13.1s\n",
      "336:\tlearn: 57466.7944293\ttotal: 6.64s\tremaining: 13.1s\n",
      "337:\tlearn: 57411.9301583\ttotal: 6.69s\tremaining: 13.1s\n",
      "338:\tlearn: 57393.2474136\ttotal: 6.7s\tremaining: 13.1s\n",
      "339:\tlearn: 57356.5341660\ttotal: 6.71s\tremaining: 13s\n",
      "340:\tlearn: 57350.7635262\ttotal: 6.72s\tremaining: 13s\n",
      "341:\tlearn: 57318.8395762\ttotal: 6.74s\tremaining: 13s\n",
      "342:\tlearn: 57310.6966408\ttotal: 6.75s\tremaining: 12.9s\n",
      "343:\tlearn: 57301.6908987\ttotal: 6.76s\tremaining: 12.9s\n",
      "344:\tlearn: 57270.7133409\ttotal: 6.78s\tremaining: 12.9s\n",
      "345:\tlearn: 57235.8707741\ttotal: 6.79s\tremaining: 12.8s\n",
      "346:\tlearn: 57227.4427416\ttotal: 6.8s\tremaining: 12.8s\n",
      "347:\tlearn: 57215.2239488\ttotal: 6.81s\tremaining: 12.8s\n",
      "348:\tlearn: 57181.7336838\ttotal: 6.83s\tremaining: 12.7s\n",
      "349:\tlearn: 57140.7256582\ttotal: 6.84s\tremaining: 12.7s\n",
      "350:\tlearn: 57083.1045395\ttotal: 6.86s\tremaining: 12.7s\n",
      "351:\tlearn: 57075.5066646\ttotal: 6.89s\tremaining: 12.7s\n",
      "352:\tlearn: 57021.4485219\ttotal: 6.91s\tremaining: 12.7s\n",
      "353:\tlearn: 57016.1585395\ttotal: 6.92s\tremaining: 12.6s\n",
      "354:\tlearn: 56996.8667995\ttotal: 6.94s\tremaining: 12.6s\n",
      "355:\tlearn: 56967.4288944\ttotal: 6.95s\tremaining: 12.6s\n",
      "356:\tlearn: 56961.1883461\ttotal: 6.97s\tremaining: 12.5s\n",
      "357:\tlearn: 56930.7738371\ttotal: 6.98s\tremaining: 12.5s\n",
      "358:\tlearn: 56907.5592326\ttotal: 6.99s\tremaining: 12.5s\n",
      "359:\tlearn: 56893.4473082\ttotal: 7.01s\tremaining: 12.5s\n",
      "360:\tlearn: 56865.5896441\ttotal: 7.02s\tremaining: 12.4s\n",
      "361:\tlearn: 56841.2958754\ttotal: 7.03s\tremaining: 12.4s\n",
      "362:\tlearn: 56791.7490772\ttotal: 7.04s\tremaining: 12.4s\n",
      "363:\tlearn: 56770.3219263\ttotal: 7.06s\tremaining: 12.3s\n",
      "364:\tlearn: 56746.6259051\ttotal: 7.07s\tremaining: 12.3s\n",
      "365:\tlearn: 56741.1833283\ttotal: 7.09s\tremaining: 12.3s\n",
      "366:\tlearn: 56722.3697343\ttotal: 7.11s\tremaining: 12.3s\n",
      "367:\tlearn: 56713.8285184\ttotal: 7.23s\tremaining: 12.4s\n",
      "368:\tlearn: 56640.5644753\ttotal: 7.24s\tremaining: 12.4s\n",
      "369:\tlearn: 56611.0950605\ttotal: 7.26s\tremaining: 12.4s\n",
      "370:\tlearn: 56559.0985725\ttotal: 7.27s\tremaining: 12.3s\n",
      "371:\tlearn: 56538.9590222\ttotal: 7.29s\tremaining: 12.3s\n",
      "372:\tlearn: 56526.8747175\ttotal: 7.33s\tremaining: 12.3s\n",
      "373:\tlearn: 56453.4887562\ttotal: 7.35s\tremaining: 12.3s\n",
      "374:\tlearn: 56424.9998286\ttotal: 7.36s\tremaining: 12.3s\n",
      "375:\tlearn: 56415.4384448\ttotal: 7.38s\tremaining: 12.2s\n",
      "376:\tlearn: 56408.4012246\ttotal: 7.39s\tremaining: 12.2s\n",
      "377:\tlearn: 56377.1001484\ttotal: 7.41s\tremaining: 12.2s\n",
      "378:\tlearn: 56371.4078807\ttotal: 7.42s\tremaining: 12.2s\n",
      "379:\tlearn: 56356.1379289\ttotal: 7.43s\tremaining: 12.1s\n",
      "380:\tlearn: 56351.5094726\ttotal: 7.44s\tremaining: 12.1s\n",
      "381:\tlearn: 56347.2307122\ttotal: 7.45s\tremaining: 12.1s\n",
      "382:\tlearn: 56321.7566748\ttotal: 7.47s\tremaining: 12s\n",
      "383:\tlearn: 56307.0528223\ttotal: 7.48s\tremaining: 12s\n",
      "384:\tlearn: 56301.0483703\ttotal: 7.5s\tremaining: 12s\n",
      "385:\tlearn: 56271.0866019\ttotal: 7.51s\tremaining: 12s\n",
      "386:\tlearn: 56170.6298259\ttotal: 7.55s\tremaining: 12s\n",
      "387:\tlearn: 56166.5397644\ttotal: 7.56s\tremaining: 11.9s\n",
      "388:\tlearn: 56151.7344896\ttotal: 7.57s\tremaining: 11.9s\n",
      "389:\tlearn: 56138.4569001\ttotal: 7.58s\tremaining: 11.9s\n",
      "390:\tlearn: 56043.8513351\ttotal: 7.6s\tremaining: 11.8s\n",
      "391:\tlearn: 56040.2226899\ttotal: 7.61s\tremaining: 11.8s\n",
      "392:\tlearn: 55990.0941709\ttotal: 7.62s\tremaining: 11.8s\n",
      "393:\tlearn: 55966.5807533\ttotal: 7.63s\tremaining: 11.7s\n",
      "394:\tlearn: 55956.8630787\ttotal: 7.65s\tremaining: 11.7s\n",
      "395:\tlearn: 55952.0310538\ttotal: 7.66s\tremaining: 11.7s\n",
      "396:\tlearn: 55924.4262619\ttotal: 7.67s\tremaining: 11.6s\n",
      "397:\tlearn: 55921.8925620\ttotal: 7.68s\tremaining: 11.6s\n",
      "398:\tlearn: 55916.4070856\ttotal: 7.7s\tremaining: 11.6s\n",
      "399:\tlearn: 55902.3121226\ttotal: 7.71s\tremaining: 11.6s\n",
      "400:\tlearn: 55885.7184324\ttotal: 7.73s\tremaining: 11.5s\n",
      "401:\tlearn: 55873.3295067\ttotal: 7.76s\tremaining: 11.5s\n",
      "402:\tlearn: 55856.0239349\ttotal: 7.78s\tremaining: 11.5s\n",
      "403:\tlearn: 55767.4205017\ttotal: 7.79s\tremaining: 11.5s\n",
      "404:\tlearn: 55719.4845439\ttotal: 7.81s\tremaining: 11.5s\n",
      "405:\tlearn: 55699.1312565\ttotal: 7.82s\tremaining: 11.4s\n",
      "406:\tlearn: 55683.6455654\ttotal: 7.84s\tremaining: 11.4s\n",
      "407:\tlearn: 55657.3250931\ttotal: 7.85s\tremaining: 11.4s\n",
      "408:\tlearn: 55588.2844427\ttotal: 7.86s\tremaining: 11.4s\n",
      "409:\tlearn: 55542.6839604\ttotal: 7.88s\tremaining: 11.3s\n",
      "410:\tlearn: 55527.8314054\ttotal: 7.88s\tremaining: 11.3s\n",
      "411:\tlearn: 55518.9853606\ttotal: 7.9s\tremaining: 11.3s\n",
      "412:\tlearn: 55495.8796888\ttotal: 7.91s\tremaining: 11.2s\n",
      "413:\tlearn: 55484.9429949\ttotal: 7.93s\tremaining: 11.2s\n",
      "414:\tlearn: 55457.5718083\ttotal: 7.97s\tremaining: 11.2s\n",
      "415:\tlearn: 55390.7696261\ttotal: 7.98s\tremaining: 11.2s\n",
      "416:\tlearn: 55365.7174978\ttotal: 7.99s\tremaining: 11.2s\n",
      "417:\tlearn: 55342.6547459\ttotal: 8.02s\tremaining: 11.2s\n",
      "418:\tlearn: 55337.9062057\ttotal: 8.04s\tremaining: 11.2s\n",
      "419:\tlearn: 55315.5728186\ttotal: 8.06s\tremaining: 11.1s\n",
      "420:\tlearn: 55239.5441907\ttotal: 8.07s\tremaining: 11.1s\n",
      "421:\tlearn: 55215.4482745\ttotal: 8.09s\tremaining: 11.1s\n",
      "422:\tlearn: 55189.3745243\ttotal: 8.1s\tremaining: 11.1s\n",
      "423:\tlearn: 55132.4909300\ttotal: 8.12s\tremaining: 11s\n",
      "424:\tlearn: 55107.6389417\ttotal: 8.14s\tremaining: 11s\n",
      "425:\tlearn: 55101.5264954\ttotal: 8.16s\tremaining: 11s\n",
      "426:\tlearn: 55079.9236592\ttotal: 8.24s\tremaining: 11.1s\n",
      "427:\tlearn: 55056.4148942\ttotal: 8.26s\tremaining: 11s\n",
      "428:\tlearn: 55043.2166450\ttotal: 8.28s\tremaining: 11s\n",
      "429:\tlearn: 54978.3356862\ttotal: 8.3s\tremaining: 11s\n",
      "430:\tlearn: 54972.9138995\ttotal: 8.31s\tremaining: 11s\n",
      "431:\tlearn: 54969.5538951\ttotal: 8.32s\tremaining: 10.9s\n",
      "432:\tlearn: 54947.2045960\ttotal: 8.34s\tremaining: 10.9s\n",
      "433:\tlearn: 54936.0990421\ttotal: 8.35s\tremaining: 10.9s\n",
      "434:\tlearn: 54914.6333669\ttotal: 8.37s\tremaining: 10.9s\n",
      "435:\tlearn: 54870.0098837\ttotal: 8.38s\tremaining: 10.8s\n",
      "436:\tlearn: 54851.0633458\ttotal: 8.41s\tremaining: 10.8s\n",
      "437:\tlearn: 54826.9885889\ttotal: 8.43s\tremaining: 10.8s\n",
      "438:\tlearn: 54803.4648705\ttotal: 8.44s\tremaining: 10.8s\n",
      "439:\tlearn: 54783.9937567\ttotal: 8.46s\tremaining: 10.8s\n",
      "440:\tlearn: 54768.8984141\ttotal: 8.47s\tremaining: 10.7s\n",
      "441:\tlearn: 54760.5224166\ttotal: 8.48s\tremaining: 10.7s\n",
      "442:\tlearn: 54741.0261184\ttotal: 8.5s\tremaining: 10.7s\n",
      "443:\tlearn: 54727.1482595\ttotal: 8.51s\tremaining: 10.7s\n",
      "444:\tlearn: 54692.7612187\ttotal: 8.52s\tremaining: 10.6s\n",
      "445:\tlearn: 54662.7496187\ttotal: 8.54s\tremaining: 10.6s\n",
      "446:\tlearn: 54607.7237531\ttotal: 8.55s\tremaining: 10.6s\n",
      "447:\tlearn: 54586.7937101\ttotal: 8.57s\tremaining: 10.6s\n",
      "448:\tlearn: 54565.2697116\ttotal: 8.58s\tremaining: 10.5s\n",
      "449:\tlearn: 54484.1875645\ttotal: 8.61s\tremaining: 10.5s\n",
      "450:\tlearn: 54465.9017492\ttotal: 8.63s\tremaining: 10.5s\n",
      "451:\tlearn: 54458.4545626\ttotal: 8.65s\tremaining: 10.5s\n",
      "452:\tlearn: 54448.0945120\ttotal: 8.67s\tremaining: 10.5s\n",
      "453:\tlearn: 54427.9499981\ttotal: 8.68s\tremaining: 10.4s\n",
      "454:\tlearn: 54419.7467571\ttotal: 8.69s\tremaining: 10.4s\n",
      "455:\tlearn: 54405.9640261\ttotal: 8.7s\tremaining: 10.4s\n",
      "456:\tlearn: 54387.1346450\ttotal: 8.72s\tremaining: 10.4s\n",
      "457:\tlearn: 54374.8411190\ttotal: 8.73s\tremaining: 10.3s\n",
      "458:\tlearn: 54357.6132490\ttotal: 8.74s\tremaining: 10.3s\n",
      "459:\tlearn: 54346.7817619\ttotal: 8.75s\tremaining: 10.3s\n",
      "460:\tlearn: 54336.3563344\ttotal: 8.76s\tremaining: 10.2s\n",
      "461:\tlearn: 54323.4839821\ttotal: 8.78s\tremaining: 10.2s\n",
      "462:\tlearn: 54309.6423032\ttotal: 8.82s\tremaining: 10.2s\n",
      "463:\tlearn: 54295.2820332\ttotal: 8.84s\tremaining: 10.2s\n",
      "464:\tlearn: 54271.8427558\ttotal: 8.86s\tremaining: 10.2s\n",
      "465:\tlearn: 54261.7941978\ttotal: 8.86s\tremaining: 10.2s\n",
      "466:\tlearn: 54251.0089433\ttotal: 8.88s\tremaining: 10.1s\n",
      "467:\tlearn: 54228.4667508\ttotal: 8.89s\tremaining: 10.1s\n",
      "468:\tlearn: 54210.4623401\ttotal: 8.9s\tremaining: 10.1s\n",
      "469:\tlearn: 54198.9570058\ttotal: 8.91s\tremaining: 10.1s\n",
      "470:\tlearn: 54134.0645651\ttotal: 8.93s\tremaining: 10s\n",
      "471:\tlearn: 54124.3620367\ttotal: 8.94s\tremaining: 10s\n",
      "472:\tlearn: 54118.0368155\ttotal: 8.96s\tremaining: 9.98s\n",
      "473:\tlearn: 54101.3437360\ttotal: 8.97s\tremaining: 9.96s\n",
      "474:\tlearn: 54082.6843724\ttotal: 8.99s\tremaining: 9.93s\n",
      "475:\tlearn: 54072.4950092\ttotal: 8.99s\tremaining: 9.9s\n",
      "476:\tlearn: 54067.9633923\ttotal: 9.01s\tremaining: 9.88s\n",
      "477:\tlearn: 53994.0161869\ttotal: 9.02s\tremaining: 9.85s\n",
      "478:\tlearn: 53931.3953456\ttotal: 9.04s\tremaining: 9.84s\n",
      "479:\tlearn: 53917.9816991\ttotal: 9.07s\tremaining: 9.82s\n",
      "480:\tlearn: 53842.0607135\ttotal: 9.1s\tremaining: 9.82s\n",
      "481:\tlearn: 53825.1720993\ttotal: 9.12s\tremaining: 9.8s\n",
      "482:\tlearn: 53809.0218084\ttotal: 9.13s\tremaining: 9.77s\n",
      "483:\tlearn: 53799.6503897\ttotal: 9.14s\tremaining: 9.74s\n",
      "484:\tlearn: 53788.6392624\ttotal: 9.16s\tremaining: 9.72s\n",
      "485:\tlearn: 53776.2378283\ttotal: 9.17s\tremaining: 9.7s\n",
      "486:\tlearn: 53767.2265749\ttotal: 9.18s\tremaining: 9.67s\n",
      "487:\tlearn: 53753.7359728\ttotal: 9.19s\tremaining: 9.64s\n",
      "488:\tlearn: 53710.7416494\ttotal: 9.21s\tremaining: 9.62s\n",
      "489:\tlearn: 53702.0527151\ttotal: 9.22s\tremaining: 9.6s\n",
      "490:\tlearn: 53686.6053388\ttotal: 9.23s\tremaining: 9.57s\n",
      "491:\tlearn: 53678.2359971\ttotal: 9.25s\tremaining: 9.55s\n",
      "492:\tlearn: 53617.6846052\ttotal: 9.27s\tremaining: 9.53s\n",
      "493:\tlearn: 53544.1331171\ttotal: 9.38s\tremaining: 9.61s\n",
      "494:\tlearn: 53522.2008808\ttotal: 9.4s\tremaining: 9.59s\n",
      "495:\tlearn: 53507.0660941\ttotal: 9.4s\tremaining: 9.56s\n",
      "496:\tlearn: 53495.6690945\ttotal: 9.42s\tremaining: 9.53s\n",
      "497:\tlearn: 53454.5386230\ttotal: 9.44s\tremaining: 9.51s\n",
      "498:\tlearn: 53445.2497993\ttotal: 9.45s\tremaining: 9.49s\n",
      "499:\tlearn: 53434.0598369\ttotal: 9.47s\tremaining: 9.47s\n",
      "500:\tlearn: 53420.4751378\ttotal: 9.48s\tremaining: 9.45s\n",
      "501:\tlearn: 53412.3950222\ttotal: 9.5s\tremaining: 9.42s\n",
      "502:\tlearn: 53404.8942794\ttotal: 9.52s\tremaining: 9.4s\n",
      "503:\tlearn: 53397.4070092\ttotal: 9.53s\tremaining: 9.38s\n",
      "504:\tlearn: 53382.9051455\ttotal: 9.57s\tremaining: 9.38s\n",
      "505:\tlearn: 53366.7595881\ttotal: 9.58s\tremaining: 9.36s\n",
      "506:\tlearn: 53348.1260652\ttotal: 9.6s\tremaining: 9.33s\n",
      "507:\tlearn: 53340.3298024\ttotal: 9.61s\tremaining: 9.3s\n",
      "508:\tlearn: 53281.7229040\ttotal: 9.62s\tremaining: 9.28s\n",
      "509:\tlearn: 53260.9177725\ttotal: 9.63s\tremaining: 9.25s\n",
      "510:\tlearn: 53247.4250866\ttotal: 9.65s\tremaining: 9.23s\n",
      "511:\tlearn: 53232.6100958\ttotal: 9.68s\tremaining: 9.22s\n",
      "512:\tlearn: 53228.3315882\ttotal: 9.71s\tremaining: 9.21s\n",
      "513:\tlearn: 53217.1778432\ttotal: 9.72s\tremaining: 9.2s\n",
      "514:\tlearn: 53160.6352353\ttotal: 9.74s\tremaining: 9.17s\n",
      "515:\tlearn: 53148.9416066\ttotal: 9.75s\tremaining: 9.14s\n",
      "516:\tlearn: 53136.7992060\ttotal: 9.76s\tremaining: 9.12s\n",
      "517:\tlearn: 53125.5209967\ttotal: 9.78s\tremaining: 9.1s\n",
      "518:\tlearn: 53107.2685334\ttotal: 9.79s\tremaining: 9.08s\n",
      "519:\tlearn: 53089.7362574\ttotal: 9.8s\tremaining: 9.05s\n",
      "520:\tlearn: 53072.8887138\ttotal: 9.81s\tremaining: 9.02s\n",
      "521:\tlearn: 53057.3914666\ttotal: 9.83s\tremaining: 9s\n",
      "522:\tlearn: 53049.1866391\ttotal: 9.84s\tremaining: 8.98s\n",
      "523:\tlearn: 53032.9813290\ttotal: 9.86s\tremaining: 8.96s\n",
      "524:\tlearn: 53017.3985258\ttotal: 9.87s\tremaining: 8.93s\n",
      "525:\tlearn: 53002.4096380\ttotal: 9.88s\tremaining: 8.9s\n",
      "526:\tlearn: 52987.9879713\ttotal: 9.9s\tremaining: 8.89s\n",
      "527:\tlearn: 52949.8468301\ttotal: 9.91s\tremaining: 8.86s\n",
      "528:\tlearn: 52942.2758845\ttotal: 9.95s\tremaining: 8.86s\n",
      "529:\tlearn: 52927.4052931\ttotal: 9.96s\tremaining: 8.84s\n",
      "530:\tlearn: 52920.1090534\ttotal: 9.98s\tremaining: 8.81s\n",
      "531:\tlearn: 52900.7648986\ttotal: 9.99s\tremaining: 8.79s\n",
      "532:\tlearn: 52893.7316556\ttotal: 10s\tremaining: 8.77s\n",
      "533:\tlearn: 52875.9850170\ttotal: 10s\tremaining: 8.75s\n",
      "534:\tlearn: 52867.7666295\ttotal: 10s\tremaining: 8.73s\n",
      "535:\tlearn: 52853.1489991\ttotal: 10.1s\tremaining: 8.7s\n",
      "536:\tlearn: 52845.6208073\ttotal: 10.1s\tremaining: 8.67s\n",
      "537:\tlearn: 52841.0548029\ttotal: 10.1s\tremaining: 8.66s\n",
      "538:\tlearn: 52822.3866778\ttotal: 10.1s\tremaining: 8.63s\n",
      "539:\tlearn: 52810.4830535\ttotal: 10.1s\tremaining: 8.61s\n",
      "540:\tlearn: 52804.8195560\ttotal: 10.1s\tremaining: 8.6s\n",
      "541:\tlearn: 52796.8645105\ttotal: 10.2s\tremaining: 8.58s\n",
      "542:\tlearn: 52779.0470095\ttotal: 10.2s\tremaining: 8.56s\n",
      "543:\tlearn: 52725.0100443\ttotal: 10.2s\tremaining: 8.54s\n",
      "544:\tlearn: 52706.7693702\ttotal: 10.2s\tremaining: 8.52s\n",
      "545:\tlearn: 52667.7604123\ttotal: 10.2s\tremaining: 8.49s\n",
      "546:\tlearn: 52628.3774862\ttotal: 10.2s\tremaining: 8.47s\n",
      "547:\tlearn: 52615.2383407\ttotal: 10.2s\tremaining: 8.44s\n",
      "548:\tlearn: 52601.6016144\ttotal: 10.3s\tremaining: 8.42s\n",
      "549:\tlearn: 52595.3432072\ttotal: 10.3s\tremaining: 8.4s\n",
      "550:\tlearn: 52578.2536225\ttotal: 10.3s\tremaining: 8.38s\n",
      "551:\tlearn: 52571.4585603\ttotal: 10.3s\tremaining: 8.35s\n",
      "552:\tlearn: 52533.5457855\ttotal: 10.3s\tremaining: 8.33s\n",
      "553:\tlearn: 52527.0225997\ttotal: 10.3s\tremaining: 8.31s\n",
      "554:\tlearn: 52446.1427558\ttotal: 10.4s\tremaining: 8.3s\n",
      "555:\tlearn: 52439.6568149\ttotal: 10.4s\tremaining: 8.28s\n",
      "556:\tlearn: 52419.9512080\ttotal: 10.4s\tremaining: 8.31s\n",
      "557:\tlearn: 52403.6602379\ttotal: 10.5s\tremaining: 8.29s\n",
      "558:\tlearn: 52396.7756787\ttotal: 10.5s\tremaining: 8.27s\n",
      "559:\tlearn: 52390.8688144\ttotal: 10.5s\tremaining: 8.25s\n",
      "560:\tlearn: 52375.2576732\ttotal: 10.5s\tremaining: 8.22s\n",
      "561:\tlearn: 52302.7621791\ttotal: 10.5s\tremaining: 8.2s\n",
      "562:\tlearn: 52285.0517802\ttotal: 10.5s\tremaining: 8.18s\n",
      "563:\tlearn: 52227.8884382\ttotal: 10.6s\tremaining: 8.16s\n",
      "564:\tlearn: 52222.6444137\ttotal: 10.6s\tremaining: 8.14s\n",
      "565:\tlearn: 52146.8795079\ttotal: 10.6s\tremaining: 8.13s\n",
      "566:\tlearn: 52129.3325556\ttotal: 10.6s\tremaining: 8.1s\n",
      "567:\tlearn: 52121.3850548\ttotal: 10.6s\tremaining: 8.08s\n",
      "568:\tlearn: 52047.8346702\ttotal: 10.6s\tremaining: 8.06s\n",
      "569:\tlearn: 51998.8521691\ttotal: 10.7s\tremaining: 8.04s\n",
      "570:\tlearn: 51984.1796221\ttotal: 10.7s\tremaining: 8.02s\n",
      "571:\tlearn: 51969.6326163\ttotal: 10.7s\tremaining: 7.99s\n",
      "572:\tlearn: 51955.7896422\ttotal: 10.7s\tremaining: 7.97s\n",
      "573:\tlearn: 51943.0781406\ttotal: 10.7s\tremaining: 7.95s\n",
      "574:\tlearn: 51916.6678936\ttotal: 10.7s\tremaining: 7.93s\n",
      "575:\tlearn: 51905.5572337\ttotal: 10.7s\tremaining: 7.91s\n",
      "576:\tlearn: 51834.4501607\ttotal: 10.8s\tremaining: 7.88s\n",
      "577:\tlearn: 51827.9311658\ttotal: 10.8s\tremaining: 7.88s\n",
      "578:\tlearn: 51805.1235457\ttotal: 10.8s\tremaining: 7.86s\n",
      "579:\tlearn: 51736.5202429\ttotal: 10.8s\tremaining: 7.84s\n",
      "580:\tlearn: 51723.0323084\ttotal: 10.8s\tremaining: 7.82s\n",
      "581:\tlearn: 51710.4810960\ttotal: 10.8s\tremaining: 7.79s\n",
      "582:\tlearn: 51703.6651961\ttotal: 10.9s\tremaining: 7.77s\n",
      "583:\tlearn: 51689.9133903\ttotal: 10.9s\tremaining: 7.75s\n",
      "584:\tlearn: 51681.1882245\ttotal: 10.9s\tremaining: 7.72s\n",
      "585:\tlearn: 51614.9393741\ttotal: 10.9s\tremaining: 7.7s\n",
      "586:\tlearn: 51544.0839668\ttotal: 10.9s\tremaining: 7.68s\n",
      "587:\tlearn: 51489.7536199\ttotal: 10.9s\tremaining: 7.66s\n",
      "588:\tlearn: 51425.7089824\ttotal: 10.9s\tremaining: 7.63s\n",
      "589:\tlearn: 51420.7477194\ttotal: 11s\tremaining: 7.61s\n",
      "590:\tlearn: 51396.0424134\ttotal: 11s\tremaining: 7.59s\n",
      "591:\tlearn: 51389.3348621\ttotal: 11s\tremaining: 7.59s\n",
      "592:\tlearn: 51379.1338144\ttotal: 11s\tremaining: 7.56s\n",
      "593:\tlearn: 51362.3964369\ttotal: 11s\tremaining: 7.54s\n",
      "594:\tlearn: 51349.1318768\ttotal: 11s\tremaining: 7.52s\n",
      "595:\tlearn: 51343.8751698\ttotal: 11.1s\tremaining: 7.49s\n",
      "596:\tlearn: 51323.9948400\ttotal: 11.1s\tremaining: 7.47s\n",
      "597:\tlearn: 51262.0655801\ttotal: 11.1s\tremaining: 7.45s\n",
      "598:\tlearn: 51202.2990534\ttotal: 11.1s\tremaining: 7.43s\n",
      "599:\tlearn: 51156.8668626\ttotal: 11.1s\tremaining: 7.41s\n",
      "600:\tlearn: 51115.8562565\ttotal: 11.1s\tremaining: 7.39s\n",
      "601:\tlearn: 51099.6466685\ttotal: 11.1s\tremaining: 7.37s\n",
      "602:\tlearn: 51041.8260046\ttotal: 11.2s\tremaining: 7.34s\n",
      "603:\tlearn: 50990.5442135\ttotal: 11.2s\tremaining: 7.33s\n",
      "604:\tlearn: 50934.6950991\ttotal: 11.2s\tremaining: 7.31s\n",
      "605:\tlearn: 50885.2068154\ttotal: 11.2s\tremaining: 7.31s\n",
      "606:\tlearn: 50875.2815806\ttotal: 11.3s\tremaining: 7.28s\n",
      "607:\tlearn: 50861.0754935\ttotal: 11.3s\tremaining: 7.26s\n",
      "608:\tlearn: 50807.0926155\ttotal: 11.3s\tremaining: 7.24s\n",
      "609:\tlearn: 50782.7440186\ttotal: 11.3s\tremaining: 7.22s\n",
      "610:\tlearn: 50713.2818379\ttotal: 11.3s\tremaining: 7.21s\n",
      "611:\tlearn: 50675.6253557\ttotal: 11.3s\tremaining: 7.19s\n",
      "612:\tlearn: 50659.8669575\ttotal: 11.4s\tremaining: 7.17s\n",
      "613:\tlearn: 50647.0313930\ttotal: 11.4s\tremaining: 7.15s\n",
      "614:\tlearn: 50594.7964163\ttotal: 11.4s\tremaining: 7.13s\n",
      "615:\tlearn: 50589.8251550\ttotal: 11.4s\tremaining: 7.11s\n",
      "616:\tlearn: 50578.1036272\ttotal: 11.5s\tremaining: 7.15s\n",
      "617:\tlearn: 50565.4879886\ttotal: 11.5s\tremaining: 7.13s\n",
      "618:\tlearn: 50514.9664074\ttotal: 11.5s\tremaining: 7.11s\n",
      "619:\tlearn: 50467.9501911\ttotal: 11.6s\tremaining: 7.08s\n",
      "620:\tlearn: 50455.7721573\ttotal: 11.6s\tremaining: 7.06s\n",
      "621:\tlearn: 50444.0493380\ttotal: 11.6s\tremaining: 7.04s\n",
      "622:\tlearn: 50438.8327383\ttotal: 11.6s\tremaining: 7.01s\n",
      "623:\tlearn: 50423.6682001\ttotal: 11.6s\tremaining: 6.99s\n",
      "624:\tlearn: 50376.5602953\ttotal: 11.6s\tremaining: 6.98s\n",
      "625:\tlearn: 50361.4420471\ttotal: 11.7s\tremaining: 6.97s\n",
      "626:\tlearn: 50315.5569630\ttotal: 11.7s\tremaining: 6.95s\n",
      "627:\tlearn: 50279.0611812\ttotal: 11.7s\tremaining: 6.93s\n",
      "628:\tlearn: 50266.2000244\ttotal: 11.7s\tremaining: 6.91s\n",
      "629:\tlearn: 50260.5649725\ttotal: 11.7s\tremaining: 6.89s\n",
      "630:\tlearn: 50248.4401442\ttotal: 11.7s\tremaining: 6.87s\n",
      "631:\tlearn: 50180.7277767\ttotal: 11.8s\tremaining: 6.85s\n",
      "632:\tlearn: 50169.9021727\ttotal: 11.8s\tremaining: 6.83s\n",
      "633:\tlearn: 50155.7221670\ttotal: 11.8s\tremaining: 6.81s\n",
      "634:\tlearn: 50107.3547277\ttotal: 11.8s\tremaining: 6.79s\n",
      "635:\tlearn: 50100.1411955\ttotal: 11.8s\tremaining: 6.76s\n",
      "636:\tlearn: 50056.0811351\ttotal: 11.8s\tremaining: 6.74s\n",
      "637:\tlearn: 50050.2905577\ttotal: 11.8s\tremaining: 6.72s\n",
      "638:\tlearn: 50038.9660872\ttotal: 11.9s\tremaining: 6.71s\n",
      "639:\tlearn: 50032.6388894\ttotal: 11.9s\tremaining: 6.69s\n",
      "640:\tlearn: 49957.4927554\ttotal: 11.9s\tremaining: 6.67s\n",
      "641:\tlearn: 49945.5769606\ttotal: 11.9s\tremaining: 6.65s\n",
      "642:\tlearn: 49922.3393388\ttotal: 11.9s\tremaining: 6.63s\n",
      "643:\tlearn: 49917.8972589\ttotal: 12s\tremaining: 6.61s\n",
      "644:\tlearn: 49907.4697904\ttotal: 12s\tremaining: 6.59s\n",
      "645:\tlearn: 49860.6558504\ttotal: 12s\tremaining: 6.57s\n",
      "646:\tlearn: 49849.3470961\ttotal: 12s\tremaining: 6.54s\n",
      "647:\tlearn: 49840.6962724\ttotal: 12s\tremaining: 6.52s\n",
      "648:\tlearn: 49826.8460150\ttotal: 12s\tremaining: 6.5s\n",
      "649:\tlearn: 49819.4949424\ttotal: 12s\tremaining: 6.48s\n",
      "650:\tlearn: 49813.1673799\ttotal: 12.1s\tremaining: 6.47s\n",
      "651:\tlearn: 49801.7709286\ttotal: 12.1s\tremaining: 6.45s\n",
      "652:\tlearn: 49790.5211456\ttotal: 12.1s\tremaining: 6.43s\n",
      "653:\tlearn: 49747.7888740\ttotal: 12.1s\tremaining: 6.41s\n",
      "654:\tlearn: 49681.8815182\ttotal: 12.1s\tremaining: 6.39s\n",
      "655:\tlearn: 49674.4379351\ttotal: 12.2s\tremaining: 6.37s\n",
      "656:\tlearn: 49633.1528181\ttotal: 12.2s\tremaining: 6.35s\n",
      "657:\tlearn: 49623.0293224\ttotal: 12.2s\tremaining: 6.33s\n",
      "658:\tlearn: 49577.6915608\ttotal: 12.2s\tremaining: 6.31s\n",
      "659:\tlearn: 49574.3262999\ttotal: 12.2s\tremaining: 6.29s\n",
      "660:\tlearn: 49564.8146624\ttotal: 12.2s\tremaining: 6.27s\n",
      "661:\tlearn: 49521.1040938\ttotal: 12.2s\tremaining: 6.25s\n",
      "662:\tlearn: 49515.4517998\ttotal: 12.2s\tremaining: 6.22s\n",
      "663:\tlearn: 49507.0689161\ttotal: 12.3s\tremaining: 6.21s\n",
      "664:\tlearn: 49468.5182193\ttotal: 12.3s\tremaining: 6.19s\n",
      "665:\tlearn: 49444.7457265\ttotal: 12.3s\tremaining: 6.18s\n",
      "666:\tlearn: 49436.0011768\ttotal: 12.3s\tremaining: 6.15s\n",
      "667:\tlearn: 49428.5508390\ttotal: 12.3s\tremaining: 6.13s\n",
      "668:\tlearn: 49414.1151896\ttotal: 12.4s\tremaining: 6.11s\n",
      "669:\tlearn: 49406.7163718\ttotal: 12.4s\tremaining: 6.09s\n",
      "670:\tlearn: 49366.7258305\ttotal: 12.4s\tremaining: 6.07s\n",
      "671:\tlearn: 49357.1592293\ttotal: 12.4s\tremaining: 6.05s\n",
      "672:\tlearn: 49343.9840432\ttotal: 12.4s\tremaining: 6.03s\n",
      "673:\tlearn: 49333.6466732\ttotal: 12.4s\tremaining: 6.01s\n",
      "674:\tlearn: 49322.7032854\ttotal: 12.4s\tremaining: 5.99s\n",
      "675:\tlearn: 49279.3365090\ttotal: 12.5s\tremaining: 5.98s\n",
      "676:\tlearn: 49269.1366932\ttotal: 12.6s\tremaining: 6s\n",
      "677:\tlearn: 49258.3282088\ttotal: 12.6s\tremaining: 5.99s\n",
      "678:\tlearn: 49247.7881018\ttotal: 12.6s\tremaining: 5.97s\n",
      "679:\tlearn: 49238.3218172\ttotal: 12.7s\tremaining: 5.97s\n",
      "680:\tlearn: 49222.0897868\ttotal: 12.7s\tremaining: 5.95s\n",
      "681:\tlearn: 49203.5009606\ttotal: 12.7s\tremaining: 5.92s\n",
      "682:\tlearn: 49129.3327923\ttotal: 12.7s\tremaining: 5.91s\n",
      "683:\tlearn: 49116.0819008\ttotal: 12.8s\tremaining: 5.89s\n",
      "684:\tlearn: 49106.2355540\ttotal: 12.8s\tremaining: 5.87s\n",
      "685:\tlearn: 49069.5726111\ttotal: 12.8s\tremaining: 5.85s\n",
      "686:\tlearn: 49059.6993720\ttotal: 12.8s\tremaining: 5.84s\n",
      "687:\tlearn: 49020.8699985\ttotal: 12.8s\tremaining: 5.82s\n",
      "688:\tlearn: 49012.9958180\ttotal: 12.8s\tremaining: 5.8s\n",
      "689:\tlearn: 49007.7411906\ttotal: 12.9s\tremaining: 5.78s\n",
      "690:\tlearn: 48988.1034869\ttotal: 12.9s\tremaining: 5.76s\n",
      "691:\tlearn: 48979.3886415\ttotal: 12.9s\tremaining: 5.74s\n",
      "692:\tlearn: 48936.2412952\ttotal: 12.9s\tremaining: 5.71s\n",
      "693:\tlearn: 48926.4186083\ttotal: 12.9s\tremaining: 5.69s\n",
      "694:\tlearn: 48891.7070743\ttotal: 12.9s\tremaining: 5.67s\n",
      "695:\tlearn: 48880.3208143\ttotal: 13s\tremaining: 5.66s\n",
      "696:\tlearn: 48871.1371580\ttotal: 13s\tremaining: 5.64s\n",
      "697:\tlearn: 48833.5551213\ttotal: 13s\tremaining: 5.62s\n",
      "698:\tlearn: 48820.2045133\ttotal: 13s\tremaining: 5.61s\n",
      "699:\tlearn: 48783.9350235\ttotal: 13.1s\tremaining: 5.59s\n",
      "700:\tlearn: 48776.8881625\ttotal: 13.1s\tremaining: 5.58s\n",
      "701:\tlearn: 48771.0620893\ttotal: 13.1s\tremaining: 5.56s\n",
      "702:\tlearn: 48758.2020883\ttotal: 13.1s\tremaining: 5.54s\n",
      "703:\tlearn: 48723.1932184\ttotal: 13.1s\tremaining: 5.52s\n",
      "704:\tlearn: 48714.2508071\ttotal: 13.1s\tremaining: 5.5s\n",
      "705:\tlearn: 48710.0778003\ttotal: 13.1s\tremaining: 5.47s\n",
      "706:\tlearn: 48699.1957734\ttotal: 13.2s\tremaining: 5.45s\n",
      "707:\tlearn: 48687.6169719\ttotal: 13.2s\tremaining: 5.43s\n",
      "708:\tlearn: 48683.4438013\ttotal: 13.2s\tremaining: 5.41s\n",
      "709:\tlearn: 48659.3758085\ttotal: 13.2s\tremaining: 5.39s\n",
      "710:\tlearn: 48651.7701593\ttotal: 13.2s\tremaining: 5.37s\n",
      "711:\tlearn: 48623.7298462\ttotal: 13.2s\tremaining: 5.35s\n",
      "712:\tlearn: 48582.4150439\ttotal: 13.2s\tremaining: 5.33s\n",
      "713:\tlearn: 48578.1151344\ttotal: 13.3s\tremaining: 5.31s\n",
      "714:\tlearn: 48542.0329301\ttotal: 13.3s\tremaining: 5.3s\n",
      "715:\tlearn: 48529.2839460\ttotal: 13.3s\tremaining: 5.28s\n",
      "716:\tlearn: 48464.1955104\ttotal: 13.3s\tremaining: 5.26s\n",
      "717:\tlearn: 48455.9027378\ttotal: 13.3s\tremaining: 5.24s\n",
      "718:\tlearn: 48450.0622089\ttotal: 13.4s\tremaining: 5.22s\n",
      "719:\tlearn: 48445.5238121\ttotal: 13.4s\tremaining: 5.2s\n",
      "720:\tlearn: 48433.2074738\ttotal: 13.4s\tremaining: 5.18s\n",
      "721:\tlearn: 48392.3357798\ttotal: 13.4s\tremaining: 5.16s\n",
      "722:\tlearn: 48386.2352052\ttotal: 13.4s\tremaining: 5.14s\n",
      "723:\tlearn: 48381.2942835\ttotal: 13.4s\tremaining: 5.12s\n",
      "724:\tlearn: 48342.7313730\ttotal: 13.4s\tremaining: 5.1s\n",
      "725:\tlearn: 48334.7294561\ttotal: 13.4s\tremaining: 5.08s\n",
      "726:\tlearn: 48322.4226499\ttotal: 13.5s\tremaining: 5.05s\n",
      "727:\tlearn: 48316.1895918\ttotal: 13.5s\tremaining: 5.03s\n",
      "728:\tlearn: 48304.7107427\ttotal: 13.5s\tremaining: 5.02s\n",
      "729:\tlearn: 48297.2510080\ttotal: 13.5s\tremaining: 5s\n",
      "730:\tlearn: 48275.3511530\ttotal: 13.5s\tremaining: 4.98s\n",
      "731:\tlearn: 48269.4927022\ttotal: 13.6s\tremaining: 4.96s\n",
      "732:\tlearn: 48232.2263597\ttotal: 13.6s\tremaining: 4.94s\n",
      "733:\tlearn: 48221.1347296\ttotal: 13.6s\tremaining: 4.92s\n",
      "734:\tlearn: 48209.4649414\ttotal: 13.6s\tremaining: 4.9s\n",
      "735:\tlearn: 48173.4959214\ttotal: 13.6s\tremaining: 4.88s\n",
      "736:\tlearn: 48167.9224982\ttotal: 13.6s\tremaining: 4.86s\n",
      "737:\tlearn: 48163.2279734\ttotal: 13.6s\tremaining: 4.84s\n",
      "738:\tlearn: 48151.9652241\ttotal: 13.7s\tremaining: 4.82s\n",
      "739:\tlearn: 48117.1027721\ttotal: 13.7s\tremaining: 4.8s\n",
      "740:\tlearn: 48082.9077657\ttotal: 13.7s\tremaining: 4.78s\n",
      "741:\tlearn: 48049.9156446\ttotal: 13.7s\tremaining: 4.76s\n",
      "742:\tlearn: 48044.2552373\ttotal: 13.7s\tremaining: 4.74s\n",
      "743:\tlearn: 48033.5157451\ttotal: 13.7s\tremaining: 4.72s\n",
      "744:\tlearn: 48001.6708406\ttotal: 13.7s\tremaining: 4.7s\n",
      "745:\tlearn: 47988.7447907\ttotal: 13.8s\tremaining: 4.68s\n",
      "746:\tlearn: 47983.1869060\ttotal: 13.8s\tremaining: 4.66s\n",
      "747:\tlearn: 47913.4056100\ttotal: 13.9s\tremaining: 4.67s\n",
      "748:\tlearn: 47879.6731553\ttotal: 13.9s\tremaining: 4.66s\n",
      "749:\tlearn: 47869.3848159\ttotal: 13.9s\tremaining: 4.63s\n",
      "750:\tlearn: 47858.6210926\ttotal: 13.9s\tremaining: 4.62s\n",
      "751:\tlearn: 47848.5934132\ttotal: 13.9s\tremaining: 4.59s\n",
      "752:\tlearn: 47842.7175604\ttotal: 13.9s\tremaining: 4.58s\n",
      "753:\tlearn: 47811.8920691\ttotal: 14s\tremaining: 4.56s\n",
      "754:\tlearn: 47802.2251273\ttotal: 14s\tremaining: 4.54s\n",
      "755:\tlearn: 47778.9794232\ttotal: 14s\tremaining: 4.52s\n",
      "756:\tlearn: 47773.5579913\ttotal: 14s\tremaining: 4.5s\n",
      "757:\tlearn: 47709.8310395\ttotal: 14s\tremaining: 4.49s\n",
      "758:\tlearn: 47704.6085049\ttotal: 14.1s\tremaining: 4.46s\n",
      "759:\tlearn: 47640.4409315\ttotal: 14.1s\tremaining: 4.45s\n",
      "760:\tlearn: 47610.5803968\ttotal: 14.1s\tremaining: 4.42s\n",
      "761:\tlearn: 47601.3772437\ttotal: 14.1s\tremaining: 4.4s\n",
      "762:\tlearn: 47572.5612222\ttotal: 14.1s\tremaining: 4.39s\n",
      "763:\tlearn: 47549.0695597\ttotal: 14.1s\tremaining: 4.37s\n",
      "764:\tlearn: 47488.6365825\ttotal: 14.2s\tremaining: 4.35s\n",
      "765:\tlearn: 47460.7843248\ttotal: 14.2s\tremaining: 4.33s\n",
      "766:\tlearn: 47451.8129149\ttotal: 14.2s\tremaining: 4.31s\n",
      "767:\tlearn: 47424.9361313\ttotal: 14.2s\tremaining: 4.3s\n",
      "768:\tlearn: 47389.4826895\ttotal: 14.2s\tremaining: 4.28s\n",
      "769:\tlearn: 47363.5300492\ttotal: 14.3s\tremaining: 4.26s\n",
      "770:\tlearn: 47354.9387516\ttotal: 14.3s\tremaining: 4.24s\n",
      "771:\tlearn: 47344.0082352\ttotal: 14.3s\tremaining: 4.22s\n",
      "772:\tlearn: 47336.9949651\ttotal: 14.3s\tremaining: 4.2s\n",
      "773:\tlearn: 47311.9441492\ttotal: 14.3s\tremaining: 4.18s\n",
      "774:\tlearn: 47279.8895046\ttotal: 14.3s\tremaining: 4.16s\n",
      "775:\tlearn: 47245.7914969\ttotal: 14.3s\tremaining: 4.14s\n",
      "776:\tlearn: 47236.6036477\ttotal: 14.4s\tremaining: 4.12s\n",
      "777:\tlearn: 47179.5059654\ttotal: 14.4s\tremaining: 4.1s\n",
      "778:\tlearn: 47173.8063794\ttotal: 14.4s\tremaining: 4.08s\n",
      "779:\tlearn: 47169.7640879\ttotal: 14.4s\tremaining: 4.06s\n",
      "780:\tlearn: 47163.2046338\ttotal: 14.4s\tremaining: 4.04s\n",
      "781:\tlearn: 47092.3886401\ttotal: 14.4s\tremaining: 4.03s\n",
      "782:\tlearn: 47072.7008577\ttotal: 14.5s\tremaining: 4.01s\n",
      "783:\tlearn: 47063.8404568\ttotal: 14.5s\tremaining: 3.99s\n",
      "784:\tlearn: 47054.5317149\ttotal: 14.5s\tremaining: 3.97s\n",
      "785:\tlearn: 47049.6284284\ttotal: 14.5s\tremaining: 3.95s\n",
      "786:\tlearn: 47041.1025847\ttotal: 14.5s\tremaining: 3.93s\n",
      "787:\tlearn: 47032.0330146\ttotal: 14.5s\tremaining: 3.91s\n",
      "788:\tlearn: 47026.9123328\ttotal: 14.5s\tremaining: 3.89s\n",
      "789:\tlearn: 47018.2805179\ttotal: 14.6s\tremaining: 3.87s\n",
      "790:\tlearn: 47010.0929260\ttotal: 14.6s\tremaining: 3.85s\n",
      "791:\tlearn: 46987.2772156\ttotal: 14.6s\tremaining: 3.83s\n",
      "792:\tlearn: 46978.4972944\ttotal: 14.6s\tremaining: 3.81s\n",
      "793:\tlearn: 46969.7902753\ttotal: 14.6s\tremaining: 3.8s\n",
      "794:\tlearn: 46947.2982454\ttotal: 14.7s\tremaining: 3.78s\n",
      "795:\tlearn: 46922.9163296\ttotal: 14.7s\tremaining: 3.76s\n",
      "796:\tlearn: 46913.1275615\ttotal: 14.7s\tremaining: 3.74s\n",
      "797:\tlearn: 46908.3937817\ttotal: 14.7s\tremaining: 3.72s\n",
      "798:\tlearn: 46900.5072004\ttotal: 14.7s\tremaining: 3.7s\n",
      "799:\tlearn: 46891.4600678\ttotal: 14.7s\tremaining: 3.68s\n",
      "800:\tlearn: 46883.8681770\ttotal: 14.7s\tremaining: 3.66s\n",
      "801:\tlearn: 46876.5590486\ttotal: 14.8s\tremaining: 3.64s\n",
      "802:\tlearn: 46869.5208302\ttotal: 14.8s\tremaining: 3.62s\n",
      "803:\tlearn: 46860.5369379\ttotal: 14.8s\tremaining: 3.6s\n",
      "804:\tlearn: 46836.9624971\ttotal: 14.8s\tremaining: 3.58s\n",
      "805:\tlearn: 46830.6160823\ttotal: 14.8s\tremaining: 3.56s\n",
      "806:\tlearn: 46795.0809416\ttotal: 14.8s\tremaining: 3.54s\n",
      "807:\tlearn: 46760.1116765\ttotal: 14.8s\tremaining: 3.52s\n",
      "808:\tlearn: 46750.3343162\ttotal: 14.9s\tremaining: 3.51s\n",
      "809:\tlearn: 46721.3372494\ttotal: 15s\tremaining: 3.51s\n",
      "810:\tlearn: 46716.0246864\ttotal: 15s\tremaining: 3.49s\n",
      "811:\tlearn: 46704.6104450\ttotal: 15s\tremaining: 3.47s\n",
      "812:\tlearn: 46700.0369278\ttotal: 15s\tremaining: 3.45s\n",
      "813:\tlearn: 46686.0989138\ttotal: 15s\tremaining: 3.43s\n",
      "814:\tlearn: 46677.4923155\ttotal: 15s\tremaining: 3.41s\n",
      "815:\tlearn: 46671.0323417\ttotal: 15s\tremaining: 3.39s\n",
      "816:\tlearn: 46663.1294783\ttotal: 15s\tremaining: 3.37s\n",
      "817:\tlearn: 46655.5958253\ttotal: 15.1s\tremaining: 3.35s\n",
      "818:\tlearn: 46621.1752711\ttotal: 15.1s\tremaining: 3.33s\n",
      "819:\tlearn: 46614.2620126\ttotal: 15.1s\tremaining: 3.32s\n",
      "820:\tlearn: 46607.0895352\ttotal: 15.1s\tremaining: 3.3s\n",
      "821:\tlearn: 46575.4868998\ttotal: 15.1s\tremaining: 3.28s\n",
      "822:\tlearn: 46568.6348652\ttotal: 15.2s\tremaining: 3.26s\n",
      "823:\tlearn: 46562.0903027\ttotal: 15.2s\tremaining: 3.24s\n",
      "824:\tlearn: 46555.8358727\ttotal: 15.2s\tremaining: 3.22s\n",
      "825:\tlearn: 46538.2358775\ttotal: 15.2s\tremaining: 3.2s\n",
      "826:\tlearn: 46531.8679957\ttotal: 15.2s\tremaining: 3.18s\n",
      "827:\tlearn: 46525.8930879\ttotal: 15.2s\tremaining: 3.16s\n",
      "828:\tlearn: 46519.2900216\ttotal: 15.2s\tremaining: 3.14s\n",
      "829:\tlearn: 46496.9577777\ttotal: 15.2s\tremaining: 3.12s\n",
      "830:\tlearn: 46465.3948367\ttotal: 15.3s\tremaining: 3.1s\n",
      "831:\tlearn: 46459.6332967\ttotal: 15.3s\tremaining: 3.08s\n",
      "832:\tlearn: 46431.5310448\ttotal: 15.3s\tremaining: 3.07s\n",
      "833:\tlearn: 46426.0153405\ttotal: 15.3s\tremaining: 3.05s\n",
      "834:\tlearn: 46420.7356159\ttotal: 15.3s\tremaining: 3.03s\n",
      "835:\tlearn: 46411.8386681\ttotal: 15.4s\tremaining: 3.01s\n",
      "836:\tlearn: 46399.8381222\ttotal: 15.4s\tremaining: 2.99s\n",
      "837:\tlearn: 46369.9102052\ttotal: 15.4s\tremaining: 2.97s\n",
      "838:\tlearn: 46339.3167026\ttotal: 15.4s\tremaining: 2.95s\n",
      "839:\tlearn: 46332.8756623\ttotal: 15.4s\tremaining: 2.93s\n",
      "840:\tlearn: 46323.7292734\ttotal: 15.4s\tremaining: 2.92s\n",
      "841:\tlearn: 46314.6422577\ttotal: 15.4s\tremaining: 2.9s\n",
      "842:\tlearn: 46253.3012506\ttotal: 15.5s\tremaining: 2.88s\n",
      "843:\tlearn: 46235.9443425\ttotal: 15.5s\tremaining: 2.86s\n",
      "844:\tlearn: 46226.9969677\ttotal: 15.5s\tremaining: 2.84s\n",
      "845:\tlearn: 46195.6157117\ttotal: 15.5s\tremaining: 2.82s\n",
      "846:\tlearn: 46136.0136496\ttotal: 15.5s\tremaining: 2.8s\n",
      "847:\tlearn: 46060.8564619\ttotal: 15.6s\tremaining: 2.79s\n",
      "848:\tlearn: 46056.1857475\ttotal: 15.6s\tremaining: 2.77s\n",
      "849:\tlearn: 46046.5706649\ttotal: 15.6s\tremaining: 2.75s\n",
      "850:\tlearn: 46038.0484275\ttotal: 15.6s\tremaining: 2.73s\n",
      "851:\tlearn: 46007.6992224\ttotal: 15.6s\tremaining: 2.71s\n",
      "852:\tlearn: 46004.4760528\ttotal: 15.6s\tremaining: 2.69s\n",
      "853:\tlearn: 45995.5192973\ttotal: 15.7s\tremaining: 2.67s\n",
      "854:\tlearn: 45990.5845233\ttotal: 15.7s\tremaining: 2.66s\n",
      "855:\tlearn: 45979.9133375\ttotal: 15.7s\tremaining: 2.64s\n",
      "856:\tlearn: 45973.6131821\ttotal: 15.7s\tremaining: 2.62s\n",
      "857:\tlearn: 45967.8938040\ttotal: 15.7s\tremaining: 2.6s\n",
      "858:\tlearn: 45963.3799835\ttotal: 15.8s\tremaining: 2.59s\n",
      "859:\tlearn: 45958.7642012\ttotal: 15.8s\tremaining: 2.57s\n",
      "860:\tlearn: 45937.2000724\ttotal: 15.8s\tremaining: 2.55s\n",
      "861:\tlearn: 45933.7685649\ttotal: 15.8s\tremaining: 2.53s\n",
      "862:\tlearn: 45881.6642165\ttotal: 15.8s\tremaining: 2.51s\n",
      "863:\tlearn: 45877.2390914\ttotal: 15.8s\tremaining: 2.49s\n",
      "864:\tlearn: 45856.4122730\ttotal: 15.8s\tremaining: 2.47s\n",
      "865:\tlearn: 45847.2334399\ttotal: 15.9s\tremaining: 2.45s\n",
      "866:\tlearn: 45827.1391140\ttotal: 15.9s\tremaining: 2.44s\n",
      "867:\tlearn: 45823.3971295\ttotal: 15.9s\tremaining: 2.42s\n",
      "868:\tlearn: 45819.3561838\ttotal: 15.9s\tremaining: 2.4s\n",
      "869:\tlearn: 45808.1803216\ttotal: 15.9s\tremaining: 2.38s\n",
      "870:\tlearn: 45800.9304996\ttotal: 15.9s\tremaining: 2.36s\n",
      "871:\tlearn: 45799.1725943\ttotal: 16.1s\tremaining: 2.36s\n",
      "872:\tlearn: 45769.9111545\ttotal: 16.1s\tremaining: 2.34s\n",
      "873:\tlearn: 45750.5087295\ttotal: 16.1s\tremaining: 2.32s\n",
      "874:\tlearn: 45741.6352617\ttotal: 16.1s\tremaining: 2.3s\n",
      "875:\tlearn: 45710.1984147\ttotal: 16.1s\tremaining: 2.28s\n",
      "876:\tlearn: 45691.4571453\ttotal: 16.1s\tremaining: 2.26s\n",
      "877:\tlearn: 45661.3384726\ttotal: 16.2s\tremaining: 2.25s\n",
      "878:\tlearn: 45643.2462017\ttotal: 16.2s\tremaining: 2.23s\n",
      "879:\tlearn: 45625.4325009\ttotal: 16.2s\tremaining: 2.21s\n",
      "880:\tlearn: 45615.7922423\ttotal: 16.2s\tremaining: 2.19s\n",
      "881:\tlearn: 45592.4149128\ttotal: 16.2s\tremaining: 2.17s\n",
      "882:\tlearn: 45586.5524255\ttotal: 16.3s\tremaining: 2.15s\n",
      "883:\tlearn: 45578.2294835\ttotal: 16.3s\tremaining: 2.13s\n",
      "884:\tlearn: 45569.6445631\ttotal: 16.3s\tremaining: 2.12s\n",
      "885:\tlearn: 45500.5091694\ttotal: 16.3s\tremaining: 2.1s\n",
      "886:\tlearn: 45483.6064831\ttotal: 16.3s\tremaining: 2.08s\n",
      "887:\tlearn: 45456.4996626\ttotal: 16.3s\tremaining: 2.06s\n",
      "888:\tlearn: 45434.7024822\ttotal: 16.3s\tremaining: 2.04s\n",
      "889:\tlearn: 45409.1747916\ttotal: 16.3s\tremaining: 2.02s\n",
      "890:\tlearn: 45398.9180821\ttotal: 16.4s\tremaining: 2s\n",
      "891:\tlearn: 45390.8828245\ttotal: 16.4s\tremaining: 1.98s\n",
      "892:\tlearn: 45325.5188111\ttotal: 16.4s\tremaining: 1.97s\n",
      "893:\tlearn: 45321.3274288\ttotal: 16.4s\tremaining: 1.95s\n",
      "894:\tlearn: 45318.5759249\ttotal: 16.5s\tremaining: 1.93s\n",
      "895:\tlearn: 45315.3112787\ttotal: 16.5s\tremaining: 1.91s\n",
      "896:\tlearn: 45312.2102035\ttotal: 16.5s\tremaining: 1.89s\n",
      "897:\tlearn: 45306.3389872\ttotal: 16.5s\tremaining: 1.87s\n",
      "898:\tlearn: 45300.4263659\ttotal: 16.5s\tremaining: 1.85s\n",
      "899:\tlearn: 45271.9302450\ttotal: 16.5s\tremaining: 1.83s\n",
      "900:\tlearn: 45260.6772492\ttotal: 16.5s\tremaining: 1.82s\n",
      "901:\tlearn: 45254.4295002\ttotal: 16.6s\tremaining: 1.8s\n",
      "902:\tlearn: 45251.4038127\ttotal: 16.6s\tremaining: 1.78s\n",
      "903:\tlearn: 45246.6594413\ttotal: 16.6s\tremaining: 1.76s\n",
      "904:\tlearn: 45222.6307512\ttotal: 16.7s\tremaining: 1.75s\n",
      "905:\tlearn: 45195.1457775\ttotal: 16.7s\tremaining: 1.73s\n",
      "906:\tlearn: 45166.2101231\ttotal: 16.7s\tremaining: 1.71s\n",
      "907:\tlearn: 45161.2171232\ttotal: 16.7s\tremaining: 1.7s\n",
      "908:\tlearn: 45154.4460936\ttotal: 16.8s\tremaining: 1.68s\n",
      "909:\tlearn: 45146.2660038\ttotal: 16.8s\tremaining: 1.66s\n",
      "910:\tlearn: 45142.4630894\ttotal: 16.8s\tremaining: 1.64s\n",
      "911:\tlearn: 45126.6036436\ttotal: 16.8s\tremaining: 1.62s\n",
      "912:\tlearn: 45082.2437240\ttotal: 16.8s\tremaining: 1.6s\n",
      "913:\tlearn: 45079.5495640\ttotal: 16.8s\tremaining: 1.58s\n",
      "914:\tlearn: 45024.3736407\ttotal: 16.9s\tremaining: 1.57s\n",
      "915:\tlearn: 45020.5208028\ttotal: 16.9s\tremaining: 1.55s\n",
      "916:\tlearn: 45016.7249299\ttotal: 16.9s\tremaining: 1.53s\n",
      "917:\tlearn: 44956.6832927\ttotal: 16.9s\tremaining: 1.51s\n",
      "918:\tlearn: 44898.8088114\ttotal: 17s\tremaining: 1.5s\n",
      "919:\tlearn: 44843.0163814\ttotal: 17s\tremaining: 1.48s\n",
      "920:\tlearn: 44789.1421354\ttotal: 17s\tremaining: 1.46s\n",
      "921:\tlearn: 44737.2304241\ttotal: 17s\tremaining: 1.44s\n",
      "922:\tlearn: 44719.2830441\ttotal: 17s\tremaining: 1.42s\n",
      "923:\tlearn: 44710.9409228\ttotal: 17s\tremaining: 1.4s\n",
      "924:\tlearn: 44660.8031226\ttotal: 17s\tremaining: 1.38s\n",
      "925:\tlearn: 44612.3738983\ttotal: 17.1s\tremaining: 1.36s\n",
      "926:\tlearn: 44565.6830696\ttotal: 17.1s\tremaining: 1.34s\n",
      "927:\tlearn: 44538.8311502\ttotal: 17.1s\tremaining: 1.32s\n",
      "928:\tlearn: 44516.0085520\ttotal: 17.1s\tremaining: 1.31s\n",
      "929:\tlearn: 44514.2364315\ttotal: 17.1s\tremaining: 1.29s\n",
      "930:\tlearn: 44469.1693288\ttotal: 17.3s\tremaining: 1.28s\n",
      "931:\tlearn: 44440.9147787\ttotal: 17.4s\tremaining: 1.27s\n",
      "932:\tlearn: 44397.4250362\ttotal: 17.7s\tremaining: 1.27s\n",
      "933:\tlearn: 44394.7490341\ttotal: 17.7s\tremaining: 1.25s\n",
      "934:\tlearn: 44351.3399922\ttotal: 18.1s\tremaining: 1.25s\n",
      "935:\tlearn: 44309.4936735\ttotal: 18.1s\tremaining: 1.24s\n",
      "936:\tlearn: 44270.4241798\ttotal: 18.1s\tremaining: 1.22s\n",
      "937:\tlearn: 44232.7459134\ttotal: 18.2s\tremaining: 1.21s\n",
      "938:\tlearn: 44224.6472801\ttotal: 18.3s\tremaining: 1.19s\n",
      "939:\tlearn: 44187.0206869\ttotal: 18.3s\tremaining: 1.17s\n",
      "940:\tlearn: 44150.8007013\ttotal: 18.3s\tremaining: 1.15s\n",
      "941:\tlearn: 44143.5269443\ttotal: 18.3s\tremaining: 1.13s\n",
      "942:\tlearn: 44109.6575560\ttotal: 18.3s\tremaining: 1.11s\n",
      "943:\tlearn: 44076.9923096\ttotal: 18.4s\tremaining: 1.09s\n",
      "944:\tlearn: 44044.8546399\ttotal: 18.4s\tremaining: 1.07s\n",
      "945:\tlearn: 44036.2962715\ttotal: 18.4s\tremaining: 1.05s\n",
      "946:\tlearn: 44004.9337919\ttotal: 18.4s\tremaining: 1.03s\n",
      "947:\tlearn: 43988.6577972\ttotal: 18.4s\tremaining: 1.01s\n",
      "948:\tlearn: 43983.6681505\ttotal: 18.4s\tremaining: 990ms\n",
      "949:\tlearn: 43977.0656804\ttotal: 18.4s\tremaining: 970ms\n",
      "950:\tlearn: 43966.6252775\ttotal: 18.4s\tremaining: 951ms\n",
      "951:\tlearn: 43963.0100375\ttotal: 18.5s\tremaining: 931ms\n",
      "952:\tlearn: 43956.9223402\ttotal: 18.5s\tremaining: 911ms\n",
      "953:\tlearn: 43948.3674661\ttotal: 18.5s\tremaining: 892ms\n",
      "954:\tlearn: 43887.0660247\ttotal: 18.5s\tremaining: 872ms\n",
      "955:\tlearn: 43880.6084515\ttotal: 18.6s\tremaining: 857ms\n",
      "956:\tlearn: 43854.3801071\ttotal: 18.6s\tremaining: 837ms\n",
      "957:\tlearn: 43850.9143905\ttotal: 18.6s\tremaining: 818ms\n",
      "958:\tlearn: 43847.8250836\ttotal: 18.7s\tremaining: 798ms\n",
      "959:\tlearn: 43816.0339219\ttotal: 18.7s\tremaining: 778ms\n",
      "960:\tlearn: 43758.1205821\ttotal: 18.7s\tremaining: 759ms\n",
      "961:\tlearn: 43741.0029812\ttotal: 18.7s\tremaining: 739ms\n",
      "962:\tlearn: 43686.3556149\ttotal: 18.7s\tremaining: 719ms\n",
      "963:\tlearn: 43677.7143196\ttotal: 18.8s\tremaining: 701ms\n",
      "964:\tlearn: 43656.1615220\ttotal: 18.8s\tremaining: 681ms\n",
      "965:\tlearn: 43654.0228437\ttotal: 18.8s\tremaining: 661ms\n",
      "966:\tlearn: 43639.7848148\ttotal: 18.8s\tremaining: 642ms\n",
      "967:\tlearn: 43619.7236907\ttotal: 18.8s\tremaining: 622ms\n",
      "968:\tlearn: 43615.8761768\ttotal: 18.8s\tremaining: 603ms\n",
      "969:\tlearn: 43607.3225652\ttotal: 18.8s\tremaining: 583ms\n",
      "970:\tlearn: 43597.7442864\ttotal: 18.9s\tremaining: 563ms\n",
      "971:\tlearn: 43589.8487237\ttotal: 18.9s\tremaining: 544ms\n",
      "972:\tlearn: 43569.3412310\ttotal: 18.9s\tremaining: 524ms\n",
      "973:\tlearn: 43517.6852843\ttotal: 18.9s\tremaining: 505ms\n",
      "974:\tlearn: 43516.2364950\ttotal: 18.9s\tremaining: 485ms\n",
      "975:\tlearn: 43500.9144850\ttotal: 18.9s\tremaining: 465ms\n",
      "976:\tlearn: 43493.5368467\ttotal: 18.9s\tremaining: 446ms\n",
      "977:\tlearn: 43468.7388464\ttotal: 19s\tremaining: 427ms\n",
      "978:\tlearn: 43461.5410382\ttotal: 19s\tremaining: 407ms\n",
      "979:\tlearn: 43442.6008027\ttotal: 19s\tremaining: 388ms\n",
      "980:\tlearn: 43435.1404825\ttotal: 19s\tremaining: 368ms\n",
      "981:\tlearn: 43429.6542593\ttotal: 19s\tremaining: 349ms\n",
      "982:\tlearn: 43380.8330699\ttotal: 19.1s\tremaining: 330ms\n",
      "983:\tlearn: 43355.7091208\ttotal: 19.1s\tremaining: 310ms\n",
      "984:\tlearn: 43342.6458205\ttotal: 19.1s\tremaining: 291ms\n",
      "985:\tlearn: 43313.0620861\ttotal: 19.1s\tremaining: 271ms\n",
      "986:\tlearn: 43284.5725663\ttotal: 19.1s\tremaining: 252ms\n",
      "987:\tlearn: 43282.1633425\ttotal: 19.1s\tremaining: 232ms\n",
      "988:\tlearn: 43280.4123979\ttotal: 19.1s\tremaining: 213ms\n",
      "989:\tlearn: 43253.8247396\ttotal: 19.2s\tremaining: 193ms\n",
      "990:\tlearn: 43185.9647273\ttotal: 19.2s\tremaining: 174ms\n",
      "991:\tlearn: 43173.8469412\ttotal: 19.2s\tremaining: 155ms\n",
      "992:\tlearn: 43164.5028592\ttotal: 19.2s\tremaining: 135ms\n",
      "993:\tlearn: 43137.5779680\ttotal: 19.2s\tremaining: 116ms\n",
      "994:\tlearn: 43112.7740643\ttotal: 19.2s\tremaining: 96.7ms\n",
      "995:\tlearn: 43088.0156651\ttotal: 19.3s\tremaining: 77.3ms\n",
      "996:\tlearn: 43068.2135886\ttotal: 19.3s\tremaining: 58ms\n",
      "997:\tlearn: 43042.9352422\ttotal: 19.3s\tremaining: 38.6ms\n",
      "998:\tlearn: 43030.1095710\ttotal: 19.3s\tremaining: 19.3ms\n",
      "999:\tlearn: 43005.8902134\ttotal: 19.3s\tremaining: 0us\n",
      "Learning rate set to 0.071716\n",
      "0:\tlearn: 76826.7812223\ttotal: 18.1ms\tremaining: 18.1s\n",
      "1:\tlearn: 76416.2657673\ttotal: 34.7ms\tremaining: 17.3s\n",
      "2:\tlearn: 76013.7153049\ttotal: 51.6ms\tremaining: 17.2s\n",
      "3:\tlearn: 75661.8139763\ttotal: 64.5ms\tremaining: 16.1s\n",
      "4:\tlearn: 75347.7353537\ttotal: 78.1ms\tremaining: 15.5s\n",
      "5:\tlearn: 75058.6172790\ttotal: 88.8ms\tremaining: 14.7s\n",
      "6:\tlearn: 74817.5670340\ttotal: 103ms\tremaining: 14.6s\n",
      "7:\tlearn: 74596.2817689\ttotal: 117ms\tremaining: 14.5s\n",
      "8:\tlearn: 74395.8452152\ttotal: 132ms\tremaining: 14.5s\n",
      "9:\tlearn: 74211.5860965\ttotal: 145ms\tremaining: 14.3s\n",
      "10:\tlearn: 74065.3794413\ttotal: 164ms\tremaining: 14.8s\n",
      "11:\tlearn: 73874.2543700\ttotal: 178ms\tremaining: 14.6s\n",
      "12:\tlearn: 73713.6579468\ttotal: 196ms\tremaining: 14.9s\n",
      "13:\tlearn: 73549.1232446\ttotal: 321ms\tremaining: 22.6s\n",
      "14:\tlearn: 73414.2286776\ttotal: 338ms\tremaining: 22.2s\n",
      "15:\tlearn: 73314.3602932\ttotal: 361ms\tremaining: 22.2s\n",
      "16:\tlearn: 73204.8496623\ttotal: 370ms\tremaining: 21.4s\n",
      "17:\tlearn: 73112.9617407\ttotal: 386ms\tremaining: 21.1s\n",
      "18:\tlearn: 73017.2897576\ttotal: 413ms\tremaining: 21.3s\n",
      "19:\tlearn: 72933.3642155\ttotal: 438ms\tremaining: 21.4s\n",
      "20:\tlearn: 72680.5662674\ttotal: 461ms\tremaining: 21.5s\n",
      "21:\tlearn: 72614.4295885\ttotal: 474ms\tremaining: 21.1s\n",
      "22:\tlearn: 72546.3994390\ttotal: 482ms\tremaining: 20.5s\n",
      "23:\tlearn: 72476.8920885\ttotal: 494ms\tremaining: 20.1s\n",
      "24:\tlearn: 72373.7391055\ttotal: 509ms\tremaining: 19.9s\n",
      "25:\tlearn: 72303.5971992\ttotal: 520ms\tremaining: 19.5s\n",
      "26:\tlearn: 72250.5317013\ttotal: 533ms\tremaining: 19.2s\n",
      "27:\tlearn: 72233.8933182\ttotal: 545ms\tremaining: 18.9s\n",
      "28:\tlearn: 72139.7065797\ttotal: 559ms\tremaining: 18.7s\n",
      "29:\tlearn: 72095.2074202\ttotal: 574ms\tremaining: 18.6s\n",
      "30:\tlearn: 72079.7624689\ttotal: 584ms\tremaining: 18.2s\n",
      "31:\tlearn: 71853.1738897\ttotal: 598ms\tremaining: 18.1s\n",
      "32:\tlearn: 71837.0266634\ttotal: 611ms\tremaining: 17.9s\n",
      "33:\tlearn: 71776.0036667\ttotal: 619ms\tremaining: 17.6s\n",
      "34:\tlearn: 71729.0506771\ttotal: 648ms\tremaining: 17.9s\n",
      "35:\tlearn: 71695.8682799\ttotal: 667ms\tremaining: 17.9s\n",
      "36:\tlearn: 71665.3520059\ttotal: 673ms\tremaining: 17.5s\n",
      "37:\tlearn: 71638.3629611\ttotal: 687ms\tremaining: 17.4s\n",
      "38:\tlearn: 71599.9766068\ttotal: 701ms\tremaining: 17.3s\n",
      "39:\tlearn: 71398.6467140\ttotal: 708ms\tremaining: 17s\n",
      "40:\tlearn: 71209.1528749\ttotal: 723ms\tremaining: 16.9s\n",
      "41:\tlearn: 71163.6589879\ttotal: 738ms\tremaining: 16.8s\n",
      "42:\tlearn: 71153.7920649\ttotal: 750ms\tremaining: 16.7s\n",
      "43:\tlearn: 71098.0798906\ttotal: 769ms\tremaining: 16.7s\n",
      "44:\tlearn: 71089.0176013\ttotal: 787ms\tremaining: 16.7s\n",
      "45:\tlearn: 71020.8656182\ttotal: 839ms\tremaining: 17.4s\n",
      "46:\tlearn: 70975.0536036\ttotal: 865ms\tremaining: 17.5s\n",
      "47:\tlearn: 70948.6371505\ttotal: 889ms\tremaining: 17.6s\n",
      "48:\tlearn: 70875.0721297\ttotal: 924ms\tremaining: 17.9s\n",
      "49:\tlearn: 70866.6016471\ttotal: 932ms\tremaining: 17.7s\n",
      "50:\tlearn: 70830.3574538\ttotal: 947ms\tremaining: 17.6s\n",
      "51:\tlearn: 70797.3220701\ttotal: 956ms\tremaining: 17.4s\n",
      "52:\tlearn: 70743.1140955\ttotal: 976ms\tremaining: 17.4s\n",
      "53:\tlearn: 70735.5734179\ttotal: 997ms\tremaining: 17.5s\n",
      "54:\tlearn: 70701.3555955\ttotal: 1.01s\tremaining: 17.3s\n",
      "55:\tlearn: 70678.7739188\ttotal: 1.02s\tremaining: 17.1s\n",
      "56:\tlearn: 70651.0407336\ttotal: 1.03s\tremaining: 17.1s\n",
      "57:\tlearn: 70618.3036002\ttotal: 1.05s\tremaining: 17s\n",
      "58:\tlearn: 70473.2945299\ttotal: 1.06s\tremaining: 16.9s\n",
      "59:\tlearn: 70435.8921707\ttotal: 1.07s\tremaining: 16.9s\n",
      "60:\tlearn: 70426.3910383\ttotal: 1.11s\tremaining: 17s\n",
      "61:\tlearn: 70399.6244995\ttotal: 1.13s\tremaining: 17.2s\n",
      "62:\tlearn: 70392.3382432\ttotal: 1.15s\tremaining: 17s\n",
      "63:\tlearn: 70347.7362064\ttotal: 1.16s\tremaining: 16.9s\n",
      "64:\tlearn: 70324.4829136\ttotal: 1.17s\tremaining: 16.9s\n",
      "65:\tlearn: 70261.4509369\ttotal: 1.19s\tremaining: 16.8s\n",
      "66:\tlearn: 70237.0761851\ttotal: 1.2s\tremaining: 16.7s\n",
      "67:\tlearn: 70228.3360640\ttotal: 1.21s\tremaining: 16.6s\n",
      "68:\tlearn: 70217.7129661\ttotal: 1.22s\tremaining: 16.4s\n",
      "69:\tlearn: 70205.7187879\ttotal: 1.24s\tremaining: 16.5s\n",
      "70:\tlearn: 70189.8446667\ttotal: 1.25s\tremaining: 16.3s\n",
      "71:\tlearn: 70024.9347951\ttotal: 1.26s\tremaining: 16.3s\n",
      "72:\tlearn: 70009.2352283\ttotal: 1.28s\tremaining: 16.2s\n",
      "73:\tlearn: 69825.2026444\ttotal: 1.3s\tremaining: 16.2s\n",
      "74:\tlearn: 69774.9232435\ttotal: 1.31s\tremaining: 16.2s\n",
      "75:\tlearn: 69764.3786713\ttotal: 1.32s\tremaining: 16.1s\n",
      "76:\tlearn: 69748.7093126\ttotal: 1.37s\tremaining: 16.4s\n",
      "77:\tlearn: 69732.7741108\ttotal: 1.38s\tremaining: 16.3s\n",
      "78:\tlearn: 69707.1214602\ttotal: 1.41s\tremaining: 16.4s\n",
      "79:\tlearn: 69698.0997532\ttotal: 1.41s\tremaining: 16.3s\n",
      "80:\tlearn: 69681.3971487\ttotal: 1.43s\tremaining: 16.2s\n",
      "81:\tlearn: 69674.0977503\ttotal: 1.44s\tremaining: 16.2s\n",
      "82:\tlearn: 69660.2976747\ttotal: 1.46s\tremaining: 16.1s\n",
      "83:\tlearn: 69651.5193871\ttotal: 1.46s\tremaining: 16s\n",
      "84:\tlearn: 69618.4570284\ttotal: 1.48s\tremaining: 15.9s\n",
      "85:\tlearn: 69610.7045760\ttotal: 1.49s\tremaining: 15.9s\n",
      "86:\tlearn: 69508.2847009\ttotal: 1.51s\tremaining: 15.9s\n",
      "87:\tlearn: 69502.3289362\ttotal: 1.53s\tremaining: 15.9s\n",
      "88:\tlearn: 69495.1261585\ttotal: 1.55s\tremaining: 15.8s\n",
      "89:\tlearn: 69315.1751850\ttotal: 1.66s\tremaining: 16.8s\n",
      "90:\tlearn: 69301.1089748\ttotal: 1.7s\tremaining: 17s\n",
      "91:\tlearn: 69253.7116347\ttotal: 1.73s\tremaining: 17.1s\n",
      "92:\tlearn: 69123.4606491\ttotal: 1.74s\tremaining: 17s\n",
      "93:\tlearn: 68994.2522134\ttotal: 1.79s\tremaining: 17.2s\n",
      "94:\tlearn: 68988.0580214\ttotal: 1.79s\tremaining: 17.1s\n",
      "95:\tlearn: 68951.6859565\ttotal: 1.81s\tremaining: 17s\n",
      "96:\tlearn: 68833.6073076\ttotal: 1.83s\tremaining: 17.1s\n",
      "97:\tlearn: 68724.5825430\ttotal: 1.84s\tremaining: 17s\n",
      "98:\tlearn: 68699.1525511\ttotal: 1.86s\tremaining: 16.9s\n",
      "99:\tlearn: 68631.4999249\ttotal: 1.87s\tremaining: 16.9s\n",
      "100:\tlearn: 68494.0094621\ttotal: 1.89s\tremaining: 16.8s\n",
      "101:\tlearn: 68392.6922660\ttotal: 1.9s\tremaining: 16.7s\n",
      "102:\tlearn: 68384.0313400\ttotal: 1.91s\tremaining: 16.6s\n",
      "103:\tlearn: 68301.2297593\ttotal: 1.93s\tremaining: 16.6s\n",
      "104:\tlearn: 68297.3536719\ttotal: 1.94s\tremaining: 16.5s\n",
      "105:\tlearn: 68244.0428861\ttotal: 1.95s\tremaining: 16.5s\n",
      "106:\tlearn: 68211.1938189\ttotal: 1.98s\tremaining: 16.5s\n",
      "107:\tlearn: 68201.0293124\ttotal: 2s\tremaining: 16.5s\n",
      "108:\tlearn: 68171.5098930\ttotal: 2.01s\tremaining: 16.4s\n",
      "109:\tlearn: 68168.0304690\ttotal: 2.02s\tremaining: 16.4s\n",
      "110:\tlearn: 68096.3950463\ttotal: 2.03s\tremaining: 16.3s\n",
      "111:\tlearn: 68084.3181874\ttotal: 2.05s\tremaining: 16.2s\n",
      "112:\tlearn: 68067.9101105\ttotal: 2.06s\tremaining: 16.1s\n",
      "113:\tlearn: 68063.5699615\ttotal: 2.07s\tremaining: 16.1s\n",
      "114:\tlearn: 68057.5069438\ttotal: 2.08s\tremaining: 16s\n",
      "115:\tlearn: 68002.3797615\ttotal: 2.1s\tremaining: 16s\n",
      "116:\tlearn: 67943.8018632\ttotal: 2.11s\tremaining: 15.9s\n",
      "117:\tlearn: 67852.7931389\ttotal: 2.13s\tremaining: 15.9s\n",
      "118:\tlearn: 67737.9136446\ttotal: 2.15s\tremaining: 15.9s\n",
      "119:\tlearn: 67668.2251666\ttotal: 2.16s\tremaining: 15.8s\n",
      "120:\tlearn: 67656.1192489\ttotal: 2.17s\tremaining: 15.8s\n",
      "121:\tlearn: 67627.3643527\ttotal: 2.21s\tremaining: 15.9s\n",
      "122:\tlearn: 67611.8370994\ttotal: 2.23s\tremaining: 15.9s\n",
      "123:\tlearn: 67592.3255766\ttotal: 2.24s\tremaining: 15.8s\n",
      "124:\tlearn: 67546.3037704\ttotal: 2.25s\tremaining: 15.8s\n",
      "125:\tlearn: 67487.2934224\ttotal: 2.27s\tremaining: 15.7s\n",
      "126:\tlearn: 67406.3323612\ttotal: 2.28s\tremaining: 15.7s\n",
      "127:\tlearn: 67402.8706086\ttotal: 2.29s\tremaining: 15.6s\n",
      "128:\tlearn: 67399.7701997\ttotal: 2.3s\tremaining: 15.5s\n",
      "129:\tlearn: 67391.8259896\ttotal: 2.32s\tremaining: 15.5s\n",
      "130:\tlearn: 67384.8912197\ttotal: 2.33s\tremaining: 15.4s\n",
      "131:\tlearn: 67274.8997127\ttotal: 2.34s\tremaining: 15.4s\n",
      "132:\tlearn: 67196.3224926\ttotal: 2.35s\tremaining: 15.3s\n",
      "133:\tlearn: 67161.5247852\ttotal: 2.37s\tremaining: 15.3s\n",
      "134:\tlearn: 67088.4512890\ttotal: 2.38s\tremaining: 15.3s\n",
      "135:\tlearn: 67055.0822073\ttotal: 2.4s\tremaining: 15.3s\n",
      "136:\tlearn: 67051.4455415\ttotal: 2.42s\tremaining: 15.3s\n",
      "137:\tlearn: 67048.7265917\ttotal: 2.44s\tremaining: 15.2s\n",
      "138:\tlearn: 66956.4605190\ttotal: 2.45s\tremaining: 15.2s\n",
      "139:\tlearn: 66915.0121288\ttotal: 2.46s\tremaining: 15.1s\n",
      "140:\tlearn: 66780.9600113\ttotal: 2.48s\tremaining: 15.1s\n",
      "141:\tlearn: 66657.1109845\ttotal: 2.49s\tremaining: 15.1s\n",
      "142:\tlearn: 66592.3664066\ttotal: 2.5s\tremaining: 15s\n",
      "143:\tlearn: 66586.0092210\ttotal: 2.51s\tremaining: 14.9s\n",
      "144:\tlearn: 66545.3341544\ttotal: 2.53s\tremaining: 14.9s\n",
      "145:\tlearn: 66524.0071273\ttotal: 2.55s\tremaining: 14.9s\n",
      "146:\tlearn: 66466.1840807\ttotal: 2.56s\tremaining: 14.9s\n",
      "147:\tlearn: 66378.5989232\ttotal: 2.58s\tremaining: 14.8s\n",
      "148:\tlearn: 66295.2780872\ttotal: 2.59s\tremaining: 14.8s\n",
      "149:\tlearn: 66215.7961895\ttotal: 2.61s\tremaining: 14.8s\n",
      "150:\tlearn: 66150.6244261\ttotal: 2.62s\tremaining: 14.7s\n",
      "151:\tlearn: 66145.7099030\ttotal: 2.66s\tremaining: 14.8s\n",
      "152:\tlearn: 66143.0340503\ttotal: 2.67s\tremaining: 14.8s\n",
      "153:\tlearn: 66070.0201172\ttotal: 2.69s\tremaining: 14.8s\n",
      "154:\tlearn: 65988.8387779\ttotal: 2.71s\tremaining: 14.7s\n",
      "155:\tlearn: 65972.2356459\ttotal: 2.72s\tremaining: 14.7s\n",
      "156:\tlearn: 65970.0769737\ttotal: 2.73s\tremaining: 14.6s\n",
      "157:\tlearn: 65866.6641856\ttotal: 2.74s\tremaining: 14.6s\n",
      "158:\tlearn: 65786.8716980\ttotal: 2.75s\tremaining: 14.6s\n",
      "159:\tlearn: 65725.2998568\ttotal: 2.77s\tremaining: 14.6s\n",
      "160:\tlearn: 65668.1531002\ttotal: 2.78s\tremaining: 14.5s\n",
      "161:\tlearn: 65614.7348641\ttotal: 2.81s\tremaining: 14.5s\n",
      "162:\tlearn: 65564.4050638\ttotal: 2.82s\tremaining: 14.5s\n",
      "163:\tlearn: 65499.0776539\ttotal: 2.92s\tremaining: 14.9s\n",
      "164:\tlearn: 65496.4191686\ttotal: 2.94s\tremaining: 14.9s\n",
      "165:\tlearn: 65494.3563448\ttotal: 2.96s\tremaining: 14.8s\n",
      "166:\tlearn: 65466.6388282\ttotal: 2.97s\tremaining: 14.8s\n",
      "167:\tlearn: 65437.6081137\ttotal: 2.99s\tremaining: 14.8s\n",
      "168:\tlearn: 65378.2680232\ttotal: 3s\tremaining: 14.7s\n",
      "169:\tlearn: 65376.3123506\ttotal: 3s\tremaining: 14.7s\n",
      "170:\tlearn: 65278.8218692\ttotal: 3.02s\tremaining: 14.7s\n",
      "171:\tlearn: 65236.3552951\ttotal: 3.04s\tremaining: 14.6s\n",
      "172:\tlearn: 65166.0646595\ttotal: 3.07s\tremaining: 14.7s\n",
      "173:\tlearn: 65108.2766439\ttotal: 3.09s\tremaining: 14.7s\n",
      "174:\tlearn: 65082.2916479\ttotal: 3.1s\tremaining: 14.6s\n",
      "175:\tlearn: 65055.9474755\ttotal: 3.11s\tremaining: 14.6s\n",
      "176:\tlearn: 64967.1244000\ttotal: 3.12s\tremaining: 14.5s\n",
      "177:\tlearn: 64917.4940171\ttotal: 3.14s\tremaining: 14.5s\n",
      "178:\tlearn: 64888.0763778\ttotal: 3.15s\tremaining: 14.5s\n",
      "179:\tlearn: 64882.0591899\ttotal: 3.17s\tremaining: 14.4s\n",
      "180:\tlearn: 64864.7457787\ttotal: 3.18s\tremaining: 14.4s\n",
      "181:\tlearn: 64818.1312651\ttotal: 3.2s\tremaining: 14.4s\n",
      "182:\tlearn: 64804.5199110\ttotal: 3.2s\tremaining: 14.3s\n",
      "183:\tlearn: 64801.8783332\ttotal: 3.22s\tremaining: 14.3s\n",
      "184:\tlearn: 64759.2511164\ttotal: 3.23s\tremaining: 14.2s\n",
      "185:\tlearn: 64744.8582597\ttotal: 3.24s\tremaining: 14.2s\n",
      "186:\tlearn: 64743.2693443\ttotal: 3.25s\tremaining: 14.1s\n",
      "187:\tlearn: 64718.4519957\ttotal: 3.26s\tremaining: 14.1s\n",
      "188:\tlearn: 64716.4825484\ttotal: 3.28s\tremaining: 14.1s\n",
      "189:\tlearn: 64709.9305467\ttotal: 3.3s\tremaining: 14.1s\n",
      "190:\tlearn: 64696.1153052\ttotal: 3.32s\tremaining: 14.1s\n",
      "191:\tlearn: 64668.6280834\ttotal: 3.35s\tremaining: 14.1s\n",
      "192:\tlearn: 64587.4926041\ttotal: 3.37s\tremaining: 14.1s\n",
      "193:\tlearn: 64571.4144509\ttotal: 3.38s\tremaining: 14s\n",
      "194:\tlearn: 64510.8667871\ttotal: 3.39s\tremaining: 14s\n",
      "195:\tlearn: 64467.7882308\ttotal: 3.41s\tremaining: 14s\n",
      "196:\tlearn: 64421.3648195\ttotal: 3.42s\tremaining: 13.9s\n",
      "197:\tlearn: 64393.8507766\ttotal: 3.43s\tremaining: 13.9s\n",
      "198:\tlearn: 64303.5176970\ttotal: 3.45s\tremaining: 13.9s\n",
      "199:\tlearn: 64262.3143687\ttotal: 3.46s\tremaining: 13.8s\n",
      "200:\tlearn: 64250.6820655\ttotal: 3.47s\tremaining: 13.8s\n",
      "201:\tlearn: 64217.3200477\ttotal: 3.48s\tremaining: 13.8s\n",
      "202:\tlearn: 64215.0140671\ttotal: 3.5s\tremaining: 13.7s\n",
      "203:\tlearn: 64109.2127433\ttotal: 3.54s\tremaining: 13.8s\n",
      "204:\tlearn: 64103.7238470\ttotal: 3.54s\tremaining: 13.8s\n",
      "205:\tlearn: 64101.6909981\ttotal: 3.56s\tremaining: 13.7s\n",
      "206:\tlearn: 64097.8598984\ttotal: 3.56s\tremaining: 13.7s\n",
      "207:\tlearn: 64085.5628466\ttotal: 3.58s\tremaining: 13.6s\n",
      "208:\tlearn: 64073.7322806\ttotal: 3.6s\tremaining: 13.6s\n",
      "209:\tlearn: 64060.4230663\ttotal: 3.61s\tremaining: 13.6s\n",
      "210:\tlearn: 64037.2900327\ttotal: 3.62s\tremaining: 13.5s\n",
      "211:\tlearn: 64033.4824163\ttotal: 3.63s\tremaining: 13.5s\n",
      "212:\tlearn: 63991.5589804\ttotal: 3.64s\tremaining: 13.5s\n",
      "213:\tlearn: 63988.3891661\ttotal: 3.66s\tremaining: 13.4s\n",
      "214:\tlearn: 63982.5467557\ttotal: 3.66s\tremaining: 13.4s\n",
      "215:\tlearn: 63979.5317122\ttotal: 3.67s\tremaining: 13.3s\n",
      "216:\tlearn: 63883.0391755\ttotal: 3.7s\tremaining: 13.3s\n",
      "217:\tlearn: 63879.6750779\ttotal: 3.71s\tremaining: 13.3s\n",
      "218:\tlearn: 63878.1036835\ttotal: 3.73s\tremaining: 13.3s\n",
      "219:\tlearn: 63853.0421381\ttotal: 3.75s\tremaining: 13.3s\n",
      "220:\tlearn: 63842.3252611\ttotal: 3.77s\tremaining: 13.3s\n",
      "221:\tlearn: 63830.0682508\ttotal: 3.78s\tremaining: 13.2s\n",
      "222:\tlearn: 63819.6491881\ttotal: 3.79s\tremaining: 13.2s\n",
      "223:\tlearn: 63810.3396780\ttotal: 3.81s\tremaining: 13.2s\n",
      "224:\tlearn: 63749.4592256\ttotal: 3.82s\tremaining: 13.2s\n",
      "225:\tlearn: 63747.9218905\ttotal: 3.83s\tremaining: 13.1s\n",
      "226:\tlearn: 63681.5401605\ttotal: 3.85s\tremaining: 13.1s\n",
      "227:\tlearn: 63656.2068869\ttotal: 3.85s\tremaining: 13.1s\n",
      "228:\tlearn: 63529.7850908\ttotal: 3.87s\tremaining: 13s\n",
      "229:\tlearn: 63491.8836373\ttotal: 3.88s\tremaining: 13s\n",
      "230:\tlearn: 63480.6157039\ttotal: 3.9s\tremaining: 13s\n",
      "231:\tlearn: 63458.0520749\ttotal: 3.91s\tremaining: 12.9s\n",
      "232:\tlearn: 63455.2752120\ttotal: 3.92s\tremaining: 12.9s\n",
      "233:\tlearn: 63390.9967631\ttotal: 3.95s\tremaining: 12.9s\n",
      "234:\tlearn: 63378.7274891\ttotal: 4.05s\tremaining: 13.2s\n",
      "235:\tlearn: 63372.4012291\ttotal: 4.07s\tremaining: 13.2s\n",
      "236:\tlearn: 63350.1013843\ttotal: 4.08s\tremaining: 13.2s\n",
      "237:\tlearn: 63336.8080924\ttotal: 4.1s\tremaining: 13.1s\n",
      "238:\tlearn: 63301.7528391\ttotal: 4.12s\tremaining: 13.1s\n",
      "239:\tlearn: 63292.4638903\ttotal: 4.13s\tremaining: 13.1s\n",
      "240:\tlearn: 63285.4387651\ttotal: 4.14s\tremaining: 13.1s\n",
      "241:\tlearn: 63228.7539897\ttotal: 4.16s\tremaining: 13s\n",
      "242:\tlearn: 63220.2780455\ttotal: 4.18s\tremaining: 13s\n",
      "243:\tlearn: 63211.6902893\ttotal: 4.21s\tremaining: 13s\n",
      "244:\tlearn: 63203.7333581\ttotal: 4.21s\tremaining: 13s\n",
      "245:\tlearn: 63201.2976304\ttotal: 4.23s\tremaining: 13s\n",
      "246:\tlearn: 63199.0453408\ttotal: 4.25s\tremaining: 12.9s\n",
      "247:\tlearn: 63184.0894967\ttotal: 4.26s\tremaining: 12.9s\n",
      "248:\tlearn: 63125.8927191\ttotal: 4.27s\tremaining: 12.9s\n",
      "249:\tlearn: 63123.9921482\ttotal: 4.28s\tremaining: 12.8s\n",
      "250:\tlearn: 63023.2162481\ttotal: 4.29s\tremaining: 12.8s\n",
      "251:\tlearn: 63003.5263623\ttotal: 4.31s\tremaining: 12.8s\n",
      "252:\tlearn: 62971.0499175\ttotal: 4.32s\tremaining: 12.8s\n",
      "253:\tlearn: 62969.2968393\ttotal: 4.33s\tremaining: 12.7s\n",
      "254:\tlearn: 62935.4337894\ttotal: 4.34s\tremaining: 12.7s\n",
      "255:\tlearn: 62927.9997155\ttotal: 4.36s\tremaining: 12.7s\n",
      "256:\tlearn: 62926.6362059\ttotal: 4.38s\tremaining: 12.7s\n",
      "257:\tlearn: 62917.6271821\ttotal: 4.39s\tremaining: 12.6s\n",
      "258:\tlearn: 62846.3407207\ttotal: 4.42s\tremaining: 12.7s\n",
      "259:\tlearn: 62840.5497357\ttotal: 4.44s\tremaining: 12.6s\n",
      "260:\tlearn: 62759.5239592\ttotal: 4.45s\tremaining: 12.6s\n",
      "261:\tlearn: 62743.2578636\ttotal: 4.46s\tremaining: 12.6s\n",
      "262:\tlearn: 62718.8308186\ttotal: 4.48s\tremaining: 12.5s\n",
      "263:\tlearn: 62643.2003721\ttotal: 4.5s\tremaining: 12.5s\n",
      "264:\tlearn: 62593.3583129\ttotal: 4.52s\tremaining: 12.5s\n",
      "265:\tlearn: 62525.0605656\ttotal: 4.52s\tremaining: 12.5s\n",
      "266:\tlearn: 62516.5532105\ttotal: 4.54s\tremaining: 12.5s\n",
      "267:\tlearn: 62455.6651413\ttotal: 4.55s\tremaining: 12.4s\n",
      "268:\tlearn: 62405.3579651\ttotal: 4.57s\tremaining: 12.4s\n",
      "269:\tlearn: 62335.3147192\ttotal: 4.58s\tremaining: 12.4s\n",
      "270:\tlearn: 62292.6891142\ttotal: 4.59s\tremaining: 12.3s\n",
      "271:\tlearn: 62289.1301986\ttotal: 4.62s\tremaining: 12.4s\n",
      "272:\tlearn: 62240.5676549\ttotal: 4.64s\tremaining: 12.4s\n",
      "273:\tlearn: 62193.7412148\ttotal: 4.65s\tremaining: 12.3s\n",
      "274:\tlearn: 62115.7325139\ttotal: 4.67s\tremaining: 12.3s\n",
      "275:\tlearn: 62092.1085146\ttotal: 4.68s\tremaining: 12.3s\n",
      "276:\tlearn: 62044.4324242\ttotal: 4.69s\tremaining: 12.2s\n",
      "277:\tlearn: 62037.6958442\ttotal: 4.72s\tremaining: 12.3s\n",
      "278:\tlearn: 62015.0007077\ttotal: 4.74s\tremaining: 12.2s\n",
      "279:\tlearn: 61936.9959560\ttotal: 4.75s\tremaining: 12.2s\n",
      "280:\tlearn: 61914.6650462\ttotal: 4.77s\tremaining: 12.2s\n",
      "281:\tlearn: 61911.4116262\ttotal: 4.78s\tremaining: 12.2s\n",
      "282:\tlearn: 61883.8729447\ttotal: 4.8s\tremaining: 12.2s\n",
      "283:\tlearn: 61815.9980835\ttotal: 4.83s\tremaining: 12.2s\n",
      "284:\tlearn: 61794.2847868\ttotal: 4.85s\tremaining: 12.2s\n",
      "285:\tlearn: 61779.2786892\ttotal: 4.87s\tremaining: 12.2s\n",
      "286:\tlearn: 61761.0668076\ttotal: 4.91s\tremaining: 12.2s\n",
      "287:\tlearn: 61693.6945551\ttotal: 4.94s\tremaining: 12.2s\n",
      "288:\tlearn: 61654.2962832\ttotal: 4.95s\tremaining: 12.2s\n",
      "289:\tlearn: 61588.7947826\ttotal: 4.97s\tremaining: 12.2s\n",
      "290:\tlearn: 61515.5920558\ttotal: 5s\tremaining: 12.2s\n",
      "291:\tlearn: 61452.4030730\ttotal: 5.02s\tremaining: 12.2s\n",
      "292:\tlearn: 61413.5806733\ttotal: 5.04s\tremaining: 12.2s\n",
      "293:\tlearn: 61352.6473888\ttotal: 5.15s\tremaining: 12.4s\n",
      "294:\tlearn: 61283.0025133\ttotal: 5.17s\tremaining: 12.4s\n",
      "295:\tlearn: 61264.8468704\ttotal: 5.18s\tremaining: 12.3s\n",
      "296:\tlearn: 61219.8305006\ttotal: 5.2s\tremaining: 12.3s\n",
      "297:\tlearn: 61177.0344522\ttotal: 5.21s\tremaining: 12.3s\n",
      "298:\tlearn: 61174.3006122\ttotal: 5.22s\tremaining: 12.2s\n",
      "299:\tlearn: 61135.6076057\ttotal: 5.27s\tremaining: 12.3s\n",
      "300:\tlearn: 61070.8322621\ttotal: 5.29s\tremaining: 12.3s\n",
      "301:\tlearn: 61068.3642255\ttotal: 5.3s\tremaining: 12.3s\n",
      "302:\tlearn: 61034.4770512\ttotal: 5.31s\tremaining: 12.2s\n",
      "303:\tlearn: 61008.2934917\ttotal: 5.33s\tremaining: 12.2s\n",
      "304:\tlearn: 60975.6273011\ttotal: 5.33s\tremaining: 12.2s\n",
      "305:\tlearn: 60916.5713109\ttotal: 5.36s\tremaining: 12.1s\n",
      "306:\tlearn: 60885.7191504\ttotal: 5.37s\tremaining: 12.1s\n",
      "307:\tlearn: 60874.2405170\ttotal: 5.38s\tremaining: 12.1s\n",
      "308:\tlearn: 60867.0676193\ttotal: 5.39s\tremaining: 12.1s\n",
      "309:\tlearn: 60860.7272071\ttotal: 5.41s\tremaining: 12s\n",
      "310:\tlearn: 60842.1896339\ttotal: 5.42s\tremaining: 12s\n",
      "311:\tlearn: 60811.7639800\ttotal: 5.44s\tremaining: 12s\n",
      "312:\tlearn: 60750.5836250\ttotal: 5.45s\tremaining: 12s\n",
      "313:\tlearn: 60691.6364159\ttotal: 5.47s\tremaining: 12s\n",
      "314:\tlearn: 60675.4266600\ttotal: 5.5s\tremaining: 12s\n",
      "315:\tlearn: 60649.3643142\ttotal: 5.52s\tremaining: 12s\n",
      "316:\tlearn: 60586.4910220\ttotal: 5.54s\tremaining: 11.9s\n",
      "317:\tlearn: 60529.2837174\ttotal: 5.56s\tremaining: 11.9s\n",
      "318:\tlearn: 60474.1297092\ttotal: 5.58s\tremaining: 11.9s\n",
      "319:\tlearn: 60433.2456389\ttotal: 5.59s\tremaining: 11.9s\n",
      "320:\tlearn: 60380.0333168\ttotal: 5.6s\tremaining: 11.9s\n",
      "321:\tlearn: 60324.3445561\ttotal: 5.62s\tremaining: 11.8s\n",
      "322:\tlearn: 60282.5022132\ttotal: 5.63s\tremaining: 11.8s\n",
      "323:\tlearn: 60277.0421846\ttotal: 5.64s\tremaining: 11.8s\n",
      "324:\tlearn: 60271.8306586\ttotal: 5.65s\tremaining: 11.7s\n",
      "325:\tlearn: 60258.5470332\ttotal: 5.67s\tremaining: 11.7s\n",
      "326:\tlearn: 60253.6982412\ttotal: 5.68s\tremaining: 11.7s\n",
      "327:\tlearn: 60173.3102407\ttotal: 5.7s\tremaining: 11.7s\n",
      "328:\tlearn: 60143.0897478\ttotal: 5.72s\tremaining: 11.7s\n",
      "329:\tlearn: 60091.6304890\ttotal: 5.75s\tremaining: 11.7s\n",
      "330:\tlearn: 60042.0083426\ttotal: 5.76s\tremaining: 11.6s\n",
      "331:\tlearn: 60003.5719941\ttotal: 5.77s\tremaining: 11.6s\n",
      "332:\tlearn: 59960.9610430\ttotal: 5.79s\tremaining: 11.6s\n",
      "333:\tlearn: 59935.8058949\ttotal: 5.8s\tremaining: 11.6s\n",
      "334:\tlearn: 59897.6722079\ttotal: 5.82s\tremaining: 11.6s\n",
      "335:\tlearn: 59852.5567053\ttotal: 5.83s\tremaining: 11.5s\n",
      "336:\tlearn: 59816.8507386\ttotal: 5.84s\tremaining: 11.5s\n",
      "337:\tlearn: 59787.8224656\ttotal: 5.86s\tremaining: 11.5s\n",
      "338:\tlearn: 59782.7357425\ttotal: 5.88s\tremaining: 11.5s\n",
      "339:\tlearn: 59706.5365809\ttotal: 5.89s\tremaining: 11.4s\n",
      "340:\tlearn: 59663.9755491\ttotal: 5.9s\tremaining: 11.4s\n",
      "341:\tlearn: 59624.9570523\ttotal: 5.92s\tremaining: 11.4s\n",
      "342:\tlearn: 59589.4354431\ttotal: 5.93s\tremaining: 11.4s\n",
      "343:\tlearn: 59581.9783992\ttotal: 5.95s\tremaining: 11.3s\n",
      "344:\tlearn: 59534.3512664\ttotal: 5.98s\tremaining: 11.4s\n",
      "345:\tlearn: 59527.5875743\ttotal: 5.99s\tremaining: 11.3s\n",
      "346:\tlearn: 59479.4076966\ttotal: 6s\tremaining: 11.3s\n",
      "347:\tlearn: 59455.8788643\ttotal: 6.02s\tremaining: 11.3s\n",
      "348:\tlearn: 59427.8718126\ttotal: 6.03s\tremaining: 11.3s\n",
      "349:\tlearn: 59355.3573395\ttotal: 6.05s\tremaining: 11.2s\n",
      "350:\tlearn: 59335.7835297\ttotal: 6.06s\tremaining: 11.2s\n",
      "351:\tlearn: 59266.4461004\ttotal: 6.08s\tremaining: 11.2s\n",
      "352:\tlearn: 59225.3442421\ttotal: 6.09s\tremaining: 11.2s\n",
      "353:\tlearn: 59186.9961955\ttotal: 6.11s\tremaining: 11.1s\n",
      "354:\tlearn: 59120.5660027\ttotal: 6.13s\tremaining: 11.1s\n",
      "355:\tlearn: 59097.4589703\ttotal: 6.23s\tremaining: 11.3s\n",
      "356:\tlearn: 59047.8610982\ttotal: 6.26s\tremaining: 11.3s\n",
      "357:\tlearn: 59023.7085084\ttotal: 6.29s\tremaining: 11.3s\n",
      "358:\tlearn: 59003.7245522\ttotal: 6.31s\tremaining: 11.3s\n",
      "359:\tlearn: 58957.1192782\ttotal: 6.32s\tremaining: 11.2s\n",
      "360:\tlearn: 58947.0374585\ttotal: 6.33s\tremaining: 11.2s\n",
      "361:\tlearn: 58916.6860582\ttotal: 6.34s\tremaining: 11.2s\n",
      "362:\tlearn: 58895.0458847\ttotal: 6.36s\tremaining: 11.2s\n",
      "363:\tlearn: 58832.6631955\ttotal: 6.38s\tremaining: 11.1s\n",
      "364:\tlearn: 58787.6143909\ttotal: 6.4s\tremaining: 11.1s\n",
      "365:\tlearn: 58743.5587304\ttotal: 6.43s\tremaining: 11.1s\n",
      "366:\tlearn: 58734.1035815\ttotal: 6.45s\tremaining: 11.1s\n",
      "367:\tlearn: 58692.1477420\ttotal: 6.47s\tremaining: 11.1s\n",
      "368:\tlearn: 58653.4844111\ttotal: 6.49s\tremaining: 11.1s\n",
      "369:\tlearn: 58614.6558872\ttotal: 6.51s\tremaining: 11.1s\n",
      "370:\tlearn: 58572.1810967\ttotal: 6.52s\tremaining: 11.1s\n",
      "371:\tlearn: 58497.8757942\ttotal: 6.54s\tremaining: 11s\n",
      "372:\tlearn: 58480.4812374\ttotal: 6.55s\tremaining: 11s\n",
      "373:\tlearn: 58439.8680498\ttotal: 6.58s\tremaining: 11s\n",
      "374:\tlearn: 58436.7420753\ttotal: 6.62s\tremaining: 11s\n",
      "375:\tlearn: 58428.5136440\ttotal: 6.64s\tremaining: 11s\n",
      "376:\tlearn: 58397.3588762\ttotal: 6.66s\tremaining: 11s\n",
      "377:\tlearn: 58333.3301435\ttotal: 6.68s\tremaining: 11s\n",
      "378:\tlearn: 58306.5850669\ttotal: 6.7s\tremaining: 11s\n",
      "379:\tlearn: 58275.3485814\ttotal: 6.71s\tremaining: 10.9s\n",
      "380:\tlearn: 58206.9380095\ttotal: 6.73s\tremaining: 10.9s\n",
      "381:\tlearn: 58189.3058401\ttotal: 6.74s\tremaining: 10.9s\n",
      "382:\tlearn: 58163.0726967\ttotal: 6.76s\tremaining: 10.9s\n",
      "383:\tlearn: 58143.9000213\ttotal: 6.78s\tremaining: 10.9s\n",
      "384:\tlearn: 58083.0341695\ttotal: 6.81s\tremaining: 10.9s\n",
      "385:\tlearn: 58070.0694726\ttotal: 6.83s\tremaining: 10.9s\n",
      "386:\tlearn: 58063.0487625\ttotal: 6.84s\tremaining: 10.8s\n",
      "387:\tlearn: 58058.0546670\ttotal: 6.86s\tremaining: 10.8s\n",
      "388:\tlearn: 58047.3732193\ttotal: 6.88s\tremaining: 10.8s\n",
      "389:\tlearn: 57975.2992500\ttotal: 6.89s\tremaining: 10.8s\n",
      "390:\tlearn: 57959.3063866\ttotal: 6.91s\tremaining: 10.8s\n",
      "391:\tlearn: 57952.7394069\ttotal: 6.93s\tremaining: 10.7s\n",
      "392:\tlearn: 57914.3561017\ttotal: 6.94s\tremaining: 10.7s\n",
      "393:\tlearn: 57913.0333026\ttotal: 6.96s\tremaining: 10.7s\n",
      "394:\tlearn: 57876.0028572\ttotal: 6.97s\tremaining: 10.7s\n",
      "395:\tlearn: 57851.9093551\ttotal: 6.99s\tremaining: 10.7s\n",
      "396:\tlearn: 57790.2102638\ttotal: 7.01s\tremaining: 10.7s\n",
      "397:\tlearn: 57787.8855883\ttotal: 7.03s\tremaining: 10.6s\n",
      "398:\tlearn: 57780.3634164\ttotal: 7.05s\tremaining: 10.6s\n",
      "399:\tlearn: 57731.4922218\ttotal: 7.07s\tremaining: 10.6s\n",
      "400:\tlearn: 57670.5059366\ttotal: 7.09s\tremaining: 10.6s\n",
      "401:\tlearn: 57641.0331970\ttotal: 7.11s\tremaining: 10.6s\n",
      "402:\tlearn: 57570.1796758\ttotal: 7.12s\tremaining: 10.6s\n",
      "403:\tlearn: 57510.9382229\ttotal: 7.14s\tremaining: 10.5s\n",
      "404:\tlearn: 57483.9064834\ttotal: 7.16s\tremaining: 10.5s\n",
      "405:\tlearn: 57456.6389989\ttotal: 7.17s\tremaining: 10.5s\n",
      "406:\tlearn: 57420.6475067\ttotal: 7.19s\tremaining: 10.5s\n",
      "407:\tlearn: 57404.9989081\ttotal: 7.21s\tremaining: 10.5s\n",
      "408:\tlearn: 57370.2666005\ttotal: 7.22s\tremaining: 10.4s\n",
      "409:\tlearn: 57366.0696919\ttotal: 7.33s\tremaining: 10.5s\n",
      "410:\tlearn: 57344.1322631\ttotal: 7.38s\tremaining: 10.6s\n",
      "411:\tlearn: 57310.6096760\ttotal: 7.43s\tremaining: 10.6s\n",
      "412:\tlearn: 57279.3764082\ttotal: 7.44s\tremaining: 10.6s\n",
      "413:\tlearn: 57268.9944719\ttotal: 7.46s\tremaining: 10.6s\n",
      "414:\tlearn: 57260.4909877\ttotal: 7.47s\tremaining: 10.5s\n",
      "415:\tlearn: 57232.7439890\ttotal: 7.49s\tremaining: 10.5s\n",
      "416:\tlearn: 57196.5250815\ttotal: 7.5s\tremaining: 10.5s\n",
      "417:\tlearn: 57126.1143409\ttotal: 7.52s\tremaining: 10.5s\n",
      "418:\tlearn: 57093.6769780\ttotal: 7.54s\tremaining: 10.5s\n",
      "419:\tlearn: 57063.8751848\ttotal: 7.55s\tremaining: 10.4s\n",
      "420:\tlearn: 57032.0329176\ttotal: 7.58s\tremaining: 10.4s\n",
      "421:\tlearn: 57025.1507996\ttotal: 7.6s\tremaining: 10.4s\n",
      "422:\tlearn: 56994.9298621\ttotal: 7.62s\tremaining: 10.4s\n",
      "423:\tlearn: 56974.2434451\ttotal: 7.64s\tremaining: 10.4s\n",
      "424:\tlearn: 56917.5477848\ttotal: 7.66s\tremaining: 10.4s\n",
      "425:\tlearn: 56898.0095834\ttotal: 7.67s\tremaining: 10.3s\n",
      "426:\tlearn: 56829.7994912\ttotal: 7.69s\tremaining: 10.3s\n",
      "427:\tlearn: 56805.4928130\ttotal: 7.71s\tremaining: 10.3s\n",
      "428:\tlearn: 56781.6704735\ttotal: 7.72s\tremaining: 10.3s\n",
      "429:\tlearn: 56727.1414582\ttotal: 7.74s\tremaining: 10.3s\n",
      "430:\tlearn: 56724.7088511\ttotal: 7.75s\tremaining: 10.2s\n",
      "431:\tlearn: 56697.1718561\ttotal: 7.77s\tremaining: 10.2s\n",
      "432:\tlearn: 56679.2770255\ttotal: 7.81s\tremaining: 10.2s\n",
      "433:\tlearn: 56615.1735234\ttotal: 7.82s\tremaining: 10.2s\n",
      "434:\tlearn: 56604.8169275\ttotal: 7.84s\tremaining: 10.2s\n",
      "435:\tlearn: 56598.1357920\ttotal: 7.86s\tremaining: 10.2s\n",
      "436:\tlearn: 56580.1045398\ttotal: 7.87s\tremaining: 10.1s\n",
      "437:\tlearn: 56577.7616506\ttotal: 7.89s\tremaining: 10.1s\n",
      "438:\tlearn: 56536.2028486\ttotal: 7.9s\tremaining: 10.1s\n",
      "439:\tlearn: 56532.6701363\ttotal: 7.92s\tremaining: 10.1s\n",
      "440:\tlearn: 56471.9758698\ttotal: 7.93s\tremaining: 10.1s\n",
      "441:\tlearn: 56459.4039842\ttotal: 7.95s\tremaining: 10s\n",
      "442:\tlearn: 56419.5049521\ttotal: 7.97s\tremaining: 10s\n",
      "443:\tlearn: 56417.2500090\ttotal: 7.98s\tremaining: 9.99s\n",
      "444:\tlearn: 56394.2603517\ttotal: 8.02s\tremaining: 10s\n",
      "445:\tlearn: 56372.0212719\ttotal: 8.04s\tremaining: 9.98s\n",
      "446:\tlearn: 56342.5261469\ttotal: 8.05s\tremaining: 9.96s\n",
      "447:\tlearn: 56295.4461790\ttotal: 8.07s\tremaining: 9.95s\n",
      "448:\tlearn: 56266.9658170\ttotal: 8.09s\tremaining: 9.93s\n",
      "449:\tlearn: 56200.5239809\ttotal: 8.11s\tremaining: 9.92s\n",
      "450:\tlearn: 56180.4104406\ttotal: 8.13s\tremaining: 9.9s\n",
      "451:\tlearn: 56178.3058084\ttotal: 8.15s\tremaining: 9.88s\n",
      "452:\tlearn: 56150.7847699\ttotal: 8.17s\tremaining: 9.86s\n",
      "453:\tlearn: 56083.6717470\ttotal: 8.18s\tremaining: 9.84s\n",
      "454:\tlearn: 56067.2185758\ttotal: 8.21s\tremaining: 9.83s\n",
      "455:\tlearn: 56060.9810323\ttotal: 8.22s\tremaining: 9.81s\n",
      "456:\tlearn: 56034.0643698\ttotal: 8.24s\tremaining: 9.79s\n",
      "457:\tlearn: 56013.3324124\ttotal: 8.29s\tremaining: 9.81s\n",
      "458:\tlearn: 55991.6792901\ttotal: 8.31s\tremaining: 9.79s\n",
      "459:\tlearn: 55969.4486839\ttotal: 8.33s\tremaining: 9.77s\n",
      "460:\tlearn: 55947.9420261\ttotal: 8.34s\tremaining: 9.75s\n",
      "461:\tlearn: 55931.9250857\ttotal: 8.36s\tremaining: 9.73s\n",
      "462:\tlearn: 55924.1289875\ttotal: 8.38s\tremaining: 9.71s\n",
      "463:\tlearn: 55918.4194308\ttotal: 8.39s\tremaining: 9.69s\n",
      "464:\tlearn: 55883.8588723\ttotal: 8.41s\tremaining: 9.67s\n",
      "465:\tlearn: 55832.5396967\ttotal: 8.43s\tremaining: 9.66s\n",
      "466:\tlearn: 55798.9556326\ttotal: 8.44s\tremaining: 9.63s\n",
      "467:\tlearn: 55786.7464904\ttotal: 8.45s\tremaining: 9.6s\n",
      "468:\tlearn: 55766.0604146\ttotal: 8.47s\tremaining: 9.59s\n",
      "469:\tlearn: 55740.7409449\ttotal: 8.48s\tremaining: 9.56s\n",
      "470:\tlearn: 55716.2420463\ttotal: 8.6s\tremaining: 9.65s\n",
      "471:\tlearn: 55666.5448274\ttotal: 8.61s\tremaining: 9.63s\n",
      "472:\tlearn: 55641.8928868\ttotal: 8.62s\tremaining: 9.61s\n",
      "473:\tlearn: 55616.8213693\ttotal: 8.64s\tremaining: 9.58s\n",
      "474:\tlearn: 55608.6545626\ttotal: 8.65s\tremaining: 9.56s\n",
      "475:\tlearn: 55592.9524153\ttotal: 8.66s\tremaining: 9.54s\n",
      "476:\tlearn: 55573.8895311\ttotal: 8.68s\tremaining: 9.52s\n",
      "477:\tlearn: 55561.4968245\ttotal: 8.7s\tremaining: 9.5s\n",
      "478:\tlearn: 55535.8684472\ttotal: 8.73s\tremaining: 9.5s\n",
      "479:\tlearn: 55517.0056396\ttotal: 8.76s\tremaining: 9.48s\n",
      "480:\tlearn: 55495.7806400\ttotal: 8.76s\tremaining: 9.45s\n",
      "481:\tlearn: 55493.9888193\ttotal: 8.78s\tremaining: 9.43s\n",
      "482:\tlearn: 55470.6038856\ttotal: 8.79s\tremaining: 9.41s\n",
      "483:\tlearn: 55413.5391488\ttotal: 8.81s\tremaining: 9.39s\n",
      "484:\tlearn: 55399.7414275\ttotal: 8.82s\tremaining: 9.37s\n",
      "485:\tlearn: 55379.5068689\ttotal: 8.83s\tremaining: 9.34s\n",
      "486:\tlearn: 55377.8192422\ttotal: 8.84s\tremaining: 9.31s\n",
      "487:\tlearn: 55349.8343494\ttotal: 8.86s\tremaining: 9.29s\n",
      "488:\tlearn: 55327.2179871\ttotal: 8.87s\tremaining: 9.27s\n",
      "489:\tlearn: 55305.4002458\ttotal: 8.88s\tremaining: 9.24s\n",
      "490:\tlearn: 55261.2462104\ttotal: 8.91s\tremaining: 9.23s\n",
      "491:\tlearn: 55241.5624344\ttotal: 8.92s\tremaining: 9.21s\n",
      "492:\tlearn: 55230.4673494\ttotal: 8.94s\tremaining: 9.2s\n",
      "493:\tlearn: 55228.8545628\ttotal: 8.96s\tremaining: 9.18s\n",
      "494:\tlearn: 55213.0883681\ttotal: 8.98s\tremaining: 9.16s\n",
      "495:\tlearn: 55199.9199909\ttotal: 8.99s\tremaining: 9.14s\n",
      "496:\tlearn: 55181.8218499\ttotal: 9.01s\tremaining: 9.12s\n",
      "497:\tlearn: 55180.3037746\ttotal: 9.02s\tremaining: 9.1s\n",
      "498:\tlearn: 55156.7909136\ttotal: 9.04s\tremaining: 9.08s\n",
      "499:\tlearn: 55110.5848532\ttotal: 9.06s\tremaining: 9.06s\n",
      "500:\tlearn: 55084.2703063\ttotal: 9.07s\tremaining: 9.04s\n",
      "501:\tlearn: 55066.9789972\ttotal: 9.08s\tremaining: 9.01s\n",
      "502:\tlearn: 55043.0684972\ttotal: 9.09s\tremaining: 8.98s\n",
      "503:\tlearn: 54964.0197969\ttotal: 9.12s\tremaining: 8.98s\n",
      "504:\tlearn: 54945.7171639\ttotal: 9.15s\tremaining: 8.97s\n",
      "505:\tlearn: 54892.4310066\ttotal: 9.17s\tremaining: 8.95s\n",
      "506:\tlearn: 54881.2737839\ttotal: 9.18s\tremaining: 8.92s\n",
      "507:\tlearn: 54864.9806191\ttotal: 9.19s\tremaining: 8.9s\n",
      "508:\tlearn: 54856.4913931\ttotal: 9.2s\tremaining: 8.88s\n",
      "509:\tlearn: 54838.8386246\ttotal: 9.22s\tremaining: 8.86s\n",
      "510:\tlearn: 54778.5341406\ttotal: 9.24s\tremaining: 8.84s\n",
      "511:\tlearn: 54777.0907616\ttotal: 9.25s\tremaining: 8.81s\n",
      "512:\tlearn: 54738.3677618\ttotal: 9.26s\tremaining: 8.79s\n",
      "513:\tlearn: 54716.0172939\ttotal: 9.27s\tremaining: 8.77s\n",
      "514:\tlearn: 54693.6813848\ttotal: 9.29s\tremaining: 8.74s\n",
      "515:\tlearn: 54676.6386253\ttotal: 9.3s\tremaining: 8.72s\n",
      "516:\tlearn: 54662.1408910\ttotal: 9.31s\tremaining: 8.7s\n",
      "517:\tlearn: 54640.6708502\ttotal: 9.33s\tremaining: 8.68s\n",
      "518:\tlearn: 54623.6550901\ttotal: 9.35s\tremaining: 8.67s\n",
      "519:\tlearn: 54602.8632815\ttotal: 9.37s\tremaining: 8.65s\n",
      "520:\tlearn: 54578.4586459\ttotal: 9.39s\tremaining: 8.63s\n",
      "521:\tlearn: 54563.9698693\ttotal: 9.4s\tremaining: 8.61s\n",
      "522:\tlearn: 54531.4522249\ttotal: 9.41s\tremaining: 8.59s\n",
      "523:\tlearn: 54516.5193664\ttotal: 9.43s\tremaining: 8.57s\n",
      "524:\tlearn: 54505.4536254\ttotal: 9.44s\tremaining: 8.54s\n",
      "525:\tlearn: 54495.0950132\ttotal: 9.46s\tremaining: 8.52s\n",
      "526:\tlearn: 54489.5791571\ttotal: 9.47s\tremaining: 8.5s\n",
      "527:\tlearn: 54485.4448424\ttotal: 9.49s\tremaining: 8.48s\n",
      "528:\tlearn: 54441.0143704\ttotal: 9.5s\tremaining: 8.46s\n",
      "529:\tlearn: 54427.0294328\ttotal: 9.52s\tremaining: 8.44s\n",
      "530:\tlearn: 54348.5714477\ttotal: 9.53s\tremaining: 8.42s\n",
      "531:\tlearn: 54343.2712250\ttotal: 9.54s\tremaining: 8.4s\n",
      "532:\tlearn: 54284.3585525\ttotal: 9.56s\tremaining: 8.38s\n",
      "533:\tlearn: 54208.6686624\ttotal: 9.67s\tremaining: 8.44s\n",
      "534:\tlearn: 54134.9056922\ttotal: 9.68s\tremaining: 8.42s\n",
      "535:\tlearn: 54121.7403300\ttotal: 9.7s\tremaining: 8.39s\n",
      "536:\tlearn: 54048.4900527\ttotal: 9.71s\tremaining: 8.37s\n",
      "537:\tlearn: 54041.7394292\ttotal: 9.72s\tremaining: 8.35s\n",
      "538:\tlearn: 54025.1360690\ttotal: 9.74s\tremaining: 8.33s\n",
      "539:\tlearn: 54008.2299663\ttotal: 9.75s\tremaining: 8.31s\n",
      "540:\tlearn: 53951.7119472\ttotal: 9.76s\tremaining: 8.28s\n",
      "541:\tlearn: 53930.5135062\ttotal: 9.78s\tremaining: 8.27s\n",
      "542:\tlearn: 53910.4073401\ttotal: 9.99s\tremaining: 8.41s\n",
      "543:\tlearn: 53839.5798923\ttotal: 10.1s\tremaining: 8.46s\n",
      "544:\tlearn: 53824.1169889\ttotal: 10.4s\tremaining: 8.64s\n",
      "545:\tlearn: 53817.0104356\ttotal: 10.4s\tremaining: 8.64s\n",
      "546:\tlearn: 53748.6430257\ttotal: 10.6s\tremaining: 8.75s\n",
      "547:\tlearn: 53693.9017525\ttotal: 10.6s\tremaining: 8.73s\n",
      "548:\tlearn: 53687.9113344\ttotal: 10.6s\tremaining: 8.73s\n",
      "549:\tlearn: 53644.6486685\ttotal: 10.6s\tremaining: 8.71s\n",
      "550:\tlearn: 53638.3236940\ttotal: 10.6s\tremaining: 8.68s\n",
      "551:\tlearn: 53630.9786124\ttotal: 10.7s\tremaining: 8.65s\n",
      "552:\tlearn: 53616.0759576\ttotal: 10.7s\tremaining: 8.63s\n",
      "553:\tlearn: 53601.7234411\ttotal: 10.7s\tremaining: 8.61s\n",
      "554:\tlearn: 53582.6684579\ttotal: 10.7s\tremaining: 8.59s\n",
      "555:\tlearn: 53578.9613536\ttotal: 10.7s\tremaining: 8.56s\n",
      "556:\tlearn: 53562.8773350\ttotal: 10.7s\tremaining: 8.54s\n",
      "557:\tlearn: 53534.4269163\ttotal: 10.8s\tremaining: 8.52s\n",
      "558:\tlearn: 53468.2128681\ttotal: 10.8s\tremaining: 8.49s\n",
      "559:\tlearn: 53452.3766425\ttotal: 10.8s\tremaining: 8.47s\n",
      "560:\tlearn: 53435.7216122\ttotal: 10.9s\tremaining: 8.52s\n",
      "561:\tlearn: 53371.7966723\ttotal: 10.9s\tremaining: 8.5s\n",
      "562:\tlearn: 53353.5973976\ttotal: 10.9s\tremaining: 8.47s\n",
      "563:\tlearn: 53300.5184110\ttotal: 10.9s\tremaining: 8.45s\n",
      "564:\tlearn: 53292.8143418\ttotal: 11s\tremaining: 8.43s\n",
      "565:\tlearn: 53267.3042875\ttotal: 11s\tremaining: 8.41s\n",
      "566:\tlearn: 53250.3542747\ttotal: 11s\tremaining: 8.38s\n",
      "567:\tlearn: 53227.9788055\ttotal: 11s\tremaining: 8.36s\n",
      "568:\tlearn: 53221.1705353\ttotal: 11s\tremaining: 8.34s\n",
      "569:\tlearn: 53216.3435054\ttotal: 11s\tremaining: 8.33s\n",
      "570:\tlearn: 53208.6766024\ttotal: 11.1s\tremaining: 8.31s\n",
      "571:\tlearn: 53146.7886046\ttotal: 11.1s\tremaining: 8.29s\n",
      "572:\tlearn: 53126.4072103\ttotal: 11.1s\tremaining: 8.26s\n",
      "573:\tlearn: 53108.0855247\ttotal: 11.1s\tremaining: 8.24s\n",
      "574:\tlearn: 53101.2974285\ttotal: 11.1s\tremaining: 8.22s\n",
      "575:\tlearn: 53095.2536452\ttotal: 11.1s\tremaining: 8.19s\n",
      "576:\tlearn: 53079.8532551\ttotal: 11.1s\tremaining: 8.17s\n",
      "577:\tlearn: 53037.7324893\ttotal: 11.2s\tremaining: 8.14s\n",
      "578:\tlearn: 53021.4572288\ttotal: 11.2s\tremaining: 8.12s\n",
      "579:\tlearn: 53003.1994017\ttotal: 11.2s\tremaining: 8.1s\n",
      "580:\tlearn: 52943.2944228\ttotal: 11.2s\tremaining: 8.07s\n",
      "581:\tlearn: 52885.4908009\ttotal: 11.2s\tremaining: 8.05s\n",
      "582:\tlearn: 52866.6224234\ttotal: 11.2s\tremaining: 8.04s\n",
      "583:\tlearn: 52846.1324395\ttotal: 11.3s\tremaining: 8.02s\n",
      "584:\tlearn: 52809.9616531\ttotal: 11.3s\tremaining: 8s\n",
      "585:\tlearn: 52797.8310341\ttotal: 11.3s\tremaining: 7.98s\n",
      "586:\tlearn: 52741.9541531\ttotal: 11.3s\tremaining: 7.96s\n",
      "587:\tlearn: 52721.3828870\ttotal: 11.3s\tremaining: 7.93s\n",
      "588:\tlearn: 52667.4272158\ttotal: 11.3s\tremaining: 7.91s\n",
      "589:\tlearn: 52638.1546647\ttotal: 11.4s\tremaining: 7.89s\n",
      "590:\tlearn: 52633.0370505\ttotal: 11.4s\tremaining: 7.87s\n",
      "591:\tlearn: 52574.0911993\ttotal: 11.4s\tremaining: 7.84s\n",
      "592:\tlearn: 52521.9326197\ttotal: 11.4s\tremaining: 7.82s\n",
      "593:\tlearn: 52506.6402709\ttotal: 11.4s\tremaining: 7.79s\n",
      "594:\tlearn: 52501.6153434\ttotal: 11.4s\tremaining: 7.77s\n",
      "595:\tlearn: 52491.8208408\ttotal: 11.5s\tremaining: 7.77s\n",
      "596:\tlearn: 52475.4324887\ttotal: 11.5s\tremaining: 7.74s\n",
      "597:\tlearn: 52441.5735964\ttotal: 11.5s\tremaining: 7.74s\n",
      "598:\tlearn: 52433.9375169\ttotal: 11.5s\tremaining: 7.71s\n",
      "599:\tlearn: 52420.2398576\ttotal: 11.5s\tremaining: 7.69s\n",
      "600:\tlearn: 52410.0211848\ttotal: 11.5s\tremaining: 7.67s\n",
      "601:\tlearn: 52402.6812549\ttotal: 11.6s\tremaining: 7.64s\n",
      "602:\tlearn: 52357.7773299\ttotal: 11.6s\tremaining: 7.62s\n",
      "603:\tlearn: 52339.8879743\ttotal: 11.6s\tremaining: 7.59s\n",
      "604:\tlearn: 52321.5018287\ttotal: 11.6s\tremaining: 7.57s\n",
      "605:\tlearn: 52314.4395665\ttotal: 11.6s\tremaining: 7.55s\n",
      "606:\tlearn: 52308.4072532\ttotal: 11.6s\tremaining: 7.53s\n",
      "607:\tlearn: 52301.6083997\ttotal: 11.6s\tremaining: 7.5s\n",
      "608:\tlearn: 52284.0444240\ttotal: 11.7s\tremaining: 7.48s\n",
      "609:\tlearn: 52263.8276510\ttotal: 11.7s\tremaining: 7.46s\n",
      "610:\tlearn: 52258.5505820\ttotal: 11.7s\tremaining: 7.44s\n",
      "611:\tlearn: 52241.7104156\ttotal: 11.7s\tremaining: 7.42s\n",
      "612:\tlearn: 52225.8586140\ttotal: 11.7s\tremaining: 7.4s\n",
      "613:\tlearn: 52208.9461276\ttotal: 11.7s\tremaining: 7.38s\n",
      "614:\tlearn: 52189.0940885\ttotal: 11.7s\tremaining: 7.35s\n",
      "615:\tlearn: 52138.4505604\ttotal: 11.8s\tremaining: 7.33s\n",
      "616:\tlearn: 52131.9073562\ttotal: 11.8s\tremaining: 7.31s\n",
      "617:\tlearn: 52126.9009940\ttotal: 11.8s\tremaining: 7.28s\n",
      "618:\tlearn: 52071.6322901\ttotal: 11.8s\tremaining: 7.26s\n",
      "619:\tlearn: 52058.3420543\ttotal: 11.8s\tremaining: 7.24s\n",
      "620:\tlearn: 52020.2027405\ttotal: 11.8s\tremaining: 7.22s\n",
      "621:\tlearn: 52015.2474271\ttotal: 11.8s\tremaining: 7.2s\n",
      "622:\tlearn: 51992.1077784\ttotal: 11.9s\tremaining: 7.18s\n",
      "623:\tlearn: 51984.4274078\ttotal: 11.9s\tremaining: 7.15s\n",
      "624:\tlearn: 51980.2347134\ttotal: 11.9s\tremaining: 7.13s\n",
      "625:\tlearn: 51965.4202768\ttotal: 11.9s\tremaining: 7.11s\n",
      "626:\tlearn: 51960.5940195\ttotal: 11.9s\tremaining: 7.09s\n",
      "627:\tlearn: 51956.9105220\ttotal: 12s\tremaining: 7.12s\n",
      "628:\tlearn: 51916.7928619\ttotal: 12s\tremaining: 7.1s\n",
      "629:\tlearn: 51886.0152247\ttotal: 12.1s\tremaining: 7.08s\n",
      "630:\tlearn: 51862.5007210\ttotal: 12.1s\tremaining: 7.05s\n",
      "631:\tlearn: 51837.5889749\ttotal: 12.1s\tremaining: 7.03s\n",
      "632:\tlearn: 51788.4178031\ttotal: 12.1s\tremaining: 7.01s\n",
      "633:\tlearn: 51735.7410360\ttotal: 12.1s\tremaining: 6.99s\n",
      "634:\tlearn: 51712.0735086\ttotal: 12.1s\tremaining: 6.97s\n",
      "635:\tlearn: 51700.0329107\ttotal: 12.2s\tremaining: 6.96s\n",
      "636:\tlearn: 51684.1213325\ttotal: 12.2s\tremaining: 6.93s\n",
      "637:\tlearn: 51668.0190677\ttotal: 12.2s\tremaining: 6.91s\n",
      "638:\tlearn: 51634.6094338\ttotal: 12.2s\tremaining: 6.89s\n",
      "639:\tlearn: 51594.3007332\ttotal: 12.2s\tremaining: 6.86s\n",
      "640:\tlearn: 51588.4485684\ttotal: 12.2s\tremaining: 6.84s\n",
      "641:\tlearn: 51572.8930070\ttotal: 12.2s\tremaining: 6.82s\n",
      "642:\tlearn: 51566.3340289\ttotal: 12.2s\tremaining: 6.8s\n",
      "643:\tlearn: 51547.9384572\ttotal: 12.3s\tremaining: 6.78s\n",
      "644:\tlearn: 51499.7196930\ttotal: 12.3s\tremaining: 6.76s\n",
      "645:\tlearn: 51484.6894664\ttotal: 12.3s\tremaining: 6.73s\n",
      "646:\tlearn: 51479.0462860\ttotal: 12.3s\tremaining: 6.71s\n",
      "647:\tlearn: 51433.1299083\ttotal: 12.3s\tremaining: 6.69s\n",
      "648:\tlearn: 51418.6144610\ttotal: 12.3s\tremaining: 6.67s\n",
      "649:\tlearn: 51389.6742544\ttotal: 12.3s\tremaining: 6.65s\n",
      "650:\tlearn: 51382.1794357\ttotal: 12.4s\tremaining: 6.63s\n",
      "651:\tlearn: 51369.5392977\ttotal: 12.4s\tremaining: 6.61s\n",
      "652:\tlearn: 51321.6758916\ttotal: 12.4s\tremaining: 6.59s\n",
      "653:\tlearn: 51275.4917495\ttotal: 12.4s\tremaining: 6.57s\n",
      "654:\tlearn: 51272.1593550\ttotal: 12.4s\tremaining: 6.55s\n",
      "655:\tlearn: 51266.7043164\ttotal: 12.4s\tremaining: 6.53s\n",
      "656:\tlearn: 51253.6808233\ttotal: 12.5s\tremaining: 6.5s\n",
      "657:\tlearn: 51248.7216928\ttotal: 12.5s\tremaining: 6.48s\n",
      "658:\tlearn: 51218.9048817\ttotal: 12.5s\tremaining: 6.46s\n",
      "659:\tlearn: 51207.1675005\ttotal: 12.5s\tremaining: 6.44s\n",
      "660:\tlearn: 51193.0939403\ttotal: 12.5s\tremaining: 6.42s\n",
      "661:\tlearn: 51177.5875583\ttotal: 12.5s\tremaining: 6.4s\n",
      "662:\tlearn: 51172.4929696\ttotal: 12.6s\tremaining: 6.38s\n",
      "663:\tlearn: 51167.9930787\ttotal: 12.6s\tremaining: 6.36s\n",
      "664:\tlearn: 51128.0358924\ttotal: 12.6s\tremaining: 6.35s\n",
      "665:\tlearn: 51121.9546406\ttotal: 12.6s\tremaining: 6.33s\n",
      "666:\tlearn: 51107.7478498\ttotal: 12.6s\tremaining: 6.3s\n",
      "667:\tlearn: 51103.1396320\ttotal: 12.6s\tremaining: 6.28s\n",
      "668:\tlearn: 51058.4229692\ttotal: 12.7s\tremaining: 6.26s\n",
      "669:\tlearn: 51052.5470070\ttotal: 12.7s\tremaining: 6.24s\n",
      "670:\tlearn: 51009.3961671\ttotal: 12.7s\tremaining: 6.22s\n",
      "671:\tlearn: 50995.8731551\ttotal: 12.7s\tremaining: 6.2s\n",
      "672:\tlearn: 50976.8384361\ttotal: 12.7s\tremaining: 6.17s\n",
      "673:\tlearn: 50962.3361146\ttotal: 12.7s\tremaining: 6.15s\n",
      "674:\tlearn: 50943.1388205\ttotal: 12.7s\tremaining: 6.13s\n",
      "675:\tlearn: 50940.1354109\ttotal: 12.8s\tremaining: 6.11s\n",
      "676:\tlearn: 50937.2913133\ttotal: 12.8s\tremaining: 6.09s\n",
      "677:\tlearn: 50920.7578431\ttotal: 12.8s\tremaining: 6.07s\n",
      "678:\tlearn: 50876.7625126\ttotal: 12.8s\tremaining: 6.05s\n",
      "679:\tlearn: 50835.0083513\ttotal: 12.8s\tremaining: 6.04s\n",
      "680:\tlearn: 50819.5694293\ttotal: 12.9s\tremaining: 6.02s\n",
      "681:\tlearn: 50809.6784526\ttotal: 12.9s\tremaining: 6s\n",
      "682:\tlearn: 50760.8498437\ttotal: 12.9s\tremaining: 5.98s\n",
      "683:\tlearn: 50754.4228010\ttotal: 12.9s\tremaining: 5.96s\n",
      "684:\tlearn: 50745.7089971\ttotal: 12.9s\tremaining: 5.94s\n",
      "685:\tlearn: 50705.3454023\ttotal: 12.9s\tremaining: 5.92s\n",
      "686:\tlearn: 50695.5390997\ttotal: 13s\tremaining: 5.9s\n",
      "687:\tlearn: 50656.5697594\ttotal: 13s\tremaining: 5.88s\n",
      "688:\tlearn: 50651.7844818\ttotal: 13s\tremaining: 5.86s\n",
      "689:\tlearn: 50634.8940681\ttotal: 13s\tremaining: 5.84s\n",
      "690:\tlearn: 50620.3362413\ttotal: 13s\tremaining: 5.82s\n",
      "691:\tlearn: 50605.2720539\ttotal: 13.1s\tremaining: 5.84s\n",
      "692:\tlearn: 50567.6332167\ttotal: 13.1s\tremaining: 5.83s\n",
      "693:\tlearn: 50554.2588392\ttotal: 13.2s\tremaining: 5.8s\n",
      "694:\tlearn: 50519.1391323\ttotal: 13.2s\tremaining: 5.79s\n",
      "695:\tlearn: 50492.6429172\ttotal: 13.2s\tremaining: 5.77s\n",
      "696:\tlearn: 50486.8863616\ttotal: 13.2s\tremaining: 5.74s\n",
      "697:\tlearn: 50470.7931887\ttotal: 13.2s\tremaining: 5.72s\n",
      "698:\tlearn: 50457.2771305\ttotal: 13.2s\tremaining: 5.7s\n",
      "699:\tlearn: 50441.9037811\ttotal: 13.3s\tremaining: 5.69s\n",
      "700:\tlearn: 50439.7213033\ttotal: 13.3s\tremaining: 5.67s\n",
      "701:\tlearn: 50427.0065289\ttotal: 13.3s\tremaining: 5.64s\n",
      "702:\tlearn: 50412.3123845\ttotal: 13.3s\tremaining: 5.62s\n",
      "703:\tlearn: 50396.4157112\ttotal: 13.3s\tremaining: 5.6s\n",
      "704:\tlearn: 50359.5452116\ttotal: 13.3s\tremaining: 5.58s\n",
      "705:\tlearn: 50299.2765266\ttotal: 13.4s\tremaining: 5.56s\n",
      "706:\tlearn: 50264.0168046\ttotal: 13.4s\tremaining: 5.54s\n",
      "707:\tlearn: 50252.3876159\ttotal: 13.4s\tremaining: 5.52s\n",
      "708:\tlearn: 50240.3689735\ttotal: 13.4s\tremaining: 5.5s\n",
      "709:\tlearn: 50226.2726547\ttotal: 13.4s\tremaining: 5.48s\n",
      "710:\tlearn: 50178.6295118\ttotal: 13.4s\tremaining: 5.46s\n",
      "711:\tlearn: 50153.8881804\ttotal: 13.4s\tremaining: 5.44s\n",
      "712:\tlearn: 50141.1041740\ttotal: 13.5s\tremaining: 5.42s\n",
      "713:\tlearn: 50125.5276726\ttotal: 13.5s\tremaining: 5.4s\n",
      "714:\tlearn: 50113.2321344\ttotal: 13.5s\tremaining: 5.38s\n",
      "715:\tlearn: 50076.1002383\ttotal: 13.5s\tremaining: 5.37s\n",
      "716:\tlearn: 50038.4338037\ttotal: 13.5s\tremaining: 5.34s\n",
      "717:\tlearn: 50032.3344076\ttotal: 13.6s\tremaining: 5.32s\n",
      "718:\tlearn: 50019.3881011\ttotal: 13.6s\tremaining: 5.3s\n",
      "719:\tlearn: 50004.5052802\ttotal: 13.6s\tremaining: 5.28s\n",
      "720:\tlearn: 49992.1436292\ttotal: 13.6s\tremaining: 5.26s\n",
      "721:\tlearn: 49959.1232583\ttotal: 13.6s\tremaining: 5.24s\n",
      "722:\tlearn: 49922.7867619\ttotal: 13.6s\tremaining: 5.22s\n",
      "723:\tlearn: 49915.4168895\ttotal: 13.6s\tremaining: 5.2s\n",
      "724:\tlearn: 49896.4775635\ttotal: 13.7s\tremaining: 5.18s\n",
      "725:\tlearn: 49892.0091387\ttotal: 13.7s\tremaining: 5.16s\n",
      "726:\tlearn: 49869.1292177\ttotal: 13.7s\tremaining: 5.14s\n",
      "727:\tlearn: 49864.8564431\ttotal: 13.7s\tremaining: 5.12s\n",
      "728:\tlearn: 49850.4270471\ttotal: 13.7s\tremaining: 5.1s\n",
      "729:\tlearn: 49836.0598639\ttotal: 13.7s\tremaining: 5.08s\n",
      "730:\tlearn: 49832.0807081\ttotal: 13.8s\tremaining: 5.06s\n",
      "731:\tlearn: 49800.1364365\ttotal: 13.8s\tremaining: 5.04s\n",
      "732:\tlearn: 49767.7591888\ttotal: 13.8s\tremaining: 5.02s\n",
      "733:\tlearn: 49743.9794399\ttotal: 13.8s\tremaining: 5s\n",
      "734:\tlearn: 49726.4054961\ttotal: 13.8s\tremaining: 4.98s\n",
      "735:\tlearn: 49713.1452357\ttotal: 13.8s\tremaining: 4.96s\n",
      "736:\tlearn: 49682.2652029\ttotal: 13.8s\tremaining: 4.94s\n",
      "737:\tlearn: 49659.3546843\ttotal: 13.9s\tremaining: 4.92s\n",
      "738:\tlearn: 49637.3044906\ttotal: 13.9s\tremaining: 4.9s\n",
      "739:\tlearn: 49626.1074139\ttotal: 13.9s\tremaining: 4.88s\n",
      "740:\tlearn: 49580.1611356\ttotal: 13.9s\tremaining: 4.87s\n",
      "741:\tlearn: 49569.3818966\ttotal: 13.9s\tremaining: 4.85s\n",
      "742:\tlearn: 49540.4082426\ttotal: 14s\tremaining: 4.83s\n",
      "743:\tlearn: 49530.6988148\ttotal: 14s\tremaining: 4.8s\n",
      "744:\tlearn: 49513.6768632\ttotal: 14s\tremaining: 4.79s\n",
      "745:\tlearn: 49479.1767538\ttotal: 14s\tremaining: 4.77s\n",
      "746:\tlearn: 49475.4583167\ttotal: 14s\tremaining: 4.75s\n",
      "747:\tlearn: 49439.6053968\ttotal: 14s\tremaining: 4.72s\n",
      "748:\tlearn: 49425.0615518\ttotal: 14s\tremaining: 4.7s\n",
      "749:\tlearn: 49410.7066808\ttotal: 14s\tremaining: 4.68s\n",
      "750:\tlearn: 49388.3753200\ttotal: 14.1s\tremaining: 4.66s\n",
      "751:\tlearn: 49373.5527373\ttotal: 14.1s\tremaining: 4.64s\n",
      "752:\tlearn: 49344.2231857\ttotal: 14.1s\tremaining: 4.62s\n",
      "753:\tlearn: 49319.8000613\ttotal: 14.1s\tremaining: 4.6s\n",
      "754:\tlearn: 49306.3116884\ttotal: 14.1s\tremaining: 4.58s\n",
      "755:\tlearn: 49276.2541193\ttotal: 14.2s\tremaining: 4.57s\n",
      "756:\tlearn: 49272.5377218\ttotal: 14.2s\tremaining: 4.55s\n",
      "757:\tlearn: 49228.3936470\ttotal: 14.2s\tremaining: 4.53s\n",
      "758:\tlearn: 49191.8456188\ttotal: 14.2s\tremaining: 4.51s\n",
      "759:\tlearn: 49178.2316597\ttotal: 14.2s\tremaining: 4.49s\n",
      "760:\tlearn: 49163.0045787\ttotal: 14.2s\tremaining: 4.47s\n",
      "761:\tlearn: 49152.7220125\ttotal: 14.3s\tremaining: 4.45s\n",
      "762:\tlearn: 49141.5855494\ttotal: 14.3s\tremaining: 4.43s\n",
      "763:\tlearn: 49121.0896023\ttotal: 14.3s\tremaining: 4.41s\n",
      "764:\tlearn: 49115.4880315\ttotal: 14.3s\tremaining: 4.39s\n",
      "765:\tlearn: 49106.6207152\ttotal: 14.3s\tremaining: 4.37s\n",
      "766:\tlearn: 49063.9324053\ttotal: 14.3s\tremaining: 4.35s\n",
      "767:\tlearn: 49054.0313982\ttotal: 14.4s\tremaining: 4.34s\n",
      "768:\tlearn: 49019.1424882\ttotal: 14.4s\tremaining: 4.34s\n",
      "769:\tlearn: 49008.6734124\ttotal: 14.5s\tremaining: 4.32s\n",
      "770:\tlearn: 48995.6179106\ttotal: 14.5s\tremaining: 4.3s\n",
      "771:\tlearn: 48985.2691727\ttotal: 14.5s\tremaining: 4.28s\n",
      "772:\tlearn: 48968.6632738\ttotal: 14.5s\tremaining: 4.26s\n",
      "773:\tlearn: 48965.1381159\ttotal: 14.5s\tremaining: 4.24s\n",
      "774:\tlearn: 48958.5467684\ttotal: 14.5s\tremaining: 4.22s\n",
      "775:\tlearn: 48955.1528258\ttotal: 14.5s\tremaining: 4.2s\n",
      "776:\tlearn: 48949.4990608\ttotal: 14.6s\tremaining: 4.18s\n",
      "777:\tlearn: 48915.9312177\ttotal: 14.6s\tremaining: 4.16s\n",
      "778:\tlearn: 48885.1979070\ttotal: 14.6s\tremaining: 4.14s\n",
      "779:\tlearn: 48865.9458877\ttotal: 14.6s\tremaining: 4.12s\n",
      "780:\tlearn: 48862.8117799\ttotal: 14.6s\tremaining: 4.1s\n",
      "781:\tlearn: 48845.5823336\ttotal: 14.7s\tremaining: 4.08s\n",
      "782:\tlearn: 48842.6814111\ttotal: 14.7s\tremaining: 4.06s\n",
      "783:\tlearn: 48815.8107540\ttotal: 14.7s\tremaining: 4.04s\n",
      "784:\tlearn: 48802.9469134\ttotal: 14.7s\tremaining: 4.02s\n",
      "785:\tlearn: 48799.3509818\ttotal: 14.7s\tremaining: 4s\n",
      "786:\tlearn: 48787.6274974\ttotal: 14.7s\tremaining: 3.98s\n",
      "787:\tlearn: 48781.6432805\ttotal: 14.7s\tremaining: 3.97s\n",
      "788:\tlearn: 48757.8789663\ttotal: 14.8s\tremaining: 3.95s\n",
      "789:\tlearn: 48740.9713329\ttotal: 14.8s\tremaining: 3.94s\n",
      "790:\tlearn: 48727.0021769\ttotal: 14.8s\tremaining: 3.92s\n",
      "791:\tlearn: 48646.8888695\ttotal: 14.8s\tremaining: 3.9s\n",
      "792:\tlearn: 48605.8978397\ttotal: 14.9s\tremaining: 3.88s\n",
      "793:\tlearn: 48591.1543136\ttotal: 14.9s\tremaining: 3.86s\n",
      "794:\tlearn: 48588.3500987\ttotal: 14.9s\tremaining: 3.84s\n",
      "795:\tlearn: 48579.2294133\ttotal: 14.9s\tremaining: 3.82s\n",
      "796:\tlearn: 48568.3104198\ttotal: 14.9s\tremaining: 3.8s\n",
      "797:\tlearn: 48561.1704434\ttotal: 14.9s\tremaining: 3.78s\n",
      "798:\tlearn: 48552.3376707\ttotal: 14.9s\tremaining: 3.76s\n",
      "799:\tlearn: 48546.4393455\ttotal: 15s\tremaining: 3.74s\n",
      "800:\tlearn: 48535.4866238\ttotal: 15s\tremaining: 3.72s\n",
      "801:\tlearn: 48525.8795263\ttotal: 15s\tremaining: 3.7s\n",
      "802:\tlearn: 48515.2824207\ttotal: 15s\tremaining: 3.68s\n",
      "803:\tlearn: 48502.1659311\ttotal: 15s\tremaining: 3.66s\n",
      "804:\tlearn: 48462.8794317\ttotal: 15s\tremaining: 3.64s\n",
      "805:\tlearn: 48456.2544270\ttotal: 15.1s\tremaining: 3.63s\n",
      "806:\tlearn: 48446.4886304\ttotal: 15.1s\tremaining: 3.6s\n",
      "807:\tlearn: 48435.5097714\ttotal: 15.1s\tremaining: 3.58s\n",
      "808:\tlearn: 48407.9845193\ttotal: 15.1s\tremaining: 3.56s\n",
      "809:\tlearn: 48398.7335351\ttotal: 15.1s\tremaining: 3.54s\n",
      "810:\tlearn: 48360.7776598\ttotal: 15.1s\tremaining: 3.52s\n",
      "811:\tlearn: 48349.9306519\ttotal: 15.1s\tremaining: 3.51s\n",
      "812:\tlearn: 48343.8838723\ttotal: 15.2s\tremaining: 3.49s\n",
      "813:\tlearn: 48310.5094319\ttotal: 15.2s\tremaining: 3.47s\n",
      "814:\tlearn: 48296.1621379\ttotal: 15.2s\tremaining: 3.45s\n",
      "815:\tlearn: 48283.5742424\ttotal: 15.2s\tremaining: 3.43s\n",
      "816:\tlearn: 48272.2628277\ttotal: 15.2s\tremaining: 3.41s\n",
      "817:\tlearn: 48246.5414940\ttotal: 15.2s\tremaining: 3.39s\n",
      "818:\tlearn: 48236.1010277\ttotal: 15.3s\tremaining: 3.37s\n",
      "819:\tlearn: 48234.4959598\ttotal: 15.3s\tremaining: 3.35s\n",
      "820:\tlearn: 48225.0642722\ttotal: 15.3s\tremaining: 3.33s\n",
      "821:\tlearn: 48215.6135065\ttotal: 15.3s\tremaining: 3.32s\n",
      "822:\tlearn: 48193.0866817\ttotal: 15.3s\tremaining: 3.3s\n",
      "823:\tlearn: 48159.8857990\ttotal: 15.3s\tremaining: 3.28s\n",
      "824:\tlearn: 48146.8968078\ttotal: 15.4s\tremaining: 3.26s\n",
      "825:\tlearn: 48138.3058541\ttotal: 15.4s\tremaining: 3.24s\n",
      "826:\tlearn: 48062.4426489\ttotal: 15.4s\tremaining: 3.22s\n",
      "827:\tlearn: 48039.8686241\ttotal: 15.4s\tremaining: 3.2s\n",
      "828:\tlearn: 48014.9542606\ttotal: 15.4s\tremaining: 3.18s\n",
      "829:\tlearn: 48008.5072510\ttotal: 15.4s\tremaining: 3.16s\n",
      "830:\tlearn: 48005.8396563\ttotal: 15.4s\tremaining: 3.14s\n",
      "831:\tlearn: 47981.8014588\ttotal: 15.5s\tremaining: 3.12s\n",
      "832:\tlearn: 47975.7952512\ttotal: 15.6s\tremaining: 3.12s\n",
      "833:\tlearn: 47940.7940886\ttotal: 15.6s\tremaining: 3.1s\n",
      "834:\tlearn: 47936.8235180\ttotal: 15.6s\tremaining: 3.08s\n",
      "835:\tlearn: 47934.3726904\ttotal: 15.6s\tremaining: 3.06s\n",
      "836:\tlearn: 47926.6299159\ttotal: 15.6s\tremaining: 3.04s\n",
      "837:\tlearn: 47923.8415965\ttotal: 15.6s\tremaining: 3.02s\n",
      "838:\tlearn: 47918.1108289\ttotal: 15.7s\tremaining: 3s\n",
      "839:\tlearn: 47899.1951369\ttotal: 15.7s\tremaining: 2.99s\n",
      "840:\tlearn: 47893.1574215\ttotal: 15.7s\tremaining: 2.97s\n",
      "841:\tlearn: 47887.9103924\ttotal: 15.7s\tremaining: 2.95s\n",
      "842:\tlearn: 47877.3374087\ttotal: 15.7s\tremaining: 2.93s\n",
      "843:\tlearn: 47840.3579505\ttotal: 15.8s\tremaining: 2.91s\n",
      "844:\tlearn: 47804.6797686\ttotal: 15.8s\tremaining: 2.89s\n",
      "845:\tlearn: 47800.1761273\ttotal: 15.8s\tremaining: 2.87s\n",
      "846:\tlearn: 47790.1067244\ttotal: 15.8s\tremaining: 2.85s\n",
      "847:\tlearn: 47783.3797702\ttotal: 15.8s\tremaining: 2.83s\n",
      "848:\tlearn: 47759.9466222\ttotal: 15.8s\tremaining: 2.81s\n",
      "849:\tlearn: 47757.3935782\ttotal: 15.8s\tremaining: 2.8s\n",
      "850:\tlearn: 47747.0751668\ttotal: 15.9s\tremaining: 2.77s\n",
      "851:\tlearn: 47712.6092506\ttotal: 15.9s\tremaining: 2.76s\n",
      "852:\tlearn: 47704.6228911\ttotal: 15.9s\tremaining: 2.74s\n",
      "853:\tlearn: 47671.3647144\ttotal: 15.9s\tremaining: 2.72s\n",
      "854:\tlearn: 47658.2523528\ttotal: 15.9s\tremaining: 2.7s\n",
      "855:\tlearn: 47627.0439582\ttotal: 15.9s\tremaining: 2.68s\n",
      "856:\tlearn: 47594.6328530\ttotal: 16s\tremaining: 2.66s\n",
      "857:\tlearn: 47592.3112436\ttotal: 16s\tremaining: 2.64s\n",
      "858:\tlearn: 47581.7940768\ttotal: 16s\tremaining: 2.63s\n",
      "859:\tlearn: 47571.9791612\ttotal: 16s\tremaining: 2.61s\n",
      "860:\tlearn: 47500.3182675\ttotal: 16s\tremaining: 2.59s\n",
      "861:\tlearn: 47497.4764551\ttotal: 16s\tremaining: 2.57s\n",
      "862:\tlearn: 47488.4126789\ttotal: 16.1s\tremaining: 2.55s\n",
      "863:\tlearn: 47486.0761052\ttotal: 16.1s\tremaining: 2.53s\n",
      "864:\tlearn: 47480.9881457\ttotal: 16.1s\tremaining: 2.51s\n",
      "865:\tlearn: 47478.6176206\ttotal: 16.1s\tremaining: 2.49s\n",
      "866:\tlearn: 47456.0140494\ttotal: 16.1s\tremaining: 2.47s\n",
      "867:\tlearn: 47453.0101639\ttotal: 16.1s\tremaining: 2.45s\n",
      "868:\tlearn: 47448.7285819\ttotal: 16.1s\tremaining: 2.43s\n",
      "869:\tlearn: 47442.7335039\ttotal: 16.2s\tremaining: 2.42s\n",
      "870:\tlearn: 47420.9267035\ttotal: 16.2s\tremaining: 2.4s\n",
      "871:\tlearn: 47418.6849354\ttotal: 16.2s\tremaining: 2.38s\n",
      "872:\tlearn: 47399.1889617\ttotal: 16.2s\tremaining: 2.36s\n",
      "873:\tlearn: 47386.8807431\ttotal: 16.2s\tremaining: 2.34s\n",
      "874:\tlearn: 47355.7156020\ttotal: 16.3s\tremaining: 2.32s\n",
      "875:\tlearn: 47334.6532196\ttotal: 16.3s\tremaining: 2.3s\n",
      "876:\tlearn: 47313.8290753\ttotal: 16.3s\tremaining: 2.29s\n",
      "877:\tlearn: 47307.9754390\ttotal: 16.3s\tremaining: 2.27s\n",
      "878:\tlearn: 47301.4939975\ttotal: 16.3s\tremaining: 2.25s\n",
      "879:\tlearn: 47292.6042497\ttotal: 16.3s\tremaining: 2.23s\n",
      "880:\tlearn: 47281.2303374\ttotal: 16.4s\tremaining: 2.21s\n",
      "881:\tlearn: 47265.7831291\ttotal: 16.4s\tremaining: 2.19s\n",
      "882:\tlearn: 47245.4411363\ttotal: 16.5s\tremaining: 2.19s\n",
      "883:\tlearn: 47239.8070964\ttotal: 16.5s\tremaining: 2.17s\n",
      "884:\tlearn: 47208.5538464\ttotal: 16.5s\tremaining: 2.15s\n",
      "885:\tlearn: 47206.3869188\ttotal: 16.5s\tremaining: 2.13s\n",
      "886:\tlearn: 47151.3106806\ttotal: 16.6s\tremaining: 2.11s\n",
      "887:\tlearn: 47139.4782982\ttotal: 16.6s\tremaining: 2.09s\n",
      "888:\tlearn: 47138.2230211\ttotal: 16.6s\tremaining: 2.07s\n",
      "889:\tlearn: 47134.1999413\ttotal: 16.6s\tremaining: 2.05s\n",
      "890:\tlearn: 47114.5204968\ttotal: 16.6s\tremaining: 2.04s\n",
      "891:\tlearn: 47113.3217128\ttotal: 16.7s\tremaining: 2.02s\n",
      "892:\tlearn: 47110.4499348\ttotal: 16.7s\tremaining: 2s\n",
      "893:\tlearn: 47108.5177626\ttotal: 16.7s\tremaining: 1.98s\n",
      "894:\tlearn: 47106.6636997\ttotal: 16.7s\tremaining: 1.96s\n",
      "895:\tlearn: 47101.9834654\ttotal: 16.7s\tremaining: 1.94s\n",
      "896:\tlearn: 47084.7740025\ttotal: 16.7s\tremaining: 1.92s\n",
      "897:\tlearn: 47075.2241960\ttotal: 16.7s\tremaining: 1.9s\n",
      "898:\tlearn: 47073.1389915\ttotal: 16.7s\tremaining: 1.88s\n",
      "899:\tlearn: 47040.6535287\ttotal: 16.8s\tremaining: 1.86s\n",
      "900:\tlearn: 47031.0185515\ttotal: 16.8s\tremaining: 1.84s\n",
      "901:\tlearn: 46991.8989714\ttotal: 16.8s\tremaining: 1.82s\n",
      "902:\tlearn: 46985.9042033\ttotal: 16.8s\tremaining: 1.81s\n",
      "903:\tlearn: 46977.8841011\ttotal: 16.9s\tremaining: 1.79s\n",
      "904:\tlearn: 46972.5889749\ttotal: 16.9s\tremaining: 1.77s\n",
      "905:\tlearn: 46971.4327433\ttotal: 16.9s\tremaining: 1.75s\n",
      "906:\tlearn: 46965.6551638\ttotal: 16.9s\tremaining: 1.73s\n",
      "907:\tlearn: 46947.6684896\ttotal: 16.9s\tremaining: 1.71s\n",
      "908:\tlearn: 46936.7455729\ttotal: 16.9s\tremaining: 1.69s\n",
      "909:\tlearn: 46917.6963089\ttotal: 16.9s\tremaining: 1.68s\n",
      "910:\tlearn: 46912.1749265\ttotal: 17s\tremaining: 1.66s\n",
      "911:\tlearn: 46893.8034170\ttotal: 17s\tremaining: 1.64s\n",
      "912:\tlearn: 46873.3513093\ttotal: 17s\tremaining: 1.62s\n",
      "913:\tlearn: 46863.8871013\ttotal: 17s\tremaining: 1.6s\n",
      "914:\tlearn: 46844.1233515\ttotal: 17s\tremaining: 1.58s\n",
      "915:\tlearn: 46839.2665016\ttotal: 17s\tremaining: 1.56s\n",
      "916:\tlearn: 46830.5815235\ttotal: 17.1s\tremaining: 1.54s\n",
      "917:\tlearn: 46821.5184794\ttotal: 17.1s\tremaining: 1.52s\n",
      "918:\tlearn: 46812.2752374\ttotal: 17.1s\tremaining: 1.5s\n",
      "919:\tlearn: 46802.2677809\ttotal: 17.1s\tremaining: 1.49s\n",
      "920:\tlearn: 46795.1872683\ttotal: 17.1s\tremaining: 1.47s\n",
      "921:\tlearn: 46776.7556432\ttotal: 17.1s\tremaining: 1.45s\n",
      "922:\tlearn: 46761.8960881\ttotal: 17.1s\tremaining: 1.43s\n",
      "923:\tlearn: 46744.1085031\ttotal: 17.3s\tremaining: 1.43s\n",
      "924:\tlearn: 46739.9596895\ttotal: 17.4s\tremaining: 1.41s\n",
      "925:\tlearn: 46725.7929938\ttotal: 17.4s\tremaining: 1.39s\n",
      "926:\tlearn: 46718.2525045\ttotal: 17.6s\tremaining: 1.38s\n",
      "927:\tlearn: 46713.5907326\ttotal: 17.7s\tremaining: 1.37s\n",
      "928:\tlearn: 46681.2204466\ttotal: 17.8s\tremaining: 1.36s\n",
      "929:\tlearn: 46669.5749342\ttotal: 17.8s\tremaining: 1.34s\n",
      "930:\tlearn: 46666.9503329\ttotal: 17.9s\tremaining: 1.33s\n",
      "931:\tlearn: 46646.8031574\ttotal: 17.9s\tremaining: 1.31s\n",
      "932:\tlearn: 46629.6185645\ttotal: 17.9s\tremaining: 1.29s\n",
      "933:\tlearn: 46592.0124817\ttotal: 18s\tremaining: 1.27s\n",
      "934:\tlearn: 46585.1638622\ttotal: 18s\tremaining: 1.25s\n",
      "935:\tlearn: 46562.9953010\ttotal: 18s\tremaining: 1.23s\n",
      "936:\tlearn: 46531.5081204\ttotal: 18s\tremaining: 1.21s\n",
      "937:\tlearn: 46523.3381209\ttotal: 18s\tremaining: 1.19s\n",
      "938:\tlearn: 46494.2051670\ttotal: 18s\tremaining: 1.17s\n",
      "939:\tlearn: 46493.2881919\ttotal: 18.1s\tremaining: 1.15s\n",
      "940:\tlearn: 46476.6922088\ttotal: 18.1s\tremaining: 1.14s\n",
      "941:\tlearn: 46468.2625743\ttotal: 18.1s\tremaining: 1.12s\n",
      "942:\tlearn: 46452.1230166\ttotal: 18.2s\tremaining: 1.1s\n",
      "943:\tlearn: 46418.8763015\ttotal: 18.2s\tremaining: 1.08s\n",
      "944:\tlearn: 46414.9457317\ttotal: 18.2s\tremaining: 1.06s\n",
      "945:\tlearn: 46409.8588143\ttotal: 18.3s\tremaining: 1.04s\n",
      "946:\tlearn: 46404.3025961\ttotal: 18.3s\tremaining: 1.02s\n",
      "947:\tlearn: 46385.4998312\ttotal: 18.3s\tremaining: 1s\n",
      "948:\tlearn: 46368.5908523\ttotal: 18.4s\tremaining: 986ms\n",
      "949:\tlearn: 46347.8195972\ttotal: 18.4s\tremaining: 967ms\n",
      "950:\tlearn: 46316.5639850\ttotal: 18.4s\tremaining: 947ms\n",
      "951:\tlearn: 46297.8321762\ttotal: 18.4s\tremaining: 928ms\n",
      "952:\tlearn: 46277.9141165\ttotal: 18.4s\tremaining: 908ms\n",
      "953:\tlearn: 46259.9661884\ttotal: 18.4s\tremaining: 888ms\n",
      "954:\tlearn: 46240.8656824\ttotal: 18.4s\tremaining: 869ms\n",
      "955:\tlearn: 46222.5428263\ttotal: 18.4s\tremaining: 849ms\n",
      "956:\tlearn: 46199.9330961\ttotal: 18.5s\tremaining: 830ms\n",
      "957:\tlearn: 46176.6548263\ttotal: 18.5s\tremaining: 810ms\n",
      "958:\tlearn: 46154.7749792\ttotal: 18.6s\tremaining: 795ms\n",
      "959:\tlearn: 46137.1480935\ttotal: 18.6s\tremaining: 775ms\n",
      "960:\tlearn: 46116.5612334\ttotal: 18.6s\tremaining: 755ms\n",
      "961:\tlearn: 46114.7313369\ttotal: 18.6s\tremaining: 736ms\n",
      "962:\tlearn: 46105.4479342\ttotal: 18.6s\tremaining: 716ms\n",
      "963:\tlearn: 46097.1271513\ttotal: 18.7s\tremaining: 697ms\n",
      "964:\tlearn: 46047.7750269\ttotal: 18.7s\tremaining: 677ms\n",
      "965:\tlearn: 46042.3834419\ttotal: 18.7s\tremaining: 658ms\n",
      "966:\tlearn: 46033.2461418\ttotal: 18.7s\tremaining: 639ms\n",
      "967:\tlearn: 46005.6670840\ttotal: 18.7s\tremaining: 619ms\n",
      "968:\tlearn: 46001.8784090\ttotal: 18.7s\tremaining: 600ms\n",
      "969:\tlearn: 45994.0287128\ttotal: 18.8s\tremaining: 580ms\n",
      "970:\tlearn: 45972.1984330\ttotal: 18.8s\tremaining: 561ms\n",
      "971:\tlearn: 45963.6559329\ttotal: 18.8s\tremaining: 541ms\n",
      "972:\tlearn: 45932.1801112\ttotal: 18.8s\tremaining: 522ms\n",
      "973:\tlearn: 45924.5799397\ttotal: 18.8s\tremaining: 502ms\n",
      "974:\tlearn: 45914.9116282\ttotal: 18.8s\tremaining: 483ms\n",
      "975:\tlearn: 45897.8829710\ttotal: 18.9s\tremaining: 464ms\n",
      "976:\tlearn: 45888.9087872\ttotal: 18.9s\tremaining: 444ms\n",
      "977:\tlearn: 45869.4568529\ttotal: 18.9s\tremaining: 425ms\n",
      "978:\tlearn: 45862.3864648\ttotal: 18.9s\tremaining: 406ms\n",
      "979:\tlearn: 45854.2783180\ttotal: 18.9s\tremaining: 386ms\n",
      "980:\tlearn: 45853.3369954\ttotal: 18.9s\tremaining: 367ms\n",
      "981:\tlearn: 45845.4420105\ttotal: 19s\tremaining: 347ms\n",
      "982:\tlearn: 45832.5214456\ttotal: 19s\tremaining: 328ms\n",
      "983:\tlearn: 45807.3523131\ttotal: 19s\tremaining: 309ms\n",
      "984:\tlearn: 45803.6498979\ttotal: 19s\tremaining: 289ms\n",
      "985:\tlearn: 45796.3407173\ttotal: 19s\tremaining: 270ms\n",
      "986:\tlearn: 45784.4493611\ttotal: 19s\tremaining: 251ms\n",
      "987:\tlearn: 45756.5639003\ttotal: 19s\tremaining: 231ms\n",
      "988:\tlearn: 45748.9213339\ttotal: 19.1s\tremaining: 212ms\n",
      "989:\tlearn: 45718.6954891\ttotal: 19.1s\tremaining: 193ms\n",
      "990:\tlearn: 45716.1586228\ttotal: 19.1s\tremaining: 173ms\n",
      "991:\tlearn: 45701.5030661\ttotal: 19.1s\tremaining: 154ms\n",
      "992:\tlearn: 45696.7176055\ttotal: 19.1s\tremaining: 135ms\n",
      "993:\tlearn: 45691.9323045\ttotal: 19.1s\tremaining: 115ms\n",
      "994:\tlearn: 45631.2555925\ttotal: 19.2s\tremaining: 96.3ms\n",
      "995:\tlearn: 45615.0611029\ttotal: 19.2s\tremaining: 77ms\n",
      "996:\tlearn: 45608.2982028\ttotal: 19.2s\tremaining: 57.7ms\n",
      "997:\tlearn: 45599.5796971\ttotal: 19.2s\tremaining: 38.5ms\n",
      "998:\tlearn: 45590.9393914\ttotal: 19.2s\tremaining: 19.2ms\n",
      "999:\tlearn: 45566.8027348\ttotal: 19.2s\tremaining: 0us\n",
      "Learning rate set to 0.071717\n",
      "0:\tlearn: 79211.6642592\ttotal: 17.4ms\tremaining: 17.4s\n",
      "1:\tlearn: 78698.3208086\ttotal: 33.2ms\tremaining: 16.6s\n",
      "2:\tlearn: 78271.1830683\ttotal: 48.6ms\tremaining: 16.1s\n",
      "3:\tlearn: 77944.9512665\ttotal: 68.6ms\tremaining: 17.1s\n",
      "4:\tlearn: 77599.1120445\ttotal: 85.1ms\tremaining: 16.9s\n",
      "5:\tlearn: 77269.0201389\ttotal: 99.9ms\tremaining: 16.6s\n",
      "6:\tlearn: 76977.1085983\ttotal: 115ms\tremaining: 16.3s\n",
      "7:\tlearn: 76756.0931845\ttotal: 130ms\tremaining: 16.1s\n",
      "8:\tlearn: 76530.6995541\ttotal: 144ms\tremaining: 15.8s\n",
      "9:\tlearn: 76359.1890698\ttotal: 159ms\tremaining: 15.7s\n",
      "10:\tlearn: 76202.8980855\ttotal: 175ms\tremaining: 15.8s\n",
      "11:\tlearn: 76017.4223121\ttotal: 197ms\tremaining: 16.2s\n",
      "12:\tlearn: 75855.2395378\ttotal: 209ms\tremaining: 15.9s\n",
      "13:\tlearn: 75726.4208534\ttotal: 237ms\tremaining: 16.7s\n",
      "14:\tlearn: 75521.9242449\ttotal: 276ms\tremaining: 18.1s\n",
      "15:\tlearn: 75351.9087350\ttotal: 287ms\tremaining: 17.6s\n",
      "16:\tlearn: 75248.7907160\ttotal: 300ms\tremaining: 17.3s\n",
      "17:\tlearn: 75135.2558247\ttotal: 314ms\tremaining: 17.1s\n",
      "18:\tlearn: 75069.6563951\ttotal: 331ms\tremaining: 17.1s\n",
      "19:\tlearn: 74967.3721301\ttotal: 349ms\tremaining: 17.1s\n",
      "20:\tlearn: 74895.3533796\ttotal: 365ms\tremaining: 17s\n",
      "21:\tlearn: 74795.9793092\ttotal: 386ms\tremaining: 17.2s\n",
      "22:\tlearn: 74697.6242740\ttotal: 397ms\tremaining: 16.9s\n",
      "23:\tlearn: 74613.0850296\ttotal: 430ms\tremaining: 17.5s\n",
      "24:\tlearn: 74483.5047319\ttotal: 462ms\tremaining: 18s\n",
      "25:\tlearn: 74426.5085771\ttotal: 592ms\tremaining: 22.2s\n",
      "26:\tlearn: 74375.8071318\ttotal: 626ms\tremaining: 22.6s\n",
      "27:\tlearn: 74245.3224349\ttotal: 1.16s\tremaining: 40.4s\n",
      "28:\tlearn: 74197.7025207\ttotal: 1.21s\tremaining: 40.4s\n",
      "29:\tlearn: 74147.1239608\ttotal: 1.28s\tremaining: 41.5s\n",
      "30:\tlearn: 74081.5352525\ttotal: 1.3s\tremaining: 40.8s\n",
      "31:\tlearn: 74047.4055921\ttotal: 1.32s\tremaining: 39.9s\n",
      "32:\tlearn: 74014.8118500\ttotal: 1.33s\tremaining: 38.9s\n",
      "33:\tlearn: 73958.8553082\ttotal: 1.34s\tremaining: 38.2s\n",
      "34:\tlearn: 73867.1138601\ttotal: 1.36s\tremaining: 37.4s\n",
      "35:\tlearn: 73820.4609368\ttotal: 1.37s\tremaining: 36.7s\n",
      "36:\tlearn: 73786.4736624\ttotal: 1.39s\tremaining: 36.1s\n",
      "37:\tlearn: 73569.9279478\ttotal: 1.4s\tremaining: 35.5s\n",
      "38:\tlearn: 73540.9050120\ttotal: 1.52s\tremaining: 37.4s\n",
      "39:\tlearn: 73505.8060319\ttotal: 1.54s\tremaining: 36.9s\n",
      "40:\tlearn: 73459.3777400\ttotal: 1.55s\tremaining: 36.3s\n",
      "41:\tlearn: 73246.4896692\ttotal: 1.56s\tremaining: 35.7s\n",
      "42:\tlearn: 73219.4298449\ttotal: 1.58s\tremaining: 35.2s\n",
      "43:\tlearn: 73192.0726069\ttotal: 1.6s\tremaining: 34.7s\n",
      "44:\tlearn: 73174.9916513\ttotal: 1.63s\tremaining: 34.5s\n",
      "45:\tlearn: 73144.4687064\ttotal: 1.67s\tremaining: 34.7s\n",
      "46:\tlearn: 73121.0080838\ttotal: 1.69s\tremaining: 34.2s\n",
      "47:\tlearn: 72934.4982438\ttotal: 1.7s\tremaining: 33.7s\n",
      "48:\tlearn: 72910.0528825\ttotal: 1.71s\tremaining: 33.1s\n",
      "49:\tlearn: 72889.5337315\ttotal: 1.72s\tremaining: 32.8s\n",
      "50:\tlearn: 72880.0307041\ttotal: 1.74s\tremaining: 32.4s\n",
      "51:\tlearn: 72834.1756165\ttotal: 1.75s\tremaining: 32s\n",
      "52:\tlearn: 72799.1432090\ttotal: 1.77s\tremaining: 31.6s\n",
      "53:\tlearn: 72595.6681144\ttotal: 1.78s\tremaining: 31.1s\n",
      "54:\tlearn: 72583.3069071\ttotal: 1.79s\tremaining: 30.8s\n",
      "55:\tlearn: 72421.9291534\ttotal: 1.8s\tremaining: 30.4s\n",
      "56:\tlearn: 72413.0349058\ttotal: 1.82s\tremaining: 30.2s\n",
      "57:\tlearn: 72334.8397908\ttotal: 1.84s\tremaining: 29.8s\n",
      "58:\tlearn: 72293.1256618\ttotal: 1.85s\tremaining: 29.6s\n",
      "59:\tlearn: 72271.5807205\ttotal: 1.88s\tremaining: 29.5s\n",
      "60:\tlearn: 72259.6182421\ttotal: 1.89s\tremaining: 29.2s\n",
      "61:\tlearn: 72244.0363611\ttotal: 1.9s\tremaining: 28.8s\n",
      "62:\tlearn: 72235.7042025\ttotal: 1.94s\tremaining: 28.9s\n",
      "63:\tlearn: 72188.5137937\ttotal: 1.96s\tremaining: 28.6s\n",
      "64:\tlearn: 72171.9237872\ttotal: 1.97s\tremaining: 28.3s\n",
      "65:\tlearn: 71981.4158072\ttotal: 1.98s\tremaining: 28.1s\n",
      "66:\tlearn: 71961.3635676\ttotal: 2s\tremaining: 27.8s\n",
      "67:\tlearn: 71943.4973930\ttotal: 2.01s\tremaining: 27.5s\n",
      "68:\tlearn: 71923.0701322\ttotal: 2.02s\tremaining: 27.2s\n",
      "69:\tlearn: 71911.6648155\ttotal: 2.04s\tremaining: 27.1s\n",
      "70:\tlearn: 71760.7874232\ttotal: 2.08s\tremaining: 27.3s\n",
      "71:\tlearn: 71736.2527440\ttotal: 2.1s\tremaining: 27.1s\n",
      "72:\tlearn: 71578.6397966\ttotal: 2.11s\tremaining: 26.8s\n",
      "73:\tlearn: 71562.0812137\ttotal: 2.12s\tremaining: 26.5s\n",
      "74:\tlearn: 71553.4981156\ttotal: 2.13s\tremaining: 26.3s\n",
      "75:\tlearn: 71521.1208078\ttotal: 2.15s\tremaining: 26.2s\n",
      "76:\tlearn: 71507.8105544\ttotal: 2.17s\tremaining: 26s\n",
      "77:\tlearn: 71496.1598021\ttotal: 2.18s\tremaining: 25.8s\n",
      "78:\tlearn: 71483.8001160\ttotal: 2.19s\tremaining: 25.5s\n",
      "79:\tlearn: 71469.8506640\ttotal: 2.2s\tremaining: 25.3s\n",
      "80:\tlearn: 71425.4941590\ttotal: 2.21s\tremaining: 25.1s\n",
      "81:\tlearn: 71307.8779019\ttotal: 2.23s\tremaining: 24.9s\n",
      "82:\tlearn: 71188.9362627\ttotal: 2.24s\tremaining: 24.8s\n",
      "83:\tlearn: 71074.5393271\ttotal: 2.27s\tremaining: 24.8s\n",
      "84:\tlearn: 70970.2856687\ttotal: 2.28s\tremaining: 24.6s\n",
      "85:\tlearn: 70957.9731840\ttotal: 2.3s\tremaining: 24.5s\n",
      "86:\tlearn: 70940.3493139\ttotal: 2.31s\tremaining: 24.3s\n",
      "87:\tlearn: 70899.9917305\ttotal: 2.32s\tremaining: 24.1s\n",
      "88:\tlearn: 70777.5363564\ttotal: 2.34s\tremaining: 23.9s\n",
      "89:\tlearn: 70768.3461623\ttotal: 2.35s\tremaining: 23.8s\n",
      "90:\tlearn: 70675.9744694\ttotal: 2.37s\tremaining: 23.6s\n",
      "91:\tlearn: 70651.5682194\ttotal: 2.38s\tremaining: 23.5s\n",
      "92:\tlearn: 70595.7266592\ttotal: 2.39s\tremaining: 23.3s\n",
      "93:\tlearn: 70583.6318165\ttotal: 2.4s\tremaining: 23.2s\n",
      "94:\tlearn: 70571.5091597\ttotal: 2.42s\tremaining: 23s\n",
      "95:\tlearn: 70560.3024870\ttotal: 2.43s\tremaining: 22.9s\n",
      "96:\tlearn: 70531.3224993\ttotal: 2.44s\tremaining: 22.7s\n",
      "97:\tlearn: 70524.0075136\ttotal: 2.46s\tremaining: 22.6s\n",
      "98:\tlearn: 70522.8630709\ttotal: 2.47s\tremaining: 22.5s\n",
      "99:\tlearn: 70423.5779644\ttotal: 2.48s\tremaining: 22.4s\n",
      "100:\tlearn: 70414.6784895\ttotal: 2.52s\tremaining: 22.4s\n",
      "101:\tlearn: 70352.8375538\ttotal: 2.53s\tremaining: 22.3s\n",
      "102:\tlearn: 70278.1590306\ttotal: 2.55s\tremaining: 22.2s\n",
      "103:\tlearn: 70159.6195264\ttotal: 2.57s\tremaining: 22.1s\n",
      "104:\tlearn: 70140.6152400\ttotal: 2.58s\tremaining: 22s\n",
      "105:\tlearn: 70126.8843465\ttotal: 2.6s\tremaining: 21.9s\n",
      "106:\tlearn: 70077.0267231\ttotal: 2.6s\tremaining: 21.7s\n",
      "107:\tlearn: 70053.1329271\ttotal: 2.62s\tremaining: 21.6s\n",
      "108:\tlearn: 70046.4449952\ttotal: 2.63s\tremaining: 21.5s\n",
      "109:\tlearn: 70037.8188514\ttotal: 2.64s\tremaining: 21.4s\n",
      "110:\tlearn: 70032.1499483\ttotal: 2.66s\tremaining: 21.3s\n",
      "111:\tlearn: 69972.9599919\ttotal: 2.67s\tremaining: 21.2s\n",
      "112:\tlearn: 69913.8970479\ttotal: 2.68s\tremaining: 21.1s\n",
      "113:\tlearn: 69877.5933944\ttotal: 2.7s\tremaining: 21s\n",
      "114:\tlearn: 69825.2114810\ttotal: 2.82s\tremaining: 21.7s\n",
      "115:\tlearn: 69773.0518539\ttotal: 2.83s\tremaining: 21.6s\n",
      "116:\tlearn: 69767.7107482\ttotal: 2.84s\tremaining: 21.4s\n",
      "117:\tlearn: 69762.7440909\ttotal: 2.85s\tremaining: 21.3s\n",
      "118:\tlearn: 69749.5845075\ttotal: 2.87s\tremaining: 21.3s\n",
      "119:\tlearn: 69719.0896454\ttotal: 2.88s\tremaining: 21.1s\n",
      "120:\tlearn: 69714.2261176\ttotal: 2.89s\tremaining: 21s\n",
      "121:\tlearn: 69706.5340845\ttotal: 2.9s\tremaining: 20.9s\n",
      "122:\tlearn: 69591.4404223\ttotal: 2.92s\tremaining: 20.8s\n",
      "123:\tlearn: 69583.5015525\ttotal: 2.94s\tremaining: 20.8s\n",
      "124:\tlearn: 69482.1116137\ttotal: 2.97s\tremaining: 20.8s\n",
      "125:\tlearn: 69389.0061989\ttotal: 2.99s\tremaining: 20.7s\n",
      "126:\tlearn: 69316.4790788\ttotal: 2.99s\tremaining: 20.6s\n",
      "127:\tlearn: 69312.0373408\ttotal: 3.01s\tremaining: 20.5s\n",
      "128:\tlearn: 69304.8498104\ttotal: 3.02s\tremaining: 20.4s\n",
      "129:\tlearn: 69288.8679068\ttotal: 3.03s\tremaining: 20.3s\n",
      "130:\tlearn: 69220.1955701\ttotal: 3.04s\tremaining: 20.2s\n",
      "131:\tlearn: 69116.1008685\ttotal: 3.06s\tremaining: 20.2s\n",
      "132:\tlearn: 68983.4172215\ttotal: 3.08s\tremaining: 20.1s\n",
      "133:\tlearn: 68977.0899034\ttotal: 3.09s\tremaining: 20s\n",
      "134:\tlearn: 68949.1938825\ttotal: 3.11s\tremaining: 19.9s\n",
      "135:\tlearn: 68848.1055167\ttotal: 3.12s\tremaining: 19.8s\n",
      "136:\tlearn: 68771.0129080\ttotal: 3.14s\tremaining: 19.8s\n",
      "137:\tlearn: 68726.9617777\ttotal: 3.18s\tremaining: 19.8s\n",
      "138:\tlearn: 68720.3976870\ttotal: 3.19s\tremaining: 19.8s\n",
      "139:\tlearn: 68657.9420724\ttotal: 3.2s\tremaining: 19.7s\n",
      "140:\tlearn: 68603.5940014\ttotal: 3.21s\tremaining: 19.5s\n",
      "141:\tlearn: 68564.4844047\ttotal: 3.22s\tremaining: 19.4s\n",
      "142:\tlearn: 68560.6924926\ttotal: 3.23s\tremaining: 19.4s\n",
      "143:\tlearn: 68473.9382309\ttotal: 3.25s\tremaining: 19.3s\n",
      "144:\tlearn: 68422.9439518\ttotal: 3.25s\tremaining: 19.2s\n",
      "145:\tlearn: 68374.0374375\ttotal: 3.27s\tremaining: 19.2s\n",
      "146:\tlearn: 68347.4610408\ttotal: 3.29s\tremaining: 19.1s\n",
      "147:\tlearn: 68265.4661797\ttotal: 3.3s\tremaining: 19s\n",
      "148:\tlearn: 68259.2483926\ttotal: 3.32s\tremaining: 18.9s\n",
      "149:\tlearn: 68116.0833158\ttotal: 3.33s\tremaining: 18.9s\n",
      "150:\tlearn: 68041.0553725\ttotal: 3.36s\tremaining: 18.9s\n",
      "151:\tlearn: 67916.9832121\ttotal: 3.38s\tremaining: 18.9s\n",
      "152:\tlearn: 67910.7744798\ttotal: 3.41s\tremaining: 18.9s\n",
      "153:\tlearn: 67907.5182003\ttotal: 3.41s\tremaining: 18.8s\n",
      "154:\tlearn: 67867.3557889\ttotal: 3.43s\tremaining: 18.7s\n",
      "155:\tlearn: 67850.6646748\ttotal: 3.44s\tremaining: 18.6s\n",
      "156:\tlearn: 67834.1217677\ttotal: 3.45s\tremaining: 18.5s\n",
      "157:\tlearn: 67804.1045980\ttotal: 3.46s\tremaining: 18.5s\n",
      "158:\tlearn: 67774.4587450\ttotal: 3.48s\tremaining: 18.4s\n",
      "159:\tlearn: 67707.1512744\ttotal: 3.49s\tremaining: 18.3s\n",
      "160:\tlearn: 67672.5452554\ttotal: 3.5s\tremaining: 18.2s\n",
      "161:\tlearn: 67610.9292501\ttotal: 3.51s\tremaining: 18.2s\n",
      "162:\tlearn: 67525.6910868\ttotal: 3.52s\tremaining: 18.1s\n",
      "163:\tlearn: 67480.0885572\ttotal: 3.54s\tremaining: 18.1s\n",
      "164:\tlearn: 67393.2148951\ttotal: 3.56s\tremaining: 18s\n",
      "165:\tlearn: 67310.8764389\ttotal: 3.6s\tremaining: 18.1s\n",
      "166:\tlearn: 67273.6710747\ttotal: 3.62s\tremaining: 18.1s\n",
      "167:\tlearn: 67191.1742054\ttotal: 3.63s\tremaining: 18s\n",
      "168:\tlearn: 67125.7505204\ttotal: 3.64s\tremaining: 17.9s\n",
      "169:\tlearn: 67045.9100279\ttotal: 3.66s\tremaining: 17.9s\n",
      "170:\tlearn: 67042.6338473\ttotal: 3.67s\tremaining: 17.8s\n",
      "171:\tlearn: 67010.5318933\ttotal: 3.69s\tremaining: 17.7s\n",
      "172:\tlearn: 67006.7396259\ttotal: 3.69s\tremaining: 17.7s\n",
      "173:\tlearn: 66990.9347527\ttotal: 3.71s\tremaining: 17.6s\n",
      "174:\tlearn: 66945.5753448\ttotal: 3.72s\tremaining: 17.6s\n",
      "175:\tlearn: 66866.7275514\ttotal: 3.74s\tremaining: 17.5s\n",
      "176:\tlearn: 66818.8543592\ttotal: 3.75s\tremaining: 17.5s\n",
      "177:\tlearn: 66759.9435248\ttotal: 3.77s\tremaining: 17.4s\n",
      "178:\tlearn: 66731.2668131\ttotal: 3.79s\tremaining: 17.4s\n",
      "179:\tlearn: 66642.6705239\ttotal: 3.89s\tremaining: 17.7s\n",
      "180:\tlearn: 66607.9280997\ttotal: 3.91s\tremaining: 17.7s\n",
      "181:\tlearn: 66544.6213549\ttotal: 3.92s\tremaining: 17.6s\n",
      "182:\tlearn: 66519.4186744\ttotal: 3.93s\tremaining: 17.5s\n",
      "183:\tlearn: 66478.8497302\ttotal: 3.94s\tremaining: 17.5s\n",
      "184:\tlearn: 66475.3415536\ttotal: 3.96s\tremaining: 17.4s\n",
      "185:\tlearn: 66467.4253288\ttotal: 3.97s\tremaining: 17.4s\n",
      "186:\tlearn: 66443.0557343\ttotal: 3.98s\tremaining: 17.3s\n",
      "187:\tlearn: 66438.7148328\ttotal: 4s\tremaining: 17.3s\n",
      "188:\tlearn: 66382.0082504\ttotal: 4.04s\tremaining: 17.3s\n",
      "189:\tlearn: 66378.8447600\ttotal: 4.05s\tremaining: 17.3s\n",
      "190:\tlearn: 66330.0723172\ttotal: 4.06s\tremaining: 17.2s\n",
      "191:\tlearn: 66317.6194140\ttotal: 4.07s\tremaining: 17.1s\n",
      "192:\tlearn: 66285.8070515\ttotal: 4.09s\tremaining: 17.1s\n",
      "193:\tlearn: 66199.1326743\ttotal: 4.1s\tremaining: 17s\n",
      "194:\tlearn: 66158.8376053\ttotal: 4.11s\tremaining: 17s\n",
      "195:\tlearn: 66111.1660870\ttotal: 4.14s\tremaining: 17s\n",
      "196:\tlearn: 66072.4065309\ttotal: 4.15s\tremaining: 16.9s\n",
      "197:\tlearn: 66039.4893206\ttotal: 4.16s\tremaining: 16.8s\n",
      "198:\tlearn: 66030.2375832\ttotal: 4.17s\tremaining: 16.8s\n",
      "199:\tlearn: 65949.0991701\ttotal: 4.18s\tremaining: 16.7s\n",
      "200:\tlearn: 65888.3511292\ttotal: 4.2s\tremaining: 16.7s\n",
      "201:\tlearn: 65796.6950779\ttotal: 4.2s\tremaining: 16.6s\n",
      "202:\tlearn: 65719.7542139\ttotal: 4.24s\tremaining: 16.6s\n",
      "203:\tlearn: 65711.2698909\ttotal: 4.26s\tremaining: 16.6s\n",
      "204:\tlearn: 65679.9622426\ttotal: 4.28s\tremaining: 16.6s\n",
      "205:\tlearn: 65607.5227891\ttotal: 4.29s\tremaining: 16.5s\n",
      "206:\tlearn: 65532.6712511\ttotal: 4.3s\tremaining: 16.5s\n",
      "207:\tlearn: 65521.2300642\ttotal: 4.32s\tremaining: 16.4s\n",
      "208:\tlearn: 65451.2917775\ttotal: 4.34s\tremaining: 16.4s\n",
      "209:\tlearn: 65388.0257614\ttotal: 4.35s\tremaining: 16.4s\n",
      "210:\tlearn: 65355.1739501\ttotal: 4.37s\tremaining: 16.3s\n",
      "211:\tlearn: 65326.1819405\ttotal: 4.38s\tremaining: 16.3s\n",
      "212:\tlearn: 65260.5521802\ttotal: 4.39s\tremaining: 16.2s\n",
      "213:\tlearn: 65257.4087395\ttotal: 4.4s\tremaining: 16.2s\n",
      "214:\tlearn: 65229.2266375\ttotal: 4.42s\tremaining: 16.1s\n",
      "215:\tlearn: 65147.0051836\ttotal: 4.43s\tremaining: 16.1s\n",
      "216:\tlearn: 65052.5983756\ttotal: 4.45s\tremaining: 16.1s\n",
      "217:\tlearn: 65044.8359183\ttotal: 4.49s\tremaining: 16.1s\n",
      "218:\tlearn: 64970.3812934\ttotal: 4.5s\tremaining: 16.1s\n",
      "219:\tlearn: 64957.4565237\ttotal: 4.52s\tremaining: 16s\n",
      "220:\tlearn: 64954.5548565\ttotal: 4.53s\tremaining: 16s\n",
      "221:\tlearn: 64925.0474051\ttotal: 4.55s\tremaining: 15.9s\n",
      "222:\tlearn: 64892.7109861\ttotal: 4.56s\tremaining: 15.9s\n",
      "223:\tlearn: 64889.8867577\ttotal: 4.58s\tremaining: 15.9s\n",
      "224:\tlearn: 64863.3668132\ttotal: 4.58s\tremaining: 15.8s\n",
      "225:\tlearn: 64860.6671573\ttotal: 4.6s\tremaining: 15.8s\n",
      "226:\tlearn: 64858.0814647\ttotal: 4.62s\tremaining: 15.7s\n",
      "227:\tlearn: 64855.6053234\ttotal: 4.63s\tremaining: 15.7s\n",
      "228:\tlearn: 64792.7207820\ttotal: 4.65s\tremaining: 15.6s\n",
      "229:\tlearn: 64759.1668195\ttotal: 4.66s\tremaining: 15.6s\n",
      "230:\tlearn: 64733.7094479\ttotal: 4.68s\tremaining: 15.6s\n",
      "231:\tlearn: 64682.5916637\ttotal: 4.7s\tremaining: 15.6s\n",
      "232:\tlearn: 64680.2131942\ttotal: 4.72s\tremaining: 15.5s\n",
      "233:\tlearn: 64620.7021879\ttotal: 4.73s\tremaining: 15.5s\n",
      "234:\tlearn: 64565.4150853\ttotal: 4.75s\tremaining: 15.5s\n",
      "235:\tlearn: 64540.7173692\ttotal: 4.76s\tremaining: 15.4s\n",
      "236:\tlearn: 64516.6701201\ttotal: 4.78s\tremaining: 15.4s\n",
      "237:\tlearn: 64447.3480399\ttotal: 4.79s\tremaining: 15.3s\n",
      "238:\tlearn: 64403.1687643\ttotal: 4.8s\tremaining: 15.3s\n",
      "239:\tlearn: 64336.3364612\ttotal: 4.81s\tremaining: 15.2s\n",
      "240:\tlearn: 64331.6306597\ttotal: 4.83s\tremaining: 15.2s\n",
      "241:\tlearn: 64303.3246841\ttotal: 4.84s\tremaining: 15.2s\n",
      "242:\tlearn: 64297.8037518\ttotal: 4.85s\tremaining: 15.1s\n",
      "243:\tlearn: 64290.4478112\ttotal: 4.86s\tremaining: 15.1s\n",
      "244:\tlearn: 64226.0040009\ttotal: 4.88s\tremaining: 15s\n",
      "245:\tlearn: 64182.0206834\ttotal: 4.9s\tremaining: 15s\n",
      "246:\tlearn: 64119.9115419\ttotal: 4.91s\tremaining: 15s\n",
      "247:\tlearn: 64086.8726715\ttotal: 5.01s\tremaining: 15.2s\n",
      "248:\tlearn: 64058.8431672\ttotal: 5.02s\tremaining: 15.2s\n",
      "249:\tlearn: 64057.1909701\ttotal: 5.03s\tremaining: 15.1s\n",
      "250:\tlearn: 63997.2990408\ttotal: 5.04s\tremaining: 15s\n",
      "251:\tlearn: 63990.5936231\ttotal: 5.06s\tremaining: 15s\n",
      "252:\tlearn: 63942.0076156\ttotal: 5.08s\tremaining: 15s\n",
      "253:\tlearn: 63928.1319910\ttotal: 5.09s\tremaining: 14.9s\n",
      "254:\tlearn: 63882.8875655\ttotal: 5.11s\tremaining: 14.9s\n",
      "255:\tlearn: 63878.4970035\ttotal: 5.14s\tremaining: 14.9s\n",
      "256:\tlearn: 63820.6458528\ttotal: 5.16s\tremaining: 14.9s\n",
      "257:\tlearn: 63764.8884747\ttotal: 5.17s\tremaining: 14.9s\n",
      "258:\tlearn: 63746.2524045\ttotal: 5.21s\tremaining: 14.9s\n",
      "259:\tlearn: 63739.8618189\ttotal: 5.22s\tremaining: 14.9s\n",
      "260:\tlearn: 63714.3722031\ttotal: 5.24s\tremaining: 14.8s\n",
      "261:\tlearn: 63660.5852456\ttotal: 5.25s\tremaining: 14.8s\n",
      "262:\tlearn: 63643.5458443\ttotal: 5.26s\tremaining: 14.7s\n",
      "263:\tlearn: 63591.6815019\ttotal: 5.27s\tremaining: 14.7s\n",
      "264:\tlearn: 63541.6822510\ttotal: 5.29s\tremaining: 14.7s\n",
      "265:\tlearn: 63493.4821984\ttotal: 5.3s\tremaining: 14.6s\n",
      "266:\tlearn: 63467.2764093\ttotal: 5.32s\tremaining: 14.6s\n",
      "267:\tlearn: 63438.1867367\ttotal: 5.36s\tremaining: 14.6s\n",
      "268:\tlearn: 63429.2604781\ttotal: 5.37s\tremaining: 14.6s\n",
      "269:\tlearn: 63412.8055046\ttotal: 5.39s\tremaining: 14.6s\n",
      "270:\tlearn: 63397.3205321\ttotal: 5.4s\tremaining: 14.5s\n",
      "271:\tlearn: 63384.0731402\ttotal: 5.42s\tremaining: 14.5s\n",
      "272:\tlearn: 63333.4476470\ttotal: 5.43s\tremaining: 14.5s\n",
      "273:\tlearn: 63290.3188423\ttotal: 5.45s\tremaining: 14.4s\n",
      "274:\tlearn: 63289.3677680\ttotal: 5.45s\tremaining: 14.4s\n",
      "275:\tlearn: 63285.7866315\ttotal: 5.46s\tremaining: 14.3s\n",
      "276:\tlearn: 63267.9271764\ttotal: 5.47s\tremaining: 14.3s\n",
      "277:\tlearn: 63221.2805936\ttotal: 5.49s\tremaining: 14.3s\n",
      "278:\tlearn: 63211.2568100\ttotal: 5.5s\tremaining: 14.2s\n",
      "279:\tlearn: 63166.2734419\ttotal: 5.52s\tremaining: 14.2s\n",
      "280:\tlearn: 63107.1882492\ttotal: 5.54s\tremaining: 14.2s\n",
      "281:\tlearn: 63052.8073982\ttotal: 5.55s\tremaining: 14.1s\n",
      "282:\tlearn: 63049.5707879\ttotal: 5.57s\tremaining: 14.1s\n",
      "283:\tlearn: 63006.1341172\ttotal: 5.58s\tremaining: 14.1s\n",
      "284:\tlearn: 62989.5277347\ttotal: 5.62s\tremaining: 14.1s\n",
      "285:\tlearn: 62977.2970956\ttotal: 5.63s\tremaining: 14.1s\n",
      "286:\tlearn: 62900.6645471\ttotal: 5.65s\tremaining: 14s\n",
      "287:\tlearn: 62793.7080743\ttotal: 5.67s\tremaining: 14s\n",
      "288:\tlearn: 62750.2093906\ttotal: 5.68s\tremaining: 14s\n",
      "289:\tlearn: 62708.2638792\ttotal: 5.7s\tremaining: 14s\n",
      "290:\tlearn: 62648.5216894\ttotal: 5.71s\tremaining: 13.9s\n",
      "291:\tlearn: 62623.8583283\ttotal: 5.73s\tremaining: 13.9s\n",
      "292:\tlearn: 62603.1734255\ttotal: 5.75s\tremaining: 13.9s\n",
      "293:\tlearn: 62587.1850992\ttotal: 5.76s\tremaining: 13.8s\n",
      "294:\tlearn: 62584.0355470\ttotal: 5.76s\tremaining: 13.8s\n",
      "295:\tlearn: 62543.4854615\ttotal: 5.79s\tremaining: 13.8s\n",
      "296:\tlearn: 62504.3823751\ttotal: 5.81s\tremaining: 13.8s\n",
      "297:\tlearn: 62466.6734001\ttotal: 5.83s\tremaining: 13.7s\n",
      "298:\tlearn: 62446.7811246\ttotal: 5.84s\tremaining: 13.7s\n",
      "299:\tlearn: 62428.7697393\ttotal: 5.85s\tremaining: 13.6s\n",
      "300:\tlearn: 62425.7020252\ttotal: 5.86s\tremaining: 13.6s\n",
      "301:\tlearn: 62386.2658058\ttotal: 5.88s\tremaining: 13.6s\n",
      "302:\tlearn: 62348.5021182\ttotal: 5.89s\tremaining: 13.5s\n",
      "303:\tlearn: 62333.0672797\ttotal: 5.9s\tremaining: 13.5s\n",
      "304:\tlearn: 62329.6072059\ttotal: 5.91s\tremaining: 13.5s\n",
      "305:\tlearn: 62309.3532627\ttotal: 5.93s\tremaining: 13.5s\n",
      "306:\tlearn: 62307.6168646\ttotal: 5.94s\tremaining: 13.4s\n",
      "307:\tlearn: 62272.3326786\ttotal: 5.96s\tremaining: 13.4s\n",
      "308:\tlearn: 62205.2225269\ttotal: 5.97s\tremaining: 13.4s\n",
      "309:\tlearn: 62148.0116247\ttotal: 5.98s\tremaining: 13.3s\n",
      "310:\tlearn: 62110.0838639\ttotal: 6.08s\tremaining: 13.5s\n",
      "311:\tlearn: 62011.7611447\ttotal: 6.09s\tremaining: 13.4s\n",
      "312:\tlearn: 61974.8500745\ttotal: 6.11s\tremaining: 13.4s\n",
      "313:\tlearn: 61956.2274532\ttotal: 6.12s\tremaining: 13.4s\n",
      "314:\tlearn: 61926.0284700\ttotal: 6.14s\tremaining: 13.3s\n",
      "315:\tlearn: 61911.2264843\ttotal: 6.15s\tremaining: 13.3s\n",
      "316:\tlearn: 61872.4720847\ttotal: 6.16s\tremaining: 13.3s\n",
      "317:\tlearn: 61853.3003603\ttotal: 6.18s\tremaining: 13.3s\n",
      "318:\tlearn: 61841.0478035\ttotal: 6.23s\tremaining: 13.3s\n",
      "319:\tlearn: 61818.7731454\ttotal: 6.24s\tremaining: 13.3s\n",
      "320:\tlearn: 61762.5816073\ttotal: 6.25s\tremaining: 13.2s\n",
      "321:\tlearn: 61748.3114968\ttotal: 6.27s\tremaining: 13.2s\n",
      "322:\tlearn: 61692.5211948\ttotal: 6.28s\tremaining: 13.2s\n",
      "323:\tlearn: 61657.4509175\ttotal: 6.3s\tremaining: 13.1s\n",
      "324:\tlearn: 61636.7443546\ttotal: 6.32s\tremaining: 13.1s\n",
      "325:\tlearn: 61630.3782962\ttotal: 6.33s\tremaining: 13.1s\n",
      "326:\tlearn: 61581.5116410\ttotal: 6.34s\tremaining: 13.1s\n",
      "327:\tlearn: 61548.4326637\ttotal: 6.35s\tremaining: 13s\n",
      "328:\tlearn: 61513.6266593\ttotal: 6.37s\tremaining: 13s\n",
      "329:\tlearn: 61468.2346489\ttotal: 6.38s\tremaining: 13s\n",
      "330:\tlearn: 61433.3690101\ttotal: 6.4s\tremaining: 12.9s\n",
      "331:\tlearn: 61393.8101563\ttotal: 6.44s\tremaining: 13s\n",
      "332:\tlearn: 61323.5294399\ttotal: 6.46s\tremaining: 12.9s\n",
      "333:\tlearn: 61302.9285813\ttotal: 6.47s\tremaining: 12.9s\n",
      "334:\tlearn: 61273.1623334\ttotal: 6.5s\tremaining: 12.9s\n",
      "335:\tlearn: 61245.3095464\ttotal: 6.52s\tremaining: 12.9s\n",
      "336:\tlearn: 61239.5189620\ttotal: 6.53s\tremaining: 12.8s\n",
      "337:\tlearn: 61225.6826732\ttotal: 6.54s\tremaining: 12.8s\n",
      "338:\tlearn: 61202.0056838\ttotal: 6.55s\tremaining: 12.8s\n",
      "339:\tlearn: 61177.1195424\ttotal: 6.56s\tremaining: 12.7s\n",
      "340:\tlearn: 61147.0479932\ttotal: 6.58s\tremaining: 12.7s\n",
      "341:\tlearn: 61122.9054011\ttotal: 6.59s\tremaining: 12.7s\n",
      "342:\tlearn: 61091.9225939\ttotal: 6.61s\tremaining: 12.7s\n",
      "343:\tlearn: 61078.5123532\ttotal: 6.64s\tremaining: 12.7s\n",
      "344:\tlearn: 61029.4232409\ttotal: 6.66s\tremaining: 12.6s\n",
      "345:\tlearn: 61008.4789201\ttotal: 6.67s\tremaining: 12.6s\n",
      "346:\tlearn: 60977.2331055\ttotal: 6.68s\tremaining: 12.6s\n",
      "347:\tlearn: 60947.8732107\ttotal: 6.69s\tremaining: 12.5s\n",
      "348:\tlearn: 60928.8362395\ttotal: 6.71s\tremaining: 12.5s\n",
      "349:\tlearn: 60915.9158580\ttotal: 6.72s\tremaining: 12.5s\n",
      "350:\tlearn: 60877.9284059\ttotal: 6.74s\tremaining: 12.5s\n",
      "351:\tlearn: 60864.9074679\ttotal: 6.75s\tremaining: 12.4s\n",
      "352:\tlearn: 60834.9490563\ttotal: 6.76s\tremaining: 12.4s\n",
      "353:\tlearn: 60751.4764955\ttotal: 6.78s\tremaining: 12.4s\n",
      "354:\tlearn: 60710.9816476\ttotal: 6.79s\tremaining: 12.3s\n",
      "355:\tlearn: 60675.2664361\ttotal: 6.8s\tremaining: 12.3s\n",
      "356:\tlearn: 60670.1231620\ttotal: 6.82s\tremaining: 12.3s\n",
      "357:\tlearn: 60641.1505617\ttotal: 6.88s\tremaining: 12.3s\n",
      "358:\tlearn: 60625.6324049\ttotal: 6.89s\tremaining: 12.3s\n",
      "359:\tlearn: 60596.0012979\ttotal: 6.9s\tremaining: 12.3s\n",
      "360:\tlearn: 60569.0411824\ttotal: 6.92s\tremaining: 12.2s\n",
      "361:\tlearn: 60551.1585969\ttotal: 6.92s\tremaining: 12.2s\n",
      "362:\tlearn: 60532.7287903\ttotal: 6.95s\tremaining: 12.2s\n",
      "363:\tlearn: 60520.1283153\ttotal: 6.96s\tremaining: 12.2s\n",
      "364:\tlearn: 60460.5144594\ttotal: 6.97s\tremaining: 12.1s\n",
      "365:\tlearn: 60433.1362939\ttotal: 6.98s\tremaining: 12.1s\n",
      "366:\tlearn: 60405.5773321\ttotal: 7s\tremaining: 12.1s\n",
      "367:\tlearn: 60387.8469242\ttotal: 7.01s\tremaining: 12s\n",
      "368:\tlearn: 60375.8088183\ttotal: 7.02s\tremaining: 12s\n",
      "369:\tlearn: 60350.6646674\ttotal: 7.04s\tremaining: 12s\n",
      "370:\tlearn: 60294.3429429\ttotal: 7.15s\tremaining: 12.1s\n",
      "371:\tlearn: 60265.8879245\ttotal: 7.18s\tremaining: 12.1s\n",
      "372:\tlearn: 60241.6011738\ttotal: 7.23s\tremaining: 12.1s\n",
      "373:\tlearn: 60187.2953048\ttotal: 7.24s\tremaining: 12.1s\n",
      "374:\tlearn: 60134.9770231\ttotal: 7.28s\tremaining: 12.1s\n",
      "375:\tlearn: 60113.4800516\ttotal: 7.3s\tremaining: 12.1s\n",
      "376:\tlearn: 60078.8661089\ttotal: 7.32s\tremaining: 12.1s\n",
      "377:\tlearn: 60029.5601518\ttotal: 7.33s\tremaining: 12.1s\n",
      "378:\tlearn: 60023.6563197\ttotal: 7.34s\tremaining: 12s\n",
      "379:\tlearn: 59976.2281689\ttotal: 7.35s\tremaining: 12s\n",
      "380:\tlearn: 59952.7866350\ttotal: 7.37s\tremaining: 12s\n",
      "381:\tlearn: 59896.7411778\ttotal: 7.38s\tremaining: 11.9s\n",
      "382:\tlearn: 59871.2451582\ttotal: 7.39s\tremaining: 11.9s\n",
      "383:\tlearn: 59858.9863518\ttotal: 7.4s\tremaining: 11.9s\n",
      "384:\tlearn: 59836.7309939\ttotal: 7.42s\tremaining: 11.8s\n",
      "385:\tlearn: 59784.5761414\ttotal: 7.43s\tremaining: 11.8s\n",
      "386:\tlearn: 59775.0323868\ttotal: 7.44s\tremaining: 11.8s\n",
      "387:\tlearn: 59749.6465786\ttotal: 7.45s\tremaining: 11.7s\n",
      "388:\tlearn: 59727.0767801\ttotal: 7.46s\tremaining: 11.7s\n",
      "389:\tlearn: 59699.1007636\ttotal: 7.48s\tremaining: 11.7s\n",
      "390:\tlearn: 59687.2645012\ttotal: 7.5s\tremaining: 11.7s\n",
      "391:\tlearn: 59671.7432063\ttotal: 7.51s\tremaining: 11.7s\n",
      "392:\tlearn: 59656.5590491\ttotal: 7.55s\tremaining: 11.7s\n",
      "393:\tlearn: 59642.2320097\ttotal: 7.56s\tremaining: 11.6s\n",
      "394:\tlearn: 59620.0472929\ttotal: 7.59s\tremaining: 11.6s\n",
      "395:\tlearn: 59608.6245250\ttotal: 7.6s\tremaining: 11.6s\n",
      "396:\tlearn: 59578.4181021\ttotal: 7.61s\tremaining: 11.6s\n",
      "397:\tlearn: 59556.5923187\ttotal: 7.62s\tremaining: 11.5s\n",
      "398:\tlearn: 59551.0951622\ttotal: 7.63s\tremaining: 11.5s\n",
      "399:\tlearn: 59530.1882136\ttotal: 7.64s\tremaining: 11.5s\n",
      "400:\tlearn: 59521.2777914\ttotal: 7.66s\tremaining: 11.4s\n",
      "401:\tlearn: 59506.2786114\ttotal: 7.67s\tremaining: 11.4s\n",
      "402:\tlearn: 59494.7640296\ttotal: 7.69s\tremaining: 11.4s\n",
      "403:\tlearn: 59479.2751639\ttotal: 7.7s\tremaining: 11.4s\n",
      "404:\tlearn: 59434.2889010\ttotal: 7.72s\tremaining: 11.3s\n",
      "405:\tlearn: 59411.4857654\ttotal: 7.74s\tremaining: 11.3s\n",
      "406:\tlearn: 59406.2515749\ttotal: 7.76s\tremaining: 11.3s\n",
      "407:\tlearn: 59362.8358148\ttotal: 7.77s\tremaining: 11.3s\n",
      "408:\tlearn: 59350.4024061\ttotal: 7.79s\tremaining: 11.3s\n",
      "409:\tlearn: 59328.9622881\ttotal: 7.8s\tremaining: 11.2s\n",
      "410:\tlearn: 59321.6092973\ttotal: 7.81s\tremaining: 11.2s\n",
      "411:\tlearn: 59309.7135669\ttotal: 7.83s\tremaining: 11.2s\n",
      "412:\tlearn: 59299.0970050\ttotal: 7.84s\tremaining: 11.1s\n",
      "413:\tlearn: 59275.2671400\ttotal: 7.85s\tremaining: 11.1s\n",
      "414:\tlearn: 59254.8594480\ttotal: 7.86s\tremaining: 11.1s\n",
      "415:\tlearn: 59200.6656314\ttotal: 7.88s\tremaining: 11.1s\n",
      "416:\tlearn: 59190.6380467\ttotal: 7.89s\tremaining: 11s\n",
      "417:\tlearn: 59176.4793361\ttotal: 7.9s\tremaining: 11s\n",
      "418:\tlearn: 59156.7744628\ttotal: 7.91s\tremaining: 11s\n",
      "419:\tlearn: 59126.7887688\ttotal: 7.93s\tremaining: 10.9s\n",
      "420:\tlearn: 59113.3723355\ttotal: 8.04s\tremaining: 11.1s\n",
      "421:\tlearn: 59097.0953995\ttotal: 8.06s\tremaining: 11s\n",
      "422:\tlearn: 59083.4769404\ttotal: 8.08s\tremaining: 11s\n",
      "423:\tlearn: 59065.3890193\ttotal: 8.1s\tremaining: 11s\n",
      "424:\tlearn: 59046.8202109\ttotal: 8.12s\tremaining: 11s\n",
      "425:\tlearn: 59027.7441364\ttotal: 8.13s\tremaining: 11s\n",
      "426:\tlearn: 59018.4387785\ttotal: 8.15s\tremaining: 10.9s\n",
      "427:\tlearn: 58949.6398608\ttotal: 8.16s\tremaining: 10.9s\n",
      "428:\tlearn: 58944.7491791\ttotal: 8.2s\tremaining: 10.9s\n",
      "429:\tlearn: 58902.6501780\ttotal: 8.22s\tremaining: 10.9s\n",
      "430:\tlearn: 58897.9779999\ttotal: 8.25s\tremaining: 10.9s\n",
      "431:\tlearn: 58877.1210541\ttotal: 8.26s\tremaining: 10.9s\n",
      "432:\tlearn: 58862.7822546\ttotal: 8.28s\tremaining: 10.8s\n",
      "433:\tlearn: 58850.0231250\ttotal: 8.29s\tremaining: 10.8s\n",
      "434:\tlearn: 58823.2054550\ttotal: 8.31s\tremaining: 10.8s\n",
      "435:\tlearn: 58812.5293220\ttotal: 8.33s\tremaining: 10.8s\n",
      "436:\tlearn: 58804.2190102\ttotal: 8.34s\tremaining: 10.7s\n",
      "437:\tlearn: 58790.8028707\ttotal: 8.36s\tremaining: 10.7s\n",
      "438:\tlearn: 58724.4197844\ttotal: 8.4s\tremaining: 10.7s\n",
      "439:\tlearn: 58716.1133015\ttotal: 8.42s\tremaining: 10.7s\n",
      "440:\tlearn: 58664.7733728\ttotal: 8.43s\tremaining: 10.7s\n",
      "441:\tlearn: 58656.0363201\ttotal: 8.45s\tremaining: 10.7s\n",
      "442:\tlearn: 58642.9903985\ttotal: 8.46s\tremaining: 10.6s\n",
      "443:\tlearn: 58625.4577857\ttotal: 8.48s\tremaining: 10.6s\n",
      "444:\tlearn: 58612.9037499\ttotal: 8.49s\tremaining: 10.6s\n",
      "445:\tlearn: 58567.4660392\ttotal: 8.52s\tremaining: 10.6s\n",
      "446:\tlearn: 58553.4167028\ttotal: 8.54s\tremaining: 10.6s\n",
      "447:\tlearn: 58544.0561657\ttotal: 8.56s\tremaining: 10.5s\n",
      "448:\tlearn: 58520.9872646\ttotal: 8.58s\tremaining: 10.5s\n",
      "449:\tlearn: 58496.5604712\ttotal: 8.62s\tremaining: 10.5s\n",
      "450:\tlearn: 58484.5559377\ttotal: 8.63s\tremaining: 10.5s\n",
      "451:\tlearn: 58428.9376462\ttotal: 8.65s\tremaining: 10.5s\n",
      "452:\tlearn: 58362.1692924\ttotal: 8.67s\tremaining: 10.5s\n",
      "453:\tlearn: 58351.9553954\ttotal: 8.69s\tremaining: 10.4s\n",
      "454:\tlearn: 58344.8115406\ttotal: 8.7s\tremaining: 10.4s\n",
      "455:\tlearn: 58327.5058037\ttotal: 8.72s\tremaining: 10.4s\n",
      "456:\tlearn: 58263.3095474\ttotal: 8.74s\tremaining: 10.4s\n",
      "457:\tlearn: 58238.2465867\ttotal: 8.75s\tremaining: 10.4s\n",
      "458:\tlearn: 58221.3198794\ttotal: 8.77s\tremaining: 10.3s\n",
      "459:\tlearn: 58204.9972776\ttotal: 8.78s\tremaining: 10.3s\n",
      "460:\tlearn: 58195.8512713\ttotal: 8.8s\tremaining: 10.3s\n",
      "461:\tlearn: 58152.2482138\ttotal: 8.81s\tremaining: 10.3s\n",
      "462:\tlearn: 58139.1128104\ttotal: 8.83s\tremaining: 10.2s\n",
      "463:\tlearn: 58120.1529447\ttotal: 8.85s\tremaining: 10.2s\n",
      "464:\tlearn: 58107.5512244\ttotal: 8.95s\tremaining: 10.3s\n",
      "465:\tlearn: 58101.0386277\ttotal: 8.97s\tremaining: 10.3s\n",
      "466:\tlearn: 58090.1057510\ttotal: 8.98s\tremaining: 10.3s\n",
      "467:\tlearn: 58046.3027724\ttotal: 9s\tremaining: 10.2s\n",
      "468:\tlearn: 58038.6193835\ttotal: 9.02s\tremaining: 10.2s\n",
      "469:\tlearn: 58028.2188968\ttotal: 9.06s\tremaining: 10.2s\n",
      "470:\tlearn: 57998.7025785\ttotal: 9.08s\tremaining: 10.2s\n",
      "471:\tlearn: 57959.0473178\ttotal: 9.09s\tremaining: 10.2s\n",
      "472:\tlearn: 57905.0820443\ttotal: 9.11s\tremaining: 10.1s\n",
      "473:\tlearn: 57889.2768540\ttotal: 9.12s\tremaining: 10.1s\n",
      "474:\tlearn: 57828.8688813\ttotal: 9.14s\tremaining: 10.1s\n",
      "475:\tlearn: 57819.8802817\ttotal: 9.16s\tremaining: 10.1s\n",
      "476:\tlearn: 57804.2300257\ttotal: 9.18s\tremaining: 10.1s\n",
      "477:\tlearn: 57802.5919100\ttotal: 9.2s\tremaining: 10s\n",
      "478:\tlearn: 57791.9529756\ttotal: 9.23s\tremaining: 10s\n",
      "479:\tlearn: 57776.6881447\ttotal: 9.29s\tremaining: 10.1s\n",
      "480:\tlearn: 57761.9668759\ttotal: 9.31s\tremaining: 10s\n",
      "481:\tlearn: 57748.1434434\ttotal: 9.34s\tremaining: 10s\n",
      "482:\tlearn: 57700.3021050\ttotal: 9.37s\tremaining: 10s\n",
      "483:\tlearn: 57684.2033011\ttotal: 9.39s\tremaining: 10s\n",
      "484:\tlearn: 57631.8465307\ttotal: 9.4s\tremaining: 9.98s\n",
      "485:\tlearn: 57569.4139480\ttotal: 9.42s\tremaining: 9.96s\n",
      "486:\tlearn: 57559.6562756\ttotal: 9.43s\tremaining: 9.93s\n",
      "487:\tlearn: 57545.4050160\ttotal: 9.45s\tremaining: 9.92s\n",
      "488:\tlearn: 57481.4786778\ttotal: 9.48s\tremaining: 9.91s\n",
      "489:\tlearn: 57477.8029777\ttotal: 9.5s\tremaining: 9.89s\n",
      "490:\tlearn: 57460.2675969\ttotal: 9.52s\tremaining: 9.87s\n",
      "491:\tlearn: 57444.5186233\ttotal: 9.6s\tremaining: 9.91s\n",
      "492:\tlearn: 57432.3930725\ttotal: 9.61s\tremaining: 9.89s\n",
      "493:\tlearn: 57372.4285535\ttotal: 9.65s\tremaining: 9.89s\n",
      "494:\tlearn: 57357.2398302\ttotal: 9.67s\tremaining: 9.87s\n",
      "495:\tlearn: 57352.7353916\ttotal: 9.69s\tremaining: 9.84s\n",
      "496:\tlearn: 57351.2032726\ttotal: 9.72s\tremaining: 9.84s\n",
      "497:\tlearn: 57336.5703855\ttotal: 9.74s\tremaining: 9.81s\n",
      "498:\tlearn: 57299.3920049\ttotal: 9.75s\tremaining: 9.79s\n",
      "499:\tlearn: 57289.9868705\ttotal: 9.77s\tremaining: 9.77s\n",
      "500:\tlearn: 57282.7279303\ttotal: 9.78s\tremaining: 9.74s\n",
      "501:\tlearn: 57243.1174246\ttotal: 9.79s\tremaining: 9.71s\n",
      "502:\tlearn: 57204.0406456\ttotal: 9.8s\tremaining: 9.69s\n",
      "503:\tlearn: 57167.1844071\ttotal: 9.82s\tremaining: 9.66s\n",
      "504:\tlearn: 57153.0450012\ttotal: 9.83s\tremaining: 9.64s\n",
      "505:\tlearn: 57120.1987218\ttotal: 9.84s\tremaining: 9.61s\n",
      "506:\tlearn: 57099.8589422\ttotal: 9.86s\tremaining: 9.59s\n",
      "507:\tlearn: 57090.3205679\ttotal: 9.87s\tremaining: 9.56s\n",
      "508:\tlearn: 57055.8710382\ttotal: 9.88s\tremaining: 9.54s\n",
      "509:\tlearn: 57022.6513037\ttotal: 9.98s\tremaining: 9.59s\n",
      "510:\tlearn: 57013.8683874\ttotal: 10s\tremaining: 9.57s\n",
      "511:\tlearn: 56989.5671008\ttotal: 10s\tremaining: 9.54s\n",
      "512:\tlearn: 56957.5321588\ttotal: 10s\tremaining: 9.52s\n",
      "513:\tlearn: 56907.9000598\ttotal: 10s\tremaining: 9.49s\n",
      "514:\tlearn: 56868.9248773\ttotal: 10.1s\tremaining: 9.47s\n",
      "515:\tlearn: 56859.4769961\ttotal: 10.1s\tremaining: 9.44s\n",
      "516:\tlearn: 56840.4289816\ttotal: 10.1s\tremaining: 9.42s\n",
      "517:\tlearn: 56813.6825857\ttotal: 10.1s\tremaining: 9.39s\n",
      "518:\tlearn: 56792.0606584\ttotal: 10.1s\tremaining: 9.39s\n",
      "519:\tlearn: 56780.3899820\ttotal: 10.2s\tremaining: 9.38s\n",
      "520:\tlearn: 56710.6643264\ttotal: 10.2s\tremaining: 9.36s\n",
      "521:\tlearn: 56685.9765614\ttotal: 10.2s\tremaining: 9.33s\n",
      "522:\tlearn: 56663.2813181\ttotal: 10.2s\tremaining: 9.3s\n",
      "523:\tlearn: 56641.5003413\ttotal: 10.2s\tremaining: 9.27s\n",
      "524:\tlearn: 56632.6784895\ttotal: 10.2s\tremaining: 9.24s\n",
      "525:\tlearn: 56609.5642597\ttotal: 10.2s\tremaining: 9.22s\n",
      "526:\tlearn: 56601.4184476\ttotal: 10.2s\tremaining: 9.2s\n",
      "527:\tlearn: 56592.9263077\ttotal: 10.3s\tremaining: 9.18s\n",
      "528:\tlearn: 56525.2753041\ttotal: 10.3s\tremaining: 9.15s\n",
      "529:\tlearn: 56512.7702761\ttotal: 10.3s\tremaining: 9.13s\n",
      "530:\tlearn: 56504.5900442\ttotal: 10.3s\tremaining: 9.1s\n",
      "531:\tlearn: 56496.7257181\ttotal: 10.3s\tremaining: 9.07s\n",
      "532:\tlearn: 56467.5967942\ttotal: 10.3s\tremaining: 9.04s\n",
      "533:\tlearn: 56453.8423679\ttotal: 10.3s\tremaining: 9.02s\n",
      "534:\tlearn: 56440.5883084\ttotal: 10.4s\tremaining: 9s\n",
      "535:\tlearn: 56427.4205367\ttotal: 10.4s\tremaining: 8.99s\n",
      "536:\tlearn: 56367.7087599\ttotal: 10.4s\tremaining: 8.97s\n",
      "537:\tlearn: 56348.7229350\ttotal: 10.4s\tremaining: 8.95s\n",
      "538:\tlearn: 56340.7685047\ttotal: 10.4s\tremaining: 8.93s\n",
      "539:\tlearn: 56335.9204574\ttotal: 10.4s\tremaining: 8.9s\n",
      "540:\tlearn: 56328.4567888\ttotal: 10.5s\tremaining: 8.88s\n",
      "541:\tlearn: 56308.8341834\ttotal: 10.5s\tremaining: 8.86s\n",
      "542:\tlearn: 56277.6439050\ttotal: 10.5s\tremaining: 8.83s\n",
      "543:\tlearn: 56256.3324841\ttotal: 10.5s\tremaining: 8.81s\n",
      "544:\tlearn: 56250.1933429\ttotal: 10.5s\tremaining: 8.79s\n",
      "545:\tlearn: 56196.8202993\ttotal: 10.5s\tremaining: 8.77s\n",
      "546:\tlearn: 56189.6124566\ttotal: 10.6s\tremaining: 8.75s\n",
      "547:\tlearn: 56149.9021293\ttotal: 10.6s\tremaining: 8.72s\n",
      "548:\tlearn: 56133.5725695\ttotal: 10.6s\tremaining: 8.72s\n",
      "549:\tlearn: 56120.7307767\ttotal: 10.6s\tremaining: 8.7s\n",
      "550:\tlearn: 56108.3538471\ttotal: 10.6s\tremaining: 8.67s\n",
      "551:\tlearn: 56078.1790249\ttotal: 10.7s\tremaining: 8.65s\n",
      "552:\tlearn: 56073.3671225\ttotal: 10.7s\tremaining: 8.62s\n",
      "553:\tlearn: 56053.6070537\ttotal: 10.7s\tremaining: 8.61s\n",
      "554:\tlearn: 56041.6589570\ttotal: 10.7s\tremaining: 8.58s\n",
      "555:\tlearn: 56026.9378219\ttotal: 10.7s\tremaining: 8.55s\n",
      "556:\tlearn: 55972.2840312\ttotal: 10.7s\tremaining: 8.53s\n",
      "557:\tlearn: 55925.7518546\ttotal: 10.7s\tremaining: 8.51s\n",
      "558:\tlearn: 55886.4562368\ttotal: 10.8s\tremaining: 8.48s\n",
      "559:\tlearn: 55868.7395529\ttotal: 10.8s\tremaining: 8.45s\n",
      "560:\tlearn: 55827.6226695\ttotal: 10.8s\tremaining: 8.43s\n",
      "561:\tlearn: 55815.2108715\ttotal: 10.8s\tremaining: 8.41s\n",
      "562:\tlearn: 55757.1978664\ttotal: 10.8s\tremaining: 8.39s\n",
      "563:\tlearn: 55746.2612577\ttotal: 10.8s\tremaining: 8.38s\n",
      "564:\tlearn: 55725.2454400\ttotal: 10.8s\tremaining: 8.35s\n",
      "565:\tlearn: 55714.0552811\ttotal: 10.9s\tremaining: 8.33s\n",
      "566:\tlearn: 55696.7211392\ttotal: 10.9s\tremaining: 8.3s\n",
      "567:\tlearn: 55680.8532643\ttotal: 10.9s\tremaining: 8.28s\n",
      "568:\tlearn: 55669.2565231\ttotal: 10.9s\tremaining: 8.25s\n",
      "569:\tlearn: 55655.4432145\ttotal: 10.9s\tremaining: 8.23s\n",
      "570:\tlearn: 55637.3346036\ttotal: 10.9s\tremaining: 8.21s\n",
      "571:\tlearn: 55631.0512696\ttotal: 10.9s\tremaining: 8.18s\n",
      "572:\tlearn: 55601.3185556\ttotal: 10.9s\tremaining: 8.16s\n",
      "573:\tlearn: 55586.1855768\ttotal: 11s\tremaining: 8.13s\n",
      "574:\tlearn: 55574.8274290\ttotal: 11s\tremaining: 8.11s\n",
      "575:\tlearn: 55561.8129112\ttotal: 11s\tremaining: 8.08s\n",
      "576:\tlearn: 55544.0256948\ttotal: 11s\tremaining: 8.07s\n",
      "577:\tlearn: 55529.9967341\ttotal: 11.1s\tremaining: 8.11s\n",
      "578:\tlearn: 55523.9633857\ttotal: 11.1s\tremaining: 8.09s\n",
      "579:\tlearn: 55506.1861614\ttotal: 11.1s\tremaining: 8.06s\n",
      "580:\tlearn: 55486.7060461\ttotal: 11.1s\tremaining: 8.03s\n",
      "581:\tlearn: 55352.6167915\ttotal: 11.2s\tremaining: 8.01s\n",
      "582:\tlearn: 55335.4479572\ttotal: 11.2s\tremaining: 7.99s\n",
      "583:\tlearn: 55326.6306741\ttotal: 11.2s\tremaining: 7.96s\n",
      "584:\tlearn: 55320.6550830\ttotal: 11.2s\tremaining: 7.94s\n",
      "585:\tlearn: 55291.6900767\ttotal: 11.2s\tremaining: 7.92s\n",
      "586:\tlearn: 55277.7707564\ttotal: 11.2s\tremaining: 7.89s\n",
      "587:\tlearn: 55248.4329942\ttotal: 11.3s\tremaining: 7.88s\n",
      "588:\tlearn: 55231.7315255\ttotal: 11.3s\tremaining: 7.86s\n",
      "589:\tlearn: 55220.3694214\ttotal: 11.3s\tremaining: 7.84s\n",
      "590:\tlearn: 55192.6177416\ttotal: 11.3s\tremaining: 7.82s\n",
      "591:\tlearn: 55181.6796239\ttotal: 11.3s\tremaining: 7.8s\n",
      "592:\tlearn: 55175.7657055\ttotal: 11.3s\tremaining: 7.77s\n",
      "593:\tlearn: 55165.3854378\ttotal: 11.3s\tremaining: 7.75s\n",
      "594:\tlearn: 55119.9761788\ttotal: 11.3s\tremaining: 7.72s\n",
      "595:\tlearn: 55062.2998750\ttotal: 11.4s\tremaining: 7.7s\n",
      "596:\tlearn: 55004.3882868\ttotal: 11.4s\tremaining: 7.68s\n",
      "597:\tlearn: 54949.9907967\ttotal: 11.4s\tremaining: 7.65s\n",
      "598:\tlearn: 54923.0986267\ttotal: 11.4s\tremaining: 7.63s\n",
      "599:\tlearn: 54904.5111544\ttotal: 11.4s\tremaining: 7.61s\n",
      "600:\tlearn: 54894.1221030\ttotal: 11.4s\tremaining: 7.59s\n",
      "601:\tlearn: 54877.4017052\ttotal: 11.4s\tremaining: 7.57s\n",
      "602:\tlearn: 54867.1049772\ttotal: 11.5s\tremaining: 7.55s\n",
      "603:\tlearn: 54861.6042234\ttotal: 11.5s\tremaining: 7.54s\n",
      "604:\tlearn: 54848.8771505\ttotal: 11.5s\tremaining: 7.51s\n",
      "605:\tlearn: 54838.5911986\ttotal: 11.5s\tremaining: 7.5s\n",
      "606:\tlearn: 54829.3938825\ttotal: 11.5s\tremaining: 7.47s\n",
      "607:\tlearn: 54813.4848640\ttotal: 11.6s\tremaining: 7.45s\n",
      "608:\tlearn: 54802.8062278\ttotal: 11.6s\tremaining: 7.42s\n",
      "609:\tlearn: 54676.0671684\ttotal: 11.6s\tremaining: 7.4s\n",
      "610:\tlearn: 54621.2773193\ttotal: 11.6s\tremaining: 7.4s\n",
      "611:\tlearn: 54603.0464211\ttotal: 11.6s\tremaining: 7.38s\n",
      "612:\tlearn: 54571.9198574\ttotal: 11.7s\tremaining: 7.37s\n",
      "613:\tlearn: 54561.9461945\ttotal: 11.7s\tremaining: 7.38s\n",
      "614:\tlearn: 54550.6254123\ttotal: 11.8s\tremaining: 7.36s\n",
      "615:\tlearn: 54535.7356840\ttotal: 11.8s\tremaining: 7.34s\n",
      "616:\tlearn: 54529.3367829\ttotal: 11.8s\tremaining: 7.34s\n",
      "617:\tlearn: 54526.9276383\ttotal: 11.8s\tremaining: 7.32s\n",
      "618:\tlearn: 54519.5090283\ttotal: 11.9s\tremaining: 7.33s\n",
      "619:\tlearn: 54514.5839526\ttotal: 11.9s\tremaining: 7.31s\n",
      "620:\tlearn: 54514.2350236\ttotal: 12s\tremaining: 7.35s\n",
      "621:\tlearn: 54505.9604489\ttotal: 12.1s\tremaining: 7.33s\n",
      "622:\tlearn: 54505.1294415\ttotal: 12.1s\tremaining: 7.31s\n",
      "623:\tlearn: 54502.0511982\ttotal: 12.3s\tremaining: 7.43s\n",
      "624:\tlearn: 54448.8988786\ttotal: 12.4s\tremaining: 7.41s\n",
      "625:\tlearn: 54362.6833313\ttotal: 12.4s\tremaining: 7.41s\n",
      "626:\tlearn: 54315.5761382\ttotal: 12.4s\tremaining: 7.39s\n",
      "627:\tlearn: 54305.4920494\ttotal: 12.4s\tremaining: 7.37s\n",
      "628:\tlearn: 54292.0808515\ttotal: 12.4s\tremaining: 7.34s\n",
      "629:\tlearn: 54247.7286060\ttotal: 12.5s\tremaining: 7.32s\n",
      "630:\tlearn: 54230.9886818\ttotal: 12.5s\tremaining: 7.3s\n",
      "631:\tlearn: 54223.3990663\ttotal: 12.5s\tremaining: 7.28s\n",
      "632:\tlearn: 54211.2127404\ttotal: 12.5s\tremaining: 7.25s\n",
      "633:\tlearn: 54197.7475703\ttotal: 12.5s\tremaining: 7.23s\n",
      "634:\tlearn: 54181.4952361\ttotal: 12.5s\tremaining: 7.21s\n",
      "635:\tlearn: 54165.4122348\ttotal: 12.6s\tremaining: 7.19s\n",
      "636:\tlearn: 54162.2459692\ttotal: 12.6s\tremaining: 7.17s\n",
      "637:\tlearn: 54159.8574103\ttotal: 12.6s\tremaining: 7.15s\n",
      "638:\tlearn: 54155.7671552\ttotal: 12.6s\tremaining: 7.13s\n",
      "639:\tlearn: 54134.6020852\ttotal: 12.6s\tremaining: 7.1s\n",
      "640:\tlearn: 54131.6442943\ttotal: 12.6s\tremaining: 7.08s\n",
      "641:\tlearn: 54128.4164648\ttotal: 12.7s\tremaining: 7.07s\n",
      "642:\tlearn: 54124.7791978\ttotal: 12.7s\tremaining: 7.04s\n",
      "643:\tlearn: 54122.1539511\ttotal: 12.7s\tremaining: 7.02s\n",
      "644:\tlearn: 54119.8252167\ttotal: 12.7s\tremaining: 7s\n",
      "645:\tlearn: 54116.7384525\ttotal: 12.7s\tremaining: 6.98s\n",
      "646:\tlearn: 54114.1303133\ttotal: 12.8s\tremaining: 6.96s\n",
      "647:\tlearn: 54105.9446759\ttotal: 12.8s\tremaining: 6.95s\n",
      "648:\tlearn: 54103.8984644\ttotal: 12.8s\tremaining: 6.93s\n",
      "649:\tlearn: 54102.3700169\ttotal: 12.8s\tremaining: 6.91s\n",
      "650:\tlearn: 54099.8575261\ttotal: 12.8s\tremaining: 6.89s\n",
      "651:\tlearn: 54098.4527819\ttotal: 12.9s\tremaining: 6.87s\n",
      "652:\tlearn: 54096.6961793\ttotal: 12.9s\tremaining: 6.84s\n",
      "653:\tlearn: 54075.1187748\ttotal: 12.9s\tremaining: 6.83s\n",
      "654:\tlearn: 54064.2160944\ttotal: 12.9s\tremaining: 6.8s\n",
      "655:\tlearn: 54062.9199442\ttotal: 12.9s\tremaining: 6.78s\n",
      "656:\tlearn: 54053.3768095\ttotal: 12.9s\tremaining: 6.75s\n",
      "657:\tlearn: 54052.1557769\ttotal: 13s\tremaining: 6.73s\n",
      "658:\tlearn: 54050.3985463\ttotal: 13s\tremaining: 6.71s\n",
      "659:\tlearn: 54041.1978668\ttotal: 13s\tremaining: 6.7s\n",
      "660:\tlearn: 54021.7505784\ttotal: 13s\tremaining: 6.68s\n",
      "661:\tlearn: 54011.5762179\ttotal: 13s\tremaining: 6.66s\n",
      "662:\tlearn: 53986.2157542\ttotal: 13.1s\tremaining: 6.63s\n",
      "663:\tlearn: 53970.4957309\ttotal: 13.1s\tremaining: 6.61s\n",
      "664:\tlearn: 53963.7553862\ttotal: 13.1s\tremaining: 6.6s\n",
      "665:\tlearn: 53961.8203687\ttotal: 13.1s\tremaining: 6.57s\n",
      "666:\tlearn: 53959.0230567\ttotal: 13.1s\tremaining: 6.55s\n",
      "667:\tlearn: 53957.0618615\ttotal: 13.1s\tremaining: 6.53s\n",
      "668:\tlearn: 53942.1152985\ttotal: 13.1s\tremaining: 6.5s\n",
      "669:\tlearn: 53923.4323880\ttotal: 13.2s\tremaining: 6.48s\n",
      "670:\tlearn: 53908.8687137\ttotal: 13.2s\tremaining: 6.46s\n",
      "671:\tlearn: 53903.2162486\ttotal: 13.2s\tremaining: 6.44s\n",
      "672:\tlearn: 53831.6983262\ttotal: 13.2s\tremaining: 6.42s\n",
      "673:\tlearn: 53779.9362682\ttotal: 13.2s\tremaining: 6.39s\n",
      "674:\tlearn: 53767.8926215\ttotal: 13.2s\tremaining: 6.37s\n",
      "675:\tlearn: 53762.3886072\ttotal: 13.3s\tremaining: 6.36s\n",
      "676:\tlearn: 53748.2140315\ttotal: 13.3s\tremaining: 6.34s\n",
      "677:\tlearn: 53734.3640228\ttotal: 13.3s\tremaining: 6.32s\n",
      "678:\tlearn: 53695.1153058\ttotal: 13.3s\tremaining: 6.29s\n",
      "679:\tlearn: 53686.8889698\ttotal: 13.3s\tremaining: 6.27s\n",
      "680:\tlearn: 53673.5148648\ttotal: 13.3s\tremaining: 6.25s\n",
      "681:\tlearn: 53664.7977626\ttotal: 13.4s\tremaining: 6.23s\n",
      "682:\tlearn: 53627.1646092\ttotal: 13.4s\tremaining: 6.21s\n",
      "683:\tlearn: 53617.2356308\ttotal: 13.4s\tremaining: 6.19s\n",
      "684:\tlearn: 53590.2070648\ttotal: 13.4s\tremaining: 6.17s\n",
      "685:\tlearn: 53513.2110117\ttotal: 13.4s\tremaining: 6.15s\n",
      "686:\tlearn: 53460.3145049\ttotal: 13.5s\tremaining: 6.13s\n",
      "687:\tlearn: 53435.8075191\ttotal: 13.6s\tremaining: 6.14s\n",
      "688:\tlearn: 53422.8485721\ttotal: 13.6s\tremaining: 6.13s\n",
      "689:\tlearn: 53413.9774247\ttotal: 13.6s\tremaining: 6.11s\n",
      "690:\tlearn: 53399.1250000\ttotal: 13.6s\tremaining: 6.08s\n",
      "691:\tlearn: 53348.1712264\ttotal: 13.6s\tremaining: 6.06s\n",
      "692:\tlearn: 53335.6769016\ttotal: 13.6s\tremaining: 6.04s\n",
      "693:\tlearn: 53286.5907282\ttotal: 13.7s\tremaining: 6.02s\n",
      "694:\tlearn: 53260.9912873\ttotal: 13.7s\tremaining: 6.01s\n",
      "695:\tlearn: 53247.0478588\ttotal: 13.7s\tremaining: 5.99s\n",
      "696:\tlearn: 53226.3351177\ttotal: 13.7s\tremaining: 5.97s\n",
      "697:\tlearn: 53217.3827330\ttotal: 13.8s\tremaining: 5.95s\n",
      "698:\tlearn: 53203.6612851\ttotal: 13.8s\tremaining: 5.93s\n",
      "699:\tlearn: 53186.4834172\ttotal: 13.8s\tremaining: 5.91s\n",
      "700:\tlearn: 53170.6761909\ttotal: 13.8s\tremaining: 5.89s\n",
      "701:\tlearn: 53155.2033465\ttotal: 13.8s\tremaining: 5.87s\n",
      "702:\tlearn: 53141.5977986\ttotal: 13.8s\tremaining: 5.85s\n",
      "703:\tlearn: 53138.8123984\ttotal: 13.9s\tremaining: 5.83s\n",
      "704:\tlearn: 53127.7092901\ttotal: 13.9s\tremaining: 5.81s\n",
      "705:\tlearn: 53102.8011232\ttotal: 13.9s\tremaining: 5.79s\n",
      "706:\tlearn: 53094.1904107\ttotal: 13.9s\tremaining: 5.77s\n",
      "707:\tlearn: 53085.6881822\ttotal: 14s\tremaining: 5.75s\n",
      "708:\tlearn: 53068.8598803\ttotal: 14s\tremaining: 5.74s\n",
      "709:\tlearn: 53028.5474286\ttotal: 14s\tremaining: 5.71s\n",
      "710:\tlearn: 53025.6384962\ttotal: 14s\tremaining: 5.7s\n",
      "711:\tlearn: 53001.0385010\ttotal: 14s\tremaining: 5.67s\n",
      "712:\tlearn: 52990.9182687\ttotal: 14s\tremaining: 5.65s\n",
      "713:\tlearn: 52985.8013661\ttotal: 14.1s\tremaining: 5.63s\n",
      "714:\tlearn: 52979.3300878\ttotal: 14.1s\tremaining: 5.61s\n",
      "715:\tlearn: 52955.3011909\ttotal: 14.1s\tremaining: 5.59s\n",
      "716:\tlearn: 52939.6646461\ttotal: 14.1s\tremaining: 5.57s\n",
      "717:\tlearn: 52934.0851998\ttotal: 14.1s\tremaining: 5.55s\n",
      "718:\tlearn: 52923.7251896\ttotal: 14.1s\tremaining: 5.53s\n",
      "719:\tlearn: 52916.1601148\ttotal: 14.3s\tremaining: 5.56s\n",
      "720:\tlearn: 52911.0146248\ttotal: 14.3s\tremaining: 5.54s\n",
      "721:\tlearn: 52908.5096957\ttotal: 14.5s\tremaining: 5.6s\n",
      "722:\tlearn: 52890.7688909\ttotal: 14.6s\tremaining: 5.59s\n",
      "723:\tlearn: 52887.2078939\ttotal: 14.8s\tremaining: 5.62s\n",
      "724:\tlearn: 52879.1302861\ttotal: 14.8s\tremaining: 5.61s\n",
      "725:\tlearn: 52850.0673048\ttotal: 14.8s\tremaining: 5.59s\n",
      "726:\tlearn: 52835.4093222\ttotal: 15.1s\tremaining: 5.69s\n",
      "727:\tlearn: 52824.6351022\ttotal: 15.3s\tremaining: 5.7s\n",
      "728:\tlearn: 52815.3296425\ttotal: 15.3s\tremaining: 5.68s\n",
      "729:\tlearn: 52749.3001331\ttotal: 15.3s\tremaining: 5.66s\n",
      "730:\tlearn: 52736.4090234\ttotal: 15.3s\tremaining: 5.63s\n",
      "731:\tlearn: 52722.3368854\ttotal: 15.3s\tremaining: 5.61s\n",
      "732:\tlearn: 52719.7211151\ttotal: 15.3s\tremaining: 5.59s\n",
      "733:\tlearn: 52707.3866729\ttotal: 15.4s\tremaining: 5.57s\n",
      "734:\tlearn: 52698.4525799\ttotal: 15.4s\tremaining: 5.55s\n",
      "735:\tlearn: 52687.3128932\ttotal: 15.4s\tremaining: 5.53s\n",
      "736:\tlearn: 52639.8976458\ttotal: 15.4s\tremaining: 5.51s\n",
      "737:\tlearn: 52632.9687283\ttotal: 15.5s\tremaining: 5.49s\n",
      "738:\tlearn: 52629.7749771\ttotal: 15.5s\tremaining: 5.46s\n",
      "739:\tlearn: 52623.4350989\ttotal: 15.5s\tremaining: 5.44s\n",
      "740:\tlearn: 52608.3757679\ttotal: 15.5s\tremaining: 5.42s\n",
      "741:\tlearn: 52590.7221685\ttotal: 15.5s\tremaining: 5.39s\n",
      "742:\tlearn: 52586.0157832\ttotal: 15.5s\tremaining: 5.37s\n",
      "743:\tlearn: 52551.1060479\ttotal: 15.5s\tremaining: 5.34s\n",
      "744:\tlearn: 52507.1964302\ttotal: 15.6s\tremaining: 5.33s\n",
      "745:\tlearn: 52502.0263145\ttotal: 15.6s\tremaining: 5.31s\n",
      "746:\tlearn: 52491.1374895\ttotal: 15.6s\tremaining: 5.29s\n",
      "747:\tlearn: 52420.4687859\ttotal: 15.7s\tremaining: 5.28s\n",
      "748:\tlearn: 52403.9630406\ttotal: 15.7s\tremaining: 5.26s\n",
      "749:\tlearn: 52335.7797846\ttotal: 15.7s\tremaining: 5.24s\n",
      "750:\tlearn: 52269.9993655\ttotal: 15.8s\tremaining: 5.22s\n",
      "751:\tlearn: 52206.5343195\ttotal: 15.8s\tremaining: 5.21s\n",
      "752:\tlearn: 52159.9972797\ttotal: 15.8s\tremaining: 5.18s\n",
      "753:\tlearn: 52098.7090607\ttotal: 15.8s\tremaining: 5.17s\n",
      "754:\tlearn: 52053.8227813\ttotal: 15.9s\tremaining: 5.15s\n",
      "755:\tlearn: 52045.9268656\ttotal: 15.9s\tremaining: 5.13s\n",
      "756:\tlearn: 51986.7318029\ttotal: 15.9s\tremaining: 5.11s\n",
      "757:\tlearn: 51982.6383032\ttotal: 15.9s\tremaining: 5.08s\n",
      "758:\tlearn: 51975.0217486\ttotal: 16s\tremaining: 5.07s\n",
      "759:\tlearn: 51962.1673071\ttotal: 16s\tremaining: 5.05s\n",
      "760:\tlearn: 51938.6973378\ttotal: 16s\tremaining: 5.03s\n",
      "761:\tlearn: 51926.7075536\ttotal: 16s\tremaining: 5s\n",
      "762:\tlearn: 51922.0483563\ttotal: 16s\tremaining: 4.98s\n",
      "763:\tlearn: 51864.8684389\ttotal: 16.1s\tremaining: 4.97s\n",
      "764:\tlearn: 51841.3549171\ttotal: 16.2s\tremaining: 4.98s\n",
      "765:\tlearn: 51787.7359667\ttotal: 16.3s\tremaining: 4.97s\n",
      "766:\tlearn: 51771.8643572\ttotal: 16.3s\tremaining: 4.95s\n",
      "767:\tlearn: 51758.0997468\ttotal: 16.3s\tremaining: 4.93s\n",
      "768:\tlearn: 51702.8124956\ttotal: 16.4s\tremaining: 4.92s\n",
      "769:\tlearn: 51695.4461941\ttotal: 16.4s\tremaining: 4.9s\n",
      "770:\tlearn: 51690.6325600\ttotal: 16.4s\tremaining: 4.87s\n",
      "771:\tlearn: 51676.9166623\ttotal: 16.4s\tremaining: 4.86s\n",
      "772:\tlearn: 51623.5338344\ttotal: 16.5s\tremaining: 4.84s\n",
      "773:\tlearn: 51605.0712055\ttotal: 16.5s\tremaining: 4.82s\n",
      "774:\tlearn: 51593.6529613\ttotal: 16.5s\tremaining: 4.8s\n",
      "775:\tlearn: 51586.2511430\ttotal: 16.5s\tremaining: 4.78s\n",
      "776:\tlearn: 51563.6321924\ttotal: 16.6s\tremaining: 4.75s\n",
      "777:\tlearn: 51556.4949443\ttotal: 16.6s\tremaining: 4.73s\n",
      "778:\tlearn: 51535.0123863\ttotal: 16.6s\tremaining: 4.71s\n",
      "779:\tlearn: 51522.9685779\ttotal: 16.6s\tremaining: 4.69s\n",
      "780:\tlearn: 51499.2193505\ttotal: 16.6s\tremaining: 4.66s\n",
      "781:\tlearn: 51473.6280631\ttotal: 16.6s\tremaining: 4.64s\n",
      "782:\tlearn: 51465.9636368\ttotal: 16.7s\tremaining: 4.62s\n",
      "783:\tlearn: 51461.9999636\ttotal: 16.7s\tremaining: 4.59s\n",
      "784:\tlearn: 51459.2462217\ttotal: 16.7s\tremaining: 4.57s\n",
      "785:\tlearn: 51449.8702946\ttotal: 16.7s\tremaining: 4.55s\n",
      "786:\tlearn: 51445.9144039\ttotal: 16.7s\tremaining: 4.53s\n",
      "787:\tlearn: 51439.9289997\ttotal: 16.8s\tremaining: 4.51s\n",
      "788:\tlearn: 51399.7679862\ttotal: 16.8s\tremaining: 4.49s\n",
      "789:\tlearn: 51375.1079741\ttotal: 16.8s\tremaining: 4.47s\n",
      "790:\tlearn: 51331.3090896\ttotal: 16.9s\tremaining: 4.45s\n",
      "791:\tlearn: 51317.4328316\ttotal: 16.9s\tremaining: 4.43s\n",
      "792:\tlearn: 51314.0867736\ttotal: 16.9s\tremaining: 4.41s\n",
      "793:\tlearn: 51305.1015630\ttotal: 16.9s\tremaining: 4.39s\n",
      "794:\tlearn: 51298.2030860\ttotal: 16.9s\tremaining: 4.36s\n",
      "795:\tlearn: 51291.5715361\ttotal: 16.9s\tremaining: 4.34s\n",
      "796:\tlearn: 51279.9355046\ttotal: 17s\tremaining: 4.32s\n",
      "797:\tlearn: 51259.5569619\ttotal: 17.1s\tremaining: 4.32s\n",
      "798:\tlearn: 51250.7426432\ttotal: 17.1s\tremaining: 4.3s\n",
      "799:\tlearn: 51239.8266918\ttotal: 17.1s\tremaining: 4.28s\n",
      "800:\tlearn: 51229.3161324\ttotal: 17.1s\tremaining: 4.25s\n",
      "801:\tlearn: 51213.7132123\ttotal: 17.1s\tremaining: 4.23s\n",
      "802:\tlearn: 51203.8322153\ttotal: 17.1s\tremaining: 4.21s\n",
      "803:\tlearn: 51193.4458132\ttotal: 17.2s\tremaining: 4.18s\n",
      "804:\tlearn: 51182.2996528\ttotal: 17.2s\tremaining: 4.17s\n",
      "805:\tlearn: 51170.1526550\ttotal: 17.2s\tremaining: 4.15s\n",
      "806:\tlearn: 51127.8423316\ttotal: 17.2s\tremaining: 4.12s\n",
      "807:\tlearn: 51112.5150286\ttotal: 17.3s\tremaining: 4.1s\n",
      "808:\tlearn: 51110.2143642\ttotal: 17.3s\tremaining: 4.08s\n",
      "809:\tlearn: 51100.6661150\ttotal: 17.3s\tremaining: 4.05s\n",
      "810:\tlearn: 51092.4884501\ttotal: 17.3s\tremaining: 4.03s\n",
      "811:\tlearn: 51070.4685508\ttotal: 17.3s\tremaining: 4.01s\n",
      "812:\tlearn: 51063.9338848\ttotal: 17.3s\tremaining: 3.99s\n",
      "813:\tlearn: 51062.0078317\ttotal: 17.4s\tremaining: 3.96s\n",
      "814:\tlearn: 51039.3881576\ttotal: 17.4s\tremaining: 3.94s\n",
      "815:\tlearn: 51019.8261545\ttotal: 17.4s\tremaining: 3.92s\n",
      "816:\tlearn: 51014.2577154\ttotal: 17.4s\tremaining: 3.9s\n",
      "817:\tlearn: 50962.1509954\ttotal: 17.4s\tremaining: 3.88s\n",
      "818:\tlearn: 50960.9894760\ttotal: 17.4s\tremaining: 3.85s\n",
      "819:\tlearn: 50949.5486682\ttotal: 17.5s\tremaining: 3.83s\n",
      "820:\tlearn: 50849.5927596\ttotal: 17.5s\tremaining: 3.81s\n",
      "821:\tlearn: 50830.3137167\ttotal: 17.5s\tremaining: 3.79s\n",
      "822:\tlearn: 50821.6966950\ttotal: 17.5s\tremaining: 3.77s\n",
      "823:\tlearn: 50772.4300437\ttotal: 17.5s\tremaining: 3.75s\n",
      "824:\tlearn: 50754.1566051\ttotal: 17.5s\tremaining: 3.72s\n",
      "825:\tlearn: 50724.2641748\ttotal: 17.6s\tremaining: 3.7s\n",
      "826:\tlearn: 50717.5555744\ttotal: 17.6s\tremaining: 3.68s\n",
      "827:\tlearn: 50706.3878962\ttotal: 17.6s\tremaining: 3.65s\n",
      "828:\tlearn: 50673.2319325\ttotal: 17.6s\tremaining: 3.63s\n",
      "829:\tlearn: 50664.2168780\ttotal: 17.6s\tremaining: 3.61s\n",
      "830:\tlearn: 50646.2499370\ttotal: 17.7s\tremaining: 3.59s\n",
      "831:\tlearn: 50624.3033334\ttotal: 17.7s\tremaining: 3.57s\n",
      "832:\tlearn: 50530.0732291\ttotal: 17.7s\tremaining: 3.55s\n",
      "833:\tlearn: 50499.4037826\ttotal: 17.7s\tremaining: 3.52s\n",
      "834:\tlearn: 50491.7750146\ttotal: 17.7s\tremaining: 3.5s\n",
      "835:\tlearn: 50483.3908769\ttotal: 17.7s\tremaining: 3.48s\n",
      "836:\tlearn: 50457.0583917\ttotal: 17.7s\tremaining: 3.46s\n",
      "837:\tlearn: 50447.0531178\ttotal: 17.8s\tremaining: 3.43s\n",
      "838:\tlearn: 50444.2203406\ttotal: 17.8s\tremaining: 3.41s\n",
      "839:\tlearn: 50427.1058902\ttotal: 17.8s\tremaining: 3.39s\n",
      "840:\tlearn: 50397.9411225\ttotal: 17.8s\tremaining: 3.37s\n",
      "841:\tlearn: 50380.3074182\ttotal: 17.9s\tremaining: 3.36s\n",
      "842:\tlearn: 50358.0593026\ttotal: 17.9s\tremaining: 3.34s\n",
      "843:\tlearn: 50351.5119663\ttotal: 18s\tremaining: 3.32s\n",
      "844:\tlearn: 50340.2783578\ttotal: 18s\tremaining: 3.3s\n",
      "845:\tlearn: 50323.3488305\ttotal: 18s\tremaining: 3.28s\n",
      "846:\tlearn: 50314.7070017\ttotal: 18s\tremaining: 3.26s\n",
      "847:\tlearn: 50311.4667965\ttotal: 18.1s\tremaining: 3.24s\n",
      "848:\tlearn: 50307.9212187\ttotal: 18.1s\tremaining: 3.22s\n",
      "849:\tlearn: 50297.9961658\ttotal: 18.1s\tremaining: 3.19s\n",
      "850:\tlearn: 50254.3497161\ttotal: 18.1s\tremaining: 3.17s\n",
      "851:\tlearn: 50245.5951048\ttotal: 18.1s\tremaining: 3.15s\n",
      "852:\tlearn: 50195.9324747\ttotal: 18.2s\tremaining: 3.13s\n",
      "853:\tlearn: 50188.4922366\ttotal: 18.2s\tremaining: 3.11s\n",
      "854:\tlearn: 50147.9410481\ttotal: 18.2s\tremaining: 3.08s\n",
      "855:\tlearn: 50124.9477892\ttotal: 18.2s\tremaining: 3.06s\n",
      "856:\tlearn: 50115.6418663\ttotal: 18.2s\tremaining: 3.04s\n",
      "857:\tlearn: 50103.0538780\ttotal: 18.2s\tremaining: 3.02s\n",
      "858:\tlearn: 50095.0048385\ttotal: 18.3s\tremaining: 3s\n",
      "859:\tlearn: 50006.1940568\ttotal: 18.3s\tremaining: 2.98s\n",
      "860:\tlearn: 49984.3558247\ttotal: 18.3s\tremaining: 2.96s\n",
      "861:\tlearn: 49968.9446975\ttotal: 18.3s\tremaining: 2.93s\n",
      "862:\tlearn: 49965.3856990\ttotal: 18.3s\tremaining: 2.91s\n",
      "863:\tlearn: 49935.0827662\ttotal: 18.4s\tremaining: 2.89s\n",
      "864:\tlearn: 49928.6950364\ttotal: 18.4s\tremaining: 2.87s\n",
      "865:\tlearn: 49860.4790606\ttotal: 18.4s\tremaining: 2.85s\n",
      "866:\tlearn: 49822.2770965\ttotal: 18.4s\tremaining: 2.82s\n",
      "867:\tlearn: 49813.6457176\ttotal: 18.4s\tremaining: 2.8s\n",
      "868:\tlearn: 49810.3769577\ttotal: 18.4s\tremaining: 2.78s\n",
      "869:\tlearn: 49804.1766988\ttotal: 18.5s\tremaining: 2.76s\n",
      "870:\tlearn: 49798.2033959\ttotal: 18.5s\tremaining: 2.74s\n",
      "871:\tlearn: 49759.0167474\ttotal: 18.5s\tremaining: 2.71s\n",
      "872:\tlearn: 49753.6681357\ttotal: 18.5s\tremaining: 2.69s\n",
      "873:\tlearn: 49670.2433186\ttotal: 18.5s\tremaining: 2.67s\n",
      "874:\tlearn: 49663.2540059\ttotal: 18.6s\tremaining: 2.65s\n",
      "875:\tlearn: 49659.9280147\ttotal: 18.6s\tremaining: 2.63s\n",
      "876:\tlearn: 49620.5474353\ttotal: 18.6s\tremaining: 2.61s\n",
      "877:\tlearn: 49616.8786173\ttotal: 18.6s\tremaining: 2.58s\n",
      "878:\tlearn: 49605.9968358\ttotal: 18.6s\tremaining: 2.56s\n",
      "879:\tlearn: 49567.7593832\ttotal: 18.6s\tremaining: 2.54s\n",
      "880:\tlearn: 49556.1412914\ttotal: 18.6s\tremaining: 2.52s\n",
      "881:\tlearn: 49539.3514957\ttotal: 18.7s\tremaining: 2.5s\n",
      "882:\tlearn: 49523.1672718\ttotal: 18.7s\tremaining: 2.48s\n",
      "883:\tlearn: 49517.9961798\ttotal: 18.8s\tremaining: 2.46s\n",
      "884:\tlearn: 49507.8974533\ttotal: 18.8s\tremaining: 2.44s\n",
      "885:\tlearn: 49502.1048392\ttotal: 18.8s\tremaining: 2.42s\n",
      "886:\tlearn: 49437.5558957\ttotal: 18.8s\tremaining: 2.4s\n",
      "887:\tlearn: 49387.3604385\ttotal: 18.8s\tremaining: 2.38s\n",
      "888:\tlearn: 49373.3992437\ttotal: 18.9s\tremaining: 2.35s\n",
      "889:\tlearn: 49344.9555522\ttotal: 18.9s\tremaining: 2.33s\n",
      "890:\tlearn: 49296.4693212\ttotal: 18.9s\tremaining: 2.31s\n",
      "891:\tlearn: 49249.6780432\ttotal: 18.9s\tremaining: 2.29s\n",
      "892:\tlearn: 49244.0606910\ttotal: 18.9s\tremaining: 2.26s\n",
      "893:\tlearn: 49232.6372509\ttotal: 18.9s\tremaining: 2.24s\n",
      "894:\tlearn: 49187.4625436\ttotal: 18.9s\tremaining: 2.22s\n",
      "895:\tlearn: 49109.9879597\ttotal: 18.9s\tremaining: 2.2s\n",
      "896:\tlearn: 49066.3260903\ttotal: 19s\tremaining: 2.18s\n",
      "897:\tlearn: 49015.6629767\ttotal: 19s\tremaining: 2.16s\n",
      "898:\tlearn: 48978.3077444\ttotal: 19s\tremaining: 2.13s\n",
      "899:\tlearn: 48965.2822592\ttotal: 19s\tremaining: 2.11s\n",
      "900:\tlearn: 48962.1048476\ttotal: 19s\tremaining: 2.09s\n",
      "901:\tlearn: 48919.8708486\ttotal: 19.1s\tremaining: 2.07s\n",
      "902:\tlearn: 48914.8243984\ttotal: 19.1s\tremaining: 2.05s\n",
      "903:\tlearn: 48886.2011136\ttotal: 19.1s\tremaining: 2.02s\n",
      "904:\tlearn: 48875.0376594\ttotal: 19.1s\tremaining: 2s\n",
      "905:\tlearn: 48864.2145165\ttotal: 19.1s\tremaining: 1.98s\n",
      "906:\tlearn: 48826.4456760\ttotal: 19.1s\tremaining: 1.96s\n",
      "907:\tlearn: 48823.3250532\ttotal: 19.1s\tremaining: 1.94s\n",
      "908:\tlearn: 48819.5421395\ttotal: 19.1s\tremaining: 1.92s\n",
      "909:\tlearn: 48809.1340397\ttotal: 19.1s\tremaining: 1.89s\n",
      "910:\tlearn: 48745.5949848\ttotal: 19.2s\tremaining: 1.87s\n",
      "911:\tlearn: 48731.9912019\ttotal: 19.2s\tremaining: 1.85s\n",
      "912:\tlearn: 48712.6719640\ttotal: 19.2s\tremaining: 1.83s\n",
      "913:\tlearn: 48702.6890099\ttotal: 19.2s\tremaining: 1.81s\n",
      "914:\tlearn: 48663.6222190\ttotal: 19.2s\tremaining: 1.78s\n",
      "915:\tlearn: 48642.5060379\ttotal: 19.3s\tremaining: 1.76s\n",
      "916:\tlearn: 48639.4104396\ttotal: 19.3s\tremaining: 1.74s\n",
      "917:\tlearn: 48628.9298724\ttotal: 19.3s\tremaining: 1.72s\n",
      "918:\tlearn: 48616.1271524\ttotal: 19.3s\tremaining: 1.7s\n",
      "919:\tlearn: 48590.6139089\ttotal: 19.3s\tremaining: 1.68s\n",
      "920:\tlearn: 48579.7121254\ttotal: 19.3s\tremaining: 1.66s\n",
      "921:\tlearn: 48576.3869799\ttotal: 19.3s\tremaining: 1.64s\n",
      "922:\tlearn: 48567.9864129\ttotal: 19.3s\tremaining: 1.61s\n",
      "923:\tlearn: 48526.9606034\ttotal: 19.3s\tremaining: 1.59s\n",
      "924:\tlearn: 48517.1512634\ttotal: 19.4s\tremaining: 1.57s\n",
      "925:\tlearn: 48512.3736814\ttotal: 19.4s\tremaining: 1.55s\n",
      "926:\tlearn: 48472.7709145\ttotal: 19.4s\tremaining: 1.53s\n",
      "927:\tlearn: 48434.5537286\ttotal: 19.4s\tremaining: 1.51s\n",
      "928:\tlearn: 48429.0314111\ttotal: 19.4s\tremaining: 1.49s\n",
      "929:\tlearn: 48393.0909411\ttotal: 19.5s\tremaining: 1.46s\n",
      "930:\tlearn: 48388.1505207\ttotal: 19.5s\tremaining: 1.44s\n",
      "931:\tlearn: 48371.3215854\ttotal: 19.5s\tremaining: 1.42s\n",
      "932:\tlearn: 48334.3853649\ttotal: 19.5s\tremaining: 1.4s\n",
      "933:\tlearn: 48260.3809325\ttotal: 19.5s\tremaining: 1.38s\n",
      "934:\tlearn: 48255.0356560\ttotal: 19.6s\tremaining: 1.36s\n",
      "935:\tlearn: 48219.9066636\ttotal: 19.6s\tremaining: 1.34s\n",
      "936:\tlearn: 48180.1090455\ttotal: 19.6s\tremaining: 1.32s\n",
      "937:\tlearn: 48145.4993232\ttotal: 19.6s\tremaining: 1.29s\n",
      "938:\tlearn: 48112.1431859\ttotal: 19.6s\tremaining: 1.27s\n",
      "939:\tlearn: 48093.9752685\ttotal: 19.6s\tremaining: 1.25s\n",
      "940:\tlearn: 48083.5984802\ttotal: 19.8s\tremaining: 1.24s\n",
      "941:\tlearn: 48078.4215856\ttotal: 19.8s\tremaining: 1.22s\n",
      "942:\tlearn: 48075.6796334\ttotal: 19.8s\tremaining: 1.2s\n",
      "943:\tlearn: 48034.6499524\ttotal: 19.8s\tremaining: 1.17s\n",
      "944:\tlearn: 48002.4039112\ttotal: 19.8s\tremaining: 1.15s\n",
      "945:\tlearn: 47994.2058646\ttotal: 19.8s\tremaining: 1.13s\n",
      "946:\tlearn: 47990.5049817\ttotal: 19.8s\tremaining: 1.11s\n",
      "947:\tlearn: 47985.7036832\ttotal: 19.9s\tremaining: 1.09s\n",
      "948:\tlearn: 47982.9184797\ttotal: 19.9s\tremaining: 1.07s\n",
      "949:\tlearn: 47913.0308945\ttotal: 19.9s\tremaining: 1.05s\n",
      "950:\tlearn: 47881.8551616\ttotal: 20s\tremaining: 1.03s\n",
      "951:\tlearn: 47866.4312022\ttotal: 20s\tremaining: 1.01s\n",
      "952:\tlearn: 47836.3378253\ttotal: 20s\tremaining: 987ms\n",
      "953:\tlearn: 47827.0240890\ttotal: 20s\tremaining: 966ms\n",
      "954:\tlearn: 47817.7878146\ttotal: 20s\tremaining: 945ms\n",
      "955:\tlearn: 47778.2214908\ttotal: 20.1s\tremaining: 924ms\n",
      "956:\tlearn: 47768.5213380\ttotal: 20.1s\tremaining: 903ms\n",
      "957:\tlearn: 47759.6177923\ttotal: 20.1s\tremaining: 882ms\n",
      "958:\tlearn: 47736.1062866\ttotal: 20.1s\tremaining: 861ms\n",
      "959:\tlearn: 47724.5853430\ttotal: 20.1s\tremaining: 840ms\n",
      "960:\tlearn: 47721.8340458\ttotal: 20.2s\tremaining: 818ms\n",
      "961:\tlearn: 47714.9126955\ttotal: 20.2s\tremaining: 797ms\n",
      "962:\tlearn: 47698.3357472\ttotal: 20.2s\tremaining: 776ms\n",
      "963:\tlearn: 47690.0330778\ttotal: 20.2s\tremaining: 755ms\n",
      "964:\tlearn: 47685.1769207\ttotal: 20.2s\tremaining: 734ms\n",
      "965:\tlearn: 47619.2839333\ttotal: 20.2s\tremaining: 712ms\n",
      "966:\tlearn: 47613.8360434\ttotal: 20.2s\tremaining: 691ms\n",
      "967:\tlearn: 47605.3126167\ttotal: 20.3s\tremaining: 670ms\n",
      "968:\tlearn: 47543.2049343\ttotal: 20.3s\tremaining: 648ms\n",
      "969:\tlearn: 47535.0624623\ttotal: 20.3s\tremaining: 628ms\n",
      "970:\tlearn: 47526.8444739\ttotal: 20.3s\tremaining: 607ms\n",
      "971:\tlearn: 47518.9319938\ttotal: 20.3s\tremaining: 586ms\n",
      "972:\tlearn: 47489.6902974\ttotal: 20.4s\tremaining: 565ms\n",
      "973:\tlearn: 47487.4227774\ttotal: 20.4s\tremaining: 544ms\n",
      "974:\tlearn: 47480.6098268\ttotal: 20.4s\tremaining: 523ms\n",
      "975:\tlearn: 47473.2482104\ttotal: 20.4s\tremaining: 502ms\n",
      "976:\tlearn: 47445.0218148\ttotal: 20.4s\tremaining: 481ms\n",
      "977:\tlearn: 47439.8623955\ttotal: 20.4s\tremaining: 460ms\n",
      "978:\tlearn: 47433.5129050\ttotal: 20.5s\tremaining: 439ms\n",
      "979:\tlearn: 47417.5185136\ttotal: 20.5s\tremaining: 418ms\n",
      "980:\tlearn: 47415.3870840\ttotal: 20.5s\tremaining: 397ms\n",
      "981:\tlearn: 47388.1311470\ttotal: 20.5s\tremaining: 376ms\n",
      "982:\tlearn: 47383.6256120\ttotal: 20.5s\tremaining: 355ms\n",
      "983:\tlearn: 47379.5026576\ttotal: 20.5s\tremaining: 334ms\n",
      "984:\tlearn: 47353.2166352\ttotal: 20.5s\tremaining: 313ms\n",
      "985:\tlearn: 47348.6654435\ttotal: 20.6s\tremaining: 292ms\n",
      "986:\tlearn: 47338.1108212\ttotal: 20.6s\tremaining: 271ms\n",
      "987:\tlearn: 47330.4466486\ttotal: 20.6s\tremaining: 250ms\n",
      "988:\tlearn: 47321.6904416\ttotal: 20.6s\tremaining: 229ms\n",
      "989:\tlearn: 47314.1644347\ttotal: 20.6s\tremaining: 208ms\n",
      "990:\tlearn: 47298.7859527\ttotal: 20.6s\tremaining: 187ms\n",
      "991:\tlearn: 47236.2070345\ttotal: 20.7s\tremaining: 167ms\n",
      "992:\tlearn: 47210.7784880\ttotal: 20.7s\tremaining: 146ms\n",
      "993:\tlearn: 47200.7483767\ttotal: 20.7s\tremaining: 125ms\n",
      "994:\tlearn: 47176.2107551\ttotal: 20.7s\tremaining: 104ms\n",
      "995:\tlearn: 47137.7568327\ttotal: 20.7s\tremaining: 83.2ms\n",
      "996:\tlearn: 47114.0619604\ttotal: 20.7s\tremaining: 62.4ms\n",
      "997:\tlearn: 47107.2493374\ttotal: 20.7s\tremaining: 41.5ms\n",
      "998:\tlearn: 47102.8518285\ttotal: 20.7s\tremaining: 20.8ms\n",
      "999:\tlearn: 47093.9321924\ttotal: 20.9s\tremaining: 0us\n",
      "Learning rate set to 0.071717\n",
      "0:\tlearn: 76368.3973135\ttotal: 18.4ms\tremaining: 18.4s\n",
      "1:\tlearn: 75951.9707858\ttotal: 35.8ms\tremaining: 17.9s\n",
      "2:\tlearn: 75538.9711276\ttotal: 54.3ms\tremaining: 18.1s\n",
      "3:\tlearn: 75185.2394089\ttotal: 65.9ms\tremaining: 16.4s\n",
      "4:\tlearn: 74806.6407322\ttotal: 82.3ms\tremaining: 16.4s\n",
      "5:\tlearn: 74462.1699759\ttotal: 97.1ms\tremaining: 16.1s\n",
      "6:\tlearn: 74208.2768204\ttotal: 112ms\tremaining: 15.9s\n",
      "7:\tlearn: 73928.5014175\ttotal: 131ms\tremaining: 16.2s\n",
      "8:\tlearn: 73716.3399790\ttotal: 163ms\tremaining: 18s\n",
      "9:\tlearn: 73535.7902707\ttotal: 180ms\tremaining: 17.8s\n",
      "10:\tlearn: 73382.4373587\ttotal: 194ms\tremaining: 17.5s\n",
      "11:\tlearn: 73122.2301553\ttotal: 212ms\tremaining: 17.5s\n",
      "12:\tlearn: 72972.2807684\ttotal: 227ms\tremaining: 17.2s\n",
      "13:\tlearn: 72841.2646408\ttotal: 264ms\tremaining: 18.6s\n",
      "14:\tlearn: 72720.5379380\ttotal: 278ms\tremaining: 18.2s\n",
      "15:\tlearn: 72545.2008527\ttotal: 291ms\tremaining: 17.9s\n",
      "16:\tlearn: 72433.0986458\ttotal: 309ms\tremaining: 17.8s\n",
      "17:\tlearn: 72290.6654419\ttotal: 321ms\tremaining: 17.5s\n",
      "18:\tlearn: 72173.9037954\ttotal: 330ms\tremaining: 17s\n",
      "19:\tlearn: 72090.4433703\ttotal: 344ms\tremaining: 16.8s\n",
      "20:\tlearn: 72012.7024210\ttotal: 355ms\tremaining: 16.6s\n",
      "21:\tlearn: 71896.1186407\ttotal: 370ms\tremaining: 16.5s\n",
      "22:\tlearn: 71749.6582108\ttotal: 377ms\tremaining: 16s\n",
      "23:\tlearn: 71664.2481162\ttotal: 392ms\tremaining: 15.9s\n",
      "24:\tlearn: 71561.6277142\ttotal: 406ms\tremaining: 15.8s\n",
      "25:\tlearn: 71300.3290489\ttotal: 423ms\tremaining: 15.9s\n",
      "26:\tlearn: 71230.9553175\ttotal: 468ms\tremaining: 16.9s\n",
      "27:\tlearn: 71162.3724346\ttotal: 476ms\tremaining: 16.5s\n",
      "28:\tlearn: 71098.0127027\ttotal: 490ms\tremaining: 16.4s\n",
      "29:\tlearn: 71023.1977469\ttotal: 505ms\tremaining: 16.3s\n",
      "30:\tlearn: 70965.2179986\ttotal: 519ms\tremaining: 16.2s\n",
      "31:\tlearn: 70930.1879519\ttotal: 526ms\tremaining: 15.9s\n",
      "32:\tlearn: 70890.1601025\ttotal: 538ms\tremaining: 15.8s\n",
      "33:\tlearn: 70829.3157892\ttotal: 552ms\tremaining: 15.7s\n",
      "34:\tlearn: 70796.9348956\ttotal: 597ms\tremaining: 16.5s\n",
      "35:\tlearn: 70754.5954774\ttotal: 620ms\tremaining: 16.6s\n",
      "36:\tlearn: 70722.6703832\ttotal: 630ms\tremaining: 16.4s\n",
      "37:\tlearn: 70684.0928617\ttotal: 642ms\tremaining: 16.2s\n",
      "38:\tlearn: 70640.9446824\ttotal: 673ms\tremaining: 16.6s\n",
      "39:\tlearn: 70605.5905500\ttotal: 695ms\tremaining: 16.7s\n",
      "40:\tlearn: 70562.6850367\ttotal: 706ms\tremaining: 16.5s\n",
      "41:\tlearn: 70439.0734054\ttotal: 721ms\tremaining: 16.5s\n",
      "42:\tlearn: 70412.4595993\ttotal: 733ms\tremaining: 16.3s\n",
      "43:\tlearn: 70363.2613292\ttotal: 743ms\tremaining: 16.1s\n",
      "44:\tlearn: 70325.6494107\ttotal: 752ms\tremaining: 16s\n",
      "45:\tlearn: 70291.8520823\ttotal: 767ms\tremaining: 15.9s\n",
      "46:\tlearn: 70267.8461680\ttotal: 817ms\tremaining: 16.6s\n",
      "47:\tlearn: 70242.0595613\ttotal: 853ms\tremaining: 16.9s\n",
      "48:\tlearn: 70224.9841161\ttotal: 966ms\tremaining: 18.7s\n",
      "49:\tlearn: 70195.2119472\ttotal: 983ms\tremaining: 18.7s\n",
      "50:\tlearn: 70171.4282620\ttotal: 998ms\tremaining: 18.6s\n",
      "51:\tlearn: 70150.0527744\ttotal: 1.01s\tremaining: 18.4s\n",
      "52:\tlearn: 70092.7244597\ttotal: 1.02s\tremaining: 18.2s\n",
      "53:\tlearn: 70064.8835076\ttotal: 1.03s\tremaining: 18.1s\n",
      "54:\tlearn: 70042.3422930\ttotal: 1.04s\tremaining: 17.9s\n",
      "55:\tlearn: 70019.0062760\ttotal: 1.05s\tremaining: 17.7s\n",
      "56:\tlearn: 69995.2380057\ttotal: 1.07s\tremaining: 17.7s\n",
      "57:\tlearn: 69966.2774411\ttotal: 1.09s\tremaining: 17.7s\n",
      "58:\tlearn: 69949.9490543\ttotal: 1.11s\tremaining: 17.7s\n",
      "59:\tlearn: 69925.9469891\ttotal: 1.13s\tremaining: 17.7s\n",
      "60:\tlearn: 69899.4134689\ttotal: 1.15s\tremaining: 17.6s\n",
      "61:\tlearn: 69882.8902126\ttotal: 1.16s\tremaining: 17.6s\n",
      "62:\tlearn: 69841.5294287\ttotal: 1.17s\tremaining: 17.4s\n",
      "63:\tlearn: 69669.4053757\ttotal: 1.19s\tremaining: 17.4s\n",
      "64:\tlearn: 69493.7018410\ttotal: 1.2s\tremaining: 17.3s\n",
      "65:\tlearn: 69477.1872531\ttotal: 1.21s\tremaining: 17.2s\n",
      "66:\tlearn: 69459.8559447\ttotal: 1.23s\tremaining: 17.1s\n",
      "67:\tlearn: 69404.3785782\ttotal: 1.24s\tremaining: 17s\n",
      "68:\tlearn: 69382.2092580\ttotal: 1.25s\tremaining: 16.8s\n",
      "69:\tlearn: 69304.0845592\ttotal: 1.26s\tremaining: 16.8s\n",
      "70:\tlearn: 69238.3226242\ttotal: 1.27s\tremaining: 16.7s\n",
      "71:\tlearn: 69218.7277580\ttotal: 1.29s\tremaining: 16.6s\n",
      "72:\tlearn: 69206.0401372\ttotal: 1.34s\tremaining: 17s\n",
      "73:\tlearn: 69196.1889246\ttotal: 1.35s\tremaining: 16.9s\n",
      "74:\tlearn: 69183.9259971\ttotal: 1.36s\tremaining: 16.8s\n",
      "75:\tlearn: 69176.3326197\ttotal: 1.38s\tremaining: 16.8s\n",
      "76:\tlearn: 69169.7767421\ttotal: 1.4s\tremaining: 16.7s\n",
      "77:\tlearn: 69162.8279312\ttotal: 1.41s\tremaining: 16.6s\n",
      "78:\tlearn: 69156.7996673\ttotal: 1.41s\tremaining: 16.5s\n",
      "79:\tlearn: 68973.7239945\ttotal: 1.43s\tremaining: 16.4s\n",
      "80:\tlearn: 68928.1891766\ttotal: 1.44s\tremaining: 16.3s\n",
      "81:\tlearn: 68785.7021148\ttotal: 1.45s\tremaining: 16.3s\n",
      "82:\tlearn: 68779.2030454\ttotal: 1.46s\tremaining: 16.1s\n",
      "83:\tlearn: 68743.9079651\ttotal: 1.48s\tremaining: 16.1s\n",
      "84:\tlearn: 68555.1547439\ttotal: 1.49s\tremaining: 16.1s\n",
      "85:\tlearn: 68541.8063428\ttotal: 1.51s\tremaining: 16.1s\n",
      "86:\tlearn: 68536.6749026\ttotal: 1.54s\tremaining: 16.1s\n",
      "87:\tlearn: 68430.0732368\ttotal: 1.55s\tremaining: 16.1s\n",
      "88:\tlearn: 68423.4513640\ttotal: 1.56s\tremaining: 16s\n",
      "89:\tlearn: 68282.8735565\ttotal: 1.58s\tremaining: 15.9s\n",
      "90:\tlearn: 68272.3800216\ttotal: 1.59s\tremaining: 15.9s\n",
      "91:\tlearn: 68261.0718222\ttotal: 1.6s\tremaining: 15.8s\n",
      "92:\tlearn: 68255.5624900\ttotal: 1.62s\tremaining: 15.8s\n",
      "93:\tlearn: 68251.0133216\ttotal: 1.62s\tremaining: 15.7s\n",
      "94:\tlearn: 68052.5546693\ttotal: 1.64s\tremaining: 15.6s\n",
      "95:\tlearn: 68029.7669041\ttotal: 1.65s\tremaining: 15.5s\n",
      "96:\tlearn: 67968.5888464\ttotal: 1.66s\tremaining: 15.4s\n",
      "97:\tlearn: 67842.6873892\ttotal: 1.67s\tremaining: 15.4s\n",
      "98:\tlearn: 67800.1985298\ttotal: 1.68s\tremaining: 15.3s\n",
      "99:\tlearn: 67786.4172934\ttotal: 1.69s\tremaining: 15.2s\n",
      "100:\tlearn: 67780.9907377\ttotal: 1.71s\tremaining: 15.2s\n",
      "101:\tlearn: 67728.6031675\ttotal: 1.72s\tremaining: 15.1s\n",
      "102:\tlearn: 67499.1136920\ttotal: 1.75s\tremaining: 15.2s\n",
      "103:\tlearn: 67467.3753563\ttotal: 1.75s\tremaining: 15.1s\n",
      "104:\tlearn: 67461.8184098\ttotal: 1.85s\tremaining: 15.8s\n",
      "105:\tlearn: 67437.7217667\ttotal: 1.86s\tremaining: 15.7s\n",
      "106:\tlearn: 67379.3054784\ttotal: 1.88s\tremaining: 15.7s\n",
      "107:\tlearn: 67327.1641219\ttotal: 1.9s\tremaining: 15.7s\n",
      "108:\tlearn: 67308.1008535\ttotal: 1.91s\tremaining: 15.6s\n",
      "109:\tlearn: 67304.1112133\ttotal: 1.92s\tremaining: 15.5s\n",
      "110:\tlearn: 67152.4236325\ttotal: 1.93s\tremaining: 15.5s\n",
      "111:\tlearn: 67139.3759945\ttotal: 1.94s\tremaining: 15.4s\n",
      "112:\tlearn: 67114.9133000\ttotal: 1.95s\tremaining: 15.3s\n",
      "113:\tlearn: 67000.4457495\ttotal: 1.97s\tremaining: 15.3s\n",
      "114:\tlearn: 66956.3073941\ttotal: 1.98s\tremaining: 15.2s\n",
      "115:\tlearn: 66802.1777573\ttotal: 2.01s\tremaining: 15.3s\n",
      "116:\tlearn: 66756.4050511\ttotal: 2.03s\tremaining: 15.3s\n",
      "117:\tlearn: 66600.0204143\ttotal: 2.04s\tremaining: 15.3s\n",
      "118:\tlearn: 66577.0738619\ttotal: 2.05s\tremaining: 15.2s\n",
      "119:\tlearn: 66464.6882114\ttotal: 2.06s\tremaining: 15.1s\n",
      "120:\tlearn: 66440.5495741\ttotal: 2.08s\tremaining: 15.1s\n",
      "121:\tlearn: 66321.4137458\ttotal: 2.09s\tremaining: 15s\n",
      "122:\tlearn: 66290.2818248\ttotal: 2.1s\tremaining: 15s\n",
      "123:\tlearn: 66285.7021447\ttotal: 2.12s\tremaining: 15s\n",
      "124:\tlearn: 66264.9906421\ttotal: 2.13s\tremaining: 14.9s\n",
      "125:\tlearn: 66261.3812990\ttotal: 2.14s\tremaining: 14.9s\n",
      "126:\tlearn: 66241.6091799\ttotal: 2.15s\tremaining: 14.8s\n",
      "127:\tlearn: 66237.8979985\ttotal: 2.17s\tremaining: 14.8s\n",
      "128:\tlearn: 66231.0044876\ttotal: 2.18s\tremaining: 14.7s\n",
      "129:\tlearn: 66210.9259626\ttotal: 2.23s\tremaining: 14.9s\n",
      "130:\tlearn: 66115.7904748\ttotal: 2.25s\tremaining: 14.9s\n",
      "131:\tlearn: 65968.1161157\ttotal: 2.26s\tremaining: 14.9s\n",
      "132:\tlearn: 65945.0254442\ttotal: 2.28s\tremaining: 14.8s\n",
      "133:\tlearn: 65938.2553782\ttotal: 2.29s\tremaining: 14.8s\n",
      "134:\tlearn: 65802.7139667\ttotal: 2.3s\tremaining: 14.7s\n",
      "135:\tlearn: 65795.3823778\ttotal: 2.32s\tremaining: 14.7s\n",
      "136:\tlearn: 65660.4016937\ttotal: 2.33s\tremaining: 14.7s\n",
      "137:\tlearn: 65589.3147546\ttotal: 2.34s\tremaining: 14.6s\n",
      "138:\tlearn: 65578.3424367\ttotal: 2.36s\tremaining: 14.6s\n",
      "139:\tlearn: 65562.7625406\ttotal: 2.37s\tremaining: 14.6s\n",
      "140:\tlearn: 65444.1348122\ttotal: 2.38s\tremaining: 14.5s\n",
      "141:\tlearn: 65435.5380386\ttotal: 2.4s\tremaining: 14.5s\n",
      "142:\tlearn: 65415.6410617\ttotal: 2.44s\tremaining: 14.6s\n",
      "143:\tlearn: 65296.1493028\ttotal: 2.46s\tremaining: 14.6s\n",
      "144:\tlearn: 65242.6070877\ttotal: 2.47s\tremaining: 14.6s\n",
      "145:\tlearn: 65134.5465478\ttotal: 2.48s\tremaining: 14.5s\n",
      "146:\tlearn: 65083.5501549\ttotal: 2.49s\tremaining: 14.5s\n",
      "147:\tlearn: 65006.1374427\ttotal: 2.51s\tremaining: 14.4s\n",
      "148:\tlearn: 64957.4908945\ttotal: 2.52s\tremaining: 14.4s\n",
      "149:\tlearn: 64854.0198199\ttotal: 2.53s\tremaining: 14.4s\n",
      "150:\tlearn: 64736.9219985\ttotal: 2.54s\tremaining: 14.3s\n",
      "151:\tlearn: 64654.0669502\ttotal: 2.55s\tremaining: 14.3s\n",
      "152:\tlearn: 64561.9982222\ttotal: 2.57s\tremaining: 14.2s\n",
      "153:\tlearn: 64559.2685168\ttotal: 2.58s\tremaining: 14.2s\n",
      "154:\tlearn: 64513.7613316\ttotal: 2.59s\tremaining: 14.1s\n",
      "155:\tlearn: 64426.2336873\ttotal: 2.6s\tremaining: 14.1s\n",
      "156:\tlearn: 64344.1899384\ttotal: 2.62s\tremaining: 14s\n",
      "157:\tlearn: 64325.6696165\ttotal: 2.64s\tremaining: 14.1s\n",
      "158:\tlearn: 64265.4656578\ttotal: 2.75s\tremaining: 14.6s\n",
      "159:\tlearn: 64194.3242560\ttotal: 2.77s\tremaining: 14.5s\n",
      "160:\tlearn: 64117.6539214\ttotal: 2.78s\tremaining: 14.5s\n",
      "161:\tlearn: 64084.2252210\ttotal: 2.79s\tremaining: 14.4s\n",
      "162:\tlearn: 64011.5521089\ttotal: 2.8s\tremaining: 14.4s\n",
      "163:\tlearn: 63966.1703725\ttotal: 2.81s\tremaining: 14.3s\n",
      "164:\tlearn: 63902.7792967\ttotal: 2.82s\tremaining: 14.3s\n",
      "165:\tlearn: 63852.3928279\ttotal: 2.84s\tremaining: 14.3s\n",
      "166:\tlearn: 63812.8998902\ttotal: 2.88s\tremaining: 14.4s\n",
      "167:\tlearn: 63790.1691680\ttotal: 2.89s\tremaining: 14.3s\n",
      "168:\tlearn: 63740.7456777\ttotal: 2.9s\tremaining: 14.3s\n",
      "169:\tlearn: 63694.7710005\ttotal: 2.92s\tremaining: 14.2s\n",
      "170:\tlearn: 63682.4841257\ttotal: 2.93s\tremaining: 14.2s\n",
      "171:\tlearn: 63614.0945742\ttotal: 2.94s\tremaining: 14.2s\n",
      "172:\tlearn: 63539.9994838\ttotal: 2.96s\tremaining: 14.2s\n",
      "173:\tlearn: 63518.1495823\ttotal: 2.98s\tremaining: 14.1s\n",
      "174:\tlearn: 63474.0934025\ttotal: 2.99s\tremaining: 14.1s\n",
      "175:\tlearn: 63462.0205870\ttotal: 3s\tremaining: 14s\n",
      "176:\tlearn: 63407.5335093\ttotal: 3.01s\tremaining: 14s\n",
      "177:\tlearn: 63345.0945854\ttotal: 3.02s\tremaining: 13.9s\n",
      "178:\tlearn: 63322.3080409\ttotal: 3.03s\tremaining: 13.9s\n",
      "179:\tlearn: 63301.0630330\ttotal: 3.04s\tremaining: 13.9s\n",
      "180:\tlearn: 63235.8304047\ttotal: 3.06s\tremaining: 13.8s\n",
      "181:\tlearn: 63176.8960444\ttotal: 3.11s\tremaining: 14s\n",
      "182:\tlearn: 63132.1636703\ttotal: 3.12s\tremaining: 13.9s\n",
      "183:\tlearn: 63097.5430318\ttotal: 3.13s\tremaining: 13.9s\n",
      "184:\tlearn: 63043.6211717\ttotal: 3.15s\tremaining: 13.9s\n",
      "185:\tlearn: 62999.9155769\ttotal: 3.16s\tremaining: 13.8s\n",
      "186:\tlearn: 62956.8902491\ttotal: 3.18s\tremaining: 13.8s\n",
      "187:\tlearn: 62884.7806321\ttotal: 3.19s\tremaining: 13.8s\n",
      "188:\tlearn: 62853.2391975\ttotal: 3.2s\tremaining: 13.7s\n",
      "189:\tlearn: 62801.9513612\ttotal: 3.21s\tremaining: 13.7s\n",
      "190:\tlearn: 62732.5118069\ttotal: 3.23s\tremaining: 13.7s\n",
      "191:\tlearn: 62690.4206430\ttotal: 3.24s\tremaining: 13.6s\n",
      "192:\tlearn: 62641.9388213\ttotal: 3.25s\tremaining: 13.6s\n",
      "193:\tlearn: 62596.0560604\ttotal: 3.27s\tremaining: 13.6s\n",
      "194:\tlearn: 62567.0153091\ttotal: 3.3s\tremaining: 13.6s\n",
      "195:\tlearn: 62526.5626851\ttotal: 3.32s\tremaining: 13.6s\n",
      "196:\tlearn: 62467.1876580\ttotal: 3.33s\tremaining: 13.6s\n",
      "197:\tlearn: 62417.7293746\ttotal: 3.34s\tremaining: 13.5s\n",
      "198:\tlearn: 62394.9542753\ttotal: 3.36s\tremaining: 13.5s\n",
      "199:\tlearn: 62347.7366854\ttotal: 3.37s\tremaining: 13.5s\n",
      "200:\tlearn: 62281.9362305\ttotal: 3.38s\tremaining: 13.4s\n",
      "201:\tlearn: 62211.9323030\ttotal: 3.39s\tremaining: 13.4s\n",
      "202:\tlearn: 62179.5285243\ttotal: 3.4s\tremaining: 13.4s\n",
      "203:\tlearn: 62168.0522588\ttotal: 3.41s\tremaining: 13.3s\n",
      "204:\tlearn: 62148.4181458\ttotal: 3.42s\tremaining: 13.3s\n",
      "205:\tlearn: 62131.4012198\ttotal: 3.44s\tremaining: 13.2s\n",
      "206:\tlearn: 62113.8591960\ttotal: 3.45s\tremaining: 13.2s\n",
      "207:\tlearn: 62082.5801286\ttotal: 3.46s\tremaining: 13.2s\n",
      "208:\tlearn: 62078.0782364\ttotal: 3.48s\tremaining: 13.2s\n",
      "209:\tlearn: 62060.4419053\ttotal: 3.49s\tremaining: 13.1s\n",
      "210:\tlearn: 61979.1127849\ttotal: 3.51s\tremaining: 13.1s\n",
      "211:\tlearn: 61906.2799346\ttotal: 3.52s\tremaining: 13.1s\n",
      "212:\tlearn: 61894.9477132\ttotal: 3.63s\tremaining: 13.4s\n",
      "213:\tlearn: 61817.2320720\ttotal: 3.64s\tremaining: 13.4s\n",
      "214:\tlearn: 61788.4454975\ttotal: 3.66s\tremaining: 13.4s\n",
      "215:\tlearn: 61732.2616991\ttotal: 3.67s\tremaining: 13.3s\n",
      "216:\tlearn: 61716.6607457\ttotal: 3.68s\tremaining: 13.3s\n",
      "217:\tlearn: 61642.6262153\ttotal: 3.69s\tremaining: 13.2s\n",
      "218:\tlearn: 61632.6101570\ttotal: 3.71s\tremaining: 13.2s\n",
      "219:\tlearn: 61608.5118259\ttotal: 3.72s\tremaining: 13.2s\n",
      "220:\tlearn: 61572.8794683\ttotal: 3.73s\tremaining: 13.1s\n",
      "221:\tlearn: 61502.4261800\ttotal: 3.76s\tremaining: 13.2s\n",
      "222:\tlearn: 61468.4321968\ttotal: 3.77s\tremaining: 13.1s\n",
      "223:\tlearn: 61458.3222225\ttotal: 3.79s\tremaining: 13.1s\n",
      "224:\tlearn: 61393.8935840\ttotal: 3.81s\tremaining: 13.1s\n",
      "225:\tlearn: 61326.4818877\ttotal: 3.82s\tremaining: 13.1s\n",
      "226:\tlearn: 61303.5428214\ttotal: 3.83s\tremaining: 13s\n",
      "227:\tlearn: 61238.7575725\ttotal: 3.84s\tremaining: 13s\n",
      "228:\tlearn: 61232.7479734\ttotal: 3.87s\tremaining: 13s\n",
      "229:\tlearn: 61170.4833079\ttotal: 3.88s\tremaining: 13s\n",
      "230:\tlearn: 61110.6266371\ttotal: 3.89s\tremaining: 12.9s\n",
      "231:\tlearn: 61068.4264543\ttotal: 3.9s\tremaining: 12.9s\n",
      "232:\tlearn: 61010.8042001\ttotal: 3.91s\tremaining: 12.9s\n",
      "233:\tlearn: 60992.9554133\ttotal: 3.92s\tremaining: 12.8s\n",
      "234:\tlearn: 60937.5102798\ttotal: 3.94s\tremaining: 12.8s\n",
      "235:\tlearn: 60918.5892984\ttotal: 3.95s\tremaining: 12.8s\n",
      "236:\tlearn: 60865.2282030\ttotal: 4.01s\tremaining: 12.9s\n",
      "237:\tlearn: 60843.0090920\ttotal: 4.02s\tremaining: 12.9s\n",
      "238:\tlearn: 60813.6706070\ttotal: 4.04s\tremaining: 12.9s\n",
      "239:\tlearn: 60756.2700358\ttotal: 4.05s\tremaining: 12.8s\n",
      "240:\tlearn: 60734.8418360\ttotal: 4.06s\tremaining: 12.8s\n",
      "241:\tlearn: 60683.1469036\ttotal: 4.08s\tremaining: 12.8s\n",
      "242:\tlearn: 60655.0199582\ttotal: 4.09s\tremaining: 12.7s\n",
      "243:\tlearn: 60605.6978268\ttotal: 4.1s\tremaining: 12.7s\n",
      "244:\tlearn: 60582.1666819\ttotal: 4.12s\tremaining: 12.7s\n",
      "245:\tlearn: 60534.4707704\ttotal: 4.13s\tremaining: 12.7s\n",
      "246:\tlearn: 60488.5554534\ttotal: 4.14s\tremaining: 12.6s\n",
      "247:\tlearn: 60417.0911174\ttotal: 4.15s\tremaining: 12.6s\n",
      "248:\tlearn: 60372.8305118\ttotal: 4.17s\tremaining: 12.6s\n",
      "249:\tlearn: 60330.3502335\ttotal: 4.18s\tremaining: 12.6s\n",
      "250:\tlearn: 60289.4204002\ttotal: 4.2s\tremaining: 12.5s\n",
      "251:\tlearn: 60253.1419925\ttotal: 4.21s\tremaining: 12.5s\n",
      "252:\tlearn: 60224.7336710\ttotal: 4.23s\tremaining: 12.5s\n",
      "253:\tlearn: 60185.2393616\ttotal: 4.26s\tremaining: 12.5s\n",
      "254:\tlearn: 60158.8644061\ttotal: 4.28s\tremaining: 12.5s\n",
      "255:\tlearn: 60120.7852527\ttotal: 4.3s\tremaining: 12.5s\n",
      "256:\tlearn: 60084.0852962\ttotal: 4.31s\tremaining: 12.5s\n",
      "257:\tlearn: 60051.3129080\ttotal: 4.32s\tremaining: 12.4s\n",
      "258:\tlearn: 60018.7417948\ttotal: 4.33s\tremaining: 12.4s\n",
      "259:\tlearn: 59983.3317857\ttotal: 4.35s\tremaining: 12.4s\n",
      "260:\tlearn: 59971.7527215\ttotal: 4.37s\tremaining: 12.4s\n",
      "261:\tlearn: 59937.6102609\ttotal: 4.38s\tremaining: 12.3s\n",
      "262:\tlearn: 59928.1718513\ttotal: 4.39s\tremaining: 12.3s\n",
      "263:\tlearn: 59911.8697634\ttotal: 4.4s\tremaining: 12.3s\n",
      "264:\tlearn: 59896.9124157\ttotal: 4.42s\tremaining: 12.2s\n",
      "265:\tlearn: 59827.5920722\ttotal: 4.43s\tremaining: 12.2s\n",
      "266:\tlearn: 59794.2744098\ttotal: 4.45s\tremaining: 12.2s\n",
      "267:\tlearn: 59762.4664238\ttotal: 4.46s\tremaining: 12.2s\n",
      "268:\tlearn: 59735.9371391\ttotal: 4.47s\tremaining: 12.1s\n",
      "269:\tlearn: 59705.2571131\ttotal: 4.63s\tremaining: 12.5s\n",
      "270:\tlearn: 59675.6779085\ttotal: 4.66s\tremaining: 12.5s\n",
      "271:\tlearn: 59647.1586350\ttotal: 5.18s\tremaining: 13.9s\n",
      "272:\tlearn: 59630.4497929\ttotal: 5.23s\tremaining: 13.9s\n",
      "273:\tlearn: 59609.6978590\ttotal: 5.45s\tremaining: 14.4s\n",
      "274:\tlearn: 59591.2108543\ttotal: 5.46s\tremaining: 14.4s\n",
      "275:\tlearn: 59567.2416247\ttotal: 5.49s\tremaining: 14.4s\n",
      "276:\tlearn: 59500.1092385\ttotal: 5.56s\tremaining: 14.5s\n",
      "277:\tlearn: 59472.6726618\ttotal: 5.57s\tremaining: 14.5s\n",
      "278:\tlearn: 59446.2165422\ttotal: 5.6s\tremaining: 14.5s\n",
      "279:\tlearn: 59431.1369970\ttotal: 5.63s\tremaining: 14.5s\n",
      "280:\tlearn: 59426.0375983\ttotal: 5.65s\tremaining: 14.5s\n",
      "281:\tlearn: 59400.5179497\ttotal: 5.68s\tremaining: 14.5s\n",
      "282:\tlearn: 59375.5418185\ttotal: 5.71s\tremaining: 14.5s\n",
      "283:\tlearn: 59352.1101875\ttotal: 5.73s\tremaining: 14.4s\n",
      "284:\tlearn: 59327.9033666\ttotal: 5.74s\tremaining: 14.4s\n",
      "285:\tlearn: 59321.2420503\ttotal: 5.75s\tremaining: 14.4s\n",
      "286:\tlearn: 59275.6244666\ttotal: 5.76s\tremaining: 14.3s\n",
      "287:\tlearn: 59208.1598846\ttotal: 5.78s\tremaining: 14.3s\n",
      "288:\tlearn: 59143.1707858\ttotal: 5.79s\tremaining: 14.2s\n",
      "289:\tlearn: 59127.0974181\ttotal: 5.8s\tremaining: 14.2s\n",
      "290:\tlearn: 59104.8235454\ttotal: 5.81s\tremaining: 14.2s\n",
      "291:\tlearn: 59044.4066569\ttotal: 5.83s\tremaining: 14.1s\n",
      "292:\tlearn: 59028.9261880\ttotal: 5.85s\tremaining: 14.1s\n",
      "293:\tlearn: 58960.8204515\ttotal: 5.86s\tremaining: 14.1s\n",
      "294:\tlearn: 58935.3295814\ttotal: 5.87s\tremaining: 14s\n",
      "295:\tlearn: 58870.3276130\ttotal: 5.88s\tremaining: 14s\n",
      "296:\tlearn: 58849.0426534\ttotal: 5.89s\tremaining: 14s\n",
      "297:\tlearn: 58831.4911715\ttotal: 5.93s\tremaining: 14s\n",
      "298:\tlearn: 58817.2158966\ttotal: 5.95s\tremaining: 14s\n",
      "299:\tlearn: 58811.8204193\ttotal: 5.96s\tremaining: 13.9s\n",
      "300:\tlearn: 58788.9858656\ttotal: 5.97s\tremaining: 13.9s\n",
      "301:\tlearn: 58766.9636983\ttotal: 6s\tremaining: 13.9s\n",
      "302:\tlearn: 58745.2468836\ttotal: 6.01s\tremaining: 13.8s\n",
      "303:\tlearn: 58730.3586303\ttotal: 6.03s\tremaining: 13.8s\n",
      "304:\tlearn: 58689.5436883\ttotal: 6.04s\tremaining: 13.8s\n",
      "305:\tlearn: 58662.6398415\ttotal: 6.05s\tremaining: 13.7s\n",
      "306:\tlearn: 58599.5717728\ttotal: 6.06s\tremaining: 13.7s\n",
      "307:\tlearn: 58568.5796912\ttotal: 6.08s\tremaining: 13.7s\n",
      "308:\tlearn: 58548.0071676\ttotal: 6.09s\tremaining: 13.6s\n",
      "309:\tlearn: 58528.4824256\ttotal: 6.11s\tremaining: 13.6s\n",
      "310:\tlearn: 58489.7733877\ttotal: 6.12s\tremaining: 13.6s\n",
      "311:\tlearn: 58467.3105146\ttotal: 6.15s\tremaining: 13.6s\n",
      "312:\tlearn: 58443.0208141\ttotal: 6.17s\tremaining: 13.5s\n",
      "313:\tlearn: 58401.4086788\ttotal: 6.19s\tremaining: 13.5s\n",
      "314:\tlearn: 58394.2960835\ttotal: 6.2s\tremaining: 13.5s\n",
      "315:\tlearn: 58381.6176572\ttotal: 6.21s\tremaining: 13.4s\n",
      "316:\tlearn: 58373.9682067\ttotal: 6.23s\tremaining: 13.4s\n",
      "317:\tlearn: 58353.1296013\ttotal: 6.24s\tremaining: 13.4s\n",
      "318:\tlearn: 58293.3723004\ttotal: 6.25s\tremaining: 13.3s\n",
      "319:\tlearn: 58270.0887018\ttotal: 6.27s\tremaining: 13.3s\n",
      "320:\tlearn: 58251.8640748\ttotal: 6.28s\tremaining: 13.3s\n",
      "321:\tlearn: 58225.3223747\ttotal: 6.29s\tremaining: 13.2s\n",
      "322:\tlearn: 58188.5227860\ttotal: 6.3s\tremaining: 13.2s\n",
      "323:\tlearn: 58173.7790049\ttotal: 6.32s\tremaining: 13.2s\n",
      "324:\tlearn: 58153.5117143\ttotal: 6.43s\tremaining: 13.4s\n",
      "325:\tlearn: 58104.4440705\ttotal: 6.44s\tremaining: 13.3s\n",
      "326:\tlearn: 58097.5434568\ttotal: 6.45s\tremaining: 13.3s\n",
      "327:\tlearn: 58030.5547684\ttotal: 6.47s\tremaining: 13.3s\n",
      "328:\tlearn: 58011.2838289\ttotal: 6.48s\tremaining: 13.2s\n",
      "329:\tlearn: 57977.3614864\ttotal: 6.49s\tremaining: 13.2s\n",
      "330:\tlearn: 57956.1768658\ttotal: 6.5s\tremaining: 13.1s\n",
      "331:\tlearn: 57949.6416013\ttotal: 6.52s\tremaining: 13.1s\n",
      "332:\tlearn: 57937.8020469\ttotal: 6.53s\tremaining: 13.1s\n",
      "333:\tlearn: 57876.4460500\ttotal: 6.55s\tremaining: 13.1s\n",
      "334:\tlearn: 57857.8469975\ttotal: 6.57s\tremaining: 13.1s\n",
      "335:\tlearn: 57822.0160029\ttotal: 6.59s\tremaining: 13s\n",
      "336:\tlearn: 57757.8691144\ttotal: 6.6s\tremaining: 13s\n",
      "337:\tlearn: 57739.5073834\ttotal: 6.61s\tremaining: 13s\n",
      "338:\tlearn: 57722.1517407\ttotal: 6.63s\tremaining: 12.9s\n",
      "339:\tlearn: 57708.9815550\ttotal: 6.64s\tremaining: 12.9s\n",
      "340:\tlearn: 57666.5443136\ttotal: 6.65s\tremaining: 12.9s\n",
      "341:\tlearn: 57661.9167797\ttotal: 6.66s\tremaining: 12.8s\n",
      "342:\tlearn: 57621.9802056\ttotal: 6.68s\tremaining: 12.8s\n",
      "343:\tlearn: 57612.5430078\ttotal: 6.69s\tremaining: 12.8s\n",
      "344:\tlearn: 57606.3705046\ttotal: 6.7s\tremaining: 12.7s\n",
      "345:\tlearn: 57597.2149217\ttotal: 6.71s\tremaining: 12.7s\n",
      "346:\tlearn: 57537.8480886\ttotal: 6.72s\tremaining: 12.7s\n",
      "347:\tlearn: 57529.4204119\ttotal: 6.74s\tremaining: 12.6s\n",
      "348:\tlearn: 57493.7677624\ttotal: 6.75s\tremaining: 12.6s\n",
      "349:\tlearn: 57489.5395476\ttotal: 6.79s\tremaining: 12.6s\n",
      "350:\tlearn: 57475.0425029\ttotal: 6.82s\tremaining: 12.6s\n",
      "351:\tlearn: 57451.3245310\ttotal: 6.83s\tremaining: 12.6s\n",
      "352:\tlearn: 57447.6666726\ttotal: 6.85s\tremaining: 12.6s\n",
      "353:\tlearn: 57439.9323073\ttotal: 6.86s\tremaining: 12.5s\n",
      "354:\tlearn: 57427.3096040\ttotal: 6.88s\tremaining: 12.5s\n",
      "355:\tlearn: 57413.4659626\ttotal: 6.89s\tremaining: 12.5s\n",
      "356:\tlearn: 57388.6725655\ttotal: 6.91s\tremaining: 12.4s\n",
      "357:\tlearn: 57355.6195472\ttotal: 6.92s\tremaining: 12.4s\n",
      "358:\tlearn: 57298.2046024\ttotal: 6.94s\tremaining: 12.4s\n",
      "359:\tlearn: 57282.5469582\ttotal: 6.95s\tremaining: 12.4s\n",
      "360:\tlearn: 57277.0289778\ttotal: 6.97s\tremaining: 12.3s\n",
      "361:\tlearn: 57239.2061610\ttotal: 6.98s\tremaining: 12.3s\n",
      "362:\tlearn: 57232.1301302\ttotal: 7s\tremaining: 12.3s\n",
      "363:\tlearn: 57224.1781221\ttotal: 7.03s\tremaining: 12.3s\n",
      "364:\tlearn: 57212.7930814\ttotal: 7.05s\tremaining: 12.3s\n",
      "365:\tlearn: 57189.4410426\ttotal: 7.06s\tremaining: 12.2s\n",
      "366:\tlearn: 57177.4613615\ttotal: 7.08s\tremaining: 12.2s\n",
      "367:\tlearn: 57115.2514074\ttotal: 7.1s\tremaining: 12.2s\n",
      "368:\tlearn: 57109.7546171\ttotal: 7.11s\tremaining: 12.2s\n",
      "369:\tlearn: 57071.8412766\ttotal: 7.12s\tremaining: 12.1s\n",
      "370:\tlearn: 57056.4629233\ttotal: 7.14s\tremaining: 12.1s\n",
      "371:\tlearn: 57049.9996050\ttotal: 7.15s\tremaining: 12.1s\n",
      "372:\tlearn: 57043.5071737\ttotal: 7.17s\tremaining: 12.1s\n",
      "373:\tlearn: 57034.7744963\ttotal: 7.19s\tremaining: 12s\n",
      "374:\tlearn: 57020.0712181\ttotal: 7.2s\tremaining: 12s\n",
      "375:\tlearn: 56966.1162005\ttotal: 7.22s\tremaining: 12s\n",
      "376:\tlearn: 56960.8803865\ttotal: 7.26s\tremaining: 12s\n",
      "377:\tlearn: 56955.8966540\ttotal: 7.28s\tremaining: 12s\n",
      "378:\tlearn: 56937.8718201\ttotal: 7.29s\tremaining: 11.9s\n",
      "379:\tlearn: 56923.2171345\ttotal: 7.3s\tremaining: 11.9s\n",
      "380:\tlearn: 56910.3834938\ttotal: 7.32s\tremaining: 11.9s\n",
      "381:\tlearn: 56905.6751711\ttotal: 7.33s\tremaining: 11.9s\n",
      "382:\tlearn: 56901.1847661\ttotal: 7.35s\tremaining: 11.8s\n",
      "383:\tlearn: 56895.8603657\ttotal: 7.37s\tremaining: 11.8s\n",
      "384:\tlearn: 56882.7132331\ttotal: 7.38s\tremaining: 11.8s\n",
      "385:\tlearn: 56856.4997483\ttotal: 7.4s\tremaining: 11.8s\n",
      "386:\tlearn: 56848.4435990\ttotal: 7.41s\tremaining: 11.7s\n",
      "387:\tlearn: 56825.1970511\ttotal: 7.43s\tremaining: 11.7s\n",
      "388:\tlearn: 56769.5157910\ttotal: 7.48s\tremaining: 11.7s\n",
      "389:\tlearn: 56758.5273809\ttotal: 7.49s\tremaining: 11.7s\n",
      "390:\tlearn: 56744.3965978\ttotal: 7.51s\tremaining: 11.7s\n",
      "391:\tlearn: 56730.1605703\ttotal: 7.52s\tremaining: 11.7s\n",
      "392:\tlearn: 56701.6248960\ttotal: 7.54s\tremaining: 11.6s\n",
      "393:\tlearn: 56687.1926523\ttotal: 7.55s\tremaining: 11.6s\n",
      "394:\tlearn: 56663.3190978\ttotal: 7.56s\tremaining: 11.6s\n",
      "395:\tlearn: 56650.1485455\ttotal: 7.58s\tremaining: 11.6s\n",
      "396:\tlearn: 56571.7356955\ttotal: 7.59s\tremaining: 11.5s\n",
      "397:\tlearn: 56559.0209488\ttotal: 7.61s\tremaining: 11.5s\n",
      "398:\tlearn: 56546.3089384\ttotal: 7.63s\tremaining: 11.5s\n",
      "399:\tlearn: 56536.8598714\ttotal: 7.64s\tremaining: 11.5s\n",
      "400:\tlearn: 56526.7493822\ttotal: 7.77s\tremaining: 11.6s\n",
      "401:\tlearn: 56466.1379641\ttotal: 7.79s\tremaining: 11.6s\n",
      "402:\tlearn: 56432.8725255\ttotal: 7.8s\tremaining: 11.6s\n",
      "403:\tlearn: 56420.4463764\ttotal: 7.82s\tremaining: 11.5s\n",
      "404:\tlearn: 56399.9263770\ttotal: 7.83s\tremaining: 11.5s\n",
      "405:\tlearn: 56377.7541911\ttotal: 7.84s\tremaining: 11.5s\n",
      "406:\tlearn: 56367.5873728\ttotal: 7.86s\tremaining: 11.4s\n",
      "407:\tlearn: 56343.1190189\ttotal: 7.9s\tremaining: 11.5s\n",
      "408:\tlearn: 56325.4466399\ttotal: 7.91s\tremaining: 11.4s\n",
      "409:\tlearn: 56287.0752992\ttotal: 7.92s\tremaining: 11.4s\n",
      "410:\tlearn: 56262.8839837\ttotal: 7.94s\tremaining: 11.4s\n",
      "411:\tlearn: 56212.2698206\ttotal: 7.95s\tremaining: 11.3s\n",
      "412:\tlearn: 56204.9128608\ttotal: 7.97s\tremaining: 11.3s\n",
      "413:\tlearn: 56150.7779488\ttotal: 7.99s\tremaining: 11.3s\n",
      "414:\tlearn: 56075.0166823\ttotal: 7.99s\tremaining: 11.3s\n",
      "415:\tlearn: 56066.3715496\ttotal: 8s\tremaining: 11.2s\n",
      "416:\tlearn: 56058.0394600\ttotal: 8.02s\tremaining: 11.2s\n",
      "417:\tlearn: 56053.7597318\ttotal: 8.02s\tremaining: 11.2s\n",
      "418:\tlearn: 56027.0920154\ttotal: 8.03s\tremaining: 11.1s\n",
      "419:\tlearn: 56006.7845227\ttotal: 8.05s\tremaining: 11.1s\n",
      "420:\tlearn: 55954.4315931\ttotal: 8.08s\tremaining: 11.1s\n",
      "421:\tlearn: 55945.5273709\ttotal: 8.11s\tremaining: 11.1s\n",
      "422:\tlearn: 55924.4064380\ttotal: 8.12s\tremaining: 11.1s\n",
      "423:\tlearn: 55912.2389922\ttotal: 8.15s\tremaining: 11.1s\n",
      "424:\tlearn: 55889.5534761\ttotal: 8.16s\tremaining: 11s\n",
      "425:\tlearn: 55864.4670054\ttotal: 8.18s\tremaining: 11s\n",
      "426:\tlearn: 55792.3673087\ttotal: 8.19s\tremaining: 11s\n",
      "427:\tlearn: 55781.1077075\ttotal: 8.21s\tremaining: 11s\n",
      "428:\tlearn: 55752.9202970\ttotal: 8.21s\tremaining: 10.9s\n",
      "429:\tlearn: 55737.2690977\ttotal: 8.23s\tremaining: 10.9s\n",
      "430:\tlearn: 55706.3104646\ttotal: 8.24s\tremaining: 10.9s\n",
      "431:\tlearn: 55702.2513703\ttotal: 8.25s\tremaining: 10.8s\n",
      "432:\tlearn: 55681.5387800\ttotal: 8.26s\tremaining: 10.8s\n",
      "433:\tlearn: 55669.3096243\ttotal: 8.28s\tremaining: 10.8s\n",
      "434:\tlearn: 55621.4163378\ttotal: 8.3s\tremaining: 10.8s\n",
      "435:\tlearn: 55555.4816207\ttotal: 8.31s\tremaining: 10.8s\n",
      "436:\tlearn: 55547.6853032\ttotal: 8.34s\tremaining: 10.7s\n",
      "437:\tlearn: 55533.1118627\ttotal: 8.35s\tremaining: 10.7s\n",
      "438:\tlearn: 55520.8535484\ttotal: 8.37s\tremaining: 10.7s\n",
      "439:\tlearn: 55508.5561839\ttotal: 8.38s\tremaining: 10.7s\n",
      "440:\tlearn: 55481.0935327\ttotal: 8.39s\tremaining: 10.6s\n",
      "441:\tlearn: 55471.8530910\ttotal: 8.4s\tremaining: 10.6s\n",
      "442:\tlearn: 55466.0417181\ttotal: 8.42s\tremaining: 10.6s\n",
      "443:\tlearn: 55445.7024802\ttotal: 8.43s\tremaining: 10.6s\n",
      "444:\tlearn: 55403.8924402\ttotal: 8.45s\tremaining: 10.5s\n",
      "445:\tlearn: 55340.5336861\ttotal: 8.46s\tremaining: 10.5s\n",
      "446:\tlearn: 55333.1437310\ttotal: 8.47s\tremaining: 10.5s\n",
      "447:\tlearn: 55288.5004037\ttotal: 8.49s\tremaining: 10.5s\n",
      "448:\tlearn: 55281.3690021\ttotal: 8.5s\tremaining: 10.4s\n",
      "449:\tlearn: 55273.0847932\ttotal: 8.52s\tremaining: 10.4s\n",
      "450:\tlearn: 55268.6424230\ttotal: 8.55s\tremaining: 10.4s\n",
      "451:\tlearn: 55261.9520706\ttotal: 8.63s\tremaining: 10.5s\n",
      "452:\tlearn: 55227.7211662\ttotal: 8.65s\tremaining: 10.4s\n",
      "453:\tlearn: 55224.3928614\ttotal: 8.66s\tremaining: 10.4s\n",
      "454:\tlearn: 55218.3545783\ttotal: 8.67s\tremaining: 10.4s\n",
      "455:\tlearn: 55207.4936485\ttotal: 8.69s\tremaining: 10.4s\n",
      "456:\tlearn: 55188.0077801\ttotal: 8.71s\tremaining: 10.3s\n",
      "457:\tlearn: 55181.2442301\ttotal: 8.71s\tremaining: 10.3s\n",
      "458:\tlearn: 55153.0207663\ttotal: 8.73s\tremaining: 10.3s\n",
      "459:\tlearn: 55129.3824469\ttotal: 8.77s\tremaining: 10.3s\n",
      "460:\tlearn: 55069.4802770\ttotal: 8.8s\tremaining: 10.3s\n",
      "461:\tlearn: 55018.2981939\ttotal: 8.81s\tremaining: 10.3s\n",
      "462:\tlearn: 54973.5031585\ttotal: 8.83s\tremaining: 10.2s\n",
      "463:\tlearn: 54962.8954023\ttotal: 8.84s\tremaining: 10.2s\n",
      "464:\tlearn: 54888.3722631\ttotal: 8.85s\tremaining: 10.2s\n",
      "465:\tlearn: 54872.5443804\ttotal: 8.86s\tremaining: 10.2s\n",
      "466:\tlearn: 54861.3185703\ttotal: 8.88s\tremaining: 10.1s\n",
      "467:\tlearn: 54850.7359402\ttotal: 8.88s\tremaining: 10.1s\n",
      "468:\tlearn: 54844.6371128\ttotal: 8.9s\tremaining: 10.1s\n",
      "469:\tlearn: 54777.6288369\ttotal: 8.91s\tremaining: 10s\n",
      "470:\tlearn: 54767.6132630\ttotal: 8.93s\tremaining: 10s\n",
      "471:\tlearn: 54761.7329445\ttotal: 8.94s\tremaining: 10s\n",
      "472:\tlearn: 54703.6963450\ttotal: 8.95s\tremaining: 9.98s\n",
      "473:\tlearn: 54697.7690612\ttotal: 8.98s\tremaining: 9.96s\n",
      "474:\tlearn: 54662.7625035\ttotal: 9s\tremaining: 9.95s\n",
      "475:\tlearn: 54636.2076190\ttotal: 9.01s\tremaining: 9.92s\n",
      "476:\tlearn: 54630.0461764\ttotal: 9.02s\tremaining: 9.89s\n",
      "477:\tlearn: 54619.7878465\ttotal: 9.03s\tremaining: 9.87s\n",
      "478:\tlearn: 54596.5311350\ttotal: 9.04s\tremaining: 9.84s\n",
      "479:\tlearn: 54591.2368763\ttotal: 9.06s\tremaining: 9.81s\n",
      "480:\tlearn: 54585.7728158\ttotal: 9.07s\tremaining: 9.79s\n",
      "481:\tlearn: 54575.8778349\ttotal: 9.08s\tremaining: 9.76s\n",
      "482:\tlearn: 54557.9488056\ttotal: 9.09s\tremaining: 9.73s\n",
      "483:\tlearn: 54496.0145233\ttotal: 9.11s\tremaining: 9.71s\n",
      "484:\tlearn: 54475.5760127\ttotal: 9.12s\tremaining: 9.69s\n",
      "485:\tlearn: 54417.2922552\ttotal: 9.14s\tremaining: 9.66s\n",
      "486:\tlearn: 54394.5567645\ttotal: 9.15s\tremaining: 9.64s\n",
      "487:\tlearn: 54326.0973272\ttotal: 9.16s\tremaining: 9.61s\n",
      "488:\tlearn: 54285.5550798\ttotal: 9.17s\tremaining: 9.59s\n",
      "489:\tlearn: 54275.5244329\ttotal: 9.21s\tremaining: 9.59s\n",
      "490:\tlearn: 54253.9636034\ttotal: 9.23s\tremaining: 9.57s\n",
      "491:\tlearn: 54248.2315673\ttotal: 9.24s\tremaining: 9.54s\n",
      "492:\tlearn: 54242.9090116\ttotal: 9.26s\tremaining: 9.52s\n",
      "493:\tlearn: 54223.6341096\ttotal: 9.27s\tremaining: 9.49s\n",
      "494:\tlearn: 54214.1202463\ttotal: 9.28s\tremaining: 9.47s\n",
      "495:\tlearn: 54203.8817777\ttotal: 9.29s\tremaining: 9.44s\n",
      "496:\tlearn: 54153.6496837\ttotal: 9.3s\tremaining: 9.42s\n",
      "497:\tlearn: 54121.1093661\ttotal: 9.32s\tremaining: 9.39s\n",
      "498:\tlearn: 54116.1912007\ttotal: 9.33s\tremaining: 9.37s\n",
      "499:\tlearn: 54104.7093641\ttotal: 9.35s\tremaining: 9.35s\n",
      "500:\tlearn: 54095.9719775\ttotal: 9.36s\tremaining: 9.32s\n",
      "501:\tlearn: 54091.0309998\ttotal: 9.37s\tremaining: 9.29s\n",
      "502:\tlearn: 54075.5281447\ttotal: 9.38s\tremaining: 9.27s\n",
      "503:\tlearn: 54048.4991302\ttotal: 9.4s\tremaining: 9.25s\n",
      "504:\tlearn: 54044.7091297\ttotal: 9.44s\tremaining: 9.25s\n",
      "505:\tlearn: 54041.0854025\ttotal: 9.45s\tremaining: 9.23s\n",
      "506:\tlearn: 54037.6179259\ttotal: 9.46s\tremaining: 9.2s\n",
      "507:\tlearn: 54025.6485595\ttotal: 9.47s\tremaining: 9.17s\n",
      "508:\tlearn: 54020.9933140\ttotal: 9.48s\tremaining: 9.15s\n",
      "509:\tlearn: 54009.4596527\ttotal: 9.5s\tremaining: 9.13s\n",
      "510:\tlearn: 53990.4431601\ttotal: 9.51s\tremaining: 9.1s\n",
      "511:\tlearn: 53982.3781355\ttotal: 9.53s\tremaining: 9.08s\n",
      "512:\tlearn: 53972.7500925\ttotal: 9.54s\tremaining: 9.05s\n",
      "513:\tlearn: 53968.1393770\ttotal: 9.55s\tremaining: 9.03s\n",
      "514:\tlearn: 53957.0136923\ttotal: 9.56s\tremaining: 9.01s\n",
      "515:\tlearn: 53952.2048914\ttotal: 9.57s\tremaining: 8.98s\n",
      "516:\tlearn: 53947.7934746\ttotal: 9.58s\tremaining: 8.95s\n",
      "517:\tlearn: 53876.0607263\ttotal: 9.6s\tremaining: 8.93s\n",
      "518:\tlearn: 53871.8053745\ttotal: 9.61s\tremaining: 8.9s\n",
      "519:\tlearn: 53807.9932969\ttotal: 9.62s\tremaining: 8.88s\n",
      "520:\tlearn: 53798.6201945\ttotal: 9.72s\tremaining: 8.93s\n",
      "521:\tlearn: 53794.3284022\ttotal: 9.73s\tremaining: 8.91s\n",
      "522:\tlearn: 53790.3903945\ttotal: 9.75s\tremaining: 8.89s\n",
      "523:\tlearn: 53741.6534474\ttotal: 9.76s\tremaining: 8.87s\n",
      "524:\tlearn: 53730.5660370\ttotal: 9.77s\tremaining: 8.84s\n",
      "525:\tlearn: 53709.3837623\ttotal: 9.79s\tremaining: 8.82s\n",
      "526:\tlearn: 53649.0250544\ttotal: 9.79s\tremaining: 8.79s\n",
      "527:\tlearn: 53639.9878736\ttotal: 9.81s\tremaining: 8.77s\n",
      "528:\tlearn: 53580.3161655\ttotal: 9.86s\tremaining: 8.78s\n",
      "529:\tlearn: 53574.7504288\ttotal: 9.87s\tremaining: 8.75s\n",
      "530:\tlearn: 53562.9338591\ttotal: 9.88s\tremaining: 8.72s\n",
      "531:\tlearn: 53535.1685496\ttotal: 9.89s\tremaining: 8.7s\n",
      "532:\tlearn: 53531.5224779\ttotal: 9.91s\tremaining: 8.68s\n",
      "533:\tlearn: 53522.8181298\ttotal: 9.92s\tremaining: 8.66s\n",
      "534:\tlearn: 53518.1798625\ttotal: 9.94s\tremaining: 8.64s\n",
      "535:\tlearn: 53487.3224238\ttotal: 9.96s\tremaining: 8.62s\n",
      "536:\tlearn: 53478.9290954\ttotal: 9.97s\tremaining: 8.6s\n",
      "537:\tlearn: 53475.3781495\ttotal: 9.98s\tremaining: 8.57s\n",
      "538:\tlearn: 53455.9064873\ttotal: 9.99s\tremaining: 8.54s\n",
      "539:\tlearn: 53433.0316346\ttotal: 10s\tremaining: 8.52s\n",
      "540:\tlearn: 53375.8952294\ttotal: 10s\tremaining: 8.5s\n",
      "541:\tlearn: 53341.4433800\ttotal: 10.1s\tremaining: 8.5s\n",
      "542:\tlearn: 53333.2512950\ttotal: 10.1s\tremaining: 8.48s\n",
      "543:\tlearn: 53309.5487611\ttotal: 10.1s\tremaining: 8.45s\n",
      "544:\tlearn: 53276.0617843\ttotal: 10.1s\tremaining: 8.43s\n",
      "545:\tlearn: 53247.1090604\ttotal: 10.1s\tremaining: 8.41s\n",
      "546:\tlearn: 53185.4601297\ttotal: 10.1s\tremaining: 8.38s\n",
      "547:\tlearn: 53175.8376407\ttotal: 10.1s\tremaining: 8.36s\n",
      "548:\tlearn: 53138.6337129\ttotal: 10.2s\tremaining: 8.34s\n",
      "549:\tlearn: 53128.4065533\ttotal: 10.2s\tremaining: 8.32s\n",
      "550:\tlearn: 53120.5900085\ttotal: 10.2s\tremaining: 8.29s\n",
      "551:\tlearn: 53116.4462471\ttotal: 10.2s\tremaining: 8.26s\n",
      "552:\tlearn: 53057.0051635\ttotal: 10.2s\tremaining: 8.24s\n",
      "553:\tlearn: 53053.6090469\ttotal: 10.2s\tremaining: 8.22s\n",
      "554:\tlearn: 53050.3657148\ttotal: 10.2s\tremaining: 8.19s\n",
      "555:\tlearn: 53039.5651769\ttotal: 10.2s\tremaining: 8.17s\n",
      "556:\tlearn: 53029.1568315\ttotal: 10.2s\tremaining: 8.15s\n",
      "557:\tlearn: 52981.6153192\ttotal: 10.3s\tremaining: 8.13s\n",
      "558:\tlearn: 52968.3376507\ttotal: 10.3s\tremaining: 8.11s\n",
      "559:\tlearn: 52951.2411018\ttotal: 10.3s\tremaining: 8.1s\n",
      "560:\tlearn: 52930.9787760\ttotal: 10.3s\tremaining: 8.07s\n",
      "561:\tlearn: 52896.2554166\ttotal: 10.3s\tremaining: 8.05s\n",
      "562:\tlearn: 52863.3749590\ttotal: 10.3s\tremaining: 8.03s\n",
      "563:\tlearn: 52856.1213724\ttotal: 10.4s\tremaining: 8.01s\n",
      "564:\tlearn: 52849.4636808\ttotal: 10.4s\tremaining: 7.99s\n",
      "565:\tlearn: 52815.1474269\ttotal: 10.4s\tremaining: 7.96s\n",
      "566:\tlearn: 52812.0850978\ttotal: 10.4s\tremaining: 7.94s\n",
      "567:\tlearn: 52753.9765334\ttotal: 10.4s\tremaining: 7.93s\n",
      "568:\tlearn: 52751.0080932\ttotal: 10.5s\tremaining: 7.92s\n",
      "569:\tlearn: 52739.3369712\ttotal: 10.5s\tremaining: 7.91s\n",
      "570:\tlearn: 52718.9579365\ttotal: 10.5s\tremaining: 7.91s\n",
      "571:\tlearn: 52709.2080709\ttotal: 10.5s\tremaining: 7.89s\n",
      "572:\tlearn: 52701.7129634\ttotal: 10.6s\tremaining: 7.86s\n",
      "573:\tlearn: 52698.7847795\ttotal: 10.6s\tremaining: 7.84s\n",
      "574:\tlearn: 52689.9179256\ttotal: 10.6s\tremaining: 7.82s\n",
      "575:\tlearn: 52677.0961697\ttotal: 10.6s\tremaining: 7.8s\n",
      "576:\tlearn: 52621.1879649\ttotal: 10.6s\tremaining: 7.78s\n",
      "577:\tlearn: 52617.0932966\ttotal: 10.6s\tremaining: 7.76s\n",
      "578:\tlearn: 52597.7861503\ttotal: 10.6s\tremaining: 7.74s\n",
      "579:\tlearn: 52595.0877803\ttotal: 10.6s\tremaining: 7.71s\n",
      "580:\tlearn: 52582.6968971\ttotal: 10.7s\tremaining: 7.69s\n",
      "581:\tlearn: 52578.9990833\ttotal: 10.7s\tremaining: 7.67s\n",
      "582:\tlearn: 52576.5133517\ttotal: 10.7s\tremaining: 7.64s\n",
      "583:\tlearn: 52573.1697695\ttotal: 10.7s\tremaining: 7.63s\n",
      "584:\tlearn: 52555.6759460\ttotal: 10.8s\tremaining: 7.66s\n",
      "585:\tlearn: 52504.2217033\ttotal: 10.8s\tremaining: 7.64s\n",
      "586:\tlearn: 52446.3197049\ttotal: 10.8s\tremaining: 7.62s\n",
      "587:\tlearn: 52443.2688009\ttotal: 10.8s\tremaining: 7.59s\n",
      "588:\tlearn: 52441.0844803\ttotal: 10.9s\tremaining: 7.57s\n",
      "589:\tlearn: 52438.9871608\ttotal: 10.9s\tremaining: 7.55s\n",
      "590:\tlearn: 52417.6199195\ttotal: 10.9s\tremaining: 7.53s\n",
      "591:\tlearn: 52413.0640289\ttotal: 10.9s\tremaining: 7.51s\n",
      "592:\tlearn: 52358.9385189\ttotal: 10.9s\tremaining: 7.49s\n",
      "593:\tlearn: 52308.5709147\ttotal: 10.9s\tremaining: 7.48s\n",
      "594:\tlearn: 52290.8411881\ttotal: 11s\tremaining: 7.46s\n",
      "595:\tlearn: 52271.5347663\ttotal: 11s\tremaining: 7.44s\n",
      "596:\tlearn: 52219.2368496\ttotal: 11s\tremaining: 7.42s\n",
      "597:\tlearn: 52160.5166853\ttotal: 11s\tremaining: 7.4s\n",
      "598:\tlearn: 52143.9001877\ttotal: 11s\tremaining: 7.38s\n",
      "599:\tlearn: 52141.9329396\ttotal: 11s\tremaining: 7.35s\n",
      "600:\tlearn: 52123.4464454\ttotal: 11s\tremaining: 7.33s\n",
      "601:\tlearn: 52065.4792071\ttotal: 11.1s\tremaining: 7.31s\n",
      "602:\tlearn: 52015.0496284\ttotal: 11.1s\tremaining: 7.28s\n",
      "603:\tlearn: 52012.3522934\ttotal: 11.1s\tremaining: 7.26s\n",
      "604:\tlearn: 52008.1035302\ttotal: 11.1s\tremaining: 7.24s\n",
      "605:\tlearn: 51974.1495327\ttotal: 11.1s\tremaining: 7.22s\n",
      "606:\tlearn: 51956.6627209\ttotal: 11.1s\tremaining: 7.21s\n",
      "607:\tlearn: 51941.6737851\ttotal: 11.2s\tremaining: 7.19s\n",
      "608:\tlearn: 51924.7609258\ttotal: 11.2s\tremaining: 7.17s\n",
      "609:\tlearn: 51907.9089892\ttotal: 11.2s\tremaining: 7.15s\n",
      "610:\tlearn: 51882.9438376\ttotal: 11.2s\tremaining: 7.13s\n",
      "611:\tlearn: 51834.7985323\ttotal: 11.2s\tremaining: 7.11s\n",
      "612:\tlearn: 51818.5358966\ttotal: 11.2s\tremaining: 7.09s\n",
      "613:\tlearn: 51805.6057272\ttotal: 11.2s\tremaining: 7.06s\n",
      "614:\tlearn: 51795.5063457\ttotal: 11.2s\tremaining: 7.04s\n",
      "615:\tlearn: 51784.0782994\ttotal: 11.3s\tremaining: 7.02s\n",
      "616:\tlearn: 51762.3113481\ttotal: 11.3s\tremaining: 7s\n",
      "617:\tlearn: 51754.2163458\ttotal: 11.3s\tremaining: 6.97s\n",
      "618:\tlearn: 51743.2756837\ttotal: 11.3s\tremaining: 6.95s\n",
      "619:\tlearn: 51732.7656544\ttotal: 11.3s\tremaining: 6.93s\n",
      "620:\tlearn: 51722.6659171\ttotal: 11.3s\tremaining: 6.91s\n",
      "621:\tlearn: 51699.1091509\ttotal: 11.4s\tremaining: 6.91s\n",
      "622:\tlearn: 51680.1693095\ttotal: 11.4s\tremaining: 6.9s\n",
      "623:\tlearn: 51672.0758801\ttotal: 11.4s\tremaining: 6.89s\n",
      "624:\tlearn: 51614.0195392\ttotal: 11.5s\tremaining: 6.88s\n",
      "625:\tlearn: 51604.7890210\ttotal: 11.5s\tremaining: 6.86s\n",
      "626:\tlearn: 51584.8223674\ttotal: 11.5s\tremaining: 6.83s\n",
      "627:\tlearn: 51582.9757752\ttotal: 11.5s\tremaining: 6.81s\n",
      "628:\tlearn: 51572.5402844\ttotal: 11.5s\tremaining: 6.79s\n",
      "629:\tlearn: 51566.1589216\ttotal: 11.5s\tremaining: 6.77s\n",
      "630:\tlearn: 51558.7682237\ttotal: 11.5s\tremaining: 6.75s\n",
      "631:\tlearn: 51557.0173174\ttotal: 11.6s\tremaining: 6.73s\n",
      "632:\tlearn: 51539.2621427\ttotal: 11.7s\tremaining: 6.75s\n",
      "633:\tlearn: 51535.3306824\ttotal: 11.7s\tremaining: 6.73s\n",
      "634:\tlearn: 51530.7352257\ttotal: 11.7s\tremaining: 6.72s\n",
      "635:\tlearn: 51524.8164005\ttotal: 11.7s\tremaining: 6.7s\n",
      "636:\tlearn: 51515.1391176\ttotal: 11.7s\tremaining: 6.67s\n",
      "637:\tlearn: 51493.2230976\ttotal: 11.7s\tremaining: 6.65s\n",
      "638:\tlearn: 51488.3204759\ttotal: 11.7s\tremaining: 6.63s\n",
      "639:\tlearn: 51468.0127187\ttotal: 11.8s\tremaining: 6.61s\n",
      "640:\tlearn: 51446.5577056\ttotal: 11.8s\tremaining: 6.61s\n",
      "641:\tlearn: 51434.1625518\ttotal: 11.8s\tremaining: 6.58s\n",
      "642:\tlearn: 51405.8321269\ttotal: 11.8s\tremaining: 6.57s\n",
      "643:\tlearn: 51381.3862866\ttotal: 11.8s\tremaining: 6.55s\n",
      "644:\tlearn: 51325.2300998\ttotal: 11.9s\tremaining: 6.53s\n",
      "645:\tlearn: 51306.7127442\ttotal: 11.9s\tremaining: 6.5s\n",
      "646:\tlearn: 51298.8079392\ttotal: 11.9s\tremaining: 6.48s\n",
      "647:\tlearn: 51273.3171119\ttotal: 11.9s\tremaining: 6.46s\n",
      "648:\tlearn: 51256.3487300\ttotal: 11.9s\tremaining: 6.44s\n",
      "649:\tlearn: 51231.9142068\ttotal: 11.9s\tremaining: 6.42s\n",
      "650:\tlearn: 51223.5086823\ttotal: 11.9s\tremaining: 6.4s\n",
      "651:\tlearn: 51215.0503324\ttotal: 11.9s\tremaining: 6.38s\n",
      "652:\tlearn: 51190.3201912\ttotal: 12s\tremaining: 6.36s\n",
      "653:\tlearn: 51160.3236358\ttotal: 12s\tremaining: 6.34s\n",
      "654:\tlearn: 51151.2054495\ttotal: 12s\tremaining: 6.32s\n",
      "655:\tlearn: 51099.7137300\ttotal: 12s\tremaining: 6.31s\n",
      "656:\tlearn: 51053.9339629\ttotal: 12s\tremaining: 6.29s\n",
      "657:\tlearn: 51018.6765498\ttotal: 12.1s\tremaining: 6.27s\n",
      "658:\tlearn: 51011.0107703\ttotal: 12.1s\tremaining: 6.24s\n",
      "659:\tlearn: 50979.4716015\ttotal: 12.1s\tremaining: 6.22s\n",
      "660:\tlearn: 50975.4199143\ttotal: 12.1s\tremaining: 6.21s\n",
      "661:\tlearn: 50963.5559471\ttotal: 12.1s\tremaining: 6.19s\n",
      "662:\tlearn: 50948.1656930\ttotal: 12.1s\tremaining: 6.17s\n",
      "663:\tlearn: 50939.2884839\ttotal: 12.1s\tremaining: 6.15s\n",
      "664:\tlearn: 50884.0664454\ttotal: 12.2s\tremaining: 6.13s\n",
      "665:\tlearn: 50868.5528146\ttotal: 12.2s\tremaining: 6.1s\n",
      "666:\tlearn: 50849.9787180\ttotal: 12.2s\tremaining: 6.08s\n",
      "667:\tlearn: 50827.9805410\ttotal: 12.2s\tremaining: 6.07s\n",
      "668:\tlearn: 50820.3296670\ttotal: 12.2s\tremaining: 6.04s\n",
      "669:\tlearn: 50791.1977450\ttotal: 12.2s\tremaining: 6.03s\n",
      "670:\tlearn: 50785.7454820\ttotal: 12.3s\tremaining: 6.01s\n",
      "671:\tlearn: 50768.1563149\ttotal: 12.3s\tremaining: 5.99s\n",
      "672:\tlearn: 50764.7282216\ttotal: 12.3s\tremaining: 5.97s\n",
      "673:\tlearn: 50741.6382209\ttotal: 12.3s\tremaining: 5.95s\n",
      "674:\tlearn: 50727.9471167\ttotal: 12.3s\tremaining: 5.93s\n",
      "675:\tlearn: 50706.6959610\ttotal: 12.3s\tremaining: 5.9s\n",
      "676:\tlearn: 50693.9248763\ttotal: 12.3s\tremaining: 5.88s\n",
      "677:\tlearn: 50692.1651608\ttotal: 12.3s\tremaining: 5.86s\n",
      "678:\tlearn: 50680.7838118\ttotal: 12.4s\tremaining: 5.84s\n",
      "679:\tlearn: 50630.5836226\ttotal: 12.4s\tremaining: 5.82s\n",
      "680:\tlearn: 50616.8336453\ttotal: 12.4s\tremaining: 5.8s\n",
      "681:\tlearn: 50598.8061990\ttotal: 12.4s\tremaining: 5.78s\n",
      "682:\tlearn: 50550.0559989\ttotal: 12.4s\tremaining: 5.76s\n",
      "683:\tlearn: 50542.2397144\ttotal: 12.4s\tremaining: 5.74s\n",
      "684:\tlearn: 50532.7396541\ttotal: 12.4s\tremaining: 5.72s\n",
      "685:\tlearn: 50527.3757900\ttotal: 12.5s\tremaining: 5.71s\n",
      "686:\tlearn: 50473.7504264\ttotal: 12.5s\tremaining: 5.71s\n",
      "687:\tlearn: 50466.1633157\ttotal: 12.6s\tremaining: 5.7s\n",
      "688:\tlearn: 50441.2703070\ttotal: 12.6s\tremaining: 5.68s\n",
      "689:\tlearn: 50433.0459293\ttotal: 12.6s\tremaining: 5.66s\n",
      "690:\tlearn: 50418.4496491\ttotal: 12.6s\tremaining: 5.64s\n",
      "691:\tlearn: 50401.3859051\ttotal: 12.6s\tremaining: 5.61s\n",
      "692:\tlearn: 50367.4741889\ttotal: 12.6s\tremaining: 5.59s\n",
      "693:\tlearn: 50361.1308786\ttotal: 12.6s\tremaining: 5.57s\n",
      "694:\tlearn: 50344.7012393\ttotal: 12.7s\tremaining: 5.56s\n",
      "695:\tlearn: 50289.8501821\ttotal: 12.7s\tremaining: 5.54s\n",
      "696:\tlearn: 50268.1826320\ttotal: 12.7s\tremaining: 5.52s\n",
      "697:\tlearn: 50254.2290695\ttotal: 12.7s\tremaining: 5.5s\n",
      "698:\tlearn: 50221.3873196\ttotal: 12.7s\tremaining: 5.48s\n",
      "699:\tlearn: 50192.5205224\ttotal: 12.7s\tremaining: 5.46s\n",
      "700:\tlearn: 50171.8799890\ttotal: 12.8s\tremaining: 5.44s\n",
      "701:\tlearn: 50127.4041587\ttotal: 12.8s\tremaining: 5.43s\n",
      "702:\tlearn: 50113.4756665\ttotal: 12.8s\tremaining: 5.41s\n",
      "703:\tlearn: 50104.5950831\ttotal: 12.8s\tremaining: 5.38s\n",
      "704:\tlearn: 50076.2233977\ttotal: 12.8s\tremaining: 5.37s\n",
      "705:\tlearn: 50064.3302835\ttotal: 12.8s\tremaining: 5.35s\n",
      "706:\tlearn: 50050.9792535\ttotal: 12.9s\tremaining: 5.33s\n",
      "707:\tlearn: 50039.2310370\ttotal: 12.9s\tremaining: 5.31s\n",
      "708:\tlearn: 50033.3909181\ttotal: 12.9s\tremaining: 5.29s\n",
      "709:\tlearn: 50017.7769827\ttotal: 12.9s\tremaining: 5.27s\n",
      "710:\tlearn: 50010.7888707\ttotal: 12.9s\tremaining: 5.26s\n",
      "711:\tlearn: 50002.5253464\ttotal: 12.9s\tremaining: 5.24s\n",
      "712:\tlearn: 49989.6859997\ttotal: 13s\tremaining: 5.22s\n",
      "713:\tlearn: 49983.9558594\ttotal: 13s\tremaining: 5.2s\n",
      "714:\tlearn: 49976.0058197\ttotal: 13s\tremaining: 5.18s\n",
      "715:\tlearn: 49949.9054551\ttotal: 13s\tremaining: 5.16s\n",
      "716:\tlearn: 49942.1390300\ttotal: 13s\tremaining: 5.14s\n",
      "717:\tlearn: 49927.7922725\ttotal: 13s\tremaining: 5.12s\n",
      "718:\tlearn: 49886.4476038\ttotal: 13s\tremaining: 5.1s\n",
      "719:\tlearn: 49846.6675937\ttotal: 13.1s\tremaining: 5.08s\n",
      "720:\tlearn: 49808.0134452\ttotal: 13.1s\tremaining: 5.06s\n",
      "721:\tlearn: 49770.0539624\ttotal: 13.1s\tremaining: 5.04s\n",
      "722:\tlearn: 49747.5763493\ttotal: 13.1s\tremaining: 5.03s\n",
      "723:\tlearn: 49723.8136873\ttotal: 13.1s\tremaining: 5s\n",
      "724:\tlearn: 49715.6056011\ttotal: 13.1s\tremaining: 4.99s\n",
      "725:\tlearn: 49708.6329204\ttotal: 13.2s\tremaining: 4.96s\n",
      "726:\tlearn: 49694.3265241\ttotal: 13.2s\tremaining: 4.95s\n",
      "727:\tlearn: 49676.2381873\ttotal: 13.2s\tremaining: 4.92s\n",
      "728:\tlearn: 49671.0246272\ttotal: 13.2s\tremaining: 4.9s\n",
      "729:\tlearn: 49648.6040876\ttotal: 13.2s\tremaining: 4.88s\n",
      "730:\tlearn: 49621.2059530\ttotal: 13.2s\tremaining: 4.86s\n",
      "731:\tlearn: 49617.9034649\ttotal: 13.2s\tremaining: 4.84s\n",
      "732:\tlearn: 49602.4545358\ttotal: 13.2s\tremaining: 4.82s\n",
      "733:\tlearn: 49595.7237442\ttotal: 13.2s\tremaining: 4.8s\n",
      "734:\tlearn: 49591.6472221\ttotal: 13.3s\tremaining: 4.78s\n",
      "735:\tlearn: 49584.7490909\ttotal: 13.3s\tremaining: 4.76s\n",
      "736:\tlearn: 49558.2165862\ttotal: 13.3s\tremaining: 4.74s\n",
      "737:\tlearn: 49527.7616690\ttotal: 13.3s\tremaining: 4.72s\n",
      "738:\tlearn: 49511.0639114\ttotal: 13.3s\tremaining: 4.71s\n",
      "739:\tlearn: 49466.3673946\ttotal: 13.4s\tremaining: 4.72s\n",
      "740:\tlearn: 49444.7982025\ttotal: 13.4s\tremaining: 4.7s\n",
      "741:\tlearn: 49391.2040669\ttotal: 13.5s\tremaining: 4.68s\n",
      "742:\tlearn: 49377.9271459\ttotal: 13.5s\tremaining: 4.66s\n",
      "743:\tlearn: 49368.3358109\ttotal: 13.5s\tremaining: 4.64s\n",
      "744:\tlearn: 49365.1907580\ttotal: 13.5s\tremaining: 4.63s\n",
      "745:\tlearn: 49360.2082561\ttotal: 13.6s\tremaining: 4.61s\n",
      "746:\tlearn: 49342.6201793\ttotal: 13.6s\tremaining: 4.59s\n",
      "747:\tlearn: 49339.1865376\ttotal: 13.6s\tremaining: 4.57s\n",
      "748:\tlearn: 49295.9597517\ttotal: 13.6s\tremaining: 4.55s\n",
      "749:\tlearn: 49274.3410685\ttotal: 13.6s\tremaining: 4.53s\n",
      "750:\tlearn: 49270.8731483\ttotal: 13.6s\tremaining: 4.51s\n",
      "751:\tlearn: 49268.0243109\ttotal: 13.6s\tremaining: 4.49s\n",
      "752:\tlearn: 49252.8435067\ttotal: 13.6s\tremaining: 4.47s\n",
      "753:\tlearn: 49226.8593939\ttotal: 13.7s\tremaining: 4.45s\n",
      "754:\tlearn: 49202.7635976\ttotal: 13.7s\tremaining: 4.43s\n",
      "755:\tlearn: 49177.9447879\ttotal: 13.7s\tremaining: 4.42s\n",
      "756:\tlearn: 49163.3821484\ttotal: 13.7s\tremaining: 4.39s\n",
      "757:\tlearn: 49141.4045561\ttotal: 13.7s\tremaining: 4.38s\n",
      "758:\tlearn: 49138.6922505\ttotal: 13.7s\tremaining: 4.36s\n",
      "759:\tlearn: 49125.3760712\ttotal: 13.7s\tremaining: 4.34s\n",
      "760:\tlearn: 49119.9505045\ttotal: 13.8s\tremaining: 4.33s\n",
      "761:\tlearn: 49096.9116646\ttotal: 13.8s\tremaining: 4.31s\n",
      "762:\tlearn: 49084.8226146\ttotal: 13.8s\tremaining: 4.29s\n",
      "763:\tlearn: 49079.7316676\ttotal: 13.8s\tremaining: 4.27s\n",
      "764:\tlearn: 49074.5145075\ttotal: 13.9s\tremaining: 4.25s\n",
      "765:\tlearn: 49066.6622900\ttotal: 13.9s\tremaining: 4.24s\n",
      "766:\tlearn: 49059.1388590\ttotal: 13.9s\tremaining: 4.21s\n",
      "767:\tlearn: 49051.9261891\ttotal: 13.9s\tremaining: 4.19s\n",
      "768:\tlearn: 49014.3477331\ttotal: 13.9s\tremaining: 4.17s\n",
      "769:\tlearn: 49011.7646605\ttotal: 13.9s\tremaining: 4.16s\n",
      "770:\tlearn: 48989.6589523\ttotal: 13.9s\tremaining: 4.14s\n",
      "771:\tlearn: 48985.9361977\ttotal: 13.9s\tremaining: 4.12s\n",
      "772:\tlearn: 48981.5364340\ttotal: 14s\tremaining: 4.11s\n",
      "773:\tlearn: 48975.2315897\ttotal: 14s\tremaining: 4.09s\n",
      "774:\tlearn: 48972.6487552\ttotal: 14s\tremaining: 4.07s\n",
      "775:\tlearn: 48966.0301327\ttotal: 14s\tremaining: 4.05s\n",
      "776:\tlearn: 48960.3362465\ttotal: 14s\tremaining: 4.03s\n",
      "777:\tlearn: 48941.2830175\ttotal: 14.1s\tremaining: 4.01s\n",
      "778:\tlearn: 48924.8013600\ttotal: 14.1s\tremaining: 3.99s\n",
      "779:\tlearn: 48876.2793057\ttotal: 14.1s\tremaining: 3.97s\n",
      "780:\tlearn: 48865.1427313\ttotal: 14.1s\tremaining: 3.95s\n",
      "781:\tlearn: 48858.2479140\ttotal: 14.1s\tremaining: 3.93s\n",
      "782:\tlearn: 48851.6312333\ttotal: 14.1s\tremaining: 3.91s\n",
      "783:\tlearn: 48838.9046742\ttotal: 14.1s\tremaining: 3.89s\n",
      "784:\tlearn: 48819.1359461\ttotal: 14.1s\tremaining: 3.87s\n",
      "785:\tlearn: 48811.9235249\ttotal: 14.2s\tremaining: 3.85s\n",
      "786:\tlearn: 48806.9131966\ttotal: 14.2s\tremaining: 3.83s\n",
      "787:\tlearn: 48802.7677967\ttotal: 14.2s\tremaining: 3.81s\n",
      "788:\tlearn: 48797.2810437\ttotal: 14.2s\tremaining: 3.8s\n",
      "789:\tlearn: 48776.5194434\ttotal: 14.2s\tremaining: 3.78s\n",
      "790:\tlearn: 48770.3327654\ttotal: 14.2s\tremaining: 3.76s\n",
      "791:\tlearn: 48760.8768510\ttotal: 14.3s\tremaining: 3.74s\n",
      "792:\tlearn: 48722.4618508\ttotal: 14.3s\tremaining: 3.72s\n",
      "793:\tlearn: 48717.9117096\ttotal: 14.3s\tremaining: 3.7s\n",
      "794:\tlearn: 48715.4192180\ttotal: 14.3s\tremaining: 3.68s\n",
      "795:\tlearn: 48709.0267223\ttotal: 14.3s\tremaining: 3.67s\n",
      "796:\tlearn: 48693.6676317\ttotal: 14.3s\tremaining: 3.65s\n",
      "797:\tlearn: 48637.9881679\ttotal: 14.3s\tremaining: 3.63s\n",
      "798:\tlearn: 48625.4012416\ttotal: 14.3s\tremaining: 3.61s\n",
      "799:\tlearn: 48593.9369070\ttotal: 14.4s\tremaining: 3.59s\n",
      "800:\tlearn: 48576.9675945\ttotal: 14.4s\tremaining: 3.57s\n",
      "801:\tlearn: 48556.5262347\ttotal: 14.5s\tremaining: 3.57s\n",
      "802:\tlearn: 48532.8875693\ttotal: 14.5s\tremaining: 3.56s\n",
      "803:\tlearn: 48511.8200406\ttotal: 14.5s\tremaining: 3.54s\n",
      "804:\tlearn: 48469.6230124\ttotal: 14.5s\tremaining: 3.52s\n",
      "805:\tlearn: 48465.8464545\ttotal: 14.5s\tremaining: 3.5s\n",
      "806:\tlearn: 48462.7598879\ttotal: 14.5s\tremaining: 3.48s\n",
      "807:\tlearn: 48436.3190864\ttotal: 14.6s\tremaining: 3.46s\n",
      "808:\tlearn: 48416.7857517\ttotal: 14.6s\tremaining: 3.44s\n",
      "809:\tlearn: 48393.5914807\ttotal: 14.6s\tremaining: 3.43s\n",
      "810:\tlearn: 48378.3852983\ttotal: 14.6s\tremaining: 3.41s\n",
      "811:\tlearn: 48374.5530640\ttotal: 14.6s\tremaining: 3.39s\n",
      "812:\tlearn: 48357.8207085\ttotal: 14.7s\tremaining: 3.37s\n",
      "813:\tlearn: 48310.4488483\ttotal: 14.7s\tremaining: 3.35s\n",
      "814:\tlearn: 48305.5294824\ttotal: 14.7s\tremaining: 3.33s\n",
      "815:\tlearn: 48251.8574413\ttotal: 14.7s\tremaining: 3.31s\n",
      "816:\tlearn: 48228.5866897\ttotal: 14.7s\tremaining: 3.29s\n",
      "817:\tlearn: 48214.2075511\ttotal: 14.7s\tremaining: 3.27s\n",
      "818:\tlearn: 48208.2062328\ttotal: 14.7s\tremaining: 3.26s\n",
      "819:\tlearn: 48189.1778065\ttotal: 14.8s\tremaining: 3.24s\n",
      "820:\tlearn: 48168.0851165\ttotal: 14.8s\tremaining: 3.22s\n",
      "821:\tlearn: 48149.8195040\ttotal: 14.8s\tremaining: 3.2s\n",
      "822:\tlearn: 48143.5364320\ttotal: 14.8s\tremaining: 3.18s\n",
      "823:\tlearn: 48125.3942554\ttotal: 14.8s\tremaining: 3.17s\n",
      "824:\tlearn: 48108.3025804\ttotal: 14.8s\tremaining: 3.15s\n",
      "825:\tlearn: 48104.7176441\ttotal: 14.9s\tremaining: 3.13s\n",
      "826:\tlearn: 48093.8237656\ttotal: 14.9s\tremaining: 3.11s\n",
      "827:\tlearn: 48057.5300095\ttotal: 14.9s\tremaining: 3.09s\n",
      "828:\tlearn: 48044.8378215\ttotal: 14.9s\tremaining: 3.07s\n",
      "829:\tlearn: 48029.6612657\ttotal: 14.9s\tremaining: 3.05s\n",
      "830:\tlearn: 48022.6535813\ttotal: 14.9s\tremaining: 3.03s\n",
      "831:\tlearn: 48005.7271066\ttotal: 14.9s\tremaining: 3.02s\n",
      "832:\tlearn: 47998.9856309\ttotal: 14.9s\tremaining: 3s\n",
      "833:\tlearn: 47979.3740777\ttotal: 15s\tremaining: 2.98s\n",
      "834:\tlearn: 47962.9231524\ttotal: 15s\tremaining: 2.96s\n",
      "835:\tlearn: 47947.0317853\ttotal: 15s\tremaining: 2.94s\n",
      "836:\tlearn: 47943.6344012\ttotal: 15s\tremaining: 2.92s\n",
      "837:\tlearn: 47923.6715122\ttotal: 15s\tremaining: 2.9s\n",
      "838:\tlearn: 47906.3311174\ttotal: 15s\tremaining: 2.88s\n",
      "839:\tlearn: 47894.7043925\ttotal: 15.1s\tremaining: 2.87s\n",
      "840:\tlearn: 47849.5804842\ttotal: 15.1s\tremaining: 2.85s\n",
      "841:\tlearn: 47832.3867823\ttotal: 15.1s\tremaining: 2.83s\n",
      "842:\tlearn: 47804.4530333\ttotal: 15.1s\tremaining: 2.81s\n",
      "843:\tlearn: 47789.7561410\ttotal: 15.1s\tremaining: 2.79s\n",
      "844:\tlearn: 47775.6406532\ttotal: 15.1s\tremaining: 2.78s\n",
      "845:\tlearn: 47740.3644112\ttotal: 15.1s\tremaining: 2.76s\n",
      "846:\tlearn: 47730.9027356\ttotal: 15.2s\tremaining: 2.74s\n",
      "847:\tlearn: 47720.1118523\ttotal: 15.2s\tremaining: 2.72s\n",
      "848:\tlearn: 47704.7156971\ttotal: 15.2s\tremaining: 2.7s\n",
      "849:\tlearn: 47702.5126543\ttotal: 15.2s\tremaining: 2.68s\n",
      "850:\tlearn: 47696.8332346\ttotal: 15.2s\tremaining: 2.66s\n",
      "851:\tlearn: 47683.2824022\ttotal: 15.2s\tremaining: 2.64s\n",
      "852:\tlearn: 47674.3136214\ttotal: 15.3s\tremaining: 2.64s\n",
      "853:\tlearn: 47669.5670132\ttotal: 15.3s\tremaining: 2.62s\n",
      "854:\tlearn: 47649.9675486\ttotal: 15.3s\tremaining: 2.6s\n",
      "855:\tlearn: 47643.9596338\ttotal: 15.4s\tremaining: 2.58s\n",
      "856:\tlearn: 47641.3642732\ttotal: 15.4s\tremaining: 2.56s\n",
      "857:\tlearn: 47637.0813487\ttotal: 15.4s\tremaining: 2.55s\n",
      "858:\tlearn: 47634.6784832\ttotal: 15.4s\tremaining: 2.53s\n",
      "859:\tlearn: 47631.4212306\ttotal: 15.4s\tremaining: 2.51s\n",
      "860:\tlearn: 47625.1523129\ttotal: 15.4s\tremaining: 2.49s\n",
      "861:\tlearn: 47620.9934168\ttotal: 15.4s\tremaining: 2.47s\n",
      "862:\tlearn: 47612.4733920\ttotal: 15.5s\tremaining: 2.45s\n",
      "863:\tlearn: 47607.0251340\ttotal: 15.5s\tremaining: 2.44s\n",
      "864:\tlearn: 47601.7878345\ttotal: 15.5s\tremaining: 2.42s\n",
      "865:\tlearn: 47598.6121734\ttotal: 15.5s\tremaining: 2.4s\n",
      "866:\tlearn: 47596.3147073\ttotal: 15.5s\tremaining: 2.38s\n",
      "867:\tlearn: 47585.6623081\ttotal: 15.5s\tremaining: 2.36s\n",
      "868:\tlearn: 47575.2615243\ttotal: 15.6s\tremaining: 2.34s\n",
      "869:\tlearn: 47570.2243866\ttotal: 15.6s\tremaining: 2.33s\n",
      "870:\tlearn: 47529.3972052\ttotal: 15.6s\tremaining: 2.31s\n",
      "871:\tlearn: 47515.2699109\ttotal: 15.6s\tremaining: 2.29s\n",
      "872:\tlearn: 47508.0182550\ttotal: 15.6s\tremaining: 2.27s\n",
      "873:\tlearn: 47503.1670906\ttotal: 15.6s\tremaining: 2.25s\n",
      "874:\tlearn: 47489.8865671\ttotal: 15.6s\tremaining: 2.23s\n",
      "875:\tlearn: 47487.9058030\ttotal: 15.7s\tremaining: 2.21s\n",
      "876:\tlearn: 47483.4580892\ttotal: 15.7s\tremaining: 2.2s\n",
      "877:\tlearn: 47477.4871249\ttotal: 15.7s\tremaining: 2.18s\n",
      "878:\tlearn: 47469.3708271\ttotal: 15.7s\tremaining: 2.16s\n",
      "879:\tlearn: 47454.0594675\ttotal: 15.7s\tremaining: 2.14s\n",
      "880:\tlearn: 47448.6329030\ttotal: 15.7s\tremaining: 2.13s\n",
      "881:\tlearn: 47433.8658242\ttotal: 15.8s\tremaining: 2.11s\n",
      "882:\tlearn: 47419.9651191\ttotal: 15.8s\tremaining: 2.09s\n",
      "883:\tlearn: 47380.8788111\ttotal: 15.8s\tremaining: 2.07s\n",
      "884:\tlearn: 47367.3885020\ttotal: 15.8s\tremaining: 2.05s\n",
      "885:\tlearn: 47354.1016679\ttotal: 15.8s\tremaining: 2.03s\n",
      "886:\tlearn: 47345.8893305\ttotal: 15.8s\tremaining: 2.01s\n",
      "887:\tlearn: 47336.7808454\ttotal: 15.8s\tremaining: 2s\n",
      "888:\tlearn: 47326.1349536\ttotal: 15.8s\tremaining: 1.98s\n",
      "889:\tlearn: 47320.8894191\ttotal: 15.8s\tremaining: 1.96s\n",
      "890:\tlearn: 47307.8211074\ttotal: 15.9s\tremaining: 1.94s\n",
      "891:\tlearn: 47303.4533041\ttotal: 15.9s\tremaining: 1.92s\n",
      "892:\tlearn: 47287.8797348\ttotal: 15.9s\tremaining: 1.9s\n",
      "893:\tlearn: 47275.1550938\ttotal: 15.9s\tremaining: 1.89s\n",
      "894:\tlearn: 47261.0369812\ttotal: 15.9s\tremaining: 1.87s\n",
      "895:\tlearn: 47244.2105101\ttotal: 15.9s\tremaining: 1.85s\n",
      "896:\tlearn: 47218.8747484\ttotal: 16s\tremaining: 1.83s\n",
      "897:\tlearn: 47204.0822775\ttotal: 16s\tremaining: 1.81s\n",
      "898:\tlearn: 47190.3710096\ttotal: 16s\tremaining: 1.79s\n",
      "899:\tlearn: 47177.1947469\ttotal: 16s\tremaining: 1.78s\n",
      "900:\tlearn: 47156.9046577\ttotal: 16s\tremaining: 1.76s\n",
      "901:\tlearn: 47155.1485095\ttotal: 16s\tremaining: 1.74s\n",
      "902:\tlearn: 47143.0669280\ttotal: 16s\tremaining: 1.72s\n",
      "903:\tlearn: 47130.7100257\ttotal: 16.1s\tremaining: 1.7s\n",
      "904:\tlearn: 47123.1355428\ttotal: 16.1s\tremaining: 1.69s\n",
      "905:\tlearn: 47115.8501026\ttotal: 16.1s\tremaining: 1.67s\n",
      "906:\tlearn: 47110.0726394\ttotal: 16.1s\tremaining: 1.65s\n",
      "907:\tlearn: 47087.9309271\ttotal: 16.1s\tremaining: 1.63s\n",
      "908:\tlearn: 47081.5802235\ttotal: 16.1s\tremaining: 1.62s\n",
      "909:\tlearn: 47064.1360013\ttotal: 16.2s\tremaining: 1.6s\n",
      "910:\tlearn: 47061.9060284\ttotal: 16.2s\tremaining: 1.58s\n",
      "911:\tlearn: 47060.3258777\ttotal: 16.2s\tremaining: 1.56s\n",
      "912:\tlearn: 47056.1484550\ttotal: 16.2s\tremaining: 1.54s\n",
      "913:\tlearn: 47052.4436217\ttotal: 16.2s\tremaining: 1.52s\n",
      "914:\tlearn: 47050.3874886\ttotal: 16.2s\tremaining: 1.51s\n",
      "915:\tlearn: 47045.0282472\ttotal: 16.2s\tremaining: 1.49s\n",
      "916:\tlearn: 47033.7548540\ttotal: 16.2s\tremaining: 1.47s\n",
      "917:\tlearn: 47032.3814332\ttotal: 16.3s\tremaining: 1.45s\n",
      "918:\tlearn: 47026.4669912\ttotal: 16.3s\tremaining: 1.43s\n",
      "919:\tlearn: 47022.5652435\ttotal: 16.3s\tremaining: 1.42s\n",
      "920:\tlearn: 47021.3535300\ttotal: 16.3s\tremaining: 1.4s\n",
      "921:\tlearn: 47009.7888496\ttotal: 16.3s\tremaining: 1.38s\n",
      "922:\tlearn: 46997.0439352\ttotal: 16.3s\tremaining: 1.36s\n",
      "923:\tlearn: 46993.2839013\ttotal: 16.3s\tremaining: 1.34s\n",
      "924:\tlearn: 46986.4259148\ttotal: 16.4s\tremaining: 1.33s\n",
      "925:\tlearn: 46981.1215946\ttotal: 16.6s\tremaining: 1.32s\n",
      "926:\tlearn: 46976.5619701\ttotal: 16.6s\tremaining: 1.31s\n",
      "927:\tlearn: 46973.7388406\ttotal: 16.6s\tremaining: 1.29s\n",
      "928:\tlearn: 46923.9564255\ttotal: 17s\tremaining: 1.3s\n",
      "929:\tlearn: 46920.6366447\ttotal: 17.1s\tremaining: 1.28s\n",
      "930:\tlearn: 46908.9572219\ttotal: 17.3s\tremaining: 1.28s\n",
      "931:\tlearn: 46897.1492815\ttotal: 17.3s\tremaining: 1.26s\n",
      "932:\tlearn: 46881.6242237\ttotal: 17.3s\tremaining: 1.24s\n",
      "933:\tlearn: 46857.2235345\ttotal: 17.3s\tremaining: 1.22s\n",
      "934:\tlearn: 46849.5613875\ttotal: 17.3s\tremaining: 1.2s\n",
      "935:\tlearn: 46837.1397020\ttotal: 17.3s\tremaining: 1.19s\n",
      "936:\tlearn: 46831.9561125\ttotal: 17.4s\tremaining: 1.17s\n",
      "937:\tlearn: 46828.5472360\ttotal: 17.4s\tremaining: 1.15s\n",
      "938:\tlearn: 46825.2754930\ttotal: 17.4s\tremaining: 1.13s\n",
      "939:\tlearn: 46818.8984752\ttotal: 17.4s\tremaining: 1.11s\n",
      "940:\tlearn: 46812.7606658\ttotal: 17.4s\tremaining: 1.09s\n",
      "941:\tlearn: 46800.8206165\ttotal: 17.4s\tremaining: 1.07s\n",
      "942:\tlearn: 46794.9107506\ttotal: 17.4s\tremaining: 1.05s\n",
      "943:\tlearn: 46773.2037779\ttotal: 17.4s\tremaining: 1.03s\n",
      "944:\tlearn: 46734.5749860\ttotal: 17.4s\tremaining: 1.01s\n",
      "945:\tlearn: 46730.7310707\ttotal: 17.5s\tremaining: 997ms\n",
      "946:\tlearn: 46724.8082457\ttotal: 17.5s\tremaining: 978ms\n",
      "947:\tlearn: 46720.6614864\ttotal: 17.6s\tremaining: 965ms\n",
      "948:\tlearn: 46707.3315215\ttotal: 17.6s\tremaining: 947ms\n",
      "949:\tlearn: 46701.6855769\ttotal: 17.6s\tremaining: 928ms\n",
      "950:\tlearn: 46695.1582943\ttotal: 17.6s\tremaining: 909ms\n",
      "951:\tlearn: 46688.0451726\ttotal: 17.7s\tremaining: 890ms\n",
      "952:\tlearn: 46682.6708151\ttotal: 17.7s\tremaining: 871ms\n",
      "953:\tlearn: 46679.3301995\ttotal: 17.7s\tremaining: 852ms\n",
      "954:\tlearn: 46672.9068554\ttotal: 17.7s\tremaining: 833ms\n",
      "955:\tlearn: 46669.7589078\ttotal: 17.7s\tremaining: 816ms\n",
      "956:\tlearn: 46664.5171734\ttotal: 17.7s\tremaining: 797ms\n",
      "957:\tlearn: 46655.8243969\ttotal: 17.8s\tremaining: 778ms\n",
      "958:\tlearn: 46653.9316553\ttotal: 17.8s\tremaining: 759ms\n",
      "959:\tlearn: 46650.5077980\ttotal: 17.8s\tremaining: 741ms\n",
      "960:\tlearn: 46615.4182127\ttotal: 17.8s\tremaining: 722ms\n",
      "961:\tlearn: 46584.5249017\ttotal: 17.8s\tremaining: 703ms\n",
      "962:\tlearn: 46581.0149424\ttotal: 17.8s\tremaining: 685ms\n",
      "963:\tlearn: 46575.9567757\ttotal: 17.8s\tremaining: 666ms\n",
      "964:\tlearn: 46568.4479226\ttotal: 17.8s\tremaining: 647ms\n",
      "965:\tlearn: 46550.7142165\ttotal: 17.9s\tremaining: 628ms\n",
      "966:\tlearn: 46534.6135637\ttotal: 17.9s\tremaining: 610ms\n",
      "967:\tlearn: 46520.9261276\ttotal: 17.9s\tremaining: 591ms\n",
      "968:\tlearn: 46516.0473221\ttotal: 17.9s\tremaining: 573ms\n",
      "969:\tlearn: 46506.9363921\ttotal: 17.9s\tremaining: 555ms\n",
      "970:\tlearn: 46496.4813379\ttotal: 18s\tremaining: 536ms\n",
      "971:\tlearn: 46484.6827205\ttotal: 18s\tremaining: 517ms\n",
      "972:\tlearn: 46481.8921216\ttotal: 18s\tremaining: 499ms\n",
      "973:\tlearn: 46464.2374162\ttotal: 18s\tremaining: 480ms\n",
      "974:\tlearn: 46447.8612397\ttotal: 18s\tremaining: 462ms\n",
      "975:\tlearn: 46436.9130672\ttotal: 18s\tremaining: 443ms\n",
      "976:\tlearn: 46426.5573448\ttotal: 18s\tremaining: 424ms\n",
      "977:\tlearn: 46391.8093428\ttotal: 18s\tremaining: 406ms\n",
      "978:\tlearn: 46390.4108762\ttotal: 18.1s\tremaining: 387ms\n",
      "979:\tlearn: 46380.0801262\ttotal: 18.1s\tremaining: 369ms\n",
      "980:\tlearn: 46375.0236193\ttotal: 18.1s\tremaining: 350ms\n",
      "981:\tlearn: 46367.6180722\ttotal: 18.1s\tremaining: 332ms\n",
      "982:\tlearn: 46360.5053182\ttotal: 18.1s\tremaining: 314ms\n",
      "983:\tlearn: 46357.8711599\ttotal: 18.1s\tremaining: 295ms\n",
      "984:\tlearn: 46355.7834497\ttotal: 18.2s\tremaining: 276ms\n",
      "985:\tlearn: 46351.1880552\ttotal: 18.2s\tremaining: 258ms\n",
      "986:\tlearn: 46347.9981207\ttotal: 18.2s\tremaining: 239ms\n",
      "987:\tlearn: 46344.2722893\ttotal: 18.2s\tremaining: 221ms\n",
      "988:\tlearn: 46341.3317678\ttotal: 18.2s\tremaining: 203ms\n",
      "989:\tlearn: 46335.0170397\ttotal: 18.2s\tremaining: 184ms\n",
      "990:\tlearn: 46326.3484910\ttotal: 18.2s\tremaining: 166ms\n",
      "991:\tlearn: 46318.8471482\ttotal: 18.2s\tremaining: 147ms\n",
      "992:\tlearn: 46313.2432409\ttotal: 18.3s\tremaining: 129ms\n",
      "993:\tlearn: 46306.8283981\ttotal: 18.3s\tremaining: 110ms\n",
      "994:\tlearn: 46296.2133682\ttotal: 18.3s\tremaining: 91.9ms\n",
      "995:\tlearn: 46268.0960384\ttotal: 18.3s\tremaining: 73.5ms\n",
      "996:\tlearn: 46263.3804008\ttotal: 18.3s\tremaining: 55.1ms\n",
      "997:\tlearn: 46258.5810848\ttotal: 18.4s\tremaining: 36.9ms\n",
      "998:\tlearn: 46241.9051614\ttotal: 18.4s\tremaining: 18.5ms\n",
      "999:\tlearn: 46234.4716846\ttotal: 18.5s\tremaining: 0us\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from lightgbm import LGBMRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from catboost import CatBoostRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import (RandomForestRegressor, GradientBoostingRegressor, \n",
    "                              AdaBoostRegressor)\n",
    "\n",
    "names = ['Linear Regression', 'Ridge Regression', 'Lasso Regression',\n",
    "         'K Neighbors Regressor', 'Decision Tree Regressor', \n",
    "         'Random Forest Regressor', 'Gradient Boosting Regressor',\n",
    "         'Adaboost Regressor', 'LGBMRegressor', 'XGBRegressor',\n",
    "         'CatBoostRegressor']\n",
    "models = [LinearRegression(), Ridge(), Lasso(),\n",
    "          KNeighborsRegressor(), DecisionTreeRegressor(),\n",
    "          RandomForestRegressor(), GradientBoostingRegressor(), \n",
    "          AdaBoostRegressor(),LGBMRegressor(), \n",
    "          XGBRegressor(),CatBoostRegressor()]\n",
    "\n",
    "#Running all algorithms\n",
    "for name, model in zip(names, models):\n",
    "    input_scores(name, model, X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLLOWING ARE THE TRAINING SCORES: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>R Squared</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Linear Regression</td>\n",
       "      <td>73568.712324</td>\n",
       "      <td>0.086644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ridge Regression</td>\n",
       "      <td>73568.619920</td>\n",
       "      <td>0.086644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Lasso Regression</td>\n",
       "      <td>73568.685131</td>\n",
       "      <td>0.086643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>K Neighbors Regressor</td>\n",
       "      <td>79191.329429</td>\n",
       "      <td>-0.069557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Decision Tree Regressor</td>\n",
       "      <td>109386.191102</td>\n",
       "      <td>-0.956019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Random Forest Regressor</td>\n",
       "      <td>78378.268288</td>\n",
       "      <td>-0.036611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Gradient Boosting Regressor</td>\n",
       "      <td>74144.835057</td>\n",
       "      <td>0.070199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Adaboost Regressor</td>\n",
       "      <td>124507.425167</td>\n",
       "      <td>-1.701734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Linear Regression</td>\n",
       "      <td>73568.712324</td>\n",
       "      <td>0.086644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Ridge Regression</td>\n",
       "      <td>73568.619920</td>\n",
       "      <td>0.086644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Lasso Regression</td>\n",
       "      <td>73568.685131</td>\n",
       "      <td>0.086643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>K Neighbors Regressor</td>\n",
       "      <td>79191.329429</td>\n",
       "      <td>-0.069557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Decision Tree Regressor</td>\n",
       "      <td>109992.254328</td>\n",
       "      <td>-1.096120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Random Forest Regressor</td>\n",
       "      <td>78141.341449</td>\n",
       "      <td>-0.025266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Gradient Boosting Regressor</td>\n",
       "      <td>73834.178782</td>\n",
       "      <td>0.075979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Adaboost Regressor</td>\n",
       "      <td>117252.290194</td>\n",
       "      <td>-2.105796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>LGBMRegressor</td>\n",
       "      <td>73311.006233</td>\n",
       "      <td>0.089150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>XGBRegressor</td>\n",
       "      <td>78830.365810</td>\n",
       "      <td>-0.052153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>CatBoostRegressor</td>\n",
       "      <td>77757.690212</td>\n",
       "      <td>-0.031308</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          Model           RMSE  R Squared\n",
       "0             Linear Regression   73568.712324   0.086644\n",
       "1              Ridge Regression   73568.619920   0.086644\n",
       "2              Lasso Regression   73568.685131   0.086643\n",
       "3         K Neighbors Regressor   79191.329429  -0.069557\n",
       "4       Decision Tree Regressor  109386.191102  -0.956019\n",
       "5       Random Forest Regressor   78378.268288  -0.036611\n",
       "6   Gradient Boosting Regressor   74144.835057   0.070199\n",
       "7            Adaboost Regressor  124507.425167  -1.701734\n",
       "8             Linear Regression   73568.712324   0.086644\n",
       "9              Ridge Regression   73568.619920   0.086644\n",
       "10             Lasso Regression   73568.685131   0.086643\n",
       "11        K Neighbors Regressor   79191.329429  -0.069557\n",
       "12      Decision Tree Regressor  109992.254328  -1.096120\n",
       "13      Random Forest Regressor   78141.341449  -0.025266\n",
       "14  Gradient Boosting Regressor   73834.178782   0.075979\n",
       "15           Adaboost Regressor  117252.290194  -2.105796\n",
       "16                LGBMRegressor   73311.006233   0.089150\n",
       "17                 XGBRegressor   78830.365810  -0.052153\n",
       "18            CatBoostRegressor   77757.690212  -0.031308"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluation = pd.DataFrame({'Model': Model,\n",
    "                           'RMSE': RMSE,\n",
    "                           'R Squared': R_sq})\n",
    "print(\"FOLLOWING ARE THE TRAINING SCORES: \")\n",
    "evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression, Ridge\n",
    "from sklearn.ensemble import GradientBoostingRegressor, StackingRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_models = [\n",
    "    ('lr', LinearRegression()),\n",
    "    ('ridge', Ridge()),\n",
    "    ('gbr', GradientBoostingRegressor()),\n",
    "    ('lgbm', LGBMRegressor())\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002546 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 617\n",
      "[LightGBM] [Info] Number of data points in the train set: 43418, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 39329.732369\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002250 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 620\n",
      "[LightGBM] [Info] Number of data points in the train set: 34734, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 39512.634882\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002266 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 618\n",
      "[LightGBM] [Info] Number of data points in the train set: 34734, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 38964.973455\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002652 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 618\n",
      "[LightGBM] [Info] Number of data points in the train set: 34734, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 39284.240658\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002788 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 614\n",
      "[LightGBM] [Info] Number of data points in the train set: 34735, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 39485.990557\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005114 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 617\n",
      "[LightGBM] [Info] Number of data points in the train set: 34735, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 39400.815748\n"
     ]
    }
   ],
   "source": [
    "# Define the meta-model\n",
    "meta_model = LinearRegression()\n",
    "\n",
    "# Create the Stacking Regressor\n",
    "stacking_model = StackingRegressor(estimators=base_models, final_estimator=meta_model)\n",
    "\n",
    "# Train the stacking model\n",
    "stacking_model.fit(X_train, y_train)\n",
    "\n",
    "# Predict using the stacking model\n",
    "y_pred = stacking_model.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stacking Model Test RMSE: 47725.0494935312\n",
      "Stacking Model Test R^2: 0.2248834755140262\n"
     ]
    }
   ],
   "source": [
    "# Calculate RMSE\n",
    "stacking_rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "print(f'Stacking Model Test RMSE: {stacking_rmse}')\n",
    "\n",
    "# Optionally, print R^2 Score\n",
    "stacking_r2 = stacking_model.score(X_test, y_test)\n",
    "print(f'Stacking Model Test R^2: {stacking_r2}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
